[2024-07-18T08:12:57.974+0000] {processor.py:157} INFO - Started process (PID=180) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:12:57.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:12:57.978+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:12:57.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:12:57.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:12:58.014+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:12:58.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:12:58.030+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:12:58.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:12:58.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-18T08:13:28.477+0000] {processor.py:157} INFO - Started process (PID=594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:13:28.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:13:28.486+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:13:28.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:13:28.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:13:28.582+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:13:28.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:13:28.616+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:13:28.616+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:13:28.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-07-18T08:13:59.215+0000] {processor.py:157} INFO - Started process (PID=619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:13:59.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:13:59.224+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:13:59.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:13:59.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:13:59.314+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:13:59.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:13:59.337+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:13:59.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:13:59.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-07-18T08:14:29.780+0000] {processor.py:157} INFO - Started process (PID=644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:14:29.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:14:29.786+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:14:29.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:14:29.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:14:29.828+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:14:29.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:14:29.840+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:14:29.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:14:29.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-18T08:15:00.289+0000] {processor.py:157} INFO - Started process (PID=669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:15:00.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:15:00.294+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:15:00.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:15:00.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:15:00.340+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:15:00.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:15:00.353+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:15:00.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:15:00.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-18T08:15:30.739+0000] {processor.py:157} INFO - Started process (PID=694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:15:30.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:15:30.741+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:15:30.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:15:30.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:15:30.762+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:15:30.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:15:30.773+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:15:30.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:15:30.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-18T08:16:01.180+0000] {processor.py:157} INFO - Started process (PID=719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:16:01.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:16:01.185+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:16:01.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:16:01.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:16:01.256+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:16:01.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:16:01.288+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:16:01.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:16:01.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-07-18T08:16:31.700+0000] {processor.py:157} INFO - Started process (PID=744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:16:31.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:16:31.704+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:16:31.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:16:31.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:16:31.745+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:16:31.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:16:31.763+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:16:31.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:16:31.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-18T08:17:02.232+0000] {processor.py:157} INFO - Started process (PID=769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:17:02.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:17:02.238+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:17:02.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:17:02.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:17:02.323+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:17:02.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:17:02.364+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:17:02.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:17:02.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-07-18T08:17:32.755+0000] {processor.py:157} INFO - Started process (PID=794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:17:32.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:17:32.759+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:17:32.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:17:32.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:17:32.803+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:17:32.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:17:32.817+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:17:32.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:17:32.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-18T08:18:03.273+0000] {processor.py:157} INFO - Started process (PID=819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:18:03.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:18:03.277+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:18:03.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:18:03.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:18:03.318+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:18:03.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:18:03.330+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:18:03.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:18:03.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-18T08:18:33.693+0000] {processor.py:157} INFO - Started process (PID=844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:18:33.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:18:33.701+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:18:33.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:18:33.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:18:33.776+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:18:33.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:18:33.791+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:18:33.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:18:33.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-18T08:19:04.365+0000] {processor.py:157} INFO - Started process (PID=869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:19:04.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:19:04.371+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:19:04.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:19:04.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:19:04.415+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:19:04.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:19:04.430+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:19:04.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:19:04.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-18T08:19:34.827+0000] {processor.py:157} INFO - Started process (PID=894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:19:34.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:19:34.833+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:19:34.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:19:34.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:19:34.870+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:19:34.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:19:34.883+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:19:34.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:19:34.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-18T08:20:05.278+0000] {processor.py:157} INFO - Started process (PID=919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:20:05.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:20:05.283+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:20:05.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:20:05.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:20:05.330+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:20:05.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:20:05.345+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:20:05.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:20:05.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-18T08:20:35.823+0000] {processor.py:157} INFO - Started process (PID=944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:20:35.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:20:35.828+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:20:35.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:20:35.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:20:35.886+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:20:35.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:20:35.910+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:20:35.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:20:35.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-18T08:21:06.263+0000] {processor.py:157} INFO - Started process (PID=969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:21:06.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:21:06.267+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:21:06.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:21:06.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:21:06.325+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:21:06.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:21:06.341+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:21:06.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:21:06.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-18T08:21:36.708+0000] {processor.py:157} INFO - Started process (PID=994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:21:36.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:21:36.712+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:21:36.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:21:36.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:21:36.768+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:21:36.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:21:36.783+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:21:36.783+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:21:36.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-18T08:22:07.183+0000] {processor.py:157} INFO - Started process (PID=1019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:22:07.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:22:07.187+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:22:07.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:22:07.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:22:07.222+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:22:07.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:22:07.234+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:22:07.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:22:07.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-18T08:22:37.654+0000] {processor.py:157} INFO - Started process (PID=1044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:22:37.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:22:37.662+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:22:37.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:22:37.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:22:37.727+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:22:37.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:22:37.774+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:22:37.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:22:37.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-07-18T08:23:08.179+0000] {processor.py:157} INFO - Started process (PID=1069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:23:08.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:23:08.183+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:23:08.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:23:08.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:23:08.217+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:23:08.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:23:08.230+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:23:08.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:23:08.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-18T08:23:38.675+0000] {processor.py:157} INFO - Started process (PID=1094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:23:38.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:23:38.692+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:23:38.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:23:38.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:23:38.750+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:23:38.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:23:38.766+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:23:38.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:23:38.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-18T08:24:09.210+0000] {processor.py:157} INFO - Started process (PID=1119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:24:09.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:24:09.217+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:24:09.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:24:09.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:24:09.297+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:24:09.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:24:09.320+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:24:09.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:24:09.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-07-18T08:24:39.729+0000] {processor.py:157} INFO - Started process (PID=1144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:24:39.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:24:39.735+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:24:39.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:24:39.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:24:39.764+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:24:39.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:24:39.778+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:24:39.778+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:24:39.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-18T08:25:10.164+0000] {processor.py:157} INFO - Started process (PID=1169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:25:10.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:25:10.168+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:25:10.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:25:10.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:25:10.200+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:25:10.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:25:10.212+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:25:10.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:25:10.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-18T08:25:40.627+0000] {processor.py:157} INFO - Started process (PID=1194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:25:40.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:25:40.632+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:25:40.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:25:40.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:25:40.672+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:25:40.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:25:40.685+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:25:40.685+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:25:40.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-18T08:26:11.065+0000] {processor.py:157} INFO - Started process (PID=1219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:26:11.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:26:11.069+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:26:11.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:26:11.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:26:11.116+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:26:11.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:26:11.130+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:26:11.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:26:11.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-18T08:26:41.583+0000] {processor.py:157} INFO - Started process (PID=1244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:26:41.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:26:41.589+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:26:41.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:26:41.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:26:41.626+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:26:41.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:26:41.639+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:26:41.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:26:41.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-18T08:27:12.023+0000] {processor.py:157} INFO - Started process (PID=1269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:27:12.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:27:12.029+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:27:12.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:27:12.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:27:12.072+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:27:12.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:27:12.087+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:27:12.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:27:12.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-18T08:27:42.448+0000] {processor.py:157} INFO - Started process (PID=1294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:27:42.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:27:42.454+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:27:42.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:27:42.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:27:42.498+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:27:42.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:27:42.511+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:27:42.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:27:42.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-18T08:28:12.955+0000] {processor.py:157} INFO - Started process (PID=1319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:28:12.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:28:12.961+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:28:12.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:28:12.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:28:13.002+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:28:13.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:28:13.016+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:28:13.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:28:13.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-18T08:28:43.354+0000] {processor.py:157} INFO - Started process (PID=1344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:28:43.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:28:43.360+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:28:43.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:28:43.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:28:43.408+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:28:43.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:28:43.421+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:28:43.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:28:43.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-18T08:29:13.683+0000] {processor.py:157} INFO - Started process (PID=1369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:29:13.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:29:13.687+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:29:13.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:29:13.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:29:13.717+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:29:13.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:29:13.727+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:29:13.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:29:13.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T08:29:44.022+0000] {processor.py:157} INFO - Started process (PID=1394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:29:44.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:29:44.028+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:29:44.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:29:44.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:29:44.063+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:29:44.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:29:44.076+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:29:44.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:29:44.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-18T08:30:14.490+0000] {processor.py:157} INFO - Started process (PID=1419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:30:14.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:30:14.497+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:30:14.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:30:14.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:30:14.528+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:30:14.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:30:14.539+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:30:14.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:30:14.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-18T08:30:44.902+0000] {processor.py:157} INFO - Started process (PID=1444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:30:44.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:30:44.907+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:30:44.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:30:44.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:30:44.942+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:30:44.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:30:44.954+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:30:44.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:30:44.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-18T08:31:15.351+0000] {processor.py:157} INFO - Started process (PID=1469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:31:15.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:31:15.355+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:31:15.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:31:15.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:31:15.394+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:31:15.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:31:15.405+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:31:15.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:31:15.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-18T08:31:45.794+0000] {processor.py:157} INFO - Started process (PID=1494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:31:45.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:31:45.800+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:31:45.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:31:45.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:31:45.841+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:31:45.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:31:45.856+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:31:45.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:31:45.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-18T08:32:16.242+0000] {processor.py:157} INFO - Started process (PID=1519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:32:16.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:32:16.245+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:32:16.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:32:16.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:32:16.278+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:32:16.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:32:16.288+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:32:16.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:32:16.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T08:32:46.689+0000] {processor.py:157} INFO - Started process (PID=1544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:32:46.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:32:46.695+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:32:46.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:32:46.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:32:46.736+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:32:46.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:32:46.750+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:32:46.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:32:46.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-18T08:33:17.197+0000] {processor.py:157} INFO - Started process (PID=1569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:33:17.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:33:17.202+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:33:17.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:33:17.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:33:17.239+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:33:17.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:33:17.251+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:33:17.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:33:17.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-18T08:33:47.644+0000] {processor.py:157} INFO - Started process (PID=1594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:33:47.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:33:47.653+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:33:47.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:33:47.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:33:47.700+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:33:47.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:33:47.713+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:33:47.713+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:33:47.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-18T08:34:18.100+0000] {processor.py:157} INFO - Started process (PID=1619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:34:18.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:34:18.104+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:34:18.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:34:18.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:34:18.149+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:34:18.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:34:18.160+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:34:18.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:34:18.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-18T08:34:48.542+0000] {processor.py:157} INFO - Started process (PID=1644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:34:48.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:34:48.550+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:34:48.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:34:48.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:34:48.649+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:34:48.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:34:48.667+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:34:48.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:34:48.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-07-18T08:35:19.112+0000] {processor.py:157} INFO - Started process (PID=1669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:35:19.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:35:19.120+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:35:19.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:35:19.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:35:19.207+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:35:19.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:35:19.222+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:35:19.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:35:19.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-07-18T08:35:49.700+0000] {processor.py:157} INFO - Started process (PID=1694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:35:49.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:35:49.716+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:35:49.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:35:49.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:35:49.775+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:35:49.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:35:49.803+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:35:49.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:35:49.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-18T08:36:20.287+0000] {processor.py:157} INFO - Started process (PID=1719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:36:20.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:36:20.293+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:36:20.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:36:20.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:36:20.371+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:36:20.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:36:20.388+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:36:20.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:36:20.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-18T08:36:50.758+0000] {processor.py:157} INFO - Started process (PID=1744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:36:50.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:36:50.767+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:36:50.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:36:50.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:36:50.844+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:36:50.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:36:50.864+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:36:50.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:36:50.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-18T08:37:21.434+0000] {processor.py:157} INFO - Started process (PID=1769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:37:21.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:37:21.445+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:37:21.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:37:21.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:37:21.543+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:37:21.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:37:21.561+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:37:21.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:37:21.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-07-18T08:37:51.976+0000] {processor.py:157} INFO - Started process (PID=1794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:37:51.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:37:51.983+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:37:51.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:37:51.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:37:52.014+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:37:52.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:37:52.028+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:37:52.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:37:52.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-18T08:38:22.475+0000] {processor.py:157} INFO - Started process (PID=1819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:38:22.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:38:22.481+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:38:22.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:38:22.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:38:22.518+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:38:22.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:38:22.532+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:38:22.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:38:22.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-18T08:38:52.950+0000] {processor.py:157} INFO - Started process (PID=1844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:38:52.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:38:52.955+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:38:52.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:38:52.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:38:52.993+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:38:52.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:38:53.006+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:38:53.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:38:53.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-18T08:39:23.361+0000] {processor.py:157} INFO - Started process (PID=1869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:39:23.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:39:23.365+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:39:23.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:39:23.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:39:23.391+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:39:23.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:39:23.401+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:39:23.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:39:23.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T08:39:53.770+0000] {processor.py:157} INFO - Started process (PID=1894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:39:53.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:39:53.776+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:39:53.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:39:53.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:39:53.815+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:39:53.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:39:53.828+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:39:53.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:39:53.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-18T08:40:24.182+0000] {processor.py:157} INFO - Started process (PID=1919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:40:24.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:40:24.186+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:40:24.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:40:24.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:40:24.260+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:40:24.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:40:24.271+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:40:24.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:40:24.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-18T08:40:54.658+0000] {processor.py:157} INFO - Started process (PID=1944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:40:54.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:40:54.664+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:40:54.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:40:54.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:40:54.698+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:40:54.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:40:54.708+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:40:54.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:40:54.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-18T08:41:25.126+0000] {processor.py:157} INFO - Started process (PID=1969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:41:25.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:41:25.131+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:41:25.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:41:25.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:41:25.178+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:41:25.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:41:25.190+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:41:25.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:41:25.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-18T08:41:55.572+0000] {processor.py:157} INFO - Started process (PID=1994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:41:55.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:41:55.576+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:41:55.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:41:55.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:41:55.617+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:41:55.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:41:55.630+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:41:55.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:41:55.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-18T08:42:26.002+0000] {processor.py:157} INFO - Started process (PID=2019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:42:26.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:42:26.007+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:42:26.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:42:26.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:42:26.048+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:42:26.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:42:26.064+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:42:26.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:42:26.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-18T08:42:56.412+0000] {processor.py:157} INFO - Started process (PID=2044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:42:56.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:42:56.427+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:42:56.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:42:56.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:42:56.466+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:42:56.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:42:56.479+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:42:56.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:42:56.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-18T08:43:26.936+0000] {processor.py:157} INFO - Started process (PID=2069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:43:26.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:43:26.938+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:43:26.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:43:26.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:43:26.964+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:43:26.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:43:26.974+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:43:26.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:43:26.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T08:43:57.375+0000] {processor.py:157} INFO - Started process (PID=2094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:43:57.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:43:57.381+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:43:57.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:43:57.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:43:57.419+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:43:57.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:43:57.431+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:43:57.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:43:57.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-18T08:44:27.867+0000] {processor.py:157} INFO - Started process (PID=2119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:44:27.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:44:27.872+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:44:27.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:44:27.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:44:27.909+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:44:27.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:44:27.920+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:44:27.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:44:27.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-18T08:44:58.322+0000] {processor.py:157} INFO - Started process (PID=2144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:44:58.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:44:58.330+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:44:58.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:44:58.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:44:58.390+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:44:58.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:44:58.409+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:44:58.409+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:44:58.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-18T08:45:28.817+0000] {processor.py:157} INFO - Started process (PID=2169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:45:28.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:45:28.826+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:45:28.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:45:28.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:45:28.882+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:45:28.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:45:28.896+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:45:28.896+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:45:28.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-18T08:45:59.346+0000] {processor.py:157} INFO - Started process (PID=2194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:45:59.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:45:59.352+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:45:59.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:45:59.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:45:59.393+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:45:59.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:45:59.406+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:45:59.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:45:59.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-18T08:46:29.875+0000] {processor.py:157} INFO - Started process (PID=2219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:46:29.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:46:29.886+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:46:29.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:46:29.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:46:30.144+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:46:30.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:46:30.209+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:46:30.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:46:30.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.359 seconds
[2024-07-18T08:47:00.679+0000] {processor.py:157} INFO - Started process (PID=2244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:47:00.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:47:00.693+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:47:00.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:47:00.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:47:00.763+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:47:00.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:47:00.785+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:47:00.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:47:00.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-18T08:47:31.211+0000] {processor.py:157} INFO - Started process (PID=2269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:47:31.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:47:31.215+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:47:31.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:47:31.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:47:31.251+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:47:31.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:47:31.262+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:47:31.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:47:31.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-18T08:48:01.705+0000] {processor.py:157} INFO - Started process (PID=2294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:48:01.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:48:01.710+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:48:01.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:48:01.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:48:01.759+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:48:01.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:48:01.773+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:48:01.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:48:01.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-18T08:48:32.219+0000] {processor.py:157} INFO - Started process (PID=2319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:48:32.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:48:32.226+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:48:32.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:48:32.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:48:32.279+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:48:32.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:48:32.291+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:48:32.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:48:32.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-18T08:49:02.731+0000] {processor.py:157} INFO - Started process (PID=2344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:49:02.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:49:02.738+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:49:02.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:49:02.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:49:02.801+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:49:02.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:49:02.829+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:49:02.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:49:02.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-07-18T08:49:33.306+0000] {processor.py:157} INFO - Started process (PID=2369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:49:33.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:49:33.312+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:49:33.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:49:33.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:49:33.375+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:49:33.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:49:33.390+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:49:33.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:49:33.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-18T08:50:03.820+0000] {processor.py:157} INFO - Started process (PID=2394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:50:03.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:50:03.843+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:50:03.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:50:03.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:50:03.893+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:50:03.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:50:03.906+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:50:03.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:50:03.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-18T08:50:34.315+0000] {processor.py:157} INFO - Started process (PID=2419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:50:34.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:50:34.321+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:50:34.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:50:34.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:50:34.350+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:50:34.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:50:34.360+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:50:34.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:50:34.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T08:51:04.782+0000] {processor.py:157} INFO - Started process (PID=2444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:51:04.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:51:04.787+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:51:04.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:51:04.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:51:04.828+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:51:04.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:51:04.841+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:51:04.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:51:04.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-18T08:51:35.258+0000] {processor.py:157} INFO - Started process (PID=2469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:51:35.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:51:35.269+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:51:35.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:51:35.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:51:35.395+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:51:35.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:51:35.442+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:51:35.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:51:35.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.212 seconds
[2024-07-18T08:52:05.833+0000] {processor.py:157} INFO - Started process (PID=2494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:52:05.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:52:05.838+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:52:05.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:52:05.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:52:05.866+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:52:05.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:52:05.879+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:52:05.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:52:05.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T08:52:36.283+0000] {processor.py:157} INFO - Started process (PID=2519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:52:36.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:52:36.292+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:52:36.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:52:36.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:52:36.353+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:52:36.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:52:36.365+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:52:36.365+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:52:36.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-18T08:53:06.807+0000] {processor.py:157} INFO - Started process (PID=2544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:53:06.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:53:06.813+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:53:06.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:53:06.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:53:06.839+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:53:06.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:53:06.849+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:53:06.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:53:06.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T08:53:37.214+0000] {processor.py:157} INFO - Started process (PID=2569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:53:37.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:53:37.229+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:53:37.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:53:37.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:53:37.287+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:53:37.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:53:37.302+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:53:37.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:53:37.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-18T08:54:07.738+0000] {processor.py:157} INFO - Started process (PID=2594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:54:07.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:54:07.743+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:54:07.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:54:07.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:54:07.775+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:54:07.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:54:07.784+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:54:07.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:54:07.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-18T08:54:38.130+0000] {processor.py:157} INFO - Started process (PID=2619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:54:38.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:54:38.132+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:54:38.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:54:38.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:54:38.168+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:54:38.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:54:38.185+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:54:38.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:54:38.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-18T08:55:08.598+0000] {processor.py:157} INFO - Started process (PID=2644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:55:08.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:55:08.603+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:55:08.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:55:08.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:55:08.635+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:55:08.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:55:08.647+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:55:08.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:55:08.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-18T08:55:39.075+0000] {processor.py:157} INFO - Started process (PID=2669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:55:39.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:55:39.083+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:55:39.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:55:39.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:55:39.131+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:55:39.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:55:39.149+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:55:39.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:55:39.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-18T08:56:09.640+0000] {processor.py:157} INFO - Started process (PID=2694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:56:09.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:56:09.648+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:56:09.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:56:09.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:56:09.689+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:56:09.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:56:09.702+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:56:09.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:56:09.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-18T08:56:40.112+0000] {processor.py:157} INFO - Started process (PID=2719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:56:40.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:56:40.120+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:56:40.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:56:40.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:56:40.179+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:56:40.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:56:40.193+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:56:40.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:56:40.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-18T08:57:10.906+0000] {processor.py:157} INFO - Started process (PID=2744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:57:10.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:57:10.919+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:57:10.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:57:10.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:57:11.018+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:57:11.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:57:11.047+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:57:11.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:57:11.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.183 seconds
[2024-07-18T08:57:41.683+0000] {processor.py:157} INFO - Started process (PID=2769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:57:41.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:57:41.692+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:57:41.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:57:41.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:57:41.869+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:57:41.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:57:41.883+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:57:41.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:57:41.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.224 seconds
[2024-07-18T08:58:12.267+0000] {processor.py:157} INFO - Started process (PID=2794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:58:12.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:58:12.271+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:58:12.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:58:12.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:58:12.306+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:58:12.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:58:12.317+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:58:12.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:58:12.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-18T08:58:42.755+0000] {processor.py:157} INFO - Started process (PID=2819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:58:42.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:58:42.758+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:58:42.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:58:42.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:58:42.792+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:58:42.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:58:42.802+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:58:42.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:58:42.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-18T08:59:13.241+0000] {processor.py:157} INFO - Started process (PID=2844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:59:13.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:59:13.246+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:59:13.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:59:13.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:59:13.304+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:59:13.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:59:13.317+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:59:13.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:59:13.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-18T08:59:43.741+0000] {processor.py:157} INFO - Started process (PID=2869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:59:43.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T08:59:43.750+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:59:43.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:59:43.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T08:59:43.815+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:59:43.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:59:43.828+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:59:43.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T08:59:43.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-18T09:00:14.233+0000] {processor.py:157} INFO - Started process (PID=2894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:00:14.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:00:14.236+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:00:14.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:00:14.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:00:14.265+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:00:14.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:00:14.274+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:00:14.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:00:14.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T09:00:44.698+0000] {processor.py:157} INFO - Started process (PID=2919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:00:44.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:00:44.705+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:00:44.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:00:44.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:00:44.750+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:00:44.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:00:44.762+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:00:44.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:00:44.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-18T09:01:15.221+0000] {processor.py:157} INFO - Started process (PID=2944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:01:15.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:01:15.225+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:01:15.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:01:15.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:01:15.251+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:01:15.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:01:15.261+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:01:15.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:01:15.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T09:01:45.680+0000] {processor.py:157} INFO - Started process (PID=2969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:01:45.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:01:45.685+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:01:45.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:01:45.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:01:45.721+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:01:45.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:01:45.734+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:01:45.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:01:45.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-18T09:02:16.381+0000] {processor.py:157} INFO - Started process (PID=2994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:02:16.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:02:16.387+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:02:16.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:02:16.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:02:16.441+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:02:16.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:02:16.455+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:02:16.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:02:16.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-18T09:02:46.863+0000] {processor.py:157} INFO - Started process (PID=3019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:02:46.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:02:46.866+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:02:46.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:02:46.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:02:46.897+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:02:46.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:02:46.907+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:02:46.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:02:46.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T09:03:17.343+0000] {processor.py:157} INFO - Started process (PID=3044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:03:17.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:03:17.349+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:03:17.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:03:17.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:03:17.399+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:03:17.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:03:17.416+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:03:17.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:03:17.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-18T09:03:47.823+0000] {processor.py:157} INFO - Started process (PID=3069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:03:47.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:03:47.826+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:03:47.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:03:47.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:03:47.854+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:03:47.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:03:47.866+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:03:47.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:03:47.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T09:04:18.349+0000] {processor.py:157} INFO - Started process (PID=3094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:04:18.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:04:18.354+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:04:18.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:04:18.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:04:18.402+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:04:18.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:04:18.414+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:04:18.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:04:18.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-18T09:04:48.836+0000] {processor.py:157} INFO - Started process (PID=3119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:04:48.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:04:48.842+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:04:48.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:04:48.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:04:48.885+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:04:48.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:04:48.900+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:04:48.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:04:48.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-18T09:05:19.316+0000] {processor.py:157} INFO - Started process (PID=3144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:05:19.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:05:19.321+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:05:19.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:05:19.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:05:19.352+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:05:19.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:05:19.365+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:05:19.365+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:05:19.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-18T09:05:49.748+0000] {processor.py:157} INFO - Started process (PID=3169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:05:49.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:05:49.752+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:05:49.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:05:49.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:05:49.779+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:05:49.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:05:49.788+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:05:49.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:05:49.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T09:06:20.240+0000] {processor.py:157} INFO - Started process (PID=3194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:06:20.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:06:20.246+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:06:20.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:06:20.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:06:20.296+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:06:20.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:06:20.310+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:06:20.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:06:20.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-18T09:06:50.716+0000] {processor.py:157} INFO - Started process (PID=3219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:06:50.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:06:50.721+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:06:50.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:06:50.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:06:50.754+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:06:50.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:06:50.763+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:06:50.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:06:50.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-18T09:07:21.184+0000] {processor.py:157} INFO - Started process (PID=3244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:07:21.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:07:21.206+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:07:21.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:07:21.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:07:21.263+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:07:21.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:07:21.288+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:07:21.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:07:21.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-07-18T09:07:51.700+0000] {processor.py:157} INFO - Started process (PID=3269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:07:51.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:07:51.707+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:07:51.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:07:51.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:07:51.769+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:07:51.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:07:51.785+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:07:51.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:07:51.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-18T09:08:22.164+0000] {processor.py:157} INFO - Started process (PID=3294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:08:22.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:08:22.169+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:08:22.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:08:22.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:08:22.232+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:08:22.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:08:22.245+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:08:22.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:08:22.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-18T09:08:52.660+0000] {processor.py:157} INFO - Started process (PID=3319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:08:52.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:08:52.664+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:08:52.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:08:52.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:08:52.697+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:08:52.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:08:52.707+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:08:52.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:08:52.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-18T09:09:23.095+0000] {processor.py:157} INFO - Started process (PID=3344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:09:23.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:09:23.102+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:09:23.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:09:23.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:09:23.149+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:09:23.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:09:23.161+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:09:23.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:09:23.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-18T09:09:53.645+0000] {processor.py:157} INFO - Started process (PID=3369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:09:53.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:09:53.662+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:09:53.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:09:53.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:09:53.734+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:09:53.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:09:53.747+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:09:53.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:09:53.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-18T09:10:24.194+0000] {processor.py:157} INFO - Started process (PID=3394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:10:24.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:10:24.200+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:10:24.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:10:24.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:10:24.239+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:10:24.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:10:24.252+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:10:24.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:10:24.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-18T09:10:54.595+0000] {processor.py:157} INFO - Started process (PID=3419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:10:54.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:10:54.597+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:10:54.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:10:54.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:10:54.620+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:10:54.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:10:54.629+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:10:54.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:10:54.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-18T09:11:25.087+0000] {processor.py:157} INFO - Started process (PID=3444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:11:25.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:11:25.095+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:11:25.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:11:25.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:11:25.167+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:11:25.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:11:25.179+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:11:25.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:11:25.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-07-18T09:11:55.655+0000] {processor.py:157} INFO - Started process (PID=3469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:11:55.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:11:55.671+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:11:55.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:11:55.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:11:55.727+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:11:55.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:11:55.741+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:11:55.741+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:11:55.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-18T09:12:26.181+0000] {processor.py:157} INFO - Started process (PID=3494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:12:26.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:12:26.187+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:12:26.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:12:26.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:12:26.235+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:12:26.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:12:26.251+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:12:26.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:12:26.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-18T09:12:56.686+0000] {processor.py:157} INFO - Started process (PID=3519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:12:56.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:12:56.691+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:12:56.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:12:56.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:12:56.731+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:12:56.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:12:56.743+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:12:56.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:12:56.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-18T09:13:27.149+0000] {processor.py:157} INFO - Started process (PID=3544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:13:27.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:13:27.154+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:13:27.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:13:27.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:13:27.191+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:13:27.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:13:27.209+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:13:27.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:13:27.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-18T09:13:57.658+0000] {processor.py:157} INFO - Started process (PID=3569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:13:57.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:13:57.664+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:13:57.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:13:57.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:13:57.710+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:13:57.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:13:57.721+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:13:57.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:13:57.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-18T09:14:28.054+0000] {processor.py:157} INFO - Started process (PID=3594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:14:28.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:14:28.060+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:14:28.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:14:28.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:14:28.088+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:14:28.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:14:28.101+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:14:28.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:14:28.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-18T09:14:58.473+0000] {processor.py:157} INFO - Started process (PID=3619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:14:58.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:14:58.488+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:14:58.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:14:58.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:14:58.536+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:14:58.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:14:58.547+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:14:58.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:14:58.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-18T09:15:28.967+0000] {processor.py:157} INFO - Started process (PID=3644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:15:28.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:15:28.975+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:15:28.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:15:28.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:15:29.006+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:15:29.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:15:29.017+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:15:29.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:15:29.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-18T09:15:59.459+0000] {processor.py:157} INFO - Started process (PID=3669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:15:59.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:15:59.464+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:15:59.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:15:59.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:15:59.507+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:15:59.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:15:59.517+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:15:59.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:15:59.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-18T09:16:29.846+0000] {processor.py:157} INFO - Started process (PID=3694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:16:29.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:16:29.849+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:16:29.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:16:29.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:16:29.879+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:16:29.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:16:29.889+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:16:29.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:16:29.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T09:17:00.258+0000] {processor.py:157} INFO - Started process (PID=3719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:17:00.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:17:00.260+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:17:00.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:17:00.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:17:00.293+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:17:00.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:17:00.308+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:17:00.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:17:00.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-18T09:17:30.638+0000] {processor.py:157} INFO - Started process (PID=3744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:17:30.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:17:30.640+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:17:30.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:17:30.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:17:30.666+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:17:30.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:17:30.675+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:17:30.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:17:30.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-18T09:18:01.040+0000] {processor.py:157} INFO - Started process (PID=3769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:18:01.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:18:01.046+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:18:01.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:18:01.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:18:01.087+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:18:01.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:18:01.099+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:18:01.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:18:01.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-18T09:18:31.525+0000] {processor.py:157} INFO - Started process (PID=3794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:18:31.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:18:31.528+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:18:31.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:18:31.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:18:31.559+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:18:31.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:18:31.568+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:18:31.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:18:31.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T09:19:01.932+0000] {processor.py:157} INFO - Started process (PID=3819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:19:01.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:19:01.935+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:19:01.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:19:01.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:19:01.971+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:19:01.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:19:01.982+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:19:01.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:19:01.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-18T09:19:32.341+0000] {processor.py:157} INFO - Started process (PID=3844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:19:32.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:19:32.345+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:19:32.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:19:32.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:19:32.377+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:19:32.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:19:32.390+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:19:32.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:19:32.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-18T09:20:02.783+0000] {processor.py:157} INFO - Started process (PID=3869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:20:02.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:20:02.786+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:20:02.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:20:02.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:20:02.816+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:20:02.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:20:02.828+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:20:02.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:20:02.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T09:20:33.188+0000] {processor.py:157} INFO - Started process (PID=3894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:20:33.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:20:33.190+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:20:33.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:20:33.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:20:33.217+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:20:33.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:20:33.227+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:20:33.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:20:33.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T09:21:03.602+0000] {processor.py:157} INFO - Started process (PID=3919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:21:03.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:21:03.606+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:21:03.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:21:03.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:21:03.646+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:21:03.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:21:03.659+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:21:03.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:21:03.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-18T09:21:34.042+0000] {processor.py:157} INFO - Started process (PID=3944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:21:34.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:21:34.046+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:21:34.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:21:34.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:21:34.072+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:21:34.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:21:34.081+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:21:34.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:21:34.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T09:22:04.455+0000] {processor.py:157} INFO - Started process (PID=3969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:22:04.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:22:04.459+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:22:04.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:22:04.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:22:04.489+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:22:04.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:22:04.498+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:22:04.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:22:04.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T09:22:34.923+0000] {processor.py:157} INFO - Started process (PID=3994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:22:34.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:22:34.928+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:22:34.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:22:34.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:22:34.961+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:22:34.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:22:34.970+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:22:34.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:22:34.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T09:23:05.404+0000] {processor.py:157} INFO - Started process (PID=4019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:23:05.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:23:05.408+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:23:05.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:23:05.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:23:05.441+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:23:05.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:23:05.455+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:23:05.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:23:05.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-18T09:23:35.898+0000] {processor.py:157} INFO - Started process (PID=4044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:23:35.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:23:35.902+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:23:35.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:23:35.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:23:35.929+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:23:35.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:23:35.939+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:23:35.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:23:35.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T09:24:06.306+0000] {processor.py:157} INFO - Started process (PID=4069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:24:06.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:24:06.310+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:24:06.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:24:06.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:24:06.338+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:24:06.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:24:06.350+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:24:06.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:24:06.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T09:24:36.709+0000] {processor.py:157} INFO - Started process (PID=4094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:24:36.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:24:36.711+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:24:36.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:24:36.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:24:36.734+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:24:36.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:24:36.745+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:24:36.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:24:36.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-18T09:25:07.423+0000] {processor.py:157} INFO - Started process (PID=4119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:25:07.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:25:07.430+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:25:07.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:25:07.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:25:07.480+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:25:07.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:25:07.493+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:25:07.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:25:07.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-18T09:25:37.898+0000] {processor.py:157} INFO - Started process (PID=4144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:25:37.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:25:37.902+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:25:37.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:25:37.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:25:37.931+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:25:37.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:25:37.941+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:25:37.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:25:37.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T09:26:08.282+0000] {processor.py:157} INFO - Started process (PID=4169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:26:08.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:26:08.285+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:26:08.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:26:08.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:26:08.311+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:26:08.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:26:08.320+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:26:08.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:26:08.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T09:26:38.721+0000] {processor.py:157} INFO - Started process (PID=4194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:26:38.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:26:38.723+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:26:38.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:26:38.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:26:38.752+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:26:38.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:26:38.761+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:26:38.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:26:38.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T09:27:09.160+0000] {processor.py:157} INFO - Started process (PID=4219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:27:09.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:27:09.163+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:27:09.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:27:09.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:27:09.189+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:27:09.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:27:09.199+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:27:09.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:27:09.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T09:27:39.596+0000] {processor.py:157} INFO - Started process (PID=4244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:27:39.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:27:39.600+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:27:39.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:27:39.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:27:39.628+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:27:39.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:27:39.638+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:27:39.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:27:39.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T09:28:10.036+0000] {processor.py:157} INFO - Started process (PID=4269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:28:10.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:28:10.040+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:28:10.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:28:10.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:28:10.068+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:28:10.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:28:10.077+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:28:10.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:28:10.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T09:28:40.467+0000] {processor.py:157} INFO - Started process (PID=4294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:28:40.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:28:40.472+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:28:40.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:28:40.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:28:40.498+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:28:40.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:28:40.507+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:28:40.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:28:40.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T09:29:10.903+0000] {processor.py:157} INFO - Started process (PID=4319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:29:10.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:29:10.906+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:29:10.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:29:10.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:29:10.932+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:29:10.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:29:10.942+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:29:10.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:29:10.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T09:29:41.302+0000] {processor.py:157} INFO - Started process (PID=4344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:29:41.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:29:41.306+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:29:41.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:29:41.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:29:41.334+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:29:41.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:29:41.343+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:29:41.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:29:41.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T09:30:11.786+0000] {processor.py:157} INFO - Started process (PID=4369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:30:11.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:30:11.792+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:30:11.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:30:11.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:30:11.830+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:30:11.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:30:11.843+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:30:11.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:30:11.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-18T09:30:42.196+0000] {processor.py:157} INFO - Started process (PID=4394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:30:42.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:30:42.199+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:30:42.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:30:42.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:30:42.226+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:30:42.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:30:42.236+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:30:42.235+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:30:42.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T09:31:12.529+0000] {processor.py:157} INFO - Started process (PID=4419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:31:12.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:31:12.532+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:31:12.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:31:12.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:31:12.561+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:31:12.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:31:12.571+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:31:12.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:31:12.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T09:31:42.977+0000] {processor.py:157} INFO - Started process (PID=4444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:31:42.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:31:42.980+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:31:42.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:31:42.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:31:43.005+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:31:43.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:31:43.015+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:31:43.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:31:43.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T09:32:13.382+0000] {processor.py:157} INFO - Started process (PID=4469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:32:13.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:32:13.385+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:32:13.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:32:13.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:32:13.416+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:32:13.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:32:13.426+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:32:13.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:32:13.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T09:32:43.780+0000] {processor.py:157} INFO - Started process (PID=4494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:32:43.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:32:43.783+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:32:43.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:32:43.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:32:43.810+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:32:43.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:32:43.820+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:32:43.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:32:43.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T09:33:14.254+0000] {processor.py:157} INFO - Started process (PID=4519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:33:14.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:33:14.258+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:33:14.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:33:14.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:33:14.284+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:33:14.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:33:14.294+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:33:14.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:33:14.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T09:33:44.649+0000] {processor.py:157} INFO - Started process (PID=4544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:33:44.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:33:44.652+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:33:44.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:33:44.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:33:44.689+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:33:44.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:33:44.701+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:33:44.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:33:44.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-18T09:34:15.077+0000] {processor.py:157} INFO - Started process (PID=4569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:34:15.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:34:15.079+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:34:15.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:34:15.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:34:15.103+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:34:15.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:34:15.112+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:34:15.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:34:15.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-18T09:34:45.459+0000] {processor.py:157} INFO - Started process (PID=4594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:34:45.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:34:45.461+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:34:45.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:34:45.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:34:45.482+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:34:45.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:34:45.494+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:34:45.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:34:45.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-18T09:35:15.916+0000] {processor.py:157} INFO - Started process (PID=4619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:35:15.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:35:15.918+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:35:15.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:35:15.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:35:15.945+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:35:15.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:35:15.955+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:35:15.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:35:15.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T09:35:46.445+0000] {processor.py:157} INFO - Started process (PID=4644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:35:46.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:35:46.452+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:35:46.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:35:46.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:35:46.513+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:35:46.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:35:46.525+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:35:46.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:35:46.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-18T09:36:16.884+0000] {processor.py:157} INFO - Started process (PID=4669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:36:16.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:36:16.887+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:36:16.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:36:16.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:36:16.907+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:36:16.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:36:16.922+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:36:16.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:36:16.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T09:36:47.312+0000] {processor.py:157} INFO - Started process (PID=4694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:36:47.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:36:47.314+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:36:47.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:36:47.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:36:47.338+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:36:47.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:36:47.347+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:36:47.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:36:47.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-18T09:37:17.656+0000] {processor.py:157} INFO - Started process (PID=4719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:37:17.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:37:17.659+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:37:17.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:37:17.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:37:17.686+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:37:17.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:37:17.698+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:37:17.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:37:17.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T09:37:48.110+0000] {processor.py:157} INFO - Started process (PID=4744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:37:48.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:37:48.114+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:37:48.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:37:48.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:37:48.143+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:37:48.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:37:48.154+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:37:48.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:37:48.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T09:38:18.549+0000] {processor.py:157} INFO - Started process (PID=4769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:38:18.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:38:18.555+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:38:18.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:38:18.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:38:18.592+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:38:18.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:38:18.603+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:38:18.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:38:18.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-18T09:38:48.990+0000] {processor.py:157} INFO - Started process (PID=4794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:38:48.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:38:48.994+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:38:48.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:38:49.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:38:49.024+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:38:49.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:38:49.036+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:38:49.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:38:49.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T09:39:19.459+0000] {processor.py:157} INFO - Started process (PID=4819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:39:19.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:39:19.463+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:39:19.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:39:19.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:39:19.492+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:39:19.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:39:19.502+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:39:19.502+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:39:19.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T09:39:49.852+0000] {processor.py:157} INFO - Started process (PID=4844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:39:49.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:39:49.858+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:39:49.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:39:49.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:39:49.885+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:39:49.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:39:49.894+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:39:49.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:39:49.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T09:40:20.241+0000] {processor.py:157} INFO - Started process (PID=4869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:40:20.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:40:20.245+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:40:20.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:40:20.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:40:20.270+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:40:20.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:40:20.279+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:40:20.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:40:20.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T09:40:50.634+0000] {processor.py:157} INFO - Started process (PID=4894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:40:50.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:40:50.637+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:40:50.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:40:50.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:40:50.661+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:40:50.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:40:50.671+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:40:50.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:40:50.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T09:41:21.088+0000] {processor.py:157} INFO - Started process (PID=4919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:41:21.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:41:21.091+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:41:21.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:41:21.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:41:21.117+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:41:21.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:41:21.126+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:41:21.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:41:21.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T09:41:51.549+0000] {processor.py:157} INFO - Started process (PID=4944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:41:51.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:41:51.558+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:41:51.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:41:51.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:41:51.595+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:41:51.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:41:51.607+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:41:51.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:41:51.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-18T09:42:22.041+0000] {processor.py:157} INFO - Started process (PID=4969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:42:22.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:42:22.046+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:42:22.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:42:22.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:42:22.087+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:42:22.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:42:22.112+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:42:22.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:42:22.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-18T09:42:52.533+0000] {processor.py:157} INFO - Started process (PID=4994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:42:52.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:42:52.535+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:42:52.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:42:52.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:42:52.564+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:42:52.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:42:52.574+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:42:52.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:42:52.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T09:43:22.962+0000] {processor.py:157} INFO - Started process (PID=5019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:43:22.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:43:22.965+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:43:22.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:43:22.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:43:22.991+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:43:22.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:43:23.001+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:43:23.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:43:23.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T09:43:53.450+0000] {processor.py:157} INFO - Started process (PID=5044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:43:53.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:43:53.455+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:43:53.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:43:53.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:43:53.484+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:43:53.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:43:53.495+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:43:53.495+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:43:53.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-18T09:44:23.931+0000] {processor.py:157} INFO - Started process (PID=5069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:44:23.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:44:23.933+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:44:23.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:44:23.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:44:23.962+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:44:23.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:44:23.974+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:44:23.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:44:23.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T09:44:54.389+0000] {processor.py:157} INFO - Started process (PID=5094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:44:54.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:44:54.393+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:44:54.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:44:54.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:44:54.419+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:44:54.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:44:54.429+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:44:54.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:44:54.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T09:45:24.797+0000] {processor.py:157} INFO - Started process (PID=5119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:45:24.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:45:24.799+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:45:24.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:45:24.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:45:24.829+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:45:24.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:45:24.839+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:45:24.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:45:24.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T09:45:55.279+0000] {processor.py:157} INFO - Started process (PID=5144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:45:55.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:45:55.282+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:45:55.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:45:55.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:45:55.309+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:45:55.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:45:55.319+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:45:55.319+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:45:55.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T09:46:25.705+0000] {processor.py:157} INFO - Started process (PID=5169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:46:25.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:46:25.710+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:46:25.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:46:25.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:46:25.737+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:46:25.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:46:25.747+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:46:25.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:46:25.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T09:46:56.177+0000] {processor.py:157} INFO - Started process (PID=5194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:46:56.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:46:56.182+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:46:56.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:46:56.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:46:56.220+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:46:56.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:46:56.233+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:46:56.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:46:56.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-18T09:47:26.666+0000] {processor.py:157} INFO - Started process (PID=5219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:47:26.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:47:26.669+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:47:26.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:47:26.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:47:26.698+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:47:26.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:47:26.708+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:47:26.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:47:26.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T09:47:57.092+0000] {processor.py:157} INFO - Started process (PID=5244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:47:57.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:47:57.096+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:47:57.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:47:57.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:47:57.125+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:47:57.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:47:57.138+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:47:57.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:47:57.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T09:48:27.553+0000] {processor.py:157} INFO - Started process (PID=5269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:48:27.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:48:27.556+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:48:27.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:48:27.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:48:27.585+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:48:27.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:48:27.596+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:48:27.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:48:27.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-18T09:48:57.988+0000] {processor.py:157} INFO - Started process (PID=5294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:48:57.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:48:57.990+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:48:57.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:48:57.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:48:58.014+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:48:58.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:48:58.023+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:48:58.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:48:58.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-18T09:49:28.429+0000] {processor.py:157} INFO - Started process (PID=5319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:49:28.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:49:28.433+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:49:28.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:49:28.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:49:28.459+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:49:28.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:49:28.469+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:49:28.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:49:28.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T09:49:58.882+0000] {processor.py:157} INFO - Started process (PID=5344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:49:58.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:49:58.885+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:49:58.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:49:58.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:49:58.912+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:49:58.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:49:58.922+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:49:58.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:49:58.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T09:50:29.300+0000] {processor.py:157} INFO - Started process (PID=5369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:50:29.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:50:29.308+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:50:29.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:50:29.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:50:29.337+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:50:29.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:50:29.351+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:50:29.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:50:29.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-18T09:50:59.795+0000] {processor.py:157} INFO - Started process (PID=5394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:50:59.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:50:59.798+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:50:59.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:50:59.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:50:59.826+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:50:59.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:50:59.836+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:50:59.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:50:59.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T09:51:30.276+0000] {processor.py:157} INFO - Started process (PID=5419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:51:30.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:51:30.278+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:51:30.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:51:30.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:51:30.303+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:51:30.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:51:30.313+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:51:30.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:51:30.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-18T09:52:00.731+0000] {processor.py:157} INFO - Started process (PID=5444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:52:00.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:52:00.734+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:52:00.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:52:00.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:52:00.766+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:52:00.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:52:00.777+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:52:00.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:52:00.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T09:52:31.156+0000] {processor.py:157} INFO - Started process (PID=5469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:52:31.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:52:31.158+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:52:31.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:52:31.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:52:31.182+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:52:31.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:52:31.191+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:52:31.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:52:31.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-18T09:53:01.648+0000] {processor.py:157} INFO - Started process (PID=5494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:53:01.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:53:01.652+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:53:01.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:53:01.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:53:01.689+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:53:01.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:53:01.701+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:53:01.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:53:01.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-18T09:53:32.158+0000] {processor.py:157} INFO - Started process (PID=5519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:53:32.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:53:32.162+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:53:32.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:53:32.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:53:32.191+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:53:32.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:53:32.205+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:53:32.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:53:32.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T09:54:02.579+0000] {processor.py:157} INFO - Started process (PID=5544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:54:02.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:54:02.582+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:54:02.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:54:02.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:54:02.613+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:54:02.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:54:02.632+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:54:02.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:54:02.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-18T09:54:33.056+0000] {processor.py:157} INFO - Started process (PID=5569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:54:33.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:54:33.061+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:54:33.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:54:33.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:54:33.094+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:54:33.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:54:33.104+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:54:33.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:54:33.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-18T09:55:03.462+0000] {processor.py:157} INFO - Started process (PID=5594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:55:03.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:55:03.465+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:55:03.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:55:03.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:55:03.492+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:55:03.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:55:03.505+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:55:03.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:55:03.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T09:55:33.949+0000] {processor.py:157} INFO - Started process (PID=5619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:55:33.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:55:33.954+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:55:33.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:55:33.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:55:33.995+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:55:33.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:55:34.010+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:55:34.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:55:34.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-18T09:56:04.461+0000] {processor.py:157} INFO - Started process (PID=5644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:56:04.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:56:04.470+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:56:04.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:56:04.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:56:04.551+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:56:04.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:56:04.570+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:56:04.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:56:04.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-07-18T09:56:35.079+0000] {processor.py:157} INFO - Started process (PID=5669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:56:35.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:56:35.085+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:56:35.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:56:35.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:56:35.139+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:56:35.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:56:35.156+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:56:35.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:56:35.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-18T09:57:05.553+0000] {processor.py:157} INFO - Started process (PID=5694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:57:05.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:57:05.579+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:57:05.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:57:05.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:57:05.652+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:57:05.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:57:05.667+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:57:05.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:57:05.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-07-18T09:57:36.112+0000] {processor.py:157} INFO - Started process (PID=5719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:57:36.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:57:36.128+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:57:36.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:57:36.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:57:36.174+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:57:36.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:57:36.188+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:57:36.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:57:36.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-18T09:58:06.596+0000] {processor.py:157} INFO - Started process (PID=5744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:58:06.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:58:06.603+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:58:06.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:58:06.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:58:06.643+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:58:06.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:58:06.656+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:58:06.656+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:58:06.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-18T09:58:37.089+0000] {processor.py:157} INFO - Started process (PID=5769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:58:37.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:58:37.093+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:58:37.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:58:37.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:58:37.124+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:58:37.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:58:37.137+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:58:37.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:58:37.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-18T09:59:07.482+0000] {processor.py:157} INFO - Started process (PID=5794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:59:07.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:59:07.485+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:59:07.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:59:07.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:59:07.517+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:59:07.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:59:07.529+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:59:07.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:59:07.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-18T09:59:37.941+0000] {processor.py:157} INFO - Started process (PID=5819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:59:37.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T09:59:37.945+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:59:37.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:59:37.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T09:59:37.983+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:59:37.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:59:37.996+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:59:37.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T09:59:38.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-18T10:00:08.374+0000] {processor.py:157} INFO - Started process (PID=5844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:00:08.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:00:08.378+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:00:08.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:00:08.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:00:08.404+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:00:08.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:00:08.414+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:00:08.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:00:08.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T10:00:38.758+0000] {processor.py:157} INFO - Started process (PID=5869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:00:38.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:00:38.762+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:00:38.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:00:38.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:00:38.794+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:00:38.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:00:38.805+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:00:38.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:00:38.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-18T10:01:09.247+0000] {processor.py:157} INFO - Started process (PID=5894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:01:09.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:01:09.252+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:01:09.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:01:09.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:01:09.286+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:01:09.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:01:09.300+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:01:09.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:01:09.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-18T10:01:39.697+0000] {processor.py:157} INFO - Started process (PID=5919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:01:39.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:01:39.702+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:01:39.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:01:39.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:01:39.738+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:01:39.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:01:39.751+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:01:39.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:01:39.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-18T10:02:10.166+0000] {processor.py:157} INFO - Started process (PID=5944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:02:10.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:02:10.169+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:02:10.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:02:10.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:02:10.195+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:02:10.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:02:10.209+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:02:10.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:02:10.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T10:02:40.518+0000] {processor.py:157} INFO - Started process (PID=5969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:02:40.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:02:40.520+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:02:40.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:02:40.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:02:40.543+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:02:40.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:02:40.554+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:02:40.554+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:02:40.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-18T10:03:10.961+0000] {processor.py:157} INFO - Started process (PID=5994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:03:10.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:03:10.963+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:03:10.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:03:10.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:03:10.992+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:03:10.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:03:11.002+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:03:11.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:03:11.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T10:03:41.383+0000] {processor.py:157} INFO - Started process (PID=6019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:03:41.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:03:41.387+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:03:41.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:03:41.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:03:41.414+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:03:41.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:03:41.424+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:03:41.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:03:41.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T10:04:11.821+0000] {processor.py:157} INFO - Started process (PID=6044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:04:11.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:04:11.823+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:04:11.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:04:11.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:04:11.854+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:04:11.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:04:11.864+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:04:11.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:04:11.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T10:04:42.282+0000] {processor.py:157} INFO - Started process (PID=6069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:04:42.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:04:42.286+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:04:42.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:04:42.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:04:42.312+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:04:42.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:04:42.322+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:04:42.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:04:42.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T10:05:12.705+0000] {processor.py:157} INFO - Started process (PID=6094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:05:12.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:05:12.710+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:05:12.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:05:12.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:05:12.737+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:05:12.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:05:12.748+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:05:12.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:05:12.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T10:05:43.113+0000] {processor.py:157} INFO - Started process (PID=6119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:05:43.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:05:43.118+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:05:43.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:05:43.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:05:43.178+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:05:43.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:05:43.192+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:05:43.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:05:43.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-18T10:06:13.601+0000] {processor.py:157} INFO - Started process (PID=6144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:06:13.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:06:13.603+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:06:13.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:06:13.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:06:13.639+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:06:13.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:06:13.663+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:06:13.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:06:13.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-18T10:06:44.122+0000] {processor.py:157} INFO - Started process (PID=6169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:06:44.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:06:44.128+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:06:44.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:06:44.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:06:44.180+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:06:44.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:06:44.195+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:06:44.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:06:44.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-18T10:07:14.604+0000] {processor.py:157} INFO - Started process (PID=6194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:07:14.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:07:14.608+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:07:14.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:07:14.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:07:14.651+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:07:14.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:07:14.663+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:07:14.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:07:14.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-18T10:07:45.129+0000] {processor.py:157} INFO - Started process (PID=6219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:07:45.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:07:45.136+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:07:45.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:07:45.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:07:45.206+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:07:45.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:07:45.240+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:07:45.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:07:45.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-07-18T10:08:15.656+0000] {processor.py:157} INFO - Started process (PID=6244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:08:15.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:08:15.665+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:08:15.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:08:15.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:08:15.710+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:08:15.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:08:15.724+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:08:15.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:08:15.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-18T10:08:46.155+0000] {processor.py:157} INFO - Started process (PID=6269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:08:46.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:08:46.160+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:08:46.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:08:46.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:08:46.185+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:08:46.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:08:46.195+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:08:46.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:08:46.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T10:09:16.611+0000] {processor.py:157} INFO - Started process (PID=6294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:09:16.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:09:16.615+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:09:16.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:09:16.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:09:16.645+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:09:16.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:09:16.654+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:09:16.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:09:16.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T10:09:46.966+0000] {processor.py:157} INFO - Started process (PID=6319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:09:46.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:09:46.969+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:09:46.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:09:46.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:09:46.993+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:09:46.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:09:47.002+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:09:47.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:09:47.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-18T10:10:17.418+0000] {processor.py:157} INFO - Started process (PID=6344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:10:17.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:10:17.422+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:10:17.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:10:17.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:10:17.447+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:10:17.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:10:17.457+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:10:17.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:10:17.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T10:10:47.849+0000] {processor.py:157} INFO - Started process (PID=6369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:10:47.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:10:47.852+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:10:47.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:10:47.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:10:47.879+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:10:47.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:10:47.890+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:10:47.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:10:47.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T10:11:18.268+0000] {processor.py:157} INFO - Started process (PID=6394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:11:18.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:11:18.273+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:11:18.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:11:18.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:11:18.311+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:11:18.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:11:18.323+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:11:18.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:11:18.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-18T10:11:48.694+0000] {processor.py:157} INFO - Started process (PID=6419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:11:48.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:11:48.698+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:11:48.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:11:48.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:11:48.724+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:11:48.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:11:48.734+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:11:48.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:11:48.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T10:12:19.068+0000] {processor.py:157} INFO - Started process (PID=6444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:12:19.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:12:19.073+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:12:19.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:12:19.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:12:19.100+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:12:19.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:12:19.111+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:12:19.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:12:19.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T10:12:49.453+0000] {processor.py:157} INFO - Started process (PID=6469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:12:49.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:12:49.457+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:12:49.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:12:49.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:12:49.482+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:12:49.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:12:49.495+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:12:49.495+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:12:49.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T10:13:19.918+0000] {processor.py:157} INFO - Started process (PID=6494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:13:19.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:13:19.921+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:13:19.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:13:19.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:13:19.946+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:13:19.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:13:19.957+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:13:19.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:13:19.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T10:13:50.378+0000] {processor.py:157} INFO - Started process (PID=6519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:13:50.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:13:50.381+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:13:50.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:13:50.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:13:50.411+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:13:50.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:13:50.420+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:13:50.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:13:50.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T10:14:20.853+0000] {processor.py:157} INFO - Started process (PID=6544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:14:20.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:14:20.856+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:14:20.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:14:20.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:14:20.884+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:14:20.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:14:20.895+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:14:20.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:14:20.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T10:14:51.323+0000] {processor.py:157} INFO - Started process (PID=6569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:14:51.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:14:51.326+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:14:51.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:14:51.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:14:51.352+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:14:51.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:14:51.365+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:14:51.365+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:14:51.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T10:15:21.722+0000] {processor.py:157} INFO - Started process (PID=6594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:15:21.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:15:21.726+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:15:21.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:15:21.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:15:21.756+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:15:21.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:15:21.765+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:15:21.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:15:21.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T10:15:52.162+0000] {processor.py:157} INFO - Started process (PID=6619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:15:52.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:15:52.165+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:15:52.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:15:52.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:15:52.191+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:15:52.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:15:52.204+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:15:52.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:15:52.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T10:16:22.586+0000] {processor.py:157} INFO - Started process (PID=6644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:16:22.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:16:22.589+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:16:22.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:16:22.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:16:22.618+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:16:22.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:16:22.627+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:16:22.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:16:22.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T10:16:53.024+0000] {processor.py:157} INFO - Started process (PID=6669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:16:53.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:16:53.030+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:16:53.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:16:53.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:16:53.063+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:16:53.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:16:53.075+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:16:53.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:16:53.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-18T10:17:23.487+0000] {processor.py:157} INFO - Started process (PID=6694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:17:23.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:17:23.490+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:17:23.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:17:23.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:17:23.520+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:17:23.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:17:23.530+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:17:23.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:17:23.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T10:17:53.929+0000] {processor.py:157} INFO - Started process (PID=6719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:17:53.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:17:53.933+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:17:53.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:17:53.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:17:53.958+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:17:53.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:17:53.970+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:17:53.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:17:53.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T10:18:24.421+0000] {processor.py:157} INFO - Started process (PID=6744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:18:24.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:18:24.424+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:18:24.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:18:24.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:18:24.455+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:18:24.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:18:24.464+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:18:24.464+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:18:24.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T10:18:54.902+0000] {processor.py:157} INFO - Started process (PID=6769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:18:54.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:18:54.906+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:18:54.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:18:54.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:18:54.932+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:18:54.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:18:54.946+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:18:54.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:18:54.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T10:19:25.339+0000] {processor.py:157} INFO - Started process (PID=6794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:19:25.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:19:25.342+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:19:25.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:19:25.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:19:25.374+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:19:25.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:19:25.386+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:19:25.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:19:25.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T10:19:55.788+0000] {processor.py:157} INFO - Started process (PID=6819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:19:55.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:19:55.792+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:19:55.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:19:55.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:19:55.817+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:19:55.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:19:55.832+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:19:55.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:19:55.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T10:20:26.251+0000] {processor.py:157} INFO - Started process (PID=6844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:20:26.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:20:26.254+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:20:26.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:20:26.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:20:26.279+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:20:26.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:20:26.289+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:20:26.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:20:26.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T10:20:56.688+0000] {processor.py:157} INFO - Started process (PID=6869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:20:56.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:20:56.694+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:20:56.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:20:56.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:20:56.720+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:20:56.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:20:56.729+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:20:56.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:20:56.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T10:21:27.185+0000] {processor.py:157} INFO - Started process (PID=6894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:21:27.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:21:27.191+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:21:27.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:21:27.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:21:27.228+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:21:27.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:21:27.239+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:21:27.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:21:27.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-18T10:21:57.607+0000] {processor.py:157} INFO - Started process (PID=6919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:21:57.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:21:57.610+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:21:57.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:21:57.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:21:57.635+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:21:57.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:21:57.645+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:21:57.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:21:57.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T10:22:28.062+0000] {processor.py:157} INFO - Started process (PID=6944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:22:28.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:22:28.064+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:22:28.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:22:28.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:22:28.090+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:22:28.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:22:28.101+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:22:28.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:22:28.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T10:22:58.505+0000] {processor.py:157} INFO - Started process (PID=6969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:22:58.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:22:58.508+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:22:58.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:22:58.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:22:58.534+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:22:58.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:22:58.544+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:22:58.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:22:58.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T10:23:28.928+0000] {processor.py:157} INFO - Started process (PID=6994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:23:28.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:23:28.932+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:23:28.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:23:28.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:23:28.957+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:23:28.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:23:28.966+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:23:28.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:23:28.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T10:23:59.369+0000] {processor.py:157} INFO - Started process (PID=7019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:23:59.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:23:59.371+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:23:59.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:23:59.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:23:59.397+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:23:59.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:23:59.406+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:23:59.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:23:59.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-18T10:24:29.822+0000] {processor.py:157} INFO - Started process (PID=7044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:24:29.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:24:29.826+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:24:29.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:24:29.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:24:29.853+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:24:29.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:24:29.864+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:24:29.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:24:29.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T10:25:00.332+0000] {processor.py:157} INFO - Started process (PID=7069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:25:00.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:25:00.335+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:25:00.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:25:00.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:25:00.359+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:25:00.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:25:00.369+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:25:00.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:25:00.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T10:25:30.727+0000] {processor.py:157} INFO - Started process (PID=7094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:25:30.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:25:30.729+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:25:30.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:25:30.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:25:30.753+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:25:30.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:25:30.763+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:25:30.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:25:30.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-18T10:26:01.179+0000] {processor.py:157} INFO - Started process (PID=7119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:26:01.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:26:01.182+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:26:01.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:26:01.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:26:01.210+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:26:01.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:26:01.220+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:26:01.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:26:01.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T10:26:31.545+0000] {processor.py:157} INFO - Started process (PID=7144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:26:31.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:26:31.548+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:26:31.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:26:31.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:26:31.573+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:26:31.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:26:31.583+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:26:31.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:26:31.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T10:27:01.996+0000] {processor.py:157} INFO - Started process (PID=7169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:27:01.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:27:01.998+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:27:01.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:27:02.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:27:02.027+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:27:02.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:27:02.037+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:27:02.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:27:02.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T10:27:32.491+0000] {processor.py:157} INFO - Started process (PID=7194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:27:32.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:27:32.495+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:27:32.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:27:32.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:27:32.534+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:27:32.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:27:32.545+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:27:32.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:27:32.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-18T10:28:02.912+0000] {processor.py:157} INFO - Started process (PID=7219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:28:02.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:28:02.914+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:28:02.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:28:02.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:28:02.939+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:28:02.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:28:02.950+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:28:02.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:28:02.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T10:28:33.397+0000] {processor.py:157} INFO - Started process (PID=7244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:28:33.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:28:33.400+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:28:33.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:28:33.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:28:33.431+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:28:33.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:28:33.443+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:28:33.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:28:33.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T10:29:03.807+0000] {processor.py:157} INFO - Started process (PID=7269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:29:03.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:29:03.810+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:29:03.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:29:03.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:29:03.838+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:29:03.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:29:03.848+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:29:03.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:29:03.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T10:29:34.401+0000] {processor.py:157} INFO - Started process (PID=7294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:29:34.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:29:34.405+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:29:34.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:29:34.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:29:34.451+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:29:34.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:29:34.464+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:29:34.464+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:29:34.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-18T10:30:04.858+0000] {processor.py:157} INFO - Started process (PID=7319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:30:04.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:30:04.863+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:30:04.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:30:04.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:30:04.924+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:30:04.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:30:04.945+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:30:04.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:30:04.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-18T10:30:35.434+0000] {processor.py:157} INFO - Started process (PID=7344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:30:35.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:30:35.439+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:30:35.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:30:35.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:30:35.498+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:30:35.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:30:35.514+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:30:35.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:30:35.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-18T10:31:05.924+0000] {processor.py:157} INFO - Started process (PID=7369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:31:05.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:31:05.928+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:31:05.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:31:05.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:31:05.962+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:31:05.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:31:05.976+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:31:05.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:31:05.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-18T10:31:36.377+0000] {processor.py:157} INFO - Started process (PID=7394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:31:36.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:31:36.384+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:31:36.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:31:36.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:31:36.452+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:31:36.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:31:36.469+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:31:36.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:31:36.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-18T10:32:06.982+0000] {processor.py:157} INFO - Started process (PID=7419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:32:06.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:32:06.989+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:32:06.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:32:07.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:32:07.063+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:32:07.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:32:07.082+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:32:07.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:32:07.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-07-18T10:32:37.511+0000] {processor.py:157} INFO - Started process (PID=7444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:32:37.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:32:37.516+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:32:37.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:32:37.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:32:37.554+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:32:37.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:32:37.566+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:32:37.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:32:37.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-18T10:33:07.983+0000] {processor.py:157} INFO - Started process (PID=7469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:33:07.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:33:07.990+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:33:07.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:33:08.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:33:08.047+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:33:08.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:33:08.080+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:33:08.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:33:08.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-18T10:33:38.459+0000] {processor.py:157} INFO - Started process (PID=7494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:33:38.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:33:38.461+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:33:38.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:33:38.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:33:38.495+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:33:38.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:33:38.510+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:33:38.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:33:38.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-18T10:34:08.998+0000] {processor.py:157} INFO - Started process (PID=7519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:34:08.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:34:09.003+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:34:09.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:34:09.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:34:09.054+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:34:09.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:34:09.069+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:34:09.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:34:09.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-18T10:34:39.464+0000] {processor.py:157} INFO - Started process (PID=7544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:34:39.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:34:39.469+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:34:39.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:34:39.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:34:39.516+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:34:39.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:34:39.531+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:34:39.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:34:39.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-18T10:35:09.880+0000] {processor.py:157} INFO - Started process (PID=7569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:35:09.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:35:09.884+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:35:09.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:35:09.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:35:09.921+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:35:09.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:35:09.937+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:35:09.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:35:09.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-18T10:35:40.416+0000] {processor.py:157} INFO - Started process (PID=7594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:35:40.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:35:40.425+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:35:40.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:35:40.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:35:40.467+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:35:40.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:35:40.482+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:35:40.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:35:40.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-18T10:36:11.070+0000] {processor.py:157} INFO - Started process (PID=7619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:36:11.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:36:11.076+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:36:11.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:36:11.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:36:11.128+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:36:11.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:36:11.142+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:36:11.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:36:11.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-18T10:36:41.496+0000] {processor.py:157} INFO - Started process (PID=7644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:36:41.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:36:41.499+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:36:41.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:36:41.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:36:41.529+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:36:41.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:36:41.542+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:36:41.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:36:41.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-18T10:37:11.945+0000] {processor.py:157} INFO - Started process (PID=7669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:37:11.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:37:11.949+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:37:11.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:37:11.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:37:11.989+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:37:11.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:37:12.003+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:37:12.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:37:12.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-18T10:37:42.476+0000] {processor.py:157} INFO - Started process (PID=7694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:37:42.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:37:42.483+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:37:42.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:37:42.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:37:42.559+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:37:42.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:37:42.576+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:37:42.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:37:42.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-18T10:38:13.027+0000] {processor.py:157} INFO - Started process (PID=7719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:38:13.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:38:13.032+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:38:13.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:38:13.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:38:13.088+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:38:13.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:38:13.103+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:38:13.103+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:38:13.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-07-18T10:38:43.556+0000] {processor.py:157} INFO - Started process (PID=7744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:38:43.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:38:43.563+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:38:43.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:38:43.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:38:43.613+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:38:43.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:38:43.634+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:38:43.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:38:43.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-18T10:39:13.978+0000] {processor.py:157} INFO - Started process (PID=7769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:39:13.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:39:13.983+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:39:13.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:39:14.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:39:14.039+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:39:14.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:39:14.058+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:39:14.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:39:14.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-18T10:39:44.775+0000] {processor.py:157} INFO - Started process (PID=7794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:39:44.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:39:44.780+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:39:44.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:39:44.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:39:44.839+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:39:44.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:39:44.858+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:39:44.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:39:44.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-18T10:40:15.288+0000] {processor.py:157} INFO - Started process (PID=7819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:40:15.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:40:15.291+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:40:15.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:40:15.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:40:15.326+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:40:15.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:40:15.338+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:40:15.338+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:40:15.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-18T10:40:45.679+0000] {processor.py:157} INFO - Started process (PID=7844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:40:45.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:40:45.684+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:40:45.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:40:45.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:40:45.716+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:40:45.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:40:45.732+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:40:45.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:40:45.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-18T10:41:16.186+0000] {processor.py:157} INFO - Started process (PID=7869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:41:16.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:41:16.191+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:41:16.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:41:16.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:41:16.252+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:41:16.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:41:16.277+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:41:16.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:41:16.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-07-18T10:41:46.647+0000] {processor.py:157} INFO - Started process (PID=7894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:41:46.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:41:46.650+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:41:46.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:41:46.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:41:46.686+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:41:46.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:41:46.700+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:41:46.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:41:46.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-18T10:42:17.124+0000] {processor.py:157} INFO - Started process (PID=7919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:42:17.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:42:17.128+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:42:17.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:42:17.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:42:17.164+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:42:17.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:42:17.178+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:42:17.177+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:42:17.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-18T10:42:47.548+0000] {processor.py:157} INFO - Started process (PID=7944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:42:47.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:42:47.554+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:42:47.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:42:47.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:42:47.599+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:42:47.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:42:47.610+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:42:47.610+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:42:47.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-18T10:43:18.023+0000] {processor.py:157} INFO - Started process (PID=7969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:43:18.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:43:18.029+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:43:18.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:43:18.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:43:18.068+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:43:18.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:43:18.084+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:43:18.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:43:18.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-18T10:43:48.432+0000] {processor.py:157} INFO - Started process (PID=7994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:43:48.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:43:48.436+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:43:48.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:43:48.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:43:48.470+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:43:48.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:43:48.482+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:43:48.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:43:48.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-18T10:44:18.826+0000] {processor.py:157} INFO - Started process (PID=8019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:44:18.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:44:18.830+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:44:18.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:44:18.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:44:18.864+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:44:18.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:44:18.876+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:44:18.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:44:18.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-18T10:44:49.270+0000] {processor.py:157} INFO - Started process (PID=8044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:44:49.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:44:49.274+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:44:49.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:44:49.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:44:49.307+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:44:49.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:44:49.321+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:44:49.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:44:49.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-18T10:45:19.746+0000] {processor.py:157} INFO - Started process (PID=8069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:45:19.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:45:19.750+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:45:19.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:45:19.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:45:19.785+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:45:19.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:45:19.797+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:45:19.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:45:19.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-18T10:45:50.241+0000] {processor.py:157} INFO - Started process (PID=8094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:45:50.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:45:50.246+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:45:50.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:45:50.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:45:50.287+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:45:50.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:45:50.298+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:45:50.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:45:50.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-18T10:46:20.704+0000] {processor.py:157} INFO - Started process (PID=8119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:46:20.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:46:20.707+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:46:20.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:46:20.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:46:20.749+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:46:20.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:46:20.764+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:46:20.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:46:20.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-18T10:46:51.124+0000] {processor.py:157} INFO - Started process (PID=8144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:46:51.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:46:51.127+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:46:51.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:46:51.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:46:51.162+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:46:51.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:46:51.174+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:46:51.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:46:51.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-18T10:47:21.529+0000] {processor.py:157} INFO - Started process (PID=8169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:47:21.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:47:21.532+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:47:21.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:47:21.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:47:21.569+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:47:21.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:47:21.590+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:47:21.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:47:21.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-18T10:47:51.951+0000] {processor.py:157} INFO - Started process (PID=8194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:47:51.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:47:51.955+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:47:51.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:47:51.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:47:51.988+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:47:51.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:47:52.000+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:47:52.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:47:52.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-18T10:48:22.402+0000] {processor.py:157} INFO - Started process (PID=8219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:48:22.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:48:22.405+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:48:22.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:48:22.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:48:22.436+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:48:22.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:48:22.452+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:48:22.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:48:22.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-18T10:48:52.795+0000] {processor.py:157} INFO - Started process (PID=8244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:48:52.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:48:52.798+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:48:52.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:48:52.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:48:52.832+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:48:52.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:48:52.846+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:48:52.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:48:52.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-18T10:49:23.195+0000] {processor.py:157} INFO - Started process (PID=8269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:49:23.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:49:23.198+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:49:23.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:49:23.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:49:23.232+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:49:23.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:49:23.243+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:49:23.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:49:23.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-18T10:49:53.660+0000] {processor.py:157} INFO - Started process (PID=8294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:49:53.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:49:53.664+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:49:53.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:49:53.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:49:53.695+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:49:53.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:49:53.706+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:49:53.706+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:49:53.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-18T10:50:24.097+0000] {processor.py:157} INFO - Started process (PID=8319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:50:24.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:50:24.103+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:50:24.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:50:24.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:50:24.146+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:50:24.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:50:24.161+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:50:24.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:50:24.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-18T10:50:54.582+0000] {processor.py:157} INFO - Started process (PID=8344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:50:54.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:50:54.588+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:50:54.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:50:54.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:50:54.632+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:50:54.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:50:54.647+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:50:54.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:50:54.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-18T10:51:25.055+0000] {processor.py:157} INFO - Started process (PID=8369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:51:25.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:51:25.059+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:51:25.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:51:25.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:51:25.093+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:51:25.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:51:25.107+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:51:25.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:51:25.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-18T10:51:55.488+0000] {processor.py:157} INFO - Started process (PID=8394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:51:55.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:51:55.492+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:51:55.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:51:55.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:51:55.523+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:51:55.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:51:55.535+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:51:55.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:51:55.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T10:52:25.924+0000] {processor.py:157} INFO - Started process (PID=8419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:52:25.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:52:25.928+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:52:25.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:52:25.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:52:25.959+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:52:25.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:52:25.973+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:52:25.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:52:25.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-18T10:52:56.374+0000] {processor.py:157} INFO - Started process (PID=8444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:52:56.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:52:56.378+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:52:56.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:52:56.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:52:56.423+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:52:56.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:52:56.438+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:52:56.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:52:56.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-18T10:53:26.797+0000] {processor.py:157} INFO - Started process (PID=8469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:53:26.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:53:26.800+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:53:26.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:53:26.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:53:26.827+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:53:26.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:53:26.837+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:53:26.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:53:26.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T10:53:57.253+0000] {processor.py:157} INFO - Started process (PID=8494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:53:57.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:53:57.257+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:53:57.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:53:57.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:53:57.293+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:53:57.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:53:57.306+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:53:57.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:53:57.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-18T10:54:27.667+0000] {processor.py:157} INFO - Started process (PID=8519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:54:27.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:54:27.673+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:54:27.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:54:27.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:54:27.725+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:54:27.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:54:27.744+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:54:27.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:54:27.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-18T10:54:58.173+0000] {processor.py:157} INFO - Started process (PID=8544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:54:58.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:54:58.179+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:54:58.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:54:58.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:54:58.214+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:54:58.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:54:58.227+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:54:58.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:54:58.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-18T10:55:28.573+0000] {processor.py:157} INFO - Started process (PID=8569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:55:28.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:55:28.577+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:55:28.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:55:28.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:55:28.615+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:55:28.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:55:28.625+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:55:28.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:55:28.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-18T10:55:59.037+0000] {processor.py:157} INFO - Started process (PID=8594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:55:59.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:55:59.042+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:55:59.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:55:59.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:55:59.080+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:55:59.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:55:59.096+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:55:59.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:55:59.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-18T10:56:29.505+0000] {processor.py:157} INFO - Started process (PID=8619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:56:29.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:56:29.510+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:56:29.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:56:29.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:56:29.545+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:56:29.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:56:29.558+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:56:29.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:56:29.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-18T10:56:59.961+0000] {processor.py:157} INFO - Started process (PID=8644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:56:59.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:56:59.965+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:56:59.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:56:59.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:57:00.002+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:57:00.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:57:00.015+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:57:00.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:57:00.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-18T10:57:30.424+0000] {processor.py:157} INFO - Started process (PID=8669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:57:30.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:57:30.427+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:57:30.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:57:30.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:57:30.459+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:57:30.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:57:30.471+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:57:30.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:57:30.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-18T10:58:00.824+0000] {processor.py:157} INFO - Started process (PID=8694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:58:00.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:58:00.827+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:58:00.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:58:00.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:58:00.860+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:58:00.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:58:00.871+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:58:00.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:58:00.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-18T10:58:31.265+0000] {processor.py:157} INFO - Started process (PID=8719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:58:31.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:58:31.268+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:58:31.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:58:31.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:58:31.301+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:58:31.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:58:31.315+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:58:31.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:58:31.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-18T10:59:01.662+0000] {processor.py:157} INFO - Started process (PID=8744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:59:01.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:59:01.666+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:59:01.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:59:01.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:59:01.701+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:59:01.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:59:01.718+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:59:01.718+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:59:01.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-18T10:59:32.073+0000] {processor.py:157} INFO - Started process (PID=8769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:59:32.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T10:59:32.077+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:59:32.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:59:32.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T10:59:32.114+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:59:32.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:59:32.128+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:59:32.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T10:59:32.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-18T11:00:02.537+0000] {processor.py:157} INFO - Started process (PID=8794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:00:02.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:00:02.542+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:00:02.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:00:02.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:00:02.582+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:00:02.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:00:02.595+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:00:02.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:00:02.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-18T11:00:32.945+0000] {processor.py:157} INFO - Started process (PID=8819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:00:32.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:00:32.949+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:00:32.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:00:32.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:00:32.984+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:00:32.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:00:32.998+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:00:32.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:00:33.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-18T11:01:03.410+0000] {processor.py:157} INFO - Started process (PID=8844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:01:03.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:01:03.414+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:01:03.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:01:03.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:01:03.447+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:01:03.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:01:03.460+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:01:03.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:01:03.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-18T11:01:33.805+0000] {processor.py:157} INFO - Started process (PID=8869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:01:33.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:01:33.809+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:01:33.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:01:33.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:01:33.842+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:01:33.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:01:33.855+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:01:33.855+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:01:33.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-18T11:02:04.186+0000] {processor.py:157} INFO - Started process (PID=8894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:02:04.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:02:04.190+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:02:04.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:02:04.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:02:04.224+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:02:04.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:02:04.237+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:02:04.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:02:04.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-18T11:02:34.581+0000] {processor.py:157} INFO - Started process (PID=8919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:02:34.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:02:34.584+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:02:34.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:02:34.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:02:34.617+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:02:34.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:02:34.631+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:02:34.631+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:02:34.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-18T11:03:05.051+0000] {processor.py:157} INFO - Started process (PID=8944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:03:05.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:03:05.054+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:03:05.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:03:05.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:03:05.090+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:03:05.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:03:05.106+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:03:05.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:03:05.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-18T11:03:35.558+0000] {processor.py:157} INFO - Started process (PID=8969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:03:35.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:03:35.568+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:03:35.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:03:35.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:03:35.625+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:03:35.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:03:35.642+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:03:35.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:03:35.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-18T11:04:05.979+0000] {processor.py:157} INFO - Started process (PID=8994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:04:05.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:04:05.984+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:04:05.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:04:05.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:04:06.018+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:04:06.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:04:06.029+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:04:06.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:04:06.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-18T11:04:36.372+0000] {processor.py:157} INFO - Started process (PID=9019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:04:36.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:04:36.378+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:04:36.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:04:36.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:04:36.417+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:04:36.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:04:36.429+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:04:36.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:04:36.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-18T11:05:06.881+0000] {processor.py:157} INFO - Started process (PID=9044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:05:06.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:05:06.886+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:05:06.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:05:06.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:05:06.945+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:05:06.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:05:06.966+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:05:06.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:05:06.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-18T11:05:37.525+0000] {processor.py:157} INFO - Started process (PID=9069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:05:37.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:05:37.547+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:05:37.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:05:37.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:05:37.674+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:05:37.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:05:37.688+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:05:37.688+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:05:37.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.207 seconds
[2024-07-18T11:06:08.331+0000] {processor.py:157} INFO - Started process (PID=9094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:06:08.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:06:08.335+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:06:08.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:06:08.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:06:08.405+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:06:08.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:06:08.427+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:06:08.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:06:08.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-07-18T11:06:38.910+0000] {processor.py:157} INFO - Started process (PID=9119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:06:38.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:06:38.921+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:06:38.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:06:38.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:06:38.984+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:06:38.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:06:39.009+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:06:39.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:06:39.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-07-18T11:07:09.435+0000] {processor.py:157} INFO - Started process (PID=9144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:07:09.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:07:09.441+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:07:09.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:07:09.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:07:09.474+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:07:09.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:07:09.488+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:07:09.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:07:09.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-18T11:07:39.854+0000] {processor.py:157} INFO - Started process (PID=9169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:07:39.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:07:39.861+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:07:39.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:07:39.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:07:39.906+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:07:39.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:07:39.921+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:07:39.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:07:39.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-18T11:08:10.286+0000] {processor.py:157} INFO - Started process (PID=9194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:08:10.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:08:10.290+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:08:10.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:08:10.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:08:10.327+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:08:10.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:08:10.339+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:08:10.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:08:10.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-18T11:08:40.771+0000] {processor.py:157} INFO - Started process (PID=9219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:08:40.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:08:40.780+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:08:40.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:08:40.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:08:40.853+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:08:40.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:08:40.878+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:08:40.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:08:40.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-07-18T11:09:11.362+0000] {processor.py:157} INFO - Started process (PID=9244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:09:11.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:09:11.382+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:09:11.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:09:11.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:09:11.450+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:09:11.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:09:11.470+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:09:11.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:09:11.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-07-18T11:09:41.956+0000] {processor.py:157} INFO - Started process (PID=9269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:09:41.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:09:41.964+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:09:41.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:09:41.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:09:42.045+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:09:42.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:09:42.062+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:09:42.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:09:42.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-07-18T11:10:12.533+0000] {processor.py:157} INFO - Started process (PID=9294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:10:12.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:10:12.553+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:10:12.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:10:12.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:10:12.614+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:10:12.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:10:12.632+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:10:12.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:10:12.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-07-18T11:10:43.190+0000] {processor.py:157} INFO - Started process (PID=9319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:10:43.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:10:43.207+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:10:43.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:10:43.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:10:43.269+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:10:43.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:10:43.294+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:10:43.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:10:43.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-07-18T11:11:13.725+0000] {processor.py:157} INFO - Started process (PID=9344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:11:13.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:11:13.734+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:11:13.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:11:13.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:11:13.794+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:11:13.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:11:13.827+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:11:13.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:11:13.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-18T11:11:44.239+0000] {processor.py:157} INFO - Started process (PID=9369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:11:44.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:11:44.246+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:11:44.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:11:44.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:11:44.313+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:11:44.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:11:44.333+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:11:44.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:11:44.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-18T11:12:14.797+0000] {processor.py:157} INFO - Started process (PID=9394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:12:14.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:12:14.810+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:12:14.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:12:14.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:12:14.880+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:12:14.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:12:14.901+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:12:14.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:12:14.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-07-18T11:12:45.345+0000] {processor.py:157} INFO - Started process (PID=9419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:12:45.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:12:45.353+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:12:45.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:12:45.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:12:45.411+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:12:45.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:12:45.431+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:12:45.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:12:45.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-18T11:13:15.911+0000] {processor.py:157} INFO - Started process (PID=9444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:13:15.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:13:15.915+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:13:15.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:13:15.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:13:15.952+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:13:15.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:13:15.967+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:13:15.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:13:15.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-18T11:13:46.489+0000] {processor.py:157} INFO - Started process (PID=9469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:13:46.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:13:46.510+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:13:46.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:13:46.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:13:46.590+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:13:46.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:13:46.607+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:13:46.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:13:46.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-07-18T11:14:17.139+0000] {processor.py:157} INFO - Started process (PID=9494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:14:17.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:14:17.151+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:14:17.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:14:17.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:14:17.226+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:14:17.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:14:17.247+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:14:17.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:14:17.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-07-18T11:14:47.715+0000] {processor.py:157} INFO - Started process (PID=9519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:14:47.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:14:47.721+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:14:47.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:14:47.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:14:47.781+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:14:47.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:14:47.796+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:14:47.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:14:47.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-18T11:15:18.227+0000] {processor.py:157} INFO - Started process (PID=9544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:15:18.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:15:18.237+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:15:18.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:15:18.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:15:18.290+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:15:18.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:15:18.311+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:15:18.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:15:18.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-18T11:15:48.839+0000] {processor.py:157} INFO - Started process (PID=9569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:15:48.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:15:48.847+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:15:48.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:15:48.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:15:48.906+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:15:48.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:15:48.924+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:15:48.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:15:48.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-18T11:16:19.277+0000] {processor.py:157} INFO - Started process (PID=9594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:16:19.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:16:19.281+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:16:19.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:16:19.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:16:19.314+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:16:19.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:16:19.328+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:16:19.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:16:19.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-18T11:16:49.814+0000] {processor.py:157} INFO - Started process (PID=9619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:16:49.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:16:49.824+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:16:49.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:16:49.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:16:49.900+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:16:49.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:16:49.921+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:16:49.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:16:49.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-18T11:17:20.363+0000] {processor.py:157} INFO - Started process (PID=9644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:17:20.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:17:20.366+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:17:20.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:17:20.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:17:20.410+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:17:20.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:17:20.433+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:17:20.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:17:20.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-18T11:17:50.863+0000] {processor.py:157} INFO - Started process (PID=9669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:17:50.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:17:50.871+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:17:50.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:17:50.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:17:50.951+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:17:50.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:17:50.970+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:17:50.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:17:50.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-07-18T11:18:21.398+0000] {processor.py:157} INFO - Started process (PID=9694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:18:21.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:18:21.405+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:18:21.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:18:21.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:18:21.478+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:18:21.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:18:21.503+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:18:21.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:18:21.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-07-18T11:18:52.263+0000] {processor.py:157} INFO - Started process (PID=9719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:18:52.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:18:52.271+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:18:52.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:18:52.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:18:52.341+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:18:52.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:18:52.361+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:18:52.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:18:52.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-18T11:19:22.834+0000] {processor.py:157} INFO - Started process (PID=9744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:19:22.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:19:22.843+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:19:22.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:19:22.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:19:22.917+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:19:22.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:19:22.935+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:19:22.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:19:22.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-18T11:19:53.428+0000] {processor.py:157} INFO - Started process (PID=9769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:19:53.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:19:53.434+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:19:53.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:19:53.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:19:53.499+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:19:53.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:19:53.539+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:19:53.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:19:53.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-07-18T11:20:23.969+0000] {processor.py:157} INFO - Started process (PID=9794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:20:23.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:20:23.973+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:20:23.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:20:23.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:20:24.015+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:20:24.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:20:24.025+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:20:24.025+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:20:24.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-18T11:20:54.342+0000] {processor.py:157} INFO - Started process (PID=9819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:20:54.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:20:54.344+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:20:54.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:20:54.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:20:54.372+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:20:54.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:20:54.388+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:20:54.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:20:54.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T11:21:24.732+0000] {processor.py:157} INFO - Started process (PID=9844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:21:24.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:21:24.735+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:21:24.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:21:24.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:21:24.768+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:21:24.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:21:24.779+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:21:24.779+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:21:24.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-18T11:21:55.143+0000] {processor.py:157} INFO - Started process (PID=9869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:21:55.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:21:55.147+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:21:55.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:21:55.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:21:55.189+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:21:55.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:21:55.202+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:21:55.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:21:55.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-18T11:22:25.565+0000] {processor.py:157} INFO - Started process (PID=9894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:22:25.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:22:25.568+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:22:25.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:22:25.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:22:25.598+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:22:25.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:22:25.611+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:22:25.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:22:25.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T11:22:55.968+0000] {processor.py:157} INFO - Started process (PID=9919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:22:55.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:22:55.984+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:22:55.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:22:56.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:22:56.038+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:22:56.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:22:56.055+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:22:56.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:22:56.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-07-18T11:23:26.466+0000] {processor.py:157} INFO - Started process (PID=9944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:23:26.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:23:26.470+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:23:26.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:23:26.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:23:26.505+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:23:26.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:23:26.519+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:23:26.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:23:26.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-18T11:23:56.954+0000] {processor.py:157} INFO - Started process (PID=9969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:23:56.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:23:56.959+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:23:56.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:23:56.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:23:57.017+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:23:57.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:23:57.043+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:23:57.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:23:57.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-18T11:24:27.454+0000] {processor.py:157} INFO - Started process (PID=9994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:24:27.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:24:27.457+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:24:27.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:24:27.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:24:27.493+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:24:27.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:24:27.510+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:24:27.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:24:27.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-18T11:24:57.858+0000] {processor.py:157} INFO - Started process (PID=10019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:24:57.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:24:57.863+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:24:57.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:24:57.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:24:57.908+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:24:57.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:24:57.927+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:24:57.927+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:24:57.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-18T11:25:28.270+0000] {processor.py:157} INFO - Started process (PID=10044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:25:28.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:25:28.275+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:25:28.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:25:28.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:25:28.317+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:25:28.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:25:28.329+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:25:28.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:25:28.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-18T11:25:58.673+0000] {processor.py:157} INFO - Started process (PID=10069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:25:58.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:25:58.679+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:25:58.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:25:58.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:25:58.733+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:25:58.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:25:58.757+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:25:58.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:25:58.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-07-18T11:26:29.153+0000] {processor.py:157} INFO - Started process (PID=10094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:26:29.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:26:29.159+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:26:29.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:26:29.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:26:29.204+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:26:29.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:26:29.220+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:26:29.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:26:29.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-18T11:26:59.688+0000] {processor.py:157} INFO - Started process (PID=10119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:26:59.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:26:59.696+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:26:59.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:26:59.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:26:59.746+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:26:59.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:26:59.769+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:26:59.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:26:59.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-18T11:27:30.234+0000] {processor.py:157} INFO - Started process (PID=10144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:27:30.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:27:30.240+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:27:30.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:27:30.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:27:30.308+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:27:30.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:27:30.331+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:27:30.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:27:30.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-18T11:28:00.787+0000] {processor.py:157} INFO - Started process (PID=10169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:28:00.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:28:00.796+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:28:00.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:28:00.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:28:00.864+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:28:00.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:28:00.882+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:28:00.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:28:00.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-07-18T11:28:31.284+0000] {processor.py:157} INFO - Started process (PID=10194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:28:31.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:28:31.290+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:28:31.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:28:31.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:28:31.342+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:28:31.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:28:31.357+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:28:31.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:28:31.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-18T11:29:01.807+0000] {processor.py:157} INFO - Started process (PID=10219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:29:01.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:29:01.812+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:29:01.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:29:01.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:29:01.863+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:29:01.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:29:01.878+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:29:01.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:29:01.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-18T11:29:32.270+0000] {processor.py:157} INFO - Started process (PID=10244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:29:32.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:29:32.275+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:29:32.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:29:32.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:29:32.319+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:29:32.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:29:32.335+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:29:32.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:29:32.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-18T11:30:02.777+0000] {processor.py:157} INFO - Started process (PID=10269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:30:02.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:30:02.781+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:30:02.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:30:02.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:30:02.829+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:30:02.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:30:02.848+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:30:02.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:30:02.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-18T11:30:33.225+0000] {processor.py:157} INFO - Started process (PID=10294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:30:33.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:30:33.249+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:30:33.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:30:33.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:30:33.307+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:30:33.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:30:33.322+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:30:33.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:30:33.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-18T11:31:03.773+0000] {processor.py:157} INFO - Started process (PID=10319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:31:03.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:31:03.781+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:31:03.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:31:03.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:31:03.840+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:31:03.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:31:03.856+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:31:03.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:31:03.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-18T11:31:34.301+0000] {processor.py:157} INFO - Started process (PID=10344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:31:34.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:31:34.307+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:31:34.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:31:34.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:31:34.374+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:31:34.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:31:34.392+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:31:34.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:31:34.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-18T11:32:04.787+0000] {processor.py:157} INFO - Started process (PID=10369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:32:04.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:32:04.793+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:32:04.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:32:04.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:32:04.840+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:32:04.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:32:04.855+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:32:04.855+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:32:04.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-18T11:32:35.262+0000] {processor.py:157} INFO - Started process (PID=10394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:32:35.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:32:35.272+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:32:35.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:32:35.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:32:35.323+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:32:35.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:32:35.340+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:32:35.340+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:32:35.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-18T11:33:05.905+0000] {processor.py:157} INFO - Started process (PID=10419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:33:05.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:33:05.912+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:33:05.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:33:05.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:33:05.992+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:33:05.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:33:06.013+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:33:06.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:33:06.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-07-18T11:33:36.455+0000] {processor.py:157} INFO - Started process (PID=10444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:33:36.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:33:36.466+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:33:36.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:33:36.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:33:36.534+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:33:36.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:33:36.551+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:33:36.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:33:36.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-07-18T11:34:07.053+0000] {processor.py:157} INFO - Started process (PID=10469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:34:07.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:34:07.063+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:34:07.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:34:07.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:34:07.167+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:34:07.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:34:07.190+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:34:07.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:34:07.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.175 seconds
[2024-07-18T11:34:37.656+0000] {processor.py:157} INFO - Started process (PID=10494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:34:37.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:34:37.665+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:34:37.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:34:37.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:34:37.741+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:34:37.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:34:37.759+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:34:37.759+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:34:37.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-18T11:35:08.310+0000] {processor.py:157} INFO - Started process (PID=10519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:35:08.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:35:08.317+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:35:08.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:35:08.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:35:08.389+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:35:08.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:35:08.406+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:35:08.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:35:08.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-18T11:35:38.816+0000] {processor.py:157} INFO - Started process (PID=10544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:35:38.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:35:38.820+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:35:38.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:35:38.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:35:38.856+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:35:38.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:35:38.867+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:35:38.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:35:38.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-18T11:36:09.241+0000] {processor.py:157} INFO - Started process (PID=10569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:36:09.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:36:09.244+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:36:09.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:36:09.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:36:09.278+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:36:09.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:36:09.292+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:36:09.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:36:09.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-18T11:36:39.660+0000] {processor.py:157} INFO - Started process (PID=10594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:36:39.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:36:39.665+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:36:39.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:36:39.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:36:39.709+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:36:39.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:36:39.725+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:36:39.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:36:39.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-18T11:37:10.078+0000] {processor.py:157} INFO - Started process (PID=10619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:37:10.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:37:10.082+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:37:10.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:37:10.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:37:10.115+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:37:10.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:37:10.128+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:37:10.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:37:10.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-18T11:37:40.483+0000] {processor.py:157} INFO - Started process (PID=10644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:37:40.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:37:40.486+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:37:40.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:37:40.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:37:40.520+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:37:40.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:37:40.535+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:37:40.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:37:40.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-18T11:38:10.965+0000] {processor.py:157} INFO - Started process (PID=10669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:38:10.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:38:10.970+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:38:10.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:38:10.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:38:11.018+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:38:11.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:38:11.033+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:38:11.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:38:11.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-18T11:38:41.483+0000] {processor.py:157} INFO - Started process (PID=10694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:38:41.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:38:41.487+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:38:41.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:38:41.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:38:41.518+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:38:41.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:38:41.531+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:38:41.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:38:41.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-18T11:39:11.931+0000] {processor.py:157} INFO - Started process (PID=10719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:39:11.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:39:11.934+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:39:11.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:39:11.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:39:11.961+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:39:11.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:39:11.971+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:39:11.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:39:11.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T11:39:42.376+0000] {processor.py:157} INFO - Started process (PID=10744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:39:42.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:39:42.384+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:39:42.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:39:42.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:39:42.447+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:39:42.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:39:42.468+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:39:42.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:39:42.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-07-18T11:40:12.979+0000] {processor.py:157} INFO - Started process (PID=10769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:40:12.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:40:12.986+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:40:12.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:40:13.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:40:13.057+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:40:13.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:40:13.074+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:40:13.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:40:13.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-18T11:40:43.489+0000] {processor.py:157} INFO - Started process (PID=10794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:40:43.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:40:43.492+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:40:43.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:40:43.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:40:43.528+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:40:43.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:40:43.539+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:40:43.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:40:43.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-18T11:41:13.929+0000] {processor.py:157} INFO - Started process (PID=10819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:41:13.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:41:13.936+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:41:13.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:41:13.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:41:13.983+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:41:13.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:41:13.997+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:41:13.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:41:14.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-18T11:41:44.420+0000] {processor.py:157} INFO - Started process (PID=10844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:41:44.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:41:44.426+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:41:44.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:41:44.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:41:44.497+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:41:44.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:41:44.514+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:41:44.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:41:44.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-07-18T11:42:14.913+0000] {processor.py:157} INFO - Started process (PID=10869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:42:14.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:42:14.917+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:42:14.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:42:14.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:42:14.950+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:42:14.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:42:14.966+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:42:14.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:42:14.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-18T11:42:45.282+0000] {processor.py:157} INFO - Started process (PID=10894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:42:45.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:42:45.285+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:42:45.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:42:45.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:42:45.314+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:42:45.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:42:45.327+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:42:45.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:42:45.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T11:43:15.713+0000] {processor.py:157} INFO - Started process (PID=10919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:43:15.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:43:15.717+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:43:15.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:43:15.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:43:15.750+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:43:15.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:43:15.763+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:43:15.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:43:15.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-18T11:43:46.163+0000] {processor.py:157} INFO - Started process (PID=10944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:43:46.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:43:46.168+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:43:46.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:43:46.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:43:46.202+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:43:46.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:43:46.214+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:43:46.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:43:46.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-18T11:44:16.565+0000] {processor.py:157} INFO - Started process (PID=10969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:44:16.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:44:16.571+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:44:16.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:44:16.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:44:16.615+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:44:16.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:44:16.630+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:44:16.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:44:16.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-18T11:44:46.982+0000] {processor.py:157} INFO - Started process (PID=10994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:44:46.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:44:46.987+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:44:46.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:44:46.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:44:47.019+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:44:47.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:44:47.031+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:44:47.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:44:47.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-18T11:45:17.387+0000] {processor.py:157} INFO - Started process (PID=11019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:45:17.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:45:17.391+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:45:17.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:45:17.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:45:17.425+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:45:17.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:45:17.441+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:45:17.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:45:17.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-18T11:45:47.772+0000] {processor.py:157} INFO - Started process (PID=11044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:45:47.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:45:47.776+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:45:47.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:45:47.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:45:47.808+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:45:47.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:45:47.819+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:45:47.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:45:47.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-18T11:46:18.156+0000] {processor.py:157} INFO - Started process (PID=11069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:46:18.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:46:18.161+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:46:18.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:46:18.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:46:18.199+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:46:18.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:46:18.210+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:46:18.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:46:18.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-18T11:46:48.631+0000] {processor.py:157} INFO - Started process (PID=11094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:46:48.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:46:48.637+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:46:48.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:46:48.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:46:48.667+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:46:48.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:46:48.679+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:46:48.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:46:48.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-18T11:47:19.033+0000] {processor.py:157} INFO - Started process (PID=11119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:47:19.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:47:19.037+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:47:19.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:47:19.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:47:19.071+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:47:19.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:47:19.084+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:47:19.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:47:19.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-18T11:47:49.429+0000] {processor.py:157} INFO - Started process (PID=11144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:47:49.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:47:49.433+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:47:49.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:47:49.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:47:49.465+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:47:49.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:47:49.477+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:47:49.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:47:49.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-18T11:48:19.900+0000] {processor.py:157} INFO - Started process (PID=11169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:48:19.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:48:19.903+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:48:19.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:48:19.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:48:19.937+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:48:19.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:48:19.949+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:48:19.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:48:19.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-18T11:48:50.278+0000] {processor.py:157} INFO - Started process (PID=11194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:48:50.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:48:50.280+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:48:50.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:48:50.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:48:50.311+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:48:50.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:48:50.322+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:48:50.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:48:50.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T11:49:20.681+0000] {processor.py:157} INFO - Started process (PID=11219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:49:20.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:49:20.686+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:49:20.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:49:20.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:49:20.724+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:49:20.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:49:20.738+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:49:20.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:49:20.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-18T11:49:51.133+0000] {processor.py:157} INFO - Started process (PID=11244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:49:51.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:49:51.135+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:49:51.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:49:51.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:49:51.167+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:49:51.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:49:51.180+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:49:51.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:49:51.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-18T11:50:21.538+0000] {processor.py:157} INFO - Started process (PID=11269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:50:21.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:50:21.542+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:50:21.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:50:21.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:50:21.575+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:50:21.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:50:21.590+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:50:21.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:50:21.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-18T11:50:52.004+0000] {processor.py:157} INFO - Started process (PID=11294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:50:52.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:50:52.008+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:50:52.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:50:52.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:50:52.043+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:50:52.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:50:52.057+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:50:52.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:50:52.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-18T11:51:22.390+0000] {processor.py:157} INFO - Started process (PID=11319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:51:22.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:51:22.395+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:51:22.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:51:22.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:51:22.424+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:51:22.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:51:22.436+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:51:22.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:51:22.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-18T11:51:52.850+0000] {processor.py:157} INFO - Started process (PID=11344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:51:52.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:51:52.854+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:51:52.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:51:52.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:51:52.886+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:51:52.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:51:52.898+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:51:52.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:51:52.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-18T11:52:23.251+0000] {processor.py:157} INFO - Started process (PID=11369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:52:23.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:52:23.256+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:52:23.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:52:23.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:52:23.292+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:52:23.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:52:23.309+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:52:23.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:52:23.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-18T11:52:53.687+0000] {processor.py:157} INFO - Started process (PID=11394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:52:53.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:52:53.690+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:52:53.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:52:53.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:52:53.719+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:52:53.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:52:53.730+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:52:53.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:52:53.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T11:53:24.098+0000] {processor.py:157} INFO - Started process (PID=11419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:53:24.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:53:24.101+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:53:24.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:53:24.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:53:24.127+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:53:24.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:53:24.137+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:53:24.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:53:24.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T11:53:54.505+0000] {processor.py:157} INFO - Started process (PID=11444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:53:54.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:53:54.511+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:53:54.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:53:54.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:53:54.556+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:53:54.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:53:54.569+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:53:54.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:53:54.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-18T11:54:24.972+0000] {processor.py:157} INFO - Started process (PID=11469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:54:24.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:54:24.976+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:54:24.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:54:24.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:54:25.010+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:54:25.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:54:25.021+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:54:25.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:54:25.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-18T11:54:55.407+0000] {processor.py:157} INFO - Started process (PID=11494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:54:55.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:54:55.412+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:54:55.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:54:55.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:54:55.445+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:54:55.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:54:55.456+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:54:55.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:54:55.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-18T11:55:25.869+0000] {processor.py:157} INFO - Started process (PID=11519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:55:25.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:55:25.875+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:55:25.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:55:25.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:55:25.913+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:55:25.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:55:25.926+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:55:25.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:55:25.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-18T11:55:56.271+0000] {processor.py:157} INFO - Started process (PID=11544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:55:56.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:55:56.276+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:55:56.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:55:56.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:55:56.308+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:55:56.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:55:56.322+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:55:56.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:55:56.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-18T11:56:26.660+0000] {processor.py:157} INFO - Started process (PID=11569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:56:26.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:56:26.663+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:56:26.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:56:26.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:56:26.697+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:56:26.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:56:26.708+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:56:26.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:56:26.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-18T11:56:57.135+0000] {processor.py:157} INFO - Started process (PID=11594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:56:57.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:56:57.141+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:56:57.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:56:57.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:56:57.188+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:56:57.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:56:57.207+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:56:57.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:56:57.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-18T11:57:27.645+0000] {processor.py:157} INFO - Started process (PID=11619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:57:27.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:57:27.652+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:57:27.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:57:27.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:57:27.711+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:57:27.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:57:27.728+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:57:27.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:57:27.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-18T11:57:58.143+0000] {processor.py:157} INFO - Started process (PID=11644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:57:58.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:57:58.147+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:57:58.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:57:58.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:57:58.190+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:57:58.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:57:58.205+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:57:58.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:57:58.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-18T11:58:28.585+0000] {processor.py:157} INFO - Started process (PID=11669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:58:28.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:58:28.591+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:58:28.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:58:28.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:58:28.628+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:58:28.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:58:28.642+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:58:28.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:58:28.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-18T11:58:59.061+0000] {processor.py:157} INFO - Started process (PID=11694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:58:59.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:58:59.073+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:58:59.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:58:59.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:58:59.129+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:58:59.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:58:59.146+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:58:59.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:58:59.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-18T11:59:29.504+0000] {processor.py:157} INFO - Started process (PID=11719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:59:29.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:59:29.509+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:59:29.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:59:29.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:59:29.553+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:59:29.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:59:29.570+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:59:29.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T11:59:29.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-18T11:59:59.932+0000] {processor.py:157} INFO - Started process (PID=11744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:59:59.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T11:59:59.936+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:59:59.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T11:59:59.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:00:00.000+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:59:59.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:00:00.015+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:00:00.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:00:00.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-18T12:00:30.483+0000] {processor.py:157} INFO - Started process (PID=11769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:00:30.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:00:30.488+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:00:30.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:00:30.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:00:30.531+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:00:30.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:00:30.546+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:00:30.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:00:30.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-18T12:01:00.962+0000] {processor.py:157} INFO - Started process (PID=11794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:01:00.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:01:00.967+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:01:00.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:01:00.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:01:01.005+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:01:01.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:01:01.020+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:01:01.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:01:01.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-18T12:01:31.422+0000] {processor.py:157} INFO - Started process (PID=11819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:01:31.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:01:31.426+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:01:31.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:01:31.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:01:31.461+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:01:31.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:01:31.475+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:01:31.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:01:31.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-18T12:02:01.886+0000] {processor.py:157} INFO - Started process (PID=11844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:02:01.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:02:01.893+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:02:01.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:02:01.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:02:01.940+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:02:01.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:02:01.957+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:02:01.957+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:02:01.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-18T12:02:32.401+0000] {processor.py:157} INFO - Started process (PID=11869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:02:32.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:02:32.406+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:02:32.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:02:32.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:02:32.451+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:02:32.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:02:32.466+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:02:32.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:02:32.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-18T12:03:02.881+0000] {processor.py:157} INFO - Started process (PID=11894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:03:02.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:03:02.886+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:03:02.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:03:02.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:03:02.926+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:03:02.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:03:02.941+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:03:02.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:03:02.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-18T12:03:33.374+0000] {processor.py:157} INFO - Started process (PID=11919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:03:33.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:03:33.377+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:03:33.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:03:33.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:03:33.410+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:03:33.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:03:33.423+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:03:33.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:03:33.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-18T12:04:03.834+0000] {processor.py:157} INFO - Started process (PID=11944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:04:03.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:04:03.839+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:04:03.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:04:03.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:04:03.903+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:04:03.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:04:03.925+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:04:03.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:04:03.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-07-18T12:04:34.274+0000] {processor.py:157} INFO - Started process (PID=11969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:04:34.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:04:34.278+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:04:34.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:04:34.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:04:34.313+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:04:34.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:04:34.328+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:04:34.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:04:34.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-18T12:05:04.708+0000] {processor.py:157} INFO - Started process (PID=11994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:05:04.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:05:04.715+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:05:04.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:05:04.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:05:04.770+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:05:04.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:05:04.805+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:05:04.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:05:04.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-18T12:05:35.229+0000] {processor.py:157} INFO - Started process (PID=12019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:05:35.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:05:35.233+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:05:35.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:05:35.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:05:35.266+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:05:35.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:05:35.277+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:05:35.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:05:35.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-18T12:06:05.646+0000] {processor.py:157} INFO - Started process (PID=12044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:06:05.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:06:05.657+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:06:05.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:06:05.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:06:05.694+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:06:05.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:06:05.710+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:06:05.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:06:05.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-18T12:06:36.176+0000] {processor.py:157} INFO - Started process (PID=12069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:06:36.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:06:36.182+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:06:36.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:06:36.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:06:36.263+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:06:36.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:06:36.283+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:06:36.283+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:06:36.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-18T12:07:06.721+0000] {processor.py:157} INFO - Started process (PID=12094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:07:06.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:07:06.740+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:07:06.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:07:06.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:07:06.799+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:07:06.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:07:06.816+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:07:06.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:07:06.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-18T12:07:37.233+0000] {processor.py:157} INFO - Started process (PID=12119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:07:37.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:07:37.239+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:07:37.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:07:37.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:07:37.305+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:07:37.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:07:37.323+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:07:37.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:07:37.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-18T12:08:07.725+0000] {processor.py:157} INFO - Started process (PID=12147) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:08:07.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:08:07.732+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:08:07.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:08:07.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:08:07.793+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:08:07.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:08:07.813+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:08:07.813+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:08:07.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-18T12:08:38.182+0000] {processor.py:157} INFO - Started process (PID=12172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:08:38.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:08:38.185+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:08:38.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:08:38.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:08:38.225+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:08:38.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:08:38.238+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:08:38.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:08:38.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-18T12:09:08.706+0000] {processor.py:157} INFO - Started process (PID=12197) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:09:08.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:09:08.715+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:09:08.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:09:08.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:09:08.773+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:09:08.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:09:08.789+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:09:08.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:09:08.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-07-18T12:09:39.306+0000] {processor.py:157} INFO - Started process (PID=12232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:09:39.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:09:39.335+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:09:39.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:09:39.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:09:39.502+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:09:39.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:09:39.536+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:09:39.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:09:39.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.283 seconds
[2024-07-18T12:10:09.976+0000] {processor.py:157} INFO - Started process (PID=12656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:10:09.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:10:09.983+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:10:09.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:10:09.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:10:10.029+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:10:10.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:10:10.055+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:10:10.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:10:10.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-18T12:10:40.482+0000] {processor.py:157} INFO - Started process (PID=12681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:10:40.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:10:40.487+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:10:40.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:10:40.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:10:40.537+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:10:40.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:10:40.556+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:10:40.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:10:40.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-18T12:11:11.010+0000] {processor.py:157} INFO - Started process (PID=12706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:11:11.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:11:11.018+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:11:11.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:11:11.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:11:11.139+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:11:11.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:11:11.163+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:11:11.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:11:11.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.195 seconds
[2024-07-18T12:11:41.603+0000] {processor.py:157} INFO - Started process (PID=12731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:11:41.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:11:41.610+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:11:41.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:11:41.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:11:41.684+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:11:41.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:11:41.708+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:11:41.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:11:41.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-18T12:12:12.050+0000] {processor.py:157} INFO - Started process (PID=12888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:12:12.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:12:12.056+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:12:12.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:12:12.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:12:12.112+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:12:12.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:12:12.131+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:12:12.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:12:12.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-18T12:12:42.532+0000] {processor.py:157} INFO - Started process (PID=13178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:12:42.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:12:42.538+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:12:42.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:12:42.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:12:42.585+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:12:42.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:12:42.606+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:12:42.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:12:42.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-18T12:13:13.016+0000] {processor.py:157} INFO - Started process (PID=13203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:13:13.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:13:13.021+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:13:13.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:13:13.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:13:13.073+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:13:13.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:13:13.097+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:13:13.097+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:13:13.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-18T12:13:43.533+0000] {processor.py:157} INFO - Started process (PID=13228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:13:43.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:13:43.539+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:13:43.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:13:43.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:13:43.583+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:13:43.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:13:43.602+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:13:43.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:13:43.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-18T12:14:14.009+0000] {processor.py:157} INFO - Started process (PID=13253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:14:14.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:14:14.015+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:14:14.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:14:14.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:14:14.055+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:14:14.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:14:14.068+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:14:14.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:14:14.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-18T12:14:44.450+0000] {processor.py:157} INFO - Started process (PID=13679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:14:44.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:14:44.460+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:14:44.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:14:44.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:14:44.508+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:14:44.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:14:44.531+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:14:44.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:14:44.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-18T12:15:14.941+0000] {processor.py:157} INFO - Started process (PID=13704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:15:14.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:15:14.948+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:15:14.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:15:14.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:15:14.997+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:15:14.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:15:15.015+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:15:15.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:15:15.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-18T12:15:45.402+0000] {processor.py:157} INFO - Started process (PID=13729) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:15:45.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:15:45.405+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:15:45.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:15:45.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:15:45.438+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:15:45.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:15:45.453+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:15:45.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:15:45.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-18T12:16:16.312+0000] {processor.py:157} INFO - Started process (PID=13754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:16:16.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:16:16.315+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:16:16.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:16:16.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:16:16.356+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:16:16.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:16:16.374+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:16:16.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:16:16.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-18T12:16:46.732+0000] {processor.py:157} INFO - Started process (PID=13782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:16:46.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:16:46.738+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:16:46.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:16:46.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:16:46.775+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:16:46.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:16:46.790+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:16:46.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:16:46.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-18T12:17:17.147+0000] {processor.py:157} INFO - Started process (PID=13807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:17:17.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:17:17.151+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:17:17.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:17:17.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:17:17.185+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:17:17.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:17:17.199+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:17:17.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:17:17.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-18T12:17:47.543+0000] {processor.py:157} INFO - Started process (PID=13832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:17:47.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:17:47.548+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:17:47.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:17:47.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:17:47.582+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:17:47.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:17:47.598+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:17:47.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:17:47.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-18T12:18:17.974+0000] {processor.py:157} INFO - Started process (PID=13857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:18:17.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:18:17.976+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:18:17.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:18:17.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:18:18.012+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:18:18.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:18:18.026+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:18:18.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:18:18.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-18T12:18:48.407+0000] {processor.py:157} INFO - Started process (PID=13882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:18:48.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:18:48.414+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:18:48.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:18:48.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:18:48.454+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:18:48.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:18:48.468+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:18:48.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:18:48.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-18T12:19:18.821+0000] {processor.py:157} INFO - Started process (PID=13907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:19:18.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:19:18.825+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:19:18.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:19:18.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:19:18.858+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:19:18.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:19:18.871+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:19:18.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:19:18.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-18T12:19:49.211+0000] {processor.py:157} INFO - Started process (PID=13932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:19:49.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:19:49.214+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:19:49.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:19:49.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:19:49.248+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:19:49.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:19:49.261+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:19:49.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:19:49.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-18T12:20:19.631+0000] {processor.py:157} INFO - Started process (PID=13957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:20:19.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:20:19.634+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:20:19.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:20:19.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:20:19.670+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:20:19.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:20:19.682+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:20:19.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:20:19.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-18T12:20:50.064+0000] {processor.py:157} INFO - Started process (PID=13982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:20:50.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:20:50.071+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:20:50.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:20:50.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:20:50.107+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:20:50.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:20:50.119+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:20:50.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:20:50.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-18T12:22:03.164+0000] {processor.py:157} INFO - Started process (PID=14012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:22:03.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:22:03.167+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:22:03.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:22:03.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:22:03.193+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:22:03.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:22:03.204+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:22:03.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:22:03.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T12:22:33.712+0000] {processor.py:157} INFO - Started process (PID=14037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:22:33.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:22:33.718+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:22:33.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:22:33.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:22:33.751+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:22:33.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:22:33.763+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:22:33.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:22:33.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-18T12:23:04.537+0000] {processor.py:157} INFO - Started process (PID=14062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:23:04.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:23:04.539+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:23:04.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:23:04.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:23:04.571+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:23:04.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:23:04.582+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:23:04.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:23:04.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T12:41:06.904+0000] {processor.py:157} INFO - Started process (PID=14087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:41:06.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:41:06.910+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:41:06.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:41:06.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:41:06.947+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:41:06.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:41:06.958+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:41:06.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:41:06.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-18T12:41:37.342+0000] {processor.py:157} INFO - Started process (PID=14110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:41:37.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:41:37.347+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:41:37.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:41:37.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:41:37.402+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:41:37.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:41:37.418+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:41:37.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:41:37.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-18T12:42:07.959+0000] {processor.py:157} INFO - Started process (PID=14137) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:42:07.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:42:07.965+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:42:07.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:42:07.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:42:08.000+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:42:08.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:42:08.013+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:42:08.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:42:08.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-18T12:42:38.470+0000] {processor.py:157} INFO - Started process (PID=14162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:42:38.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:42:38.473+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:42:38.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:42:38.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:42:38.504+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:42:38.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:42:38.515+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:42:38.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:42:38.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-18T12:43:08.928+0000] {processor.py:157} INFO - Started process (PID=14187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:43:08.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:43:08.932+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:43:08.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:43:08.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:43:08.960+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:43:08.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:43:08.970+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:43:08.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:43:08.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T12:43:39.345+0000] {processor.py:157} INFO - Started process (PID=14212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:43:39.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:43:39.348+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:43:39.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:43:39.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:43:39.377+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:43:39.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:43:39.390+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:43:39.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:43:39.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T12:44:09.845+0000] {processor.py:157} INFO - Started process (PID=14237) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:44:09.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:44:09.850+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:44:09.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:44:09.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:44:09.885+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:44:09.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:44:09.897+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:44:09.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:44:09.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-18T12:44:40.286+0000] {processor.py:157} INFO - Started process (PID=14262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:44:40.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:44:40.290+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:44:40.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:44:40.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:44:40.319+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:44:40.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:44:40.331+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:44:40.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:44:40.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T12:45:10.713+0000] {processor.py:157} INFO - Started process (PID=14287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:45:10.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:45:10.717+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:45:10.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:45:10.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:45:10.747+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:45:10.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:45:10.758+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:45:10.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:45:10.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T12:45:41.188+0000] {processor.py:157} INFO - Started process (PID=14312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:45:41.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:45:41.191+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:45:41.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:45:41.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:45:41.222+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:45:41.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:45:41.234+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:45:41.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:45:41.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T12:46:11.656+0000] {processor.py:157} INFO - Started process (PID=14337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:46:11.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:46:11.658+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:46:11.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:46:11.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:46:11.686+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:46:11.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:46:11.696+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:46:11.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:46:11.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T12:46:42.186+0000] {processor.py:157} INFO - Started process (PID=14362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:46:42.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:46:42.189+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:46:42.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:46:42.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:46:42.217+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:46:42.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:46:42.226+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:46:42.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:46:42.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T12:47:12.636+0000] {processor.py:157} INFO - Started process (PID=14387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:47:12.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:47:12.638+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:47:12.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:47:12.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:47:12.667+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:47:12.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:47:12.678+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:47:12.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:47:12.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T12:47:43.205+0000] {processor.py:157} INFO - Started process (PID=14412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:47:43.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:47:43.209+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:47:43.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:47:43.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:47:43.237+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:47:43.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:47:43.248+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:47:43.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:47:43.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T12:48:13.666+0000] {processor.py:157} INFO - Started process (PID=14437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:48:13.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:48:13.668+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:48:13.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:48:13.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:48:13.698+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:48:13.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:48:13.709+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:48:13.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:48:13.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T12:48:44.084+0000] {processor.py:157} INFO - Started process (PID=14462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:48:44.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:48:44.087+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:48:44.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:48:44.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:48:44.119+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:48:44.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:48:44.130+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:48:44.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:48:44.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T12:49:14.612+0000] {processor.py:157} INFO - Started process (PID=14487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:49:14.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:49:14.614+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:49:14.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:49:14.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:49:14.643+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:49:14.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:49:14.655+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:49:14.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:49:14.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T12:49:45.051+0000] {processor.py:157} INFO - Started process (PID=14512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:49:45.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:49:45.056+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:49:45.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:49:45.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:49:45.095+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:49:45.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:49:45.108+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:49:45.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:49:45.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-18T12:50:15.495+0000] {processor.py:157} INFO - Started process (PID=14537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:50:15.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:50:15.498+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:50:15.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:50:15.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:50:15.549+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:50:15.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:50:15.563+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:50:15.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:50:15.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-18T12:50:46.036+0000] {processor.py:157} INFO - Started process (PID=14562) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:50:46.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:50:46.045+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:50:46.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:50:46.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:50:46.075+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:50:46.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:50:46.085+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:50:46.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:50:46.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-18T12:51:16.484+0000] {processor.py:157} INFO - Started process (PID=14587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:51:16.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:51:16.487+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:51:16.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:51:16.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:51:16.513+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:51:16.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:51:16.523+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:51:16.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:51:16.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T12:51:46.892+0000] {processor.py:157} INFO - Started process (PID=14612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:51:46.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:51:46.895+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:51:46.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:51:46.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:51:46.922+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:51:46.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:51:46.934+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:51:46.934+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:51:46.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T12:52:17.352+0000] {processor.py:157} INFO - Started process (PID=14637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:52:17.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:52:17.355+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:52:17.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:52:17.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:52:17.384+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:52:17.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:52:17.394+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:52:17.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:52:17.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T12:52:47.861+0000] {processor.py:157} INFO - Started process (PID=14662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:52:47.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:52:47.866+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:52:47.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:52:47.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:52:47.895+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:52:47.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:52:47.904+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:52:47.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:52:47.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T12:53:18.267+0000] {processor.py:157} INFO - Started process (PID=14687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:53:18.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:53:18.271+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:53:18.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:53:18.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:53:18.298+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:53:18.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:53:18.311+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:53:18.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:53:18.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T12:53:48.828+0000] {processor.py:157} INFO - Started process (PID=14712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:53:48.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:53:48.832+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:53:48.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:53:48.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:53:48.862+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:53:48.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:53:48.873+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:53:48.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:53:48.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T12:54:19.371+0000] {processor.py:157} INFO - Started process (PID=14737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:54:19.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:54:19.376+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:54:19.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:54:19.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:54:19.425+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:54:19.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:54:19.448+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:54:19.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:54:19.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-18T12:54:49.877+0000] {processor.py:157} INFO - Started process (PID=14762) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:54:49.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:54:49.880+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:54:49.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:54:49.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:54:49.907+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:54:49.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:54:49.917+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:54:49.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:54:49.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T12:55:20.280+0000] {processor.py:157} INFO - Started process (PID=14787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:55:20.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:55:20.284+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:55:20.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:55:20.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:55:20.314+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:55:20.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:55:20.324+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:55:20.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:55:20.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T12:55:50.731+0000] {processor.py:157} INFO - Started process (PID=14812) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:55:50.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:55:50.736+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:55:50.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:55:50.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:55:50.768+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:55:50.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:55:50.778+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:55:50.778+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:55:50.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T12:56:21.135+0000] {processor.py:157} INFO - Started process (PID=14837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:56:21.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:56:21.140+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:56:21.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:56:21.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:56:21.167+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:56:21.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:56:21.179+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:56:21.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:56:21.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T12:56:51.566+0000] {processor.py:157} INFO - Started process (PID=14862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:56:51.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:56:51.569+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:56:51.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:56:51.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:56:51.598+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:56:51.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:56:51.607+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:56:51.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:56:51.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T12:57:22.003+0000] {processor.py:157} INFO - Started process (PID=14887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:57:22.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:57:22.006+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:57:22.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:57:22.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:57:22.034+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:57:22.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:57:22.045+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:57:22.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:57:22.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T12:57:52.392+0000] {processor.py:157} INFO - Started process (PID=14912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:57:52.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:57:52.395+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:57:52.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:57:52.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:57:52.423+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:57:52.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:57:52.435+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:57:52.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:57:52.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T12:58:22.806+0000] {processor.py:157} INFO - Started process (PID=14937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:58:22.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:58:22.811+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:58:22.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:58:22.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:58:22.842+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:58:22.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:58:22.854+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:58:22.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:58:22.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T12:58:53.272+0000] {processor.py:157} INFO - Started process (PID=14962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:58:53.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:58:53.277+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:58:53.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:58:53.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:58:53.306+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:58:53.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:58:53.318+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:58:53.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:58:53.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T12:59:23.713+0000] {processor.py:157} INFO - Started process (PID=14987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:59:23.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:59:23.716+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:59:23.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:59:23.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:59:23.745+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:59:23.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:59:23.755+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:59:23.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:59:23.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T12:59:54.143+0000] {processor.py:157} INFO - Started process (PID=15012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:59:54.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T12:59:54.146+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:59:54.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:59:54.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T12:59:54.173+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:59:54.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:59:54.183+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:59:54.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T12:59:54.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T13:00:24.632+0000] {processor.py:157} INFO - Started process (PID=15037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:00:24.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:00:24.638+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:00:24.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:00:24.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:00:24.680+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:00:24.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:00:24.698+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:00:24.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:00:24.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-18T13:00:55.135+0000] {processor.py:157} INFO - Started process (PID=15062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:00:55.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:00:55.138+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:00:55.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:00:55.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:00:55.168+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:00:55.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:00:55.178+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:00:55.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:00:55.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T13:01:25.645+0000] {processor.py:157} INFO - Started process (PID=15087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:01:25.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:01:25.648+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:01:25.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:01:25.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:01:25.675+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:01:25.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:01:25.685+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:01:25.685+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:01:25.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T13:01:56.103+0000] {processor.py:157} INFO - Started process (PID=15112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:01:56.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:01:56.106+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:01:56.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:01:56.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:01:56.135+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:01:56.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:01:56.146+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:01:56.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:01:56.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T13:02:26.465+0000] {processor.py:157} INFO - Started process (PID=15137) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:02:26.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:02:26.468+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:02:26.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:02:26.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:02:26.497+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:02:26.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:02:26.506+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:02:26.506+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:02:26.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T13:02:56.999+0000] {processor.py:157} INFO - Started process (PID=15162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:02:57.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:02:57.003+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:02:57.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:02:57.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:02:57.030+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:02:57.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:02:57.040+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:02:57.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:02:57.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T13:03:27.397+0000] {processor.py:157} INFO - Started process (PID=15187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:03:27.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:03:27.400+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:03:27.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:03:27.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:03:27.425+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:03:27.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:03:27.437+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:03:27.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:03:27.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T13:04:06.300+0000] {processor.py:157} INFO - Started process (PID=15212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:04:06.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:04:06.303+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:04:06.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:04:06.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:04:06.330+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:04:06.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:04:06.339+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:04:06.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:04:06.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T13:04:36.761+0000] {processor.py:157} INFO - Started process (PID=15239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:04:36.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:04:36.764+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:04:36.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:04:36.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:04:36.791+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:04:36.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:04:36.800+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:04:36.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:04:36.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T13:12:35.823+0000] {processor.py:157} INFO - Started process (PID=15266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:12:35.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:12:35.825+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:12:35.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:12:35.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:12:35.849+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:12:35.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:12:35.858+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:12:35.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:12:35.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-18T13:13:06.248+0000] {processor.py:157} INFO - Started process (PID=15291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:13:06.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:13:06.255+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:13:06.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:13:06.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:13:06.284+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:13:06.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:13:06.299+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:13:06.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:13:06.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-18T13:28:36.412+0000] {processor.py:157} INFO - Started process (PID=15318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:28:36.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:28:36.417+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:28:36.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:28:36.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:28:36.459+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:28:36.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:28:36.478+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:28:36.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:28:36.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-18T13:45:19.218+0000] {processor.py:157} INFO - Started process (PID=15343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:45:19.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:45:19.223+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:45:19.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:45:19.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:45:19.249+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:45:19.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:45:19.261+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:45:19.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:45:19.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T13:45:49.689+0000] {processor.py:157} INFO - Started process (PID=15368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:45:49.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:45:49.695+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:45:49.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:45:49.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:45:49.747+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:45:49.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:45:49.766+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:45:49.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:45:49.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-18T13:46:20.155+0000] {processor.py:157} INFO - Started process (PID=15393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:46:20.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:46:20.159+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:46:20.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:46:20.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:46:20.185+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:46:20.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:46:20.196+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:46:20.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:46:20.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T13:46:50.686+0000] {processor.py:157} INFO - Started process (PID=15418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:46:50.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:46:50.689+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:46:50.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:46:50.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:46:50.716+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:46:50.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:46:50.728+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:46:50.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:46:50.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T13:47:21.132+0000] {processor.py:157} INFO - Started process (PID=15443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:47:21.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:47:21.134+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:47:21.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:47:21.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:47:21.166+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:47:21.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:47:21.177+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:47:21.177+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:47:21.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T13:47:51.545+0000] {processor.py:157} INFO - Started process (PID=15468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:47:51.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:47:51.547+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:47:51.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:47:51.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:47:51.577+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:47:51.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:47:51.588+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:47:51.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:47:51.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T13:48:21.990+0000] {processor.py:157} INFO - Started process (PID=15493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:48:21.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:48:21.994+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:48:21.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:48:22.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:48:22.025+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:48:22.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:48:22.034+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:48:22.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:48:22.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T13:48:52.403+0000] {processor.py:157} INFO - Started process (PID=15518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:48:52.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:48:52.406+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:48:52.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:48:52.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:48:52.436+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:48:52.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:48:52.446+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:48:52.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:48:52.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T13:49:22.848+0000] {processor.py:157} INFO - Started process (PID=15543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:49:22.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:49:22.854+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:49:22.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:49:22.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:49:22.884+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:49:22.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:49:22.893+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:49:22.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:49:22.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T13:49:53.268+0000] {processor.py:157} INFO - Started process (PID=15568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:49:53.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:49:53.272+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:49:53.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:49:53.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:49:53.314+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:49:53.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:49:53.326+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:49:53.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:49:53.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-18T13:50:23.761+0000] {processor.py:157} INFO - Started process (PID=15593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:50:23.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:50:23.763+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:50:23.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:50:23.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:50:23.791+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:50:23.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:50:23.803+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:50:23.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:50:23.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T13:50:54.214+0000] {processor.py:157} INFO - Started process (PID=15618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:50:54.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:50:54.216+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:50:54.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:50:54.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:50:54.246+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:50:54.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:50:54.257+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:50:54.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:50:54.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T13:51:24.598+0000] {processor.py:157} INFO - Started process (PID=15643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:51:24.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:51:24.600+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:51:24.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:51:24.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:51:24.626+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:51:24.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:51:24.635+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:51:24.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:51:24.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-18T13:51:55.005+0000] {processor.py:157} INFO - Started process (PID=15668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:51:55.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:51:55.007+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:51:55.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:51:55.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:51:55.035+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:51:55.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:51:55.045+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:51:55.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:51:55.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T13:52:25.418+0000] {processor.py:157} INFO - Started process (PID=15693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:52:25.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:52:25.421+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:52:25.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:52:25.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:52:25.449+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:52:25.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:52:25.457+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:52:25.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:52:25.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T13:52:55.843+0000] {processor.py:157} INFO - Started process (PID=15718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:52:55.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:52:55.848+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:52:55.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:52:55.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:52:55.880+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:52:55.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:52:55.891+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:52:55.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:52:55.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-18T13:53:26.280+0000] {processor.py:157} INFO - Started process (PID=15743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:53:26.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:53:26.284+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:53:26.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:53:26.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:53:26.317+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:53:26.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:53:26.329+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:53:26.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:53:26.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T13:53:56.769+0000] {processor.py:157} INFO - Started process (PID=15768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:53:56.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:53:56.772+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:53:56.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:53:56.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:53:56.801+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:53:56.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:53:56.812+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:53:56.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:53:56.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T13:54:27.155+0000] {processor.py:157} INFO - Started process (PID=15793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:54:27.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:54:27.157+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:54:27.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:54:27.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:54:27.187+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:54:27.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:54:27.199+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:54:27.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:54:27.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T13:54:57.537+0000] {processor.py:157} INFO - Started process (PID=15818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:54:57.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:54:57.539+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:54:57.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:54:57.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:54:57.568+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:54:57.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:54:57.578+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:54:57.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:54:57.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T13:55:28.005+0000] {processor.py:157} INFO - Started process (PID=15843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:55:28.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:55:28.008+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:55:28.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:55:28.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:55:28.039+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:55:28.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:55:28.049+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:55:28.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:55:28.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T13:55:58.430+0000] {processor.py:157} INFO - Started process (PID=15868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:55:58.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:55:58.433+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:55:58.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:55:58.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:55:58.460+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:55:58.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:55:58.470+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:55:58.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:55:58.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T13:56:28.859+0000] {processor.py:157} INFO - Started process (PID=15893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:56:28.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:56:28.862+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:56:28.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:56:28.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:56:28.888+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:56:28.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:56:28.901+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:56:28.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:56:28.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T13:56:59.324+0000] {processor.py:157} INFO - Started process (PID=15918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:56:59.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:56:59.331+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:56:59.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:56:59.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:56:59.368+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:56:59.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:56:59.380+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:56:59.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:56:59.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-18T13:57:29.791+0000] {processor.py:157} INFO - Started process (PID=15943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:57:29.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:57:29.798+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:57:29.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:57:29.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:57:29.820+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:57:29.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:57:29.829+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:57:29.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:57:29.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T13:58:00.223+0000] {processor.py:157} INFO - Started process (PID=15968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:58:00.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:58:00.225+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:58:00.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:58:00.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:58:00.256+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:58:00.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:58:00.267+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:58:00.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:58:00.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T13:58:30.673+0000] {processor.py:157} INFO - Started process (PID=15993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:58:30.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:58:30.675+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:58:30.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:58:30.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:58:30.701+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:58:30.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:58:30.713+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:58:30.713+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:58:30.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T13:59:01.114+0000] {processor.py:157} INFO - Started process (PID=16018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:59:01.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:59:01.117+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:59:01.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:59:01.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:59:01.149+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:59:01.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:59:01.160+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:59:01.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:59:01.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T13:59:31.577+0000] {processor.py:157} INFO - Started process (PID=16043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:59:31.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T13:59:31.579+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:59:31.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:59:31.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T13:59:31.606+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:59:31.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:59:31.618+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:59:31.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T13:59:31.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T14:00:02.029+0000] {processor.py:157} INFO - Started process (PID=16068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:00:02.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:00:02.034+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:00:02.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:00:02.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:00:02.061+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:00:02.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:00:02.073+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:00:02.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:00:02.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T14:00:32.523+0000] {processor.py:157} INFO - Started process (PID=16093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:00:32.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:00:32.526+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:00:32.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:00:32.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:00:32.552+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:00:32.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:00:32.564+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:00:32.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:00:32.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T14:01:03.050+0000] {processor.py:157} INFO - Started process (PID=16118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:01:03.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:01:03.052+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:01:03.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:01:03.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:01:03.075+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:01:03.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:01:03.089+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:01:03.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:01:03.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T14:01:33.465+0000] {processor.py:157} INFO - Started process (PID=16143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:01:33.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:01:33.468+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:01:33.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:01:33.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:01:33.495+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:01:33.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:01:33.507+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:01:33.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:01:33.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T14:02:03.935+0000] {processor.py:157} INFO - Started process (PID=16168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:02:03.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:02:03.938+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:02:03.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:02:03.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:02:03.962+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:02:03.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:02:03.972+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:02:03.972+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:02:03.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-18T14:02:34.390+0000] {processor.py:157} INFO - Started process (PID=16193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:02:34.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:02:34.395+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:02:34.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:02:34.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:02:34.423+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:02:34.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:02:34.432+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:02:34.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:02:34.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T14:03:04.898+0000] {processor.py:157} INFO - Started process (PID=16218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:03:04.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:03:04.901+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:03:04.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:03:04.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:03:04.929+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:03:04.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:03:04.938+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:03:04.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:03:04.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T14:03:35.368+0000] {processor.py:157} INFO - Started process (PID=16243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:03:35.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:03:35.371+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:03:35.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:03:35.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:03:35.397+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:03:35.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:03:35.406+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:03:35.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:03:35.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T14:04:05.798+0000] {processor.py:157} INFO - Started process (PID=16268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:04:05.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:04:05.802+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:04:05.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:04:05.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:04:05.829+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:04:05.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:04:05.838+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:04:05.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:04:05.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T14:04:36.283+0000] {processor.py:157} INFO - Started process (PID=16293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:04:36.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:04:36.286+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:04:36.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:04:36.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:04:36.314+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:04:36.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:04:36.327+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:04:36.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:04:36.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T14:05:06.757+0000] {processor.py:157} INFO - Started process (PID=16318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:05:06.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:05:06.761+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:05:06.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:05:06.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:05:06.791+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:05:06.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:05:06.802+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:05:06.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:05:06.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T14:05:37.190+0000] {processor.py:157} INFO - Started process (PID=16343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:05:37.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:05:37.192+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:05:37.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:05:37.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:05:37.223+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:05:37.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:05:37.234+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:05:37.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:05:37.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T14:06:07.603+0000] {processor.py:157} INFO - Started process (PID=16368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:06:07.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:06:07.606+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:06:07.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:06:07.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:06:07.633+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:06:07.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:06:07.645+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:06:07.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:06:07.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T14:06:38.079+0000] {processor.py:157} INFO - Started process (PID=16393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:06:38.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:06:38.082+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:06:38.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:06:38.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:06:38.108+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:06:38.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:06:38.117+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:06:38.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:06:38.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-18T14:07:08.533+0000] {processor.py:157} INFO - Started process (PID=16418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:07:08.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:07:08.535+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:07:08.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:07:08.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:07:08.559+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:07:08.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:07:08.571+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:07:08.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:07:08.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-18T14:07:39.011+0000] {processor.py:157} INFO - Started process (PID=16443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:07:39.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:07:39.014+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:07:39.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:07:39.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:07:39.041+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:07:39.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:07:39.053+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:07:39.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:07:39.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T14:08:09.425+0000] {processor.py:157} INFO - Started process (PID=16468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:08:09.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:08:09.427+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:08:09.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:08:09.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:08:09.451+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:08:09.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:08:09.463+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:08:09.463+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:08:09.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-18T14:08:39.902+0000] {processor.py:157} INFO - Started process (PID=16493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:08:39.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:08:39.905+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:08:39.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:08:39.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:08:39.932+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:08:39.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:08:39.944+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:08:39.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:08:39.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T14:09:10.444+0000] {processor.py:157} INFO - Started process (PID=16518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:09:10.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:09:10.447+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:09:10.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:09:10.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:09:10.472+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:09:10.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:09:10.482+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:09:10.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:09:10.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T14:09:40.850+0000] {processor.py:157} INFO - Started process (PID=16543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:09:40.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:09:40.853+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:09:40.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:09:40.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:09:40.890+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:09:40.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:09:40.901+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:09:40.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:09:40.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-18T14:10:11.303+0000] {processor.py:157} INFO - Started process (PID=16568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:10:11.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:10:11.306+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:10:11.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:10:11.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:10:11.336+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:10:11.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:10:11.346+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:10:11.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:10:11.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T14:10:41.759+0000] {processor.py:157} INFO - Started process (PID=16593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:10:41.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:10:41.764+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:10:41.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:10:41.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:10:41.791+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:10:41.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:10:41.803+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:10:41.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:10:41.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T14:11:12.224+0000] {processor.py:157} INFO - Started process (PID=16618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:11:12.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:11:12.229+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:11:12.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:11:12.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:11:12.259+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:11:12.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:11:12.269+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:11:12.269+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:11:12.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T14:11:42.703+0000] {processor.py:157} INFO - Started process (PID=16643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:11:42.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:11:42.706+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:11:42.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:11:42.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:11:42.735+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:11:42.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:11:42.746+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:11:42.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:11:42.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T14:12:13.182+0000] {processor.py:157} INFO - Started process (PID=16668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:12:13.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:12:13.185+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:12:13.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:12:13.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:12:13.212+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:12:13.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:12:13.222+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:12:13.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:12:13.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T14:12:43.611+0000] {processor.py:157} INFO - Started process (PID=16693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:12:43.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:12:43.614+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:12:43.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:12:43.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:12:43.640+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:12:43.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:12:43.651+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:12:43.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:12:43.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T14:13:13.972+0000] {processor.py:157} INFO - Started process (PID=16718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:13:13.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:13:13.976+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:13:13.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:13:13.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:13:14.006+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:13:14.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:13:14.016+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:13:14.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:13:14.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T14:13:44.446+0000] {processor.py:157} INFO - Started process (PID=16743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:13:44.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:13:44.449+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:13:44.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:13:44.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:13:44.481+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:13:44.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:13:44.493+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:13:44.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:13:44.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-18T14:14:14.929+0000] {processor.py:157} INFO - Started process (PID=16768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:14:14.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:14:14.931+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:14:14.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:14:14.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:14:14.957+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:14:14.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:14:14.966+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:14:14.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:14:14.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-18T14:14:45.444+0000] {processor.py:157} INFO - Started process (PID=16793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:14:45.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:14:45.447+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:14:45.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:14:45.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:14:45.473+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:14:45.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:14:45.483+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:14:45.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:14:45.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T14:15:15.945+0000] {processor.py:157} INFO - Started process (PID=16818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:15:15.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:15:15.948+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:15:15.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:15:15.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:15:15.978+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:15:15.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:15:15.988+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:15:15.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:15:15.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T14:15:46.460+0000] {processor.py:157} INFO - Started process (PID=16843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:15:46.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:15:46.463+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:15:46.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:15:46.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:15:46.493+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:15:46.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:15:46.504+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:15:46.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:15:46.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T14:16:16.889+0000] {processor.py:157} INFO - Started process (PID=16868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:16:16.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:16:16.891+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:16:16.891+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:16:16.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:16:16.916+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:16:16.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:16:16.926+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:16:16.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:16:16.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T14:16:47.369+0000] {processor.py:157} INFO - Started process (PID=16893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:16:47.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:16:47.375+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:16:47.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:16:47.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:16:47.416+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:16:47.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:16:47.428+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:16:47.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:16:47.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-18T14:17:17.873+0000] {processor.py:157} INFO - Started process (PID=16918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:17:17.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:17:17.877+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:17:17.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:17:17.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:17:17.907+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:17:17.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:17:17.921+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:17:17.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:17:17.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-18T14:17:48.300+0000] {processor.py:157} INFO - Started process (PID=16943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:17:48.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:17:48.304+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:17:48.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:17:48.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:17:48.332+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:17:48.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:17:48.341+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:17:48.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:17:48.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T14:18:18.715+0000] {processor.py:157} INFO - Started process (PID=16968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:18:18.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:18:18.718+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:18:18.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:18:18.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:18:18.746+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:18:18.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:18:18.757+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:18:18.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:18:18.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T14:18:49.157+0000] {processor.py:157} INFO - Started process (PID=16993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:18:49.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:18:49.160+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:18:49.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:18:49.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:18:49.187+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:18:49.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:18:49.198+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:18:49.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:18:49.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T14:19:19.618+0000] {processor.py:157} INFO - Started process (PID=17018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:19:19.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:19:19.622+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:19:19.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:19:19.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:19:19.651+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:19:19.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:19:19.662+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:19:19.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:19:19.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T14:19:50.069+0000] {processor.py:157} INFO - Started process (PID=17043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:19:50.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:19:50.072+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:19:50.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:19:50.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:19:50.098+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:19:50.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:19:50.107+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:19:50.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:19:50.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-18T14:20:20.534+0000] {processor.py:157} INFO - Started process (PID=17068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:20:20.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:20:20.538+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:20:20.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:20:20.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:20:20.565+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:20:20.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:20:20.577+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:20:20.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:20:20.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T14:20:50.972+0000] {processor.py:157} INFO - Started process (PID=17093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:20:50.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:20:50.976+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:20:50.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:20:50.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:20:51.004+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:20:51.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:20:51.014+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:20:51.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:20:51.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T14:21:21.466+0000] {processor.py:157} INFO - Started process (PID=17118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:21:21.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:21:21.469+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:21:21.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:21:21.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:21:21.496+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:21:21.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:21:21.505+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:21:21.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:21:21.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T14:21:51.882+0000] {processor.py:157} INFO - Started process (PID=17143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:21:51.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:21:51.885+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:21:51.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:21:51.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:21:51.909+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:21:51.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:21:51.919+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:21:51.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:21:51.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-18T14:22:22.355+0000] {processor.py:157} INFO - Started process (PID=17168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:22:22.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:22:22.359+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:22:22.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:22:22.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:22:22.387+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:22:22.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:22:22.397+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:22:22.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:22:22.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T14:22:52.831+0000] {processor.py:157} INFO - Started process (PID=17193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:22:52.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:22:52.835+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:22:52.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:22:52.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:22:52.861+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:22:52.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:22:52.870+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:22:52.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:22:52.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T14:23:23.208+0000] {processor.py:157} INFO - Started process (PID=17218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:23:23.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:23:23.211+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:23:23.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:23:23.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:23:23.237+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:23:23.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:23:23.248+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:23:23.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:23:23.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T14:23:53.660+0000] {processor.py:157} INFO - Started process (PID=17243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:23:53.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:23:53.662+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:23:53.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:23:53.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:23:53.685+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:23:53.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:23:53.695+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:23:53.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:23:53.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-18T14:24:24.139+0000] {processor.py:157} INFO - Started process (PID=17268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:24:24.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:24:24.142+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:24:24.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:24:24.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:24:24.170+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:24:24.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:24:24.182+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:24:24.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:24:24.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T14:24:54.552+0000] {processor.py:157} INFO - Started process (PID=17293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:24:54.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:24:54.557+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:24:54.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:24:54.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:24:54.585+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:24:54.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:24:54.597+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:24:54.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:24:54.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T14:25:25.051+0000] {processor.py:157} INFO - Started process (PID=17318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:25:25.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:25:25.055+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:25:25.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:25:25.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:25:25.081+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:25:25.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:25:25.094+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:25:25.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:25:25.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T14:25:55.463+0000] {processor.py:157} INFO - Started process (PID=17343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:25:55.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:25:55.466+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:25:55.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:25:55.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:25:55.493+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:25:55.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:25:55.505+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:25:55.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:25:55.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T14:26:25.857+0000] {processor.py:157} INFO - Started process (PID=17368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:26:25.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:26:25.861+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:26:25.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:26:25.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:26:25.888+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:26:25.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:26:25.897+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:26:25.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:26:25.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T14:26:56.273+0000] {processor.py:157} INFO - Started process (PID=17393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:26:56.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:26:56.276+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:26:56.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:26:56.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:26:56.305+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:26:56.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:26:56.317+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:26:56.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:26:56.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T14:27:26.672+0000] {processor.py:157} INFO - Started process (PID=17418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:27:26.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:27:26.675+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:27:26.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:27:26.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:27:26.702+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:27:26.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:27:26.712+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:27:26.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:27:26.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T14:27:57.136+0000] {processor.py:157} INFO - Started process (PID=17443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:27:57.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:27:57.139+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:27:57.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:27:57.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:27:57.167+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:27:57.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:27:57.179+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:27:57.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:27:57.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T14:28:27.587+0000] {processor.py:157} INFO - Started process (PID=17468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:28:27.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:28:27.590+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:28:27.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:28:27.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:28:27.612+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:28:27.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:28:27.624+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:28:27.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:28:27.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-18T14:28:57.990+0000] {processor.py:157} INFO - Started process (PID=17493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:28:57.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:28:57.993+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:28:57.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:28:58.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:28:58.018+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:28:58.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:28:58.027+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:28:58.027+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:28:58.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-18T14:29:28.427+0000] {processor.py:157} INFO - Started process (PID=17518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:29:28.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:29:28.431+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:29:28.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:29:28.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:29:28.461+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:29:28.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:29:28.470+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:29:28.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:29:28.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T14:29:58.826+0000] {processor.py:157} INFO - Started process (PID=17543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:29:58.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:29:58.829+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:29:58.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:29:58.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:29:58.860+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:29:58.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:29:58.871+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:29:58.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:29:58.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T14:30:29.329+0000] {processor.py:157} INFO - Started process (PID=17568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:30:29.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:30:29.333+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:30:29.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:30:29.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:30:29.362+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:30:29.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:30:29.373+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:30:29.372+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:30:29.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T14:30:59.795+0000] {processor.py:157} INFO - Started process (PID=17593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:30:59.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:30:59.798+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:30:59.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:30:59.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:30:59.824+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:30:59.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:30:59.835+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:30:59.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:30:59.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T14:31:30.233+0000] {processor.py:157} INFO - Started process (PID=17618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:31:30.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:31:30.237+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:31:30.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:31:30.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:31:30.261+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:31:30.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:31:30.271+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:31:30.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:31:30.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T14:32:00.559+0000] {processor.py:157} INFO - Started process (PID=17643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:32:00.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:32:00.567+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:32:00.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:32:00.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:32:00.604+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:32:00.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:32:00.615+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:32:00.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:32:00.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-18T14:32:31.009+0000] {processor.py:157} INFO - Started process (PID=17668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:32:31.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:32:31.013+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:32:31.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:32:31.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:32:31.041+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:32:31.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:32:31.052+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:32:31.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:32:31.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T14:33:01.473+0000] {processor.py:157} INFO - Started process (PID=17693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:33:01.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:33:01.475+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:33:01.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:33:01.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:33:01.502+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:33:01.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:33:01.514+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:33:01.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:33:01.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T14:33:31.855+0000] {processor.py:157} INFO - Started process (PID=17718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:33:31.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:33:31.858+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:33:31.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:33:31.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:33:31.886+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:33:31.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:33:31.898+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:33:31.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:33:31.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T14:34:02.311+0000] {processor.py:157} INFO - Started process (PID=17743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:34:02.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:34:02.314+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:34:02.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:34:02.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:34:02.344+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:34:02.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:34:02.353+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:34:02.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:34:02.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T14:34:32.719+0000] {processor.py:157} INFO - Started process (PID=17768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:34:32.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:34:32.721+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:34:32.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:34:32.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:34:32.749+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:34:32.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:34:32.762+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:34:32.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:34:32.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T14:35:03.172+0000] {processor.py:157} INFO - Started process (PID=17793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:35:03.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:35:03.174+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:35:03.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:35:03.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:35:03.204+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:35:03.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:35:03.217+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:35:03.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:35:03.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T14:35:33.620+0000] {processor.py:157} INFO - Started process (PID=17818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:35:33.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:35:33.624+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:35:33.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:35:33.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:35:33.651+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:35:33.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:35:33.662+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:35:33.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:35:33.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T14:36:04.096+0000] {processor.py:157} INFO - Started process (PID=17843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:36:04.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:36:04.101+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:36:04.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:36:04.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:36:04.127+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:36:04.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:36:04.137+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:36:04.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:36:04.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T14:36:34.568+0000] {processor.py:157} INFO - Started process (PID=17868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:36:34.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:36:34.571+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:36:34.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:36:34.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:36:34.596+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:36:34.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:36:34.608+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:36:34.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:36:34.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T14:37:04.995+0000] {processor.py:157} INFO - Started process (PID=17893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:37:04.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:37:04.998+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:37:04.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:37:05.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:37:05.027+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:37:05.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:37:05.038+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:37:05.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:37:05.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T14:37:35.395+0000] {processor.py:157} INFO - Started process (PID=17918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:37:35.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:37:35.397+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:37:35.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:37:35.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:37:35.426+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:37:35.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:37:35.436+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:37:35.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:37:35.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T14:38:05.867+0000] {processor.py:157} INFO - Started process (PID=17943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:38:05.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:38:05.871+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:38:05.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:38:05.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:38:05.898+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:38:05.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:38:05.910+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:38:05.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:38:05.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T14:38:36.325+0000] {processor.py:157} INFO - Started process (PID=17968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:38:36.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:38:36.328+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:38:36.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:38:36.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:38:36.355+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:38:36.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:38:36.364+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:38:36.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:38:36.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T14:39:06.781+0000] {processor.py:157} INFO - Started process (PID=17993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:39:06.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:39:06.784+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:39:06.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:39:06.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:39:06.811+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:39:06.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:39:06.821+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:39:06.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:39:06.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T14:39:37.259+0000] {processor.py:157} INFO - Started process (PID=18018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:39:37.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:39:37.263+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:39:37.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:39:37.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:39:37.289+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:39:37.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:39:37.298+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:39:37.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:39:37.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T14:40:07.729+0000] {processor.py:157} INFO - Started process (PID=18043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:40:07.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:40:07.733+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:40:07.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:40:07.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:40:07.760+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:40:07.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:40:07.770+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:40:07.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:40:07.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T14:40:38.155+0000] {processor.py:157} INFO - Started process (PID=18068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:40:38.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:40:38.158+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:40:38.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:40:38.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:40:38.189+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:40:38.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:40:38.199+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:40:38.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:40:38.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T14:41:08.670+0000] {processor.py:157} INFO - Started process (PID=18093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:41:08.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:41:08.672+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:41:08.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:41:08.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:41:08.699+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:41:08.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:41:08.711+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:41:08.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:41:08.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T14:41:39.079+0000] {processor.py:157} INFO - Started process (PID=18118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:41:39.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:41:39.082+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:41:39.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:41:39.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:41:39.109+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:41:39.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:41:39.122+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:41:39.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:41:39.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T14:42:09.499+0000] {processor.py:157} INFO - Started process (PID=18143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:42:09.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:42:09.502+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:42:09.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:42:09.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:42:09.530+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:42:09.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:42:09.541+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:42:09.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:42:09.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T14:42:39.938+0000] {processor.py:157} INFO - Started process (PID=18168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:42:39.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:42:39.941+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:42:39.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:42:39.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:42:39.967+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:42:39.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:42:39.976+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:42:39.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:42:39.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T14:43:10.270+0000] {processor.py:157} INFO - Started process (PID=18193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:43:10.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:43:10.273+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:43:10.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:43:10.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:43:10.298+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:43:10.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:43:10.309+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:43:10.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:43:10.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-18T14:43:40.729+0000] {processor.py:157} INFO - Started process (PID=18218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:43:40.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:43:40.733+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:43:40.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:43:40.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:43:40.762+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:43:40.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:43:40.771+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:43:40.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:43:40.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T14:44:11.173+0000] {processor.py:157} INFO - Started process (PID=18243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:44:11.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:44:11.176+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:44:11.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:44:11.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:44:11.207+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:44:11.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:44:11.216+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:44:11.216+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:44:11.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T14:44:41.580+0000] {processor.py:157} INFO - Started process (PID=18268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:44:41.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:44:41.583+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:44:41.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:44:41.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:44:41.610+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:44:41.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:44:41.622+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:44:41.622+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:44:41.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T14:45:12.057+0000] {processor.py:157} INFO - Started process (PID=18293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:45:12.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:45:12.060+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:45:12.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:45:12.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:45:12.088+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:45:12.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:45:12.101+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:45:12.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:45:12.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T14:45:42.446+0000] {processor.py:157} INFO - Started process (PID=18318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:45:42.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:45:42.449+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:45:42.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:45:42.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:45:42.481+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:45:42.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:45:42.490+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:45:42.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:45:42.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T14:46:12.944+0000] {processor.py:157} INFO - Started process (PID=18343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:46:12.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:46:12.948+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:46:12.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:46:12.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:46:12.976+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:46:12.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:46:12.985+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:46:12.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:46:12.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T14:46:43.342+0000] {processor.py:157} INFO - Started process (PID=18368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:46:43.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:46:43.345+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:46:43.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:46:43.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:46:43.371+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:46:43.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:46:43.381+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:46:43.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:46:43.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T14:47:13.976+0000] {processor.py:157} INFO - Started process (PID=18393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:47:13.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:47:13.979+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:47:13.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:47:13.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:47:14.005+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:47:14.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:47:14.014+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:47:14.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:47:14.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T14:47:44.498+0000] {processor.py:157} INFO - Started process (PID=18418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:47:44.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:47:44.503+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:47:44.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:47:44.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:47:44.529+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:47:44.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:47:44.542+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:47:44.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:47:44.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T14:48:14.929+0000] {processor.py:157} INFO - Started process (PID=18442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:48:14.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:48:14.931+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:48:14.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:48:14.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:48:14.958+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:48:14.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:48:14.967+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:48:14.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:48:14.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T14:48:45.382+0000] {processor.py:157} INFO - Started process (PID=18468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:48:45.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:48:45.389+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:48:45.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:48:45.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:48:45.424+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:48:45.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:48:45.433+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:48:45.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:48:45.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-18T14:49:15.847+0000] {processor.py:157} INFO - Started process (PID=18493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:49:15.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:49:15.849+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:49:15.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:49:15.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:49:15.877+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:49:15.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:49:15.889+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:49:15.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:49:15.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T14:49:46.263+0000] {processor.py:157} INFO - Started process (PID=18518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:49:46.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:49:46.265+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:49:46.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:49:46.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:49:46.292+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:49:46.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:49:46.301+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:49:46.301+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:49:46.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T14:50:16.706+0000] {processor.py:157} INFO - Started process (PID=18543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:50:16.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:50:16.708+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:50:16.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:50:16.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:50:16.735+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:50:16.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:50:16.744+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:50:16.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:50:16.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T14:50:47.145+0000] {processor.py:157} INFO - Started process (PID=18568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:50:47.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:50:47.149+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:50:47.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:50:47.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:50:47.181+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:50:47.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:50:47.191+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:50:47.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:50:47.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T14:51:17.583+0000] {processor.py:157} INFO - Started process (PID=18593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:51:17.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:51:17.585+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:51:17.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:51:17.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:51:17.609+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:51:17.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:51:17.621+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:51:17.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:51:17.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-18T14:51:48.082+0000] {processor.py:157} INFO - Started process (PID=18618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:51:48.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:51:48.085+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:51:48.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:51:48.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:51:48.113+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:51:48.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:51:48.123+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:51:48.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:51:48.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T14:52:18.534+0000] {processor.py:157} INFO - Started process (PID=18643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:52:18.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:52:18.537+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:52:18.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:52:18.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:52:18.565+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:52:18.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:52:18.576+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:52:18.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:52:18.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T14:52:48.946+0000] {processor.py:157} INFO - Started process (PID=18668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:52:48.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:52:48.950+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:52:48.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:52:48.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:52:48.977+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:52:48.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:52:48.987+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:52:48.987+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:52:48.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T14:53:19.385+0000] {processor.py:157} INFO - Started process (PID=18693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:53:19.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:53:19.389+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:53:19.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:53:19.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:53:19.417+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:53:19.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:53:19.427+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:53:19.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:53:19.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T14:53:49.834+0000] {processor.py:157} INFO - Started process (PID=18718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:53:49.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:53:49.837+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:53:49.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:53:49.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:53:49.862+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:53:49.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:53:49.872+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:53:49.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:53:49.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T14:54:20.235+0000] {processor.py:157} INFO - Started process (PID=18743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:54:20.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:54:20.237+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:54:20.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:54:20.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:54:20.262+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:54:20.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:54:20.272+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:54:20.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:54:20.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T14:54:50.731+0000] {processor.py:157} INFO - Started process (PID=18768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:54:50.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:54:50.735+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:54:50.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:54:50.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:54:50.763+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:54:50.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:54:50.773+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:54:50.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:54:50.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T14:55:21.153+0000] {processor.py:157} INFO - Started process (PID=18793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:55:21.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:55:21.156+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:55:21.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:55:21.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:55:21.182+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:55:21.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:55:21.194+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:55:21.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:55:21.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T14:55:51.591+0000] {processor.py:157} INFO - Started process (PID=18818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:55:51.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:55:51.593+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:55:51.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:55:51.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:55:51.622+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:55:51.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:55:51.633+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:55:51.633+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:55:51.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T14:56:22.069+0000] {processor.py:157} INFO - Started process (PID=18843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:56:22.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:56:22.073+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:56:22.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:56:22.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:56:22.103+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:56:22.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:56:22.112+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:56:22.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:56:22.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T14:56:52.457+0000] {processor.py:157} INFO - Started process (PID=18868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:56:52.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:56:52.459+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:56:52.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:56:52.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:56:52.488+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:56:52.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:56:52.498+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:56:52.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:56:52.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T14:57:22.917+0000] {processor.py:157} INFO - Started process (PID=18893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:57:22.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:57:22.921+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:57:22.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:57:22.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:57:22.949+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:57:22.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:57:22.961+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:57:22.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:57:22.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T14:57:53.393+0000] {processor.py:157} INFO - Started process (PID=18918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:57:53.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:57:53.398+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:57:53.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:57:53.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:57:53.429+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:57:53.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:57:53.438+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:57:53.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:57:53.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T14:58:23.824+0000] {processor.py:157} INFO - Started process (PID=18943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:58:23.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:58:23.828+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:58:23.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:58:23.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:58:23.857+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:58:23.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:58:23.867+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:58:23.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:58:23.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T14:58:54.313+0000] {processor.py:157} INFO - Started process (PID=18968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:58:54.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:58:54.317+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:58:54.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:58:54.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:58:54.347+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:58:54.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:58:54.359+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:58:54.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:58:54.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T14:59:24.754+0000] {processor.py:157} INFO - Started process (PID=18993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:59:24.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:59:24.758+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:59:24.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:59:24.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:59:24.785+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:59:24.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:59:24.795+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:59:24.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:59:24.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T14:59:55.176+0000] {processor.py:157} INFO - Started process (PID=19018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:59:55.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T14:59:55.179+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:59:55.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:59:55.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T14:59:55.205+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:59:55.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:59:55.214+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:59:55.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T14:59:55.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T15:00:25.666+0000] {processor.py:157} INFO - Started process (PID=19043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:00:25.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:00:25.672+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:00:25.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:00:25.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:00:25.704+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:00:25.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:00:25.715+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:00:25.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:00:25.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-18T15:00:56.132+0000] {processor.py:157} INFO - Started process (PID=19068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:00:56.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:00:56.135+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:00:56.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:00:56.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:00:56.164+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:00:56.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:00:56.176+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:00:56.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:00:56.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T15:01:26.646+0000] {processor.py:157} INFO - Started process (PID=19093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:01:26.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:01:26.648+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:01:26.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:01:26.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:01:26.674+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:01:26.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:01:26.684+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:01:26.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:01:26.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T15:01:57.129+0000] {processor.py:157} INFO - Started process (PID=19118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:01:57.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:01:57.132+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:01:57.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:01:57.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:01:57.162+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:01:57.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:01:57.172+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:01:57.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:01:57.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T15:02:27.588+0000] {processor.py:157} INFO - Started process (PID=19143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:02:27.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:02:27.591+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:02:27.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:02:27.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:02:27.618+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:02:27.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:02:27.627+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:02:27.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:02:27.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T15:02:58.029+0000] {processor.py:157} INFO - Started process (PID=19168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:02:58.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:02:58.033+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:02:58.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:02:58.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:02:58.064+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:02:58.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:02:58.073+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:02:58.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:02:58.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T15:03:28.432+0000] {processor.py:157} INFO - Started process (PID=19193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:03:28.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:03:28.436+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:03:28.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:03:28.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:03:28.463+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:03:28.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:03:28.476+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:03:28.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:03:28.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T15:03:58.932+0000] {processor.py:157} INFO - Started process (PID=19218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:03:58.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:03:58.936+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:03:58.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:03:58.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:03:58.964+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:03:58.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:03:58.975+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:03:58.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:03:58.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T15:04:29.371+0000] {processor.py:157} INFO - Started process (PID=19243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:04:29.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:04:29.374+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:04:29.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:04:29.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:04:29.403+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:04:29.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:04:29.413+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:04:29.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:04:29.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T15:04:59.803+0000] {processor.py:157} INFO - Started process (PID=19268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:04:59.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:04:59.806+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:04:59.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:04:59.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:04:59.837+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:04:59.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:04:59.848+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:04:59.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:04:59.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T15:05:30.218+0000] {processor.py:157} INFO - Started process (PID=19293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:05:30.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:05:30.222+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:05:30.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:05:30.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:05:30.251+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:05:30.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:05:30.260+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:05:30.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:05:30.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T15:06:00.668+0000] {processor.py:157} INFO - Started process (PID=19318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:06:00.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:06:00.673+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:06:00.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:06:00.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:06:00.708+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:06:00.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:06:00.719+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:06:00.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:06:00.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-18T15:06:31.169+0000] {processor.py:157} INFO - Started process (PID=19343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:06:31.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:06:31.172+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:06:31.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:06:31.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:06:31.202+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:06:31.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:06:31.211+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:06:31.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:06:31.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T15:07:01.592+0000] {processor.py:157} INFO - Started process (PID=19368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:07:01.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:07:01.595+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:07:01.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:07:01.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:07:01.627+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:07:01.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:07:01.638+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:07:01.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:07:01.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T15:07:32.014+0000] {processor.py:157} INFO - Started process (PID=19393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:07:32.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:07:32.017+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:07:32.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:07:32.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:07:32.046+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:07:32.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:07:32.056+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:07:32.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:07:32.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T15:08:02.468+0000] {processor.py:157} INFO - Started process (PID=19418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:08:02.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:08:02.471+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:08:02.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:08:02.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:08:02.502+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:08:02.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:08:02.512+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:08:02.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:08:02.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T15:08:32.961+0000] {processor.py:157} INFO - Started process (PID=19443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:08:32.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:08:32.963+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:08:32.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:08:32.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:08:32.990+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:08:32.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:08:33.000+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:08:33.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:08:33.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T15:09:03.426+0000] {processor.py:157} INFO - Started process (PID=19468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:09:03.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:09:03.429+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:09:03.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:09:03.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:09:03.456+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:09:03.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:09:03.466+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:09:03.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:09:03.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T15:09:33.895+0000] {processor.py:157} INFO - Started process (PID=19493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:09:33.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:09:33.900+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:09:33.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:09:33.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:09:33.929+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:09:33.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:09:33.938+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:09:33.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:09:33.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T15:10:04.316+0000] {processor.py:157} INFO - Started process (PID=19518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:10:04.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:10:04.319+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:10:04.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:10:04.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:10:04.350+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:10:04.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:10:04.360+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:10:04.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:10:04.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T15:10:34.752+0000] {processor.py:157} INFO - Started process (PID=19543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:10:34.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:10:34.755+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:10:34.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:10:34.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:10:34.784+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:10:34.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:10:34.797+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:10:34.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:10:34.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T15:11:05.190+0000] {processor.py:157} INFO - Started process (PID=19568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:11:05.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:11:05.193+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:11:05.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:11:05.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:11:05.224+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:11:05.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:11:05.237+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:11:05.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:11:05.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T15:11:35.667+0000] {processor.py:157} INFO - Started process (PID=19593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:11:35.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:11:35.672+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:11:35.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:11:35.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:11:35.699+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:11:35.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:11:35.709+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:11:35.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:11:35.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T15:12:06.148+0000] {processor.py:157} INFO - Started process (PID=19618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:12:06.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:12:06.152+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:12:06.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:12:06.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:12:06.180+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:12:06.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:12:06.191+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:12:06.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:12:06.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T15:12:36.579+0000] {processor.py:157} INFO - Started process (PID=19643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:12:36.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:12:36.584+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:12:36.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:12:36.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:12:36.613+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:12:36.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:12:36.626+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:12:36.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:12:36.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T15:13:07.025+0000] {processor.py:157} INFO - Started process (PID=19668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:13:07.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:13:07.031+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:13:07.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:13:07.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:13:07.057+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:13:07.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:13:07.068+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:13:07.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:13:07.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T15:13:37.509+0000] {processor.py:157} INFO - Started process (PID=19693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:13:37.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:13:37.515+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:13:37.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:13:37.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:13:37.538+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:13:37.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:13:37.547+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:13:37.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:13:37.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T15:14:07.901+0000] {processor.py:157} INFO - Started process (PID=19718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:14:07.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:14:07.903+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:14:07.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:14:07.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:14:07.928+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:14:07.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:14:07.938+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:14:07.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:14:07.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T15:14:38.356+0000] {processor.py:157} INFO - Started process (PID=19743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:14:38.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:14:38.359+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:14:38.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:14:38.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:14:38.386+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:14:38.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:14:38.397+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:14:38.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:14:38.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T15:15:08.887+0000] {processor.py:157} INFO - Started process (PID=19768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:15:08.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:15:08.892+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:15:08.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:15:08.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:15:08.921+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:15:08.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:15:08.932+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:15:08.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:15:08.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T15:15:39.343+0000] {processor.py:157} INFO - Started process (PID=19793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:15:39.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:15:39.347+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:15:39.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:15:39.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:15:39.377+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:15:39.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:15:39.389+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:15:39.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:15:39.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T15:16:09.812+0000] {processor.py:157} INFO - Started process (PID=19818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:16:09.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:16:09.815+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:16:09.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:16:09.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:16:09.844+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:16:09.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:16:09.856+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:16:09.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:16:09.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T15:16:40.282+0000] {processor.py:157} INFO - Started process (PID=19843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:16:40.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:16:40.286+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:16:40.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:16:40.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:16:40.335+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:16:40.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:16:40.350+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:16:40.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:16:40.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-18T15:17:10.703+0000] {processor.py:157} INFO - Started process (PID=19868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:17:10.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:17:10.709+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:17:10.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:17:10.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:17:10.756+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:17:10.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:17:10.773+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:17:10.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:17:10.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-18T15:17:41.167+0000] {processor.py:157} INFO - Started process (PID=19893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:17:41.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:17:41.170+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:17:41.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:17:41.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:17:41.196+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:17:41.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:17:41.206+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:17:41.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:17:41.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T15:18:11.632+0000] {processor.py:157} INFO - Started process (PID=19918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:18:11.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:18:11.637+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:18:11.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:18:11.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:18:11.677+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:18:11.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:18:11.690+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:18:11.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:18:11.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-18T15:18:42.050+0000] {processor.py:157} INFO - Started process (PID=19943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:18:42.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:18:42.054+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:18:42.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:18:42.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:18:42.089+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:18:42.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:18:42.100+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:18:42.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:18:42.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-18T15:19:12.477+0000] {processor.py:157} INFO - Started process (PID=19968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:19:12.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:19:12.481+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:19:12.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:19:12.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:19:12.511+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:19:12.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:19:12.523+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:19:12.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:19:12.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T15:19:42.872+0000] {processor.py:157} INFO - Started process (PID=19993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:19:42.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:19:42.874+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:19:42.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:19:42.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:19:42.906+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:19:42.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:19:42.919+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:19:42.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:19:42.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T15:20:13.337+0000] {processor.py:157} INFO - Started process (PID=20018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:20:13.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:20:13.344+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:20:13.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:20:13.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:20:13.388+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:20:13.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:20:13.400+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:20:13.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:20:13.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-18T15:20:43.865+0000] {processor.py:157} INFO - Started process (PID=20043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:20:43.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:20:43.867+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:20:43.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:20:43.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:20:43.896+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:20:43.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:20:43.906+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:20:43.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:20:43.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T15:21:14.374+0000] {processor.py:157} INFO - Started process (PID=20068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:21:14.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:21:14.381+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:21:14.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:21:14.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:21:14.441+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:21:14.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:21:14.456+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:21:14.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:21:14.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-18T15:21:44.868+0000] {processor.py:157} INFO - Started process (PID=20093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:21:44.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:21:44.875+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:21:44.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:21:44.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:21:44.918+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:21:44.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:21:44.932+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:21:44.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:21:44.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-18T15:22:15.320+0000] {processor.py:157} INFO - Started process (PID=20118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:22:15.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:22:15.326+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:22:15.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:22:15.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:22:15.353+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:22:15.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:22:15.361+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:22:15.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:22:15.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T15:22:45.772+0000] {processor.py:157} INFO - Started process (PID=20143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:22:45.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:22:45.775+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:22:45.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:22:45.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:22:45.804+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:22:45.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:22:45.816+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:22:45.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:22:45.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T15:23:16.152+0000] {processor.py:157} INFO - Started process (PID=20168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:23:16.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:23:16.155+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:23:16.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:23:16.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:23:16.178+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:23:16.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:23:16.187+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:23:16.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:23:16.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-18T15:23:46.924+0000] {processor.py:157} INFO - Started process (PID=20193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:23:46.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:23:46.931+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:23:46.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:23:46.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:23:47.009+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:23:47.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:23:47.028+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:23:47.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:23:47.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-18T15:24:17.441+0000] {processor.py:157} INFO - Started process (PID=20218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:24:17.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:24:17.449+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:24:17.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:24:17.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:24:17.515+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:24:17.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:24:17.551+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:24:17.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:24:17.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-07-18T15:24:47.960+0000] {processor.py:157} INFO - Started process (PID=20243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:24:47.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:24:47.970+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:24:47.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:24:47.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:24:48.026+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:24:48.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:24:48.042+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:24:48.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:24:48.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-18T15:25:18.464+0000] {processor.py:157} INFO - Started process (PID=20267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:25:18.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:25:18.471+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:25:18.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:25:18.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:25:18.536+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:25:18.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:25:18.556+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:25:18.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:25:18.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-07-18T15:25:49.103+0000] {processor.py:157} INFO - Started process (PID=20292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:25:49.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:25:49.111+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:25:49.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:25:49.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:25:49.156+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:25:49.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:25:49.168+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:25:49.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:25:49.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-18T15:26:19.555+0000] {processor.py:157} INFO - Started process (PID=20318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:26:19.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:26:19.559+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:26:19.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:26:19.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:26:19.585+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:26:19.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:26:19.597+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:26:19.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:26:19.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T15:26:49.936+0000] {processor.py:157} INFO - Started process (PID=20343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:26:49.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:26:49.939+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:26:49.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:26:49.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:26:49.967+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:26:49.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:26:49.977+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:26:49.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:26:49.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T15:27:20.381+0000] {processor.py:157} INFO - Started process (PID=20368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:27:20.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:27:20.384+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:27:20.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:27:20.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:27:20.411+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:27:20.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:27:20.421+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:27:20.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:27:20.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T15:27:50.812+0000] {processor.py:157} INFO - Started process (PID=20392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:27:50.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:27:50.817+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:27:50.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:27:50.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:27:50.856+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:27:50.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:27:50.869+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:27:50.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:27:50.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-18T15:28:21.284+0000] {processor.py:157} INFO - Started process (PID=20418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:28:21.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:28:21.287+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:28:21.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:28:21.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:28:21.315+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:28:21.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:28:21.326+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:28:21.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:28:21.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T15:28:51.734+0000] {processor.py:157} INFO - Started process (PID=20443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:28:51.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:28:51.739+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:28:51.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:28:51.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:28:51.769+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:28:51.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:28:51.782+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:28:51.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:28:51.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T15:29:22.130+0000] {processor.py:157} INFO - Started process (PID=20468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:29:22.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:29:22.136+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:29:22.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:29:22.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:29:22.170+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:29:22.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:29:22.182+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:29:22.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:29:22.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-18T15:29:52.604+0000] {processor.py:157} INFO - Started process (PID=20493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:29:52.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:29:52.608+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:29:52.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:29:52.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:29:52.634+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:29:52.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:29:52.646+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:29:52.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:29:52.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T15:30:23.058+0000] {processor.py:157} INFO - Started process (PID=20518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:30:23.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:30:23.063+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:30:23.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:30:23.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:30:23.088+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:30:23.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:30:23.099+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:30:23.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:30:23.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T15:30:53.493+0000] {processor.py:157} INFO - Started process (PID=20543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:30:53.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:30:53.496+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:30:53.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:30:53.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:30:53.526+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:30:53.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:30:53.538+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:30:53.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:30:53.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T15:31:23.883+0000] {processor.py:157} INFO - Started process (PID=20568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:31:23.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:31:23.885+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:31:23.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:31:23.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:31:23.910+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:31:23.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:31:23.919+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:31:23.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:31:23.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-18T15:31:54.273+0000] {processor.py:157} INFO - Started process (PID=20593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:31:54.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:31:54.275+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:31:54.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:31:54.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:31:54.302+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:31:54.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:31:54.312+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:31:54.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:31:54.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T15:32:24.763+0000] {processor.py:157} INFO - Started process (PID=20618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:32:24.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:32:24.767+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:32:24.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:32:24.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:32:24.793+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:32:24.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:32:24.803+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:32:24.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:32:24.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T15:32:55.205+0000] {processor.py:157} INFO - Started process (PID=20643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:32:55.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:32:55.208+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:32:55.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:32:55.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:32:55.238+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:32:55.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:32:55.250+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:32:55.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:32:55.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T15:33:25.650+0000] {processor.py:157} INFO - Started process (PID=20668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:33:25.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:33:25.653+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:33:25.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:33:25.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:33:25.681+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:33:25.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:33:25.691+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:33:25.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:33:25.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T15:33:56.094+0000] {processor.py:157} INFO - Started process (PID=20693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:33:56.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:33:56.100+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:33:56.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:33:56.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:33:56.126+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:33:56.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:33:56.141+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:33:56.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:33:56.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T15:34:26.540+0000] {processor.py:157} INFO - Started process (PID=20718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:34:26.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:34:26.547+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:34:26.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:34:26.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:34:26.583+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:34:26.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:34:26.595+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:34:26.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:34:26.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-18T15:34:56.938+0000] {processor.py:157} INFO - Started process (PID=20743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:34:56.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:34:56.941+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:34:56.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:34:56.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:34:56.965+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:34:56.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:34:56.974+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:34:56.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:34:56.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-18T15:35:27.362+0000] {processor.py:157} INFO - Started process (PID=20768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:35:27.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:35:27.364+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:35:27.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:35:27.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:35:27.393+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:35:27.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:35:27.404+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:35:27.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:35:27.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T15:35:57.801+0000] {processor.py:157} INFO - Started process (PID=20792) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:35:57.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:35:57.806+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:35:57.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:35:57.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:35:57.849+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:35:57.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:35:57.866+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:35:57.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:35:57.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-18T15:36:28.251+0000] {processor.py:157} INFO - Started process (PID=20818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:36:28.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:36:28.253+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:36:28.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:36:28.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:36:28.281+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:36:28.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:36:28.290+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:36:28.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:36:28.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T15:36:58.676+0000] {processor.py:157} INFO - Started process (PID=20843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:36:58.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:36:58.678+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:36:58.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:36:58.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:36:58.703+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:36:58.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:36:58.713+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:36:58.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:36:58.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-18T15:37:29.072+0000] {processor.py:157} INFO - Started process (PID=20868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:37:29.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:37:29.075+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:37:29.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:37:29.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:37:29.102+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:37:29.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:37:29.114+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:37:29.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:37:29.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T15:37:59.492+0000] {processor.py:157} INFO - Started process (PID=20893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:37:59.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:37:59.496+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:37:59.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:37:59.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:37:59.527+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:37:59.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:37:59.537+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:37:59.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:37:59.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T15:38:30.112+0000] {processor.py:157} INFO - Started process (PID=20918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:38:30.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:38:30.147+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:38:30.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:38:30.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:38:30.224+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:38:30.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:38:30.255+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:38:30.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:38:30.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.183 seconds
[2024-07-18T15:39:00.690+0000] {processor.py:157} INFO - Started process (PID=20943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:39:00.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:39:00.695+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:39:00.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:39:00.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:39:00.748+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:39:00.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:39:00.764+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:39:00.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:39:00.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-18T15:39:31.163+0000] {processor.py:157} INFO - Started process (PID=20968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:39:31.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:39:31.166+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:39:31.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:39:31.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:39:31.194+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:39:31.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:39:31.203+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:39:31.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:39:31.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T15:40:01.574+0000] {processor.py:157} INFO - Started process (PID=20993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:40:01.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:40:01.577+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:40:01.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:40:01.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:40:01.607+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:40:01.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:40:01.617+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:40:01.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:40:01.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T15:40:32.001+0000] {processor.py:157} INFO - Started process (PID=21018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:40:32.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:40:32.005+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:40:32.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:40:32.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:40:32.031+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:40:32.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:40:32.040+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:40:32.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:40:32.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T15:41:02.418+0000] {processor.py:157} INFO - Started process (PID=21043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:41:02.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:41:02.423+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:41:02.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:41:02.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:41:02.453+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:41:02.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:41:02.463+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:41:02.463+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:41:02.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T15:41:32.883+0000] {processor.py:157} INFO - Started process (PID=21068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:41:32.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:41:32.886+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:41:32.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:41:32.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:41:32.912+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:41:32.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:41:32.922+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:41:32.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:41:32.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T15:42:03.320+0000] {processor.py:157} INFO - Started process (PID=21093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:42:03.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:42:03.323+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:42:03.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:42:03.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:42:03.350+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:42:03.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:42:03.361+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:42:03.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:42:03.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T15:42:33.788+0000] {processor.py:157} INFO - Started process (PID=21118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:42:33.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:42:33.793+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:42:33.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:42:33.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:42:33.835+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:42:33.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:42:33.849+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:42:33.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:42:33.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-18T15:43:04.276+0000] {processor.py:157} INFO - Started process (PID=21143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:43:04.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:43:04.278+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:43:04.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:43:04.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:43:04.305+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:43:04.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:43:04.314+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:43:04.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:43:04.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T15:43:34.681+0000] {processor.py:157} INFO - Started process (PID=21168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:43:34.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:43:34.684+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:43:34.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:43:34.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:43:34.710+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:43:34.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:43:34.720+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:43:34.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:43:34.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T15:44:05.117+0000] {processor.py:157} INFO - Started process (PID=21193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:44:05.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:44:05.120+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:44:05.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:44:05.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:44:05.146+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:44:05.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:44:05.155+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:44:05.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:44:05.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T15:44:35.701+0000] {processor.py:157} INFO - Started process (PID=21218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:44:35.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:44:35.707+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:44:35.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:44:35.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:44:35.753+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:44:35.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:44:35.767+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:44:35.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:44:35.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-18T15:45:06.163+0000] {processor.py:157} INFO - Started process (PID=21243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:45:06.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:45:06.169+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:45:06.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:45:06.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:45:06.193+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:45:06.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:45:06.207+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:45:06.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:45:06.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-18T15:45:36.644+0000] {processor.py:157} INFO - Started process (PID=21268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:45:36.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:45:36.650+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:45:36.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:45:36.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:45:36.685+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:45:36.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:45:36.698+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:45:36.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:45:36.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-18T15:46:07.094+0000] {processor.py:157} INFO - Started process (PID=21293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:46:07.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:46:07.097+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:46:07.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:46:07.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:46:07.128+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:46:07.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:46:07.141+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:46:07.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:46:07.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T15:46:37.492+0000] {processor.py:157} INFO - Started process (PID=21318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:46:37.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:46:37.495+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:46:37.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:46:37.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:46:37.523+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:46:37.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:46:37.536+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:46:37.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:46:37.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T15:47:07.882+0000] {processor.py:157} INFO - Started process (PID=21343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:47:07.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:47:07.884+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:47:07.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:47:07.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:47:07.914+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:47:07.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:47:07.925+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:47:07.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:47:07.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T15:47:38.335+0000] {processor.py:157} INFO - Started process (PID=21368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:47:38.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:47:38.337+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:47:38.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:47:38.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:47:38.368+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:47:38.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:47:38.380+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:47:38.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:47:38.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T15:48:08.794+0000] {processor.py:157} INFO - Started process (PID=21393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:48:08.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:48:08.802+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:48:08.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:48:08.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:48:08.824+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:48:08.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:48:08.833+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:48:08.833+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:48:08.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T15:48:39.184+0000] {processor.py:157} INFO - Started process (PID=21418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:48:39.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:48:39.187+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:48:39.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:48:39.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:48:39.216+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:48:39.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:48:39.226+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:48:39.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:48:39.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T15:49:09.606+0000] {processor.py:157} INFO - Started process (PID=21443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:49:09.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:49:09.609+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:49:09.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:49:09.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:49:09.638+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:49:09.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:49:09.649+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:49:09.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:49:09.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T15:49:40.058+0000] {processor.py:157} INFO - Started process (PID=21468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:49:40.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:49:40.064+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:49:40.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:49:40.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:49:40.097+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:49:40.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:49:40.109+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:49:40.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:49:40.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-18T15:50:10.544+0000] {processor.py:157} INFO - Started process (PID=21493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:50:10.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:50:10.548+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:50:10.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:50:10.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:50:10.580+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:50:10.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:50:10.590+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:50:10.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:50:10.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T15:50:41.049+0000] {processor.py:157} INFO - Started process (PID=21518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:50:41.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:50:41.052+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:50:41.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:50:41.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:50:41.080+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:50:41.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:50:41.090+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:50:41.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:50:41.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T15:51:11.510+0000] {processor.py:157} INFO - Started process (PID=21543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:51:11.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:51:11.514+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:51:11.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:51:11.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:51:11.543+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:51:11.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:51:11.553+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:51:11.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:51:11.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T15:51:41.906+0000] {processor.py:157} INFO - Started process (PID=21568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:51:41.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:51:41.909+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:51:41.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:51:41.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:51:41.936+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:51:41.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:51:41.945+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:51:41.945+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:51:41.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T15:52:12.312+0000] {processor.py:157} INFO - Started process (PID=21593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:52:12.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:52:12.315+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:52:12.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:52:12.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:52:12.342+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:52:12.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:52:12.352+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:52:12.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:52:12.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T15:52:42.760+0000] {processor.py:157} INFO - Started process (PID=21618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:52:42.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:52:42.763+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:52:42.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:52:42.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:52:42.797+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:52:42.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:52:42.807+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:52:42.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:52:42.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T15:53:13.221+0000] {processor.py:157} INFO - Started process (PID=21642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:53:13.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:53:13.227+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:53:13.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:53:13.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:53:13.283+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:53:13.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:53:13.300+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:53:13.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:53:13.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-18T15:53:43.861+0000] {processor.py:157} INFO - Started process (PID=21667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:53:43.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:53:43.866+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:53:43.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:53:43.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:53:43.923+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:53:43.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:53:43.937+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:53:43.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:53:43.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-18T15:54:14.365+0000] {processor.py:157} INFO - Started process (PID=21693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:54:14.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:54:14.371+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:54:14.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:54:14.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:54:14.425+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:54:14.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:54:14.440+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:54:14.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:54:14.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-18T15:54:44.884+0000] {processor.py:157} INFO - Started process (PID=21718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:54:44.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:54:44.889+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:54:44.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:54:44.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:54:44.932+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:54:44.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:54:44.946+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:54:44.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:54:44.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-18T15:55:15.378+0000] {processor.py:157} INFO - Started process (PID=21743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:55:15.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:55:15.381+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:55:15.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:55:15.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:55:15.407+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:55:15.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:55:15.417+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:55:15.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:55:15.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T15:55:45.812+0000] {processor.py:157} INFO - Started process (PID=21768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:55:45.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:55:45.815+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:55:45.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:55:45.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:55:45.845+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:55:45.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:55:45.856+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:55:45.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:55:45.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T15:56:16.286+0000] {processor.py:157} INFO - Started process (PID=21793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:56:16.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:56:16.293+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:56:16.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:56:16.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:56:16.353+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:56:16.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:56:16.370+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:56:16.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:56:16.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-18T15:56:46.755+0000] {processor.py:157} INFO - Started process (PID=21818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:56:46.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:56:46.758+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:56:46.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:56:46.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:56:46.787+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:56:46.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:56:46.797+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:56:46.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:56:46.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T15:57:17.217+0000] {processor.py:157} INFO - Started process (PID=21843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:57:17.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:57:17.221+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:57:17.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:57:17.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:57:17.251+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:57:17.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:57:17.262+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:57:17.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:57:17.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T15:57:47.602+0000] {processor.py:157} INFO - Started process (PID=21868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:57:47.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:57:47.605+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:57:47.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:57:47.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:57:47.631+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:57:47.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:57:47.644+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:57:47.644+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:57:47.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T15:58:18.013+0000] {processor.py:157} INFO - Started process (PID=21893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:58:18.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:58:18.015+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:58:18.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:58:18.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:58:18.043+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:58:18.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:58:18.054+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:58:18.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:58:18.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T15:58:48.407+0000] {processor.py:157} INFO - Started process (PID=21918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:58:48.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:58:48.411+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:58:48.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:58:48.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:58:48.447+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:58:48.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:58:48.461+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:58:48.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:58:48.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-18T15:59:18.816+0000] {processor.py:157} INFO - Started process (PID=21943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:59:18.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:59:18.820+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:59:18.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:59:18.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:59:18.872+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:59:18.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:59:18.892+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:59:18.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:59:18.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-18T15:59:49.367+0000] {processor.py:157} INFO - Started process (PID=21967) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:59:49.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T15:59:49.372+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:59:49.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:59:49.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T15:59:49.403+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:59:49.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:59:49.416+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:59:49.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T15:59:49.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-18T16:00:19.829+0000] {processor.py:157} INFO - Started process (PID=21993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:00:19.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:00:19.832+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:00:19.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:00:19.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:00:19.865+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:00:19.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:00:19.879+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:00:19.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:00:19.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-18T16:00:50.320+0000] {processor.py:157} INFO - Started process (PID=22018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:00:50.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:00:50.323+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:00:50.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:00:50.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:00:50.354+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:00:50.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:00:50.363+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:00:50.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:00:50.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T16:01:20.799+0000] {processor.py:157} INFO - Started process (PID=22043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:01:20.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:01:20.801+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:01:20.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:01:20.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:01:20.827+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:01:20.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:01:20.837+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:01:20.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:01:20.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T16:01:51.198+0000] {processor.py:157} INFO - Started process (PID=22066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:01:51.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:01:51.202+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:01:51.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:01:51.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:01:51.228+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:01:51.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:01:51.240+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:01:51.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:01:51.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T16:02:21.635+0000] {processor.py:157} INFO - Started process (PID=22093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:02:21.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:02:21.638+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:02:21.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:02:21.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:02:21.670+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:02:21.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:02:21.680+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:02:21.680+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:02:21.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T16:02:52.073+0000] {processor.py:157} INFO - Started process (PID=22118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:02:52.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:02:52.079+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:02:52.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:02:52.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:02:52.108+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:02:52.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:02:52.119+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:02:52.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:02:52.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T16:03:22.493+0000] {processor.py:157} INFO - Started process (PID=22143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:03:22.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:03:22.496+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:03:22.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:03:22.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:03:22.524+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:03:22.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:03:22.535+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:03:22.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:03:22.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T16:03:52.895+0000] {processor.py:157} INFO - Started process (PID=22168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:03:52.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:03:52.899+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:03:52.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:03:52.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:03:52.935+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:03:52.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:03:52.948+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:03:52.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:03:52.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-18T16:04:23.361+0000] {processor.py:157} INFO - Started process (PID=22193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:04:23.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:04:23.367+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:04:23.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:04:23.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:04:23.405+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:04:23.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:04:23.421+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:04:23.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:04:23.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-18T16:04:53.864+0000] {processor.py:157} INFO - Started process (PID=22218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:04:53.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:04:53.867+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:04:53.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:04:53.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:04:53.894+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:04:53.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:04:53.903+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:04:53.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:04:53.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T16:05:24.342+0000] {processor.py:157} INFO - Started process (PID=22243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:05:24.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:05:24.346+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:05:24.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:05:24.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:05:24.387+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:05:24.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:05:24.400+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:05:24.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:05:24.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-18T16:05:54.809+0000] {processor.py:157} INFO - Started process (PID=22268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:05:54.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:05:54.814+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:05:54.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:05:54.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:05:54.842+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:05:54.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:05:54.854+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:05:54.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:05:54.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T16:06:25.207+0000] {processor.py:157} INFO - Started process (PID=22293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:06:25.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:06:25.216+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:06:25.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:06:25.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:06:25.238+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:06:25.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:06:25.248+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:06:25.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:06:25.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T16:06:55.590+0000] {processor.py:157} INFO - Started process (PID=22318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:06:55.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:06:55.597+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:06:55.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:06:55.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:06:55.634+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:06:55.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:06:55.650+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:06:55.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:06:55.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-18T16:07:26.080+0000] {processor.py:157} INFO - Started process (PID=22343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:07:26.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:07:26.083+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:07:26.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:07:26.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:07:26.113+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:07:26.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:07:26.125+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:07:26.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:07:26.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T16:07:56.513+0000] {processor.py:157} INFO - Started process (PID=22368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:07:56.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:07:56.516+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:07:56.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:07:56.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:07:56.545+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:07:56.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:07:56.554+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:07:56.554+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:07:56.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T16:08:26.967+0000] {processor.py:157} INFO - Started process (PID=22393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:08:26.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:08:26.969+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:08:26.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:08:26.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:08:26.996+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:08:26.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:08:27.005+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:08:27.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:08:27.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-18T16:08:57.409+0000] {processor.py:157} INFO - Started process (PID=22418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:08:57.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:08:57.412+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:08:57.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:08:57.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:08:57.439+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:08:57.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:08:57.449+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:08:57.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:08:57.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T16:09:27.810+0000] {processor.py:157} INFO - Started process (PID=22443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:09:27.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:09:27.814+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:09:27.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:09:27.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:09:27.850+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:09:27.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:09:27.862+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:09:27.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:09:27.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-18T16:09:58.267+0000] {processor.py:157} INFO - Started process (PID=22468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:09:58.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:09:58.269+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:09:58.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:09:58.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:09:58.297+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:09:58.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:09:58.308+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:09:58.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:09:58.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T16:10:28.711+0000] {processor.py:157} INFO - Started process (PID=22493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:10:28.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:10:28.714+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:10:28.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:10:28.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:10:28.743+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:10:28.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:10:28.753+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:10:28.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:10:28.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T16:10:59.159+0000] {processor.py:157} INFO - Started process (PID=22518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:10:59.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:10:59.162+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:10:59.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:10:59.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:10:59.190+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:10:59.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:10:59.199+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:10:59.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:10:59.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T16:11:29.614+0000] {processor.py:157} INFO - Started process (PID=22543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:11:29.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:11:29.617+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:11:29.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:11:29.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:11:29.647+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:11:29.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:11:29.658+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:11:29.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:11:29.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T16:11:59.976+0000] {processor.py:157} INFO - Started process (PID=22568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:11:59.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:11:59.979+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:11:59.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:11:59.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:12:00.004+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:12:00.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:12:00.014+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:12:00.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:12:00.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T16:12:30.392+0000] {processor.py:157} INFO - Started process (PID=22593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:12:30.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:12:30.396+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:12:30.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:12:30.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:12:30.426+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:12:30.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:12:30.439+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:12:30.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:12:30.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-18T16:13:00.840+0000] {processor.py:157} INFO - Started process (PID=22618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:13:00.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:13:00.844+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:13:00.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:13:00.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:13:00.873+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:13:00.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:13:00.885+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:13:00.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:13:00.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T16:13:31.242+0000] {processor.py:157} INFO - Started process (PID=22643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:13:31.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:13:31.245+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:13:31.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:13:31.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:13:31.271+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:13:31.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:13:31.280+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:13:31.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:13:31.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T16:14:01.702+0000] {processor.py:157} INFO - Started process (PID=22668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:14:01.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:14:01.705+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:14:01.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:14:01.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:14:01.733+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:14:01.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:14:01.744+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:14:01.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:14:01.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T16:14:32.125+0000] {processor.py:157} INFO - Started process (PID=22693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:14:32.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:14:32.128+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:14:32.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:14:32.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:14:32.153+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:14:32.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:14:32.166+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:14:32.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:14:32.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T16:15:02.514+0000] {processor.py:157} INFO - Started process (PID=22718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:15:02.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:15:02.517+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:15:02.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:15:02.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:15:02.544+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:15:02.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:15:02.554+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:15:02.554+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:15:02.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T16:15:32.949+0000] {processor.py:157} INFO - Started process (PID=22743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:15:32.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:15:32.952+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:15:32.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:15:32.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:15:32.983+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:15:32.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:15:32.994+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:15:32.994+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:15:33.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T16:16:03.427+0000] {processor.py:157} INFO - Started process (PID=22768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:16:03.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:16:03.429+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:16:03.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:16:03.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:16:03.454+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:16:03.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:16:03.464+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:16:03.464+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:16:03.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-18T16:16:33.841+0000] {processor.py:157} INFO - Started process (PID=22793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:16:33.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:16:33.844+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:16:33.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:16:33.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:16:33.873+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:16:33.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:16:33.882+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:16:33.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:16:33.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T16:17:04.229+0000] {processor.py:157} INFO - Started process (PID=22818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:17:04.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:17:04.234+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:17:04.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:17:04.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:17:04.271+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:17:04.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:17:04.287+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:17:04.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:17:04.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-18T16:17:34.768+0000] {processor.py:157} INFO - Started process (PID=22843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:17:34.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:17:34.771+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:17:34.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:17:34.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:17:34.803+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:17:34.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:17:34.814+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:17:34.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:17:34.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-18T16:18:05.220+0000] {processor.py:157} INFO - Started process (PID=22868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:18:05.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:18:05.225+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:18:05.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:18:05.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:18:05.254+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:18:05.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:18:05.264+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:18:05.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:18:05.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T16:18:35.631+0000] {processor.py:157} INFO - Started process (PID=22893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:18:35.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:18:35.634+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:18:35.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:18:35.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:18:35.661+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:18:35.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:18:35.672+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:18:35.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:18:35.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T16:19:06.090+0000] {processor.py:157} INFO - Started process (PID=22918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:19:06.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:19:06.095+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:19:06.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:19:06.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:19:06.131+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:19:06.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:19:06.145+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:19:06.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:19:06.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-18T16:19:36.520+0000] {processor.py:157} INFO - Started process (PID=22943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:19:36.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:19:36.527+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:19:36.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:19:36.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:19:36.593+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:19:36.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:19:36.611+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:19:36.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:19:36.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-18T16:20:06.989+0000] {processor.py:157} INFO - Started process (PID=22968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:20:06.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:20:06.992+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:20:06.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:20:07.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:20:07.025+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:20:07.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:20:07.034+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:20:07.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:20:07.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T16:20:37.480+0000] {processor.py:157} INFO - Started process (PID=22993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:20:37.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:20:37.484+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:20:37.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:20:37.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:20:37.519+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:20:37.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:20:37.535+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:20:37.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:20:37.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-18T16:21:07.953+0000] {processor.py:157} INFO - Started process (PID=23018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:21:07.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:21:07.957+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:21:07.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:21:07.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:21:07.990+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:21:07.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:21:08.002+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:21:08.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:21:08.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-18T16:21:38.347+0000] {processor.py:157} INFO - Started process (PID=23043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:21:38.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:21:38.350+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:21:38.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:21:38.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:21:38.379+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:21:38.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:21:38.390+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:21:38.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:21:38.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T16:22:08.793+0000] {processor.py:157} INFO - Started process (PID=23068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:22:08.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:22:08.799+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:22:08.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:22:08.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:22:08.824+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:22:08.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:22:08.834+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:22:08.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:22:08.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T16:22:39.219+0000] {processor.py:157} INFO - Started process (PID=23093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:22:39.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:22:39.223+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:22:39.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:22:39.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:22:39.255+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:22:39.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:22:39.265+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:22:39.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:22:39.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-18T16:23:09.651+0000] {processor.py:157} INFO - Started process (PID=23118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:23:09.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:23:09.654+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:23:09.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:23:09.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:23:09.683+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:23:09.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:23:09.693+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:23:09.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:23:09.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T16:23:40.064+0000] {processor.py:157} INFO - Started process (PID=23143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:23:40.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:23:40.067+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:23:40.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:23:40.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:23:40.096+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:23:40.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:23:40.106+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:23:40.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:23:40.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T16:24:10.454+0000] {processor.py:157} INFO - Started process (PID=23168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:24:10.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:24:10.457+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:24:10.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:24:10.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:24:10.486+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:24:10.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:24:10.498+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:24:10.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:24:10.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T16:24:40.959+0000] {processor.py:157} INFO - Started process (PID=23193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:24:40.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:24:40.962+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:24:40.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:24:40.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:24:40.992+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:24:40.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:24:41.005+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:24:41.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:24:41.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T16:25:11.379+0000] {processor.py:157} INFO - Started process (PID=23218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:25:11.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:25:11.382+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:25:11.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:25:11.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:25:11.408+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:25:11.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:25:11.419+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:25:11.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:25:11.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T16:25:41.868+0000] {processor.py:157} INFO - Started process (PID=23243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:25:41.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:25:41.871+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:25:41.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:25:41.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:25:41.906+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:25:41.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:25:41.917+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:25:41.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:25:41.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-18T16:26:12.310+0000] {processor.py:157} INFO - Started process (PID=23268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:26:12.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:26:12.316+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:26:12.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:26:12.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:26:12.347+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:26:12.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:26:12.359+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:26:12.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:26:12.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-18T16:26:42.784+0000] {processor.py:157} INFO - Started process (PID=23293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:26:42.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:26:42.787+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:26:42.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:26:42.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:26:42.818+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:26:42.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:26:42.827+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:26:42.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:26:42.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T16:27:13.198+0000] {processor.py:157} INFO - Started process (PID=23318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:27:13.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:27:13.201+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:27:13.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:27:13.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:27:13.229+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:27:13.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:27:13.238+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:27:13.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:27:13.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T16:27:43.575+0000] {processor.py:157} INFO - Started process (PID=23343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:27:43.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:27:43.577+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:27:43.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:27:43.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:27:43.607+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:27:43.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:27:43.618+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:27:43.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:27:43.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T16:28:14.037+0000] {processor.py:157} INFO - Started process (PID=23368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:28:14.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:28:14.040+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:28:14.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:28:14.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:28:14.071+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:28:14.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:28:14.080+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:28:14.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:28:14.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T16:28:44.463+0000] {processor.py:157} INFO - Started process (PID=23393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:28:44.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:28:44.466+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:28:44.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:28:44.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:28:44.490+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:28:44.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:28:44.499+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:28:44.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:28:44.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-18T16:29:14.896+0000] {processor.py:157} INFO - Started process (PID=23418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:29:14.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:29:14.901+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:29:14.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:29:14.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:29:14.930+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:29:14.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:29:14.940+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:29:14.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:29:14.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T16:29:45.340+0000] {processor.py:157} INFO - Started process (PID=23443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:29:45.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:29:45.343+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:29:45.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:29:45.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:29:45.373+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:29:45.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:29:45.382+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:29:45.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:29:45.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T16:30:15.805+0000] {processor.py:157} INFO - Started process (PID=23468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:30:15.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:30:15.808+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:30:15.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:30:15.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:30:15.836+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:30:15.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:30:15.846+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:30:15.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:30:15.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T16:30:46.281+0000] {processor.py:157} INFO - Started process (PID=23493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:30:46.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:30:46.284+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:30:46.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:30:46.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:30:46.319+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:30:46.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:30:46.330+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:30:46.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:30:46.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-18T16:31:16.655+0000] {processor.py:157} INFO - Started process (PID=23518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:31:16.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:31:16.658+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:31:16.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:31:16.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:31:16.687+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:31:16.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:31:16.697+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:31:16.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:31:16.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T16:31:47.068+0000] {processor.py:157} INFO - Started process (PID=23543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:31:47.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:31:47.071+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:31:47.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:31:47.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:31:47.102+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:31:47.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:31:47.111+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:31:47.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:31:47.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T16:32:17.466+0000] {processor.py:157} INFO - Started process (PID=23568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:32:17.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:32:17.469+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:32:17.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:32:17.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:32:17.496+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:32:17.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:32:17.508+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:32:17.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:32:17.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T16:32:47.861+0000] {processor.py:157} INFO - Started process (PID=23593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:32:47.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:32:47.865+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:32:47.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:32:47.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:32:47.891+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:32:47.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:32:47.901+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:32:47.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:32:47.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T16:33:18.290+0000] {processor.py:157} INFO - Started process (PID=23618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:33:18.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:33:18.294+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:33:18.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:33:18.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:33:18.323+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:33:18.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:33:18.333+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:33:18.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:33:18.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T16:33:48.748+0000] {processor.py:157} INFO - Started process (PID=23643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:33:48.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:33:48.753+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:33:48.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:33:48.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:33:48.786+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:33:48.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:33:48.801+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:33:48.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:33:48.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-18T16:34:19.201+0000] {processor.py:157} INFO - Started process (PID=23668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:34:19.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:34:19.204+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:34:19.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:34:19.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:34:19.231+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:34:19.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:34:19.242+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:34:19.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:34:19.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T16:34:49.621+0000] {processor.py:157} INFO - Started process (PID=23693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:34:49.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:34:49.624+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:34:49.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:34:49.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:34:49.656+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:34:49.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:34:49.666+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:34:49.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:34:49.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T16:35:20.066+0000] {processor.py:157} INFO - Started process (PID=23718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:35:20.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:35:20.070+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:35:20.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:35:20.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:35:20.108+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:35:20.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:35:20.121+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:35:20.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:35:20.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-18T16:35:50.536+0000] {processor.py:157} INFO - Started process (PID=23743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:35:50.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:35:50.541+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:35:50.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:35:50.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:35:50.569+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:35:50.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:35:50.582+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:35:50.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:35:50.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T16:36:20.951+0000] {processor.py:157} INFO - Started process (PID=23768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:36:20.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:36:20.956+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:36:20.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:36:20.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:36:20.983+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:36:20.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:36:20.993+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:36:20.993+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:36:21.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T16:36:51.411+0000] {processor.py:157} INFO - Started process (PID=23793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:36:51.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:36:51.415+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:36:51.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:36:51.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:36:51.444+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:36:51.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:36:51.455+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:36:51.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:36:51.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T16:37:21.860+0000] {processor.py:157} INFO - Started process (PID=23818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:37:21.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:37:21.865+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:37:21.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:37:21.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:37:21.926+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:37:21.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:37:21.942+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:37:21.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:37:21.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-18T16:37:52.386+0000] {processor.py:157} INFO - Started process (PID=23843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:37:52.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:37:52.388+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:37:52.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:37:52.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:37:52.414+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:37:52.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:37:52.424+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:37:52.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:37:52.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T16:38:22.777+0000] {processor.py:157} INFO - Started process (PID=23868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:38:22.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:38:22.782+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:38:22.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:38:22.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:38:22.817+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:38:22.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:38:22.831+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:38:22.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:38:22.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-18T16:38:53.241+0000] {processor.py:157} INFO - Started process (PID=23893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:38:53.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:38:53.244+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:38:53.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:38:53.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:38:53.275+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:38:53.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:38:53.288+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:38:53.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:38:53.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T16:39:23.702+0000] {processor.py:157} INFO - Started process (PID=23918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:39:23.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:39:23.705+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:39:23.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:39:23.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:39:23.734+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:39:23.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:39:23.744+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:39:23.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:39:23.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T16:39:54.112+0000] {processor.py:157} INFO - Started process (PID=23943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:39:54.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:39:54.116+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:39:54.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:39:54.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:39:54.146+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:39:54.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:39:54.157+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:39:54.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:39:54.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T16:40:24.559+0000] {processor.py:157} INFO - Started process (PID=23968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:40:24.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:40:24.562+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:40:24.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:40:24.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:40:24.590+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:40:24.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:40:24.600+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:40:24.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:40:24.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T16:40:54.974+0000] {processor.py:157} INFO - Started process (PID=23993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:40:54.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:40:54.978+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:40:54.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:40:54.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:40:55.004+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:40:55.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:40:55.014+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:40:55.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:40:55.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T16:41:25.433+0000] {processor.py:157} INFO - Started process (PID=24018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:41:25.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:41:25.436+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:41:25.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:41:25.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:41:25.461+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:41:25.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:41:25.471+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:41:25.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:41:25.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T16:41:55.889+0000] {processor.py:157} INFO - Started process (PID=24043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:41:55.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:41:55.892+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:41:55.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:41:55.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:41:55.924+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:41:55.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:41:55.935+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:41:55.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:41:55.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T16:42:26.369+0000] {processor.py:157} INFO - Started process (PID=24068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:42:26.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:42:26.372+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:42:26.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:42:26.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:42:26.407+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:42:26.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:42:26.420+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:42:26.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:42:26.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-18T16:42:56.843+0000] {processor.py:157} INFO - Started process (PID=24093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:42:56.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:42:56.845+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:42:56.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:42:56.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:42:56.868+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:42:56.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:42:56.878+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:42:56.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:42:56.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-18T16:43:27.241+0000] {processor.py:157} INFO - Started process (PID=24118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:43:27.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:43:27.244+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:43:27.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:43:27.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:43:27.272+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:43:27.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:43:27.283+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:43:27.283+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:43:27.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T16:43:57.590+0000] {processor.py:157} INFO - Started process (PID=24143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:43:57.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:43:57.593+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:43:57.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:43:57.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:43:57.620+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:43:57.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:43:57.632+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:43:57.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:43:57.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T16:44:28.013+0000] {processor.py:157} INFO - Started process (PID=24168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:44:28.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:44:28.017+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:44:28.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:44:28.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:44:28.045+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:44:28.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:44:28.055+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:44:28.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:44:28.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T16:44:58.477+0000] {processor.py:157} INFO - Started process (PID=24193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:44:58.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:44:58.481+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:44:58.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:44:58.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:44:58.510+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:44:58.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:44:58.520+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:44:58.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:44:58.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T16:45:28.938+0000] {processor.py:157} INFO - Started process (PID=24218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:45:28.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:45:28.940+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:45:28.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:45:28.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:45:28.969+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:45:28.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:45:28.979+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:45:28.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:45:28.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T16:45:59.351+0000] {processor.py:157} INFO - Started process (PID=24243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:45:59.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:45:59.354+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:45:59.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:45:59.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:45:59.380+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:45:59.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:45:59.389+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:45:59.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:45:59.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T16:46:29.737+0000] {processor.py:157} INFO - Started process (PID=24268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:46:29.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:46:29.740+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:46:29.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:46:29.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:46:29.768+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:46:29.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:46:29.778+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:46:29.778+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:46:29.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T16:47:00.172+0000] {processor.py:157} INFO - Started process (PID=24293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:47:00.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:47:00.176+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:47:00.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:47:00.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:47:00.204+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:47:00.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:47:00.215+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:47:00.215+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:47:00.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T16:47:30.667+0000] {processor.py:157} INFO - Started process (PID=24318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:47:30.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:47:30.672+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:47:30.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:47:30.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:47:30.698+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:47:30.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:47:30.708+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:47:30.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:47:30.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T16:48:01.135+0000] {processor.py:157} INFO - Started process (PID=24343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:48:01.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:48:01.138+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:48:01.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:48:01.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:48:01.164+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:48:01.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:48:01.173+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:48:01.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:48:01.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T16:48:31.555+0000] {processor.py:157} INFO - Started process (PID=24368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:48:31.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:48:31.558+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:48:31.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:48:31.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:48:31.586+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:48:31.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:48:31.595+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:48:31.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:48:31.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T16:49:02.031+0000] {processor.py:157} INFO - Started process (PID=24393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:49:02.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:49:02.034+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:49:02.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:49:02.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:49:02.062+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:49:02.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:49:02.072+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:49:02.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:49:02.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T16:49:32.477+0000] {processor.py:157} INFO - Started process (PID=24418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:49:32.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:49:32.479+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:49:32.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:49:32.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:49:32.505+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:49:32.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:49:32.515+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:49:32.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:49:32.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T16:50:02.982+0000] {processor.py:157} INFO - Started process (PID=24443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:50:02.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:50:02.986+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:50:02.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:50:02.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:50:03.013+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:50:03.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:50:03.023+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:50:03.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:50:03.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T16:50:33.448+0000] {processor.py:157} INFO - Started process (PID=24468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:50:33.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:50:33.451+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:50:33.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:50:33.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:50:33.480+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:50:33.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:50:33.492+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:50:33.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:50:33.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T16:51:03.879+0000] {processor.py:157} INFO - Started process (PID=24493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:51:03.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:51:03.884+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:51:03.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:51:03.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:51:03.915+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:51:03.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:51:03.925+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:51:03.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:51:03.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T16:51:34.328+0000] {processor.py:157} INFO - Started process (PID=24518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:51:34.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:51:34.331+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:51:34.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:51:34.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:51:34.366+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:51:34.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:51:34.377+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:51:34.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:51:34.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-18T16:52:04.832+0000] {processor.py:157} INFO - Started process (PID=24543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:52:04.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:52:04.836+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:52:04.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:52:04.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:52:04.874+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:52:04.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:52:04.888+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:52:04.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:52:04.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-18T16:52:35.303+0000] {processor.py:157} INFO - Started process (PID=24568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:52:35.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:52:35.307+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:52:35.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:52:35.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:52:35.338+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:52:35.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:52:35.351+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:52:35.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:52:35.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-18T16:53:05.776+0000] {processor.py:157} INFO - Started process (PID=24593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:53:05.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:53:05.779+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:53:05.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:53:05.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:53:05.811+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:53:05.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:53:05.822+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:53:05.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:53:05.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-18T16:53:36.191+0000] {processor.py:157} INFO - Started process (PID=24618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:53:36.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:53:36.194+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:53:36.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:53:36.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:53:36.232+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:53:36.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:53:36.243+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:53:36.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:53:36.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-18T16:54:06.621+0000] {processor.py:157} INFO - Started process (PID=24643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:54:06.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:54:06.625+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:54:06.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:54:06.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:54:06.652+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:54:06.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:54:06.663+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:54:06.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:54:06.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T16:54:37.001+0000] {processor.py:157} INFO - Started process (PID=24668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:54:37.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:54:37.004+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:54:37.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:54:37.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:54:37.027+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:54:37.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:54:37.039+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:54:37.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:54:37.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T16:55:07.462+0000] {processor.py:157} INFO - Started process (PID=24693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:55:07.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:55:07.466+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:55:07.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:55:07.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:55:07.493+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:55:07.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:55:07.505+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:55:07.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:55:07.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T16:55:37.978+0000] {processor.py:157} INFO - Started process (PID=24718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:55:37.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:55:37.981+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:55:37.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:55:37.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:55:38.008+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:55:38.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:55:38.019+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:55:38.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:55:38.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T16:56:08.435+0000] {processor.py:157} INFO - Started process (PID=24743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:56:08.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:56:08.440+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:56:08.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:56:08.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:56:08.464+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:56:08.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:56:08.473+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:56:08.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:56:08.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T16:56:38.894+0000] {processor.py:157} INFO - Started process (PID=24768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:56:38.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:56:38.899+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:56:38.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:56:38.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:56:38.926+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:56:38.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:56:38.935+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:56:38.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:56:38.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T16:57:09.267+0000] {processor.py:157} INFO - Started process (PID=24793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:57:09.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:57:09.269+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:57:09.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:57:09.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:57:09.297+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:57:09.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:57:09.307+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:57:09.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:57:09.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T16:57:39.708+0000] {processor.py:157} INFO - Started process (PID=24818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:57:39.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:57:39.710+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:57:39.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:57:39.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:57:39.737+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:57:39.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:57:39.746+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:57:39.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:57:39.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-18T16:58:10.152+0000] {processor.py:157} INFO - Started process (PID=24843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:58:10.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:58:10.157+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:58:10.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:58:10.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:58:10.184+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:58:10.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:58:10.194+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:58:10.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:58:10.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T16:58:40.572+0000] {processor.py:157} INFO - Started process (PID=24868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:58:40.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:58:40.575+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:58:40.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:58:40.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:58:40.602+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:58:40.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:58:40.612+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:58:40.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:58:40.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T16:59:11.067+0000] {processor.py:157} INFO - Started process (PID=24893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:59:11.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:59:11.072+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:59:11.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:59:11.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:59:11.100+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:59:11.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:59:11.110+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:59:11.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:59:11.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T16:59:41.498+0000] {processor.py:157} INFO - Started process (PID=24918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:59:41.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T16:59:41.502+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:59:41.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:59:41.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T16:59:41.531+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:59:41.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:59:41.543+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:59:41.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T16:59:41.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T17:00:11.906+0000] {processor.py:157} INFO - Started process (PID=24943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:00:11.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T17:00:11.911+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:00:11.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:00:11.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:00:11.950+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:00:11.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:00:11.962+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:00:11.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T17:00:11.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-18T17:00:42.358+0000] {processor.py:157} INFO - Started process (PID=24968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:00:42.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T17:00:42.361+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:00:42.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:00:42.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:00:42.389+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:00:42.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:00:42.400+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:00:42.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T17:00:42.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T17:01:12.720+0000] {processor.py:157} INFO - Started process (PID=24993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:01:12.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T17:01:12.722+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:01:12.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:01:12.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:01:12.751+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:01:12.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:01:12.761+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:01:12.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T17:01:12.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T17:01:43.177+0000] {processor.py:157} INFO - Started process (PID=25018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:01:43.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T17:01:43.181+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:01:43.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:01:43.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:01:43.205+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:01:43.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:01:43.215+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:01:43.215+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T17:01:43.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T17:02:13.581+0000] {processor.py:157} INFO - Started process (PID=25043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:02:13.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T17:02:13.585+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:02:13.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:02:13.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:02:13.613+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:02:13.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:02:13.623+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:02:13.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T17:02:13.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T17:02:44.087+0000] {processor.py:157} INFO - Started process (PID=25068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:02:44.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T17:02:44.094+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:02:44.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:02:44.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:02:44.152+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:02:44.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:02:44.173+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:02:44.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T17:02:44.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-18T17:03:20.068+0000] {processor.py:157} INFO - Started process (PID=25095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:03:20.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T17:03:20.070+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:03:20.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:03:20.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:03:20.094+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:03:20.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:03:20.105+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:03:20.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T17:03:20.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-18T17:03:50.520+0000] {processor.py:157} INFO - Started process (PID=25120) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:03:50.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T17:03:50.525+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:03:50.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:03:50.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:03:50.552+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:03:50.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:03:50.563+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:03:50.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T17:03:50.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T17:19:19.033+0000] {processor.py:157} INFO - Started process (PID=25145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:19:19.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T17:19:19.036+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:19:19.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:19:19.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:19:19.059+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:19:19.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:19:19.069+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:19:19.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T17:19:19.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T17:19:49.434+0000] {processor.py:157} INFO - Started process (PID=25168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:19:49.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T17:19:49.438+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:19:49.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:19:49.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:19:49.472+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:19:49.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:19:49.483+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:19:49.483+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T17:19:49.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-18T17:20:19.889+0000] {processor.py:157} INFO - Started process (PID=25195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:20:19.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T17:20:19.893+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:20:19.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:20:19.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:20:19.930+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:20:19.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:20:19.941+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:20:19.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T17:20:19.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-18T17:20:50.354+0000] {processor.py:157} INFO - Started process (PID=25220) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:20:50.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T17:20:50.357+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:20:50.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:20:50.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:20:50.385+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:20:50.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:20:50.396+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:20:50.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T17:20:50.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T17:21:20.811+0000] {processor.py:157} INFO - Started process (PID=25245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:21:20.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T17:21:20.814+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:21:20.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:21:20.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:21:20.838+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:21:20.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:21:20.847+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:21:20.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T17:21:20.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-18T17:21:51.246+0000] {processor.py:157} INFO - Started process (PID=25270) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:21:51.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T17:21:51.248+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:21:51.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:21:51.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:21:51.276+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:21:51.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:21:51.289+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:21:51.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T17:21:51.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T17:37:17.326+0000] {processor.py:157} INFO - Started process (PID=25295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:37:17.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T17:37:17.336+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:37:17.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:37:17.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:37:17.404+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:37:17.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:37:17.436+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:37:17.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T17:37:17.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-07-18T17:53:02.676+0000] {processor.py:157} INFO - Started process (PID=25322) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:53:02.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T17:53:02.679+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:53:02.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:53:02.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:53:02.713+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:53:02.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:53:02.726+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:53:02.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T17:53:02.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-18T17:53:33.152+0000] {processor.py:157} INFO - Started process (PID=25347) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:53:33.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T17:53:33.155+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:53:33.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:53:33.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:53:33.192+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:53:33.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:53:33.204+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:53:33.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T17:53:33.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-18T17:54:03.652+0000] {processor.py:157} INFO - Started process (PID=25372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:54:03.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T17:54:03.654+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:54:03.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:54:03.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T17:54:03.681+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:54:03.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:54:03.691+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:54:03.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T17:54:03.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T18:09:50.314+0000] {processor.py:157} INFO - Started process (PID=25397) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:09:50.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:09:50.319+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:09:50.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:09:50.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:09:50.364+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:09:50.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:09:50.401+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:09:50.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:09:50.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-07-18T18:26:10.968+0000] {processor.py:157} INFO - Started process (PID=25422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:26:10.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:26:10.970+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:26:10.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:26:10.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:26:11.007+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:26:11.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:26:11.021+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:26:11.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:26:11.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-18T18:26:41.538+0000] {processor.py:157} INFO - Started process (PID=25447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:26:41.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:26:41.545+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:26:41.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:26:41.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:26:41.577+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:26:41.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:26:41.590+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:26:41.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:26:41.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-18T18:27:11.957+0000] {processor.py:157} INFO - Started process (PID=25472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:27:11.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:27:11.959+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:27:11.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:27:11.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:27:11.986+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:27:11.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:27:11.998+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:27:11.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:27:12.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T18:27:42.312+0000] {processor.py:157} INFO - Started process (PID=25497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:27:42.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:27:42.315+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:27:42.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:27:42.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:27:42.341+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:27:42.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:27:42.350+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:27:42.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:27:42.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T18:28:12.824+0000] {processor.py:157} INFO - Started process (PID=25522) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:28:12.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:28:12.826+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:28:12.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:28:12.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:28:12.853+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:28:12.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:28:12.864+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:28:12.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:28:12.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T18:40:19.741+0000] {processor.py:157} INFO - Started process (PID=25547) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:40:19.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:40:19.745+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:40:19.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:40:19.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:40:19.783+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:40:19.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:40:19.798+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:40:19.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:40:19.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-18T18:40:50.348+0000] {processor.py:157} INFO - Started process (PID=25572) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:40:50.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:40:50.369+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:40:50.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:40:50.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:40:50.418+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:40:50.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:40:50.432+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:40:50.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:40:50.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-18T18:41:20.837+0000] {processor.py:157} INFO - Started process (PID=25597) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:41:20.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:41:20.840+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:41:20.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:41:20.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:41:20.872+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:41:20.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:41:20.884+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:41:20.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:41:20.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T18:41:51.273+0000] {processor.py:157} INFO - Started process (PID=25622) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:41:51.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:41:51.276+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:41:51.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:41:51.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:41:51.306+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:41:51.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:41:51.316+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:41:51.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:41:51.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T18:42:21.768+0000] {processor.py:157} INFO - Started process (PID=25647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:42:21.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:42:21.773+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:42:21.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:42:21.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:42:21.803+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:42:21.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:42:21.814+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:42:21.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:42:21.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T18:42:52.229+0000] {processor.py:157} INFO - Started process (PID=25672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:42:52.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:42:52.234+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:42:52.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:42:52.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:42:52.273+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:42:52.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:42:52.285+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:42:52.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:42:52.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-18T18:43:22.715+0000] {processor.py:157} INFO - Started process (PID=25697) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:43:22.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:43:22.718+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:43:22.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:43:22.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:43:22.744+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:43:22.744+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:43:22.754+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:43:22.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:43:22.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T18:43:53.135+0000] {processor.py:157} INFO - Started process (PID=25722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:43:53.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:43:53.138+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:43:53.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:43:53.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:43:53.164+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:43:53.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:43:53.174+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:43:53.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:43:53.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T18:44:23.673+0000] {processor.py:157} INFO - Started process (PID=25747) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:44:23.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:44:23.676+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:44:23.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:44:23.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:44:23.708+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:44:23.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:44:23.718+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:44:23.718+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:44:23.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T18:44:54.219+0000] {processor.py:157} INFO - Started process (PID=25772) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:44:54.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:44:54.223+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:44:54.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:44:54.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:44:54.251+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:44:54.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:44:54.262+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:44:54.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:44:54.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T18:45:24.704+0000] {processor.py:157} INFO - Started process (PID=25797) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:45:24.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:45:24.707+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:45:24.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:45:24.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:45:24.731+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:45:24.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:45:24.740+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:45:24.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:45:24.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-18T18:45:55.222+0000] {processor.py:157} INFO - Started process (PID=25822) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:45:55.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:45:55.227+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:45:55.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:45:55.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:45:55.255+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:45:55.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:45:55.265+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:45:55.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:45:55.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T18:46:25.689+0000] {processor.py:157} INFO - Started process (PID=25847) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:46:25.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:46:25.694+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:46:25.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:46:25.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:46:25.724+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:46:25.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:46:25.733+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:46:25.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:46:25.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T18:46:56.090+0000] {processor.py:157} INFO - Started process (PID=25872) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:46:56.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:46:56.093+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:46:56.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:46:56.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:46:56.121+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:46:56.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:46:56.134+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:46:56.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:46:56.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T18:47:26.584+0000] {processor.py:157} INFO - Started process (PID=25897) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:47:26.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:47:26.586+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:47:26.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:47:26.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:47:26.614+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:47:26.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:47:26.623+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:47:26.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:47:26.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T18:47:57.012+0000] {processor.py:157} INFO - Started process (PID=25922) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:47:57.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:47:57.014+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:47:57.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:47:57.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:47:57.037+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:47:57.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:47:57.046+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:47:57.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:47:57.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-18T18:48:27.520+0000] {processor.py:157} INFO - Started process (PID=25947) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:48:27.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:48:27.523+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:48:27.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:48:27.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:48:27.552+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:48:27.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:48:27.561+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:48:27.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:48:27.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T18:48:57.969+0000] {processor.py:157} INFO - Started process (PID=25972) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:48:57.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:48:57.972+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:48:57.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:48:57.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:48:58.002+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:48:58.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:48:58.013+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:48:58.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:48:58.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T18:49:28.420+0000] {processor.py:157} INFO - Started process (PID=25997) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:49:28.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:49:28.423+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:49:28.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:49:28.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:49:28.449+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:49:28.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:49:28.459+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:49:28.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:49:28.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T18:49:58.921+0000] {processor.py:157} INFO - Started process (PID=26022) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:49:58.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:49:58.924+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:49:58.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:49:58.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:49:58.953+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:49:58.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:49:58.963+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:49:58.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:49:58.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T18:50:29.399+0000] {processor.py:157} INFO - Started process (PID=26047) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:50:29.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:50:29.402+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:50:29.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:50:29.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:50:29.430+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:50:29.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:50:29.440+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:50:29.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:50:29.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T18:50:59.832+0000] {processor.py:157} INFO - Started process (PID=26072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:50:59.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:50:59.834+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:50:59.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:50:59.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:50:59.861+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:50:59.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:50:59.870+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:50:59.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:50:59.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T18:51:30.270+0000] {processor.py:157} INFO - Started process (PID=26097) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:51:30.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:51:30.273+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:51:30.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:51:30.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:51:30.302+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:51:30.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:51:30.311+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:51:30.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:51:30.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T18:52:00.773+0000] {processor.py:157} INFO - Started process (PID=26122) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:52:00.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:52:00.777+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:52:00.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:52:00.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:52:00.808+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:52:00.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:52:00.818+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:52:00.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:52:00.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T18:52:31.244+0000] {processor.py:157} INFO - Started process (PID=26147) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:52:31.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:52:31.247+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:52:31.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:52:31.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:52:31.278+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:52:31.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:52:31.289+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:52:31.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:52:31.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T18:53:01.722+0000] {processor.py:157} INFO - Started process (PID=26172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:53:01.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:53:01.726+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:53:01.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:53:01.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:53:01.754+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:53:01.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:53:01.765+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:53:01.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:53:01.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T18:53:32.207+0000] {processor.py:157} INFO - Started process (PID=26197) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:53:32.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:53:32.211+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:53:32.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:53:32.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:53:32.242+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:53:32.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:53:32.254+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:53:32.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:53:32.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T18:54:02.626+0000] {processor.py:157} INFO - Started process (PID=26222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:54:02.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:54:02.628+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:54:02.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:54:02.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:54:02.652+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:54:02.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:54:02.661+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:54:02.661+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:54:02.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-18T18:54:33.132+0000] {processor.py:157} INFO - Started process (PID=26247) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:54:33.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:54:33.134+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:54:33.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:54:33.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:54:33.161+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:54:33.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:54:33.170+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:54:33.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:54:33.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T18:55:03.628+0000] {processor.py:157} INFO - Started process (PID=26272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:55:03.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:55:03.630+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:55:03.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:55:03.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:55:03.656+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:55:03.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:55:03.666+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:55:03.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:55:03.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-18T18:55:34.223+0000] {processor.py:157} INFO - Started process (PID=26297) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:55:34.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:55:34.230+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:55:34.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:55:34.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:55:34.315+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:55:34.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:55:34.332+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:55:34.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:55:34.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-07-18T18:56:04.829+0000] {processor.py:157} INFO - Started process (PID=26322) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:56:04.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:56:04.838+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:56:04.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:56:04.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:56:04.865+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:56:04.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:56:04.875+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:56:04.875+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:56:04.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T18:56:35.393+0000] {processor.py:157} INFO - Started process (PID=26347) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:56:35.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:56:35.400+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:56:35.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:56:35.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:56:35.432+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:56:35.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:56:35.444+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:56:35.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:56:35.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-18T18:57:05.830+0000] {processor.py:157} INFO - Started process (PID=26372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:57:05.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:57:05.834+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:57:05.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:57:05.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:57:05.862+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:57:05.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:57:05.872+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:57:05.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:57:05.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T18:57:36.383+0000] {processor.py:157} INFO - Started process (PID=26397) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:57:36.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:57:36.387+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:57:36.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:57:36.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:57:36.419+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:57:36.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:57:36.429+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:57:36.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:57:36.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T18:58:06.868+0000] {processor.py:157} INFO - Started process (PID=26422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:58:06.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:58:06.871+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:58:06.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:58:06.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:58:06.904+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:58:06.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:58:06.914+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:58:06.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:58:06.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T18:58:37.324+0000] {processor.py:157} INFO - Started process (PID=26447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:58:37.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:58:37.327+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:58:37.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:58:37.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:58:37.354+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:58:37.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:58:37.364+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:58:37.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:58:37.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T18:59:07.745+0000] {processor.py:157} INFO - Started process (PID=26472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:59:07.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:59:07.748+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:59:07.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:59:07.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:59:07.781+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:59:07.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:59:07.793+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:59:07.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:59:07.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-18T18:59:38.183+0000] {processor.py:157} INFO - Started process (PID=26497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:59:38.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T18:59:38.186+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:59:38.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:59:38.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T18:59:38.214+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:59:38.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:59:38.227+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:59:38.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T18:59:38.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T19:00:08.610+0000] {processor.py:157} INFO - Started process (PID=26522) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:00:08.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:00:08.612+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:00:08.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:00:08.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:00:08.640+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:00:08.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:00:08.649+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:00:08.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:00:08.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T19:00:39.018+0000] {processor.py:157} INFO - Started process (PID=26547) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:00:39.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:00:39.021+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:00:39.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:00:39.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:00:39.045+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:00:39.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:00:39.055+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:00:39.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:00:39.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-18T19:01:09.488+0000] {processor.py:157} INFO - Started process (PID=26572) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:01:09.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:01:09.491+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:01:09.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:01:09.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:01:09.518+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:01:09.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:01:09.528+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:01:09.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:01:09.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T19:01:39.863+0000] {processor.py:157} INFO - Started process (PID=26597) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:01:39.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:01:39.865+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:01:39.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:01:39.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:01:39.893+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:01:39.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:01:39.904+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:01:39.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:01:39.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T19:02:10.380+0000] {processor.py:157} INFO - Started process (PID=26621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:02:10.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:02:10.382+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:02:10.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:02:10.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:02:10.410+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:02:10.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:02:10.423+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:02:10.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:02:10.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T19:02:40.834+0000] {processor.py:157} INFO - Started process (PID=26647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:02:40.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:02:40.837+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:02:40.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:02:40.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:02:40.870+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:02:40.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:02:40.879+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:02:40.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:02:40.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-18T19:03:11.303+0000] {processor.py:157} INFO - Started process (PID=26672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:03:11.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:03:11.306+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:03:11.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:03:11.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:03:11.335+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:03:11.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:03:11.347+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:03:11.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:03:11.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T19:03:41.783+0000] {processor.py:157} INFO - Started process (PID=26697) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:03:41.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:03:41.786+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:03:41.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:03:41.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:03:41.816+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:03:41.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:03:41.828+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:03:41.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:03:41.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T19:04:12.221+0000] {processor.py:157} INFO - Started process (PID=26722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:04:12.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:04:12.224+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:04:12.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:04:12.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:04:12.257+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:04:12.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:04:12.267+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:04:12.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:04:12.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T19:04:42.777+0000] {processor.py:157} INFO - Started process (PID=26747) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:04:42.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:04:42.779+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:04:42.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:04:42.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:04:42.804+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:04:42.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:04:42.814+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:04:42.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:04:42.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-18T19:05:13.194+0000] {processor.py:157} INFO - Started process (PID=26772) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:05:13.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:05:13.196+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:05:13.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:05:13.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:05:13.227+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:05:13.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:05:13.237+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:05:13.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:05:13.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T19:05:43.722+0000] {processor.py:157} INFO - Started process (PID=26797) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:05:43.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:05:43.726+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:05:43.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:05:43.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:05:43.751+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:05:43.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:05:43.760+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:05:43.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:05:43.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T19:06:14.109+0000] {processor.py:157} INFO - Started process (PID=26822) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:06:14.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:06:14.111+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:06:14.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:06:14.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:06:14.133+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:06:14.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:06:14.146+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:06:14.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:06:14.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-18T19:06:44.549+0000] {processor.py:157} INFO - Started process (PID=26847) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:06:44.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:06:44.554+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:06:44.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:06:44.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:06:44.584+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:06:44.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:06:44.594+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:06:44.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:06:44.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T19:07:15.028+0000] {processor.py:157} INFO - Started process (PID=26872) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:07:15.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:07:15.031+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:07:15.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:07:15.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:07:15.059+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:07:15.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:07:15.069+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:07:15.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:07:15.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T19:07:45.469+0000] {processor.py:157} INFO - Started process (PID=26897) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:07:45.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:07:45.474+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:07:45.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:07:45.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:07:45.510+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:07:45.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:07:45.526+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:07:45.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:07:45.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-18T19:08:15.980+0000] {processor.py:157} INFO - Started process (PID=26922) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:08:15.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:08:15.982+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:08:15.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:08:15.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:08:16.012+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:08:16.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:08:16.023+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:08:16.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:08:16.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T19:08:46.433+0000] {processor.py:157} INFO - Started process (PID=26947) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:08:46.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:08:46.435+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:08:46.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:08:46.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:08:46.463+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:08:46.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:08:46.473+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:08:46.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:08:46.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T19:09:16.899+0000] {processor.py:157} INFO - Started process (PID=26972) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:09:16.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:09:16.902+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:09:16.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:09:16.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:09:16.932+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:09:16.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:09:16.943+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:09:16.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:09:16.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T19:09:47.400+0000] {processor.py:157} INFO - Started process (PID=26997) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:09:47.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:09:47.402+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:09:47.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:09:47.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:09:47.429+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:09:47.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:09:47.442+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:09:47.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:09:47.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T19:10:17.889+0000] {processor.py:157} INFO - Started process (PID=27022) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:10:17.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:10:17.892+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:10:17.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:10:17.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:10:17.919+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:10:17.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:10:17.932+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:10:17.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:10:17.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T19:10:48.336+0000] {processor.py:157} INFO - Started process (PID=27047) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:10:48.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:10:48.340+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:10:48.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:10:48.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:10:48.372+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:10:48.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:10:48.383+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:10:48.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:10:48.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T19:11:18.822+0000] {processor.py:157} INFO - Started process (PID=27072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:11:18.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:11:18.826+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:11:18.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:11:18.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:11:18.858+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:11:18.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:11:18.867+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:11:18.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:11:18.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T19:11:49.289+0000] {processor.py:157} INFO - Started process (PID=27097) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:11:49.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:11:49.292+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:11:49.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:11:49.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:11:49.317+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:11:49.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:11:49.329+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:11:49.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:11:49.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T19:12:19.790+0000] {processor.py:157} INFO - Started process (PID=27122) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:12:19.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:12:19.792+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:12:19.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:12:19.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:12:19.822+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:12:19.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:12:19.833+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:12:19.833+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:12:19.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T19:12:50.245+0000] {processor.py:157} INFO - Started process (PID=27147) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:12:50.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:12:50.248+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:12:50.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:12:50.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:12:50.275+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:12:50.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:12:50.286+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:12:50.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:12:50.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T19:13:20.772+0000] {processor.py:157} INFO - Started process (PID=27172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:13:20.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:13:20.774+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:13:20.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:13:20.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:13:20.801+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:13:20.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:13:20.810+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:13:20.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:13:20.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-18T19:13:51.208+0000] {processor.py:157} INFO - Started process (PID=27197) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:13:51.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:13:51.211+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:13:51.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:13:51.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:13:51.240+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:13:51.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:13:51.252+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:13:51.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:13:51.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T19:14:21.633+0000] {processor.py:157} INFO - Started process (PID=27222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:14:21.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:14:21.637+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:14:21.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:14:21.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:14:21.666+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:14:21.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:14:21.679+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:14:21.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:14:21.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T19:14:52.072+0000] {processor.py:157} INFO - Started process (PID=27247) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:14:52.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:14:52.077+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:14:52.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:14:52.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:14:52.104+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:14:52.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:14:52.117+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:14:52.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:14:52.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T19:15:22.557+0000] {processor.py:157} INFO - Started process (PID=27272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:15:22.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:15:22.559+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:15:22.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:15:22.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:15:22.583+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:15:22.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:15:22.593+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:15:22.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:15:22.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-18T19:15:53.030+0000] {processor.py:157} INFO - Started process (PID=27297) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:15:53.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:15:53.033+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:15:53.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:15:53.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:15:53.060+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:15:53.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:15:53.070+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:15:53.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:15:53.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T19:16:23.452+0000] {processor.py:157} INFO - Started process (PID=27322) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:16:23.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:16:23.455+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:16:23.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:16:23.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:16:23.480+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:16:23.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:16:23.490+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:16:23.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:16:23.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T19:16:53.853+0000] {processor.py:157} INFO - Started process (PID=27347) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:16:53.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:16:53.856+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:16:53.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:16:53.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:16:53.883+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:16:53.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:16:53.895+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:16:53.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:16:53.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T19:17:24.335+0000] {processor.py:157} INFO - Started process (PID=27372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:17:24.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:17:24.337+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:17:24.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:17:24.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:17:24.368+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:17:24.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:17:24.377+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:17:24.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:17:24.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T19:17:54.796+0000] {processor.py:157} INFO - Started process (PID=27397) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:17:54.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:17:54.803+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:17:54.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:17:54.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:17:54.836+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:17:54.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:17:54.846+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:17:54.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:17:54.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-18T19:18:25.296+0000] {processor.py:157} INFO - Started process (PID=27422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:18:25.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:18:25.300+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:18:25.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:18:25.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:18:25.334+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:18:25.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:18:25.346+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:18:25.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:18:25.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-18T19:18:55.807+0000] {processor.py:157} INFO - Started process (PID=27447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:18:55.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:18:55.810+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:18:55.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:18:55.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:18:55.838+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:18:55.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:18:55.847+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:18:55.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:18:55.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T19:19:26.300+0000] {processor.py:157} INFO - Started process (PID=27472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:19:26.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:19:26.303+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:19:26.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:19:26.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:19:26.329+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:19:26.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:19:26.340+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:19:26.340+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:19:26.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T19:19:56.759+0000] {processor.py:157} INFO - Started process (PID=27497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:19:56.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:19:56.761+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:19:56.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:19:56.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:19:56.787+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:19:56.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:19:56.798+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:19:56.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:19:56.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T19:20:27.243+0000] {processor.py:157} INFO - Started process (PID=27522) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:20:27.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:20:27.245+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:20:27.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:20:27.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:20:27.272+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:20:27.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:20:27.282+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:20:27.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:20:27.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T19:20:57.686+0000] {processor.py:157} INFO - Started process (PID=27547) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:20:57.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:20:57.688+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:20:57.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:20:57.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:20:57.718+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:20:57.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:20:57.728+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:20:57.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:20:57.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T19:21:28.171+0000] {processor.py:157} INFO - Started process (PID=27572) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:21:28.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:21:28.176+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:21:28.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:21:28.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:21:28.202+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:21:28.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:21:28.211+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:21:28.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:21:28.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T19:21:58.549+0000] {processor.py:157} INFO - Started process (PID=27597) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:21:58.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:21:58.553+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:21:58.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:21:58.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:21:58.581+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:21:58.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:21:58.593+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:21:58.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:21:58.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T19:22:29.004+0000] {processor.py:157} INFO - Started process (PID=27622) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:22:29.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:22:29.007+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:22:29.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:22:29.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:22:29.034+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:22:29.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:22:29.045+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:22:29.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:22:29.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T19:22:59.494+0000] {processor.py:157} INFO - Started process (PID=27647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:22:59.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:22:59.497+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:22:59.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:22:59.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:22:59.521+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:22:59.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:22:59.530+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:22:59.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:22:59.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T19:23:29.905+0000] {processor.py:157} INFO - Started process (PID=27672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:23:29.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:23:29.907+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:23:29.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:23:29.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:23:29.936+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:23:29.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:23:29.948+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:23:29.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:23:29.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T19:24:00.357+0000] {processor.py:157} INFO - Started process (PID=27697) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:24:00.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:24:00.359+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:24:00.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:24:00.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:24:00.387+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:24:00.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:24:00.399+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:24:00.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:24:00.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T19:24:30.881+0000] {processor.py:157} INFO - Started process (PID=27722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:24:30.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:24:30.884+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:24:30.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:24:30.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:24:30.911+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:24:30.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:24:30.921+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:24:30.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:24:30.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T19:25:01.384+0000] {processor.py:157} INFO - Started process (PID=27747) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:25:01.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:25:01.387+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:25:01.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:25:01.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:25:01.414+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:25:01.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:25:01.424+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:25:01.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:25:01.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T19:25:31.885+0000] {processor.py:157} INFO - Started process (PID=27772) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:25:31.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:25:31.889+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:25:31.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:25:31.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:25:31.917+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:25:31.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:25:31.932+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:25:31.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:25:31.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-18T19:26:02.338+0000] {processor.py:157} INFO - Started process (PID=27797) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:26:02.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:26:02.341+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:26:02.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:26:02.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:26:02.369+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:26:02.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:26:02.381+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:26:02.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:26:02.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T19:26:32.789+0000] {processor.py:157} INFO - Started process (PID=27822) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:26:32.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:26:32.792+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:26:32.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:26:32.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:26:32.820+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:26:32.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:26:32.832+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:26:32.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:26:32.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T19:27:03.243+0000] {processor.py:157} INFO - Started process (PID=27847) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:27:03.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:27:03.246+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:27:03.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:27:03.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:27:03.278+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:27:03.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:27:03.288+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:27:03.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:27:03.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T19:27:33.735+0000] {processor.py:157} INFO - Started process (PID=27872) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:27:33.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:27:33.738+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:27:33.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:27:33.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:27:33.765+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:27:33.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:27:33.776+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:27:33.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:27:33.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T19:28:04.224+0000] {processor.py:157} INFO - Started process (PID=27897) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:28:04.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:28:04.228+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:28:04.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:28:04.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:28:04.254+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:28:04.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:28:04.264+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:28:04.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:28:04.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T19:28:34.705+0000] {processor.py:157} INFO - Started process (PID=27922) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:28:34.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:28:34.708+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:28:34.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:28:34.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:28:34.736+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:28:34.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:28:34.746+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:28:34.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:28:34.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T19:29:05.167+0000] {processor.py:157} INFO - Started process (PID=27947) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:29:05.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:29:05.170+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:29:05.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:29:05.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:29:05.194+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:29:05.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:29:05.205+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:29:05.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:29:05.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-18T19:29:35.589+0000] {processor.py:157} INFO - Started process (PID=27972) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:29:35.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:29:35.592+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:29:35.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:29:35.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:29:35.617+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:29:35.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:29:35.628+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:29:35.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:29:35.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T19:30:06.087+0000] {processor.py:157} INFO - Started process (PID=27997) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:30:06.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:30:06.091+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:30:06.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:30:06.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:30:06.116+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:30:06.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:30:06.126+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:30:06.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:30:06.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T19:30:36.609+0000] {processor.py:157} INFO - Started process (PID=28022) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:30:36.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:30:36.612+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:30:36.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:30:36.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:30:36.640+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:30:36.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:30:36.651+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:30:36.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:30:36.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T19:31:07.055+0000] {processor.py:157} INFO - Started process (PID=28047) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:31:07.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:31:07.061+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:31:07.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:31:07.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:31:07.093+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:31:07.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:31:07.105+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:31:07.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:31:07.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-18T19:31:37.522+0000] {processor.py:157} INFO - Started process (PID=28072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:31:37.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:31:37.527+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:31:37.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:31:37.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:31:37.557+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:31:37.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:31:37.566+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:31:37.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:31:37.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T19:32:07.988+0000] {processor.py:157} INFO - Started process (PID=28097) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:32:07.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:32:07.991+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:32:07.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:32:08.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:32:08.023+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:32:08.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:32:08.035+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:32:08.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:32:08.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-18T19:32:38.484+0000] {processor.py:157} INFO - Started process (PID=28122) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:32:38.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:32:38.487+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:32:38.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:32:38.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:32:38.511+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:32:38.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:32:38.522+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:32:38.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:32:38.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T19:33:08.996+0000] {processor.py:157} INFO - Started process (PID=28147) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:33:08.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:33:09.001+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:33:09.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:33:09.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:33:09.028+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:33:09.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:33:09.039+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:33:09.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:33:09.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T19:33:39.455+0000] {processor.py:157} INFO - Started process (PID=28172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:33:39.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:33:39.458+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:33:39.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:33:39.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:33:39.487+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:33:39.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:33:39.496+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:33:39.496+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:33:39.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T19:34:09.883+0000] {processor.py:157} INFO - Started process (PID=28197) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:34:09.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:34:09.887+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:34:09.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:34:09.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:34:09.921+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:34:09.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:34:09.933+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:34:09.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:34:09.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-18T19:34:40.396+0000] {processor.py:157} INFO - Started process (PID=28222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:34:40.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:34:40.399+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:34:40.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:34:40.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:34:40.431+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:34:40.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:34:40.443+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:34:40.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:34:40.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-18T19:35:10.839+0000] {processor.py:157} INFO - Started process (PID=28247) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:35:10.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:35:10.841+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:35:10.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:35:10.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:35:10.875+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:35:10.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:35:10.887+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:35:10.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:35:10.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-18T19:35:41.301+0000] {processor.py:157} INFO - Started process (PID=28272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:35:41.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:35:41.305+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:35:41.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:35:41.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:35:41.329+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:35:41.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:35:41.339+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:35:41.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:35:41.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T19:36:11.754+0000] {processor.py:157} INFO - Started process (PID=28297) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:36:11.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:36:11.758+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:36:11.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:36:11.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:36:11.786+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:36:11.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:36:11.795+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:36:11.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:36:11.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T19:36:42.184+0000] {processor.py:157} INFO - Started process (PID=28322) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:36:42.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:36:42.189+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:36:42.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:36:42.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:36:42.220+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:36:42.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:36:42.231+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:36:42.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:36:42.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T19:37:12.602+0000] {processor.py:157} INFO - Started process (PID=28347) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:37:12.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:37:12.604+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:37:12.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:37:12.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:37:12.638+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:37:12.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:37:12.648+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:37:12.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:37:12.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T19:37:42.988+0000] {processor.py:157} INFO - Started process (PID=28372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:37:42.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:37:42.990+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:37:42.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:37:43.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:37:43.017+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:37:43.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:37:43.027+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:37:43.027+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:37:43.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T19:38:13.452+0000] {processor.py:157} INFO - Started process (PID=28397) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:38:13.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:38:13.456+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:38:13.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:38:13.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:38:13.485+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:38:13.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:38:13.496+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:38:13.496+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:38:13.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T19:38:43.852+0000] {processor.py:157} INFO - Started process (PID=28422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:38:43.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:38:43.857+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:38:43.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:38:43.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:38:43.888+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:38:43.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:38:43.899+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:38:43.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:38:43.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-18T19:39:14.287+0000] {processor.py:157} INFO - Started process (PID=28447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:39:14.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:39:14.290+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:39:14.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:39:14.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:39:14.319+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:39:14.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:39:14.330+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:39:14.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:39:14.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T19:39:44.687+0000] {processor.py:157} INFO - Started process (PID=28472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:39:44.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:39:44.693+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:39:44.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:39:44.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:39:44.727+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:39:44.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:39:44.738+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:39:44.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:39:44.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-18T19:40:15.161+0000] {processor.py:157} INFO - Started process (PID=28497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:40:15.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:40:15.166+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:40:15.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:40:15.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:40:15.195+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:40:15.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:40:15.204+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:40:15.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:40:15.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T19:40:45.633+0000] {processor.py:157} INFO - Started process (PID=28522) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:40:45.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:40:45.636+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:40:45.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:40:45.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:40:45.666+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:40:45.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:40:45.678+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:40:45.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:40:45.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T19:41:19.129+0000] {processor.py:157} INFO - Started process (PID=28549) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:41:19.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:41:19.131+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:41:19.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:41:19.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:41:19.154+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:41:19.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:41:19.166+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:41:19.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:41:19.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-18T19:41:49.606+0000] {processor.py:157} INFO - Started process (PID=28574) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:41:49.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:41:49.611+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:41:49.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:41:49.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:41:49.636+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:41:49.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:41:49.646+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:41:49.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:41:49.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T19:57:57.463+0000] {processor.py:157} INFO - Started process (PID=28599) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:57:57.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:57:57.465+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:57:57.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:57:57.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:57:57.504+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:57:57.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:57:57.515+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:57:57.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:57:57.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-18T19:58:28.109+0000] {processor.py:157} INFO - Started process (PID=28624) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:58:28.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:58:28.114+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:58:28.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:58:28.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:58:28.149+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:58:28.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:58:28.161+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:58:28.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:58:28.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-18T19:58:58.608+0000] {processor.py:157} INFO - Started process (PID=28649) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:58:58.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:58:58.612+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:58:58.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:58:58.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:58:58.640+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:58:58.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:58:58.652+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:58:58.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:58:58.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T19:59:29.135+0000] {processor.py:157} INFO - Started process (PID=28674) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:59:29.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:59:29.138+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:59:29.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:59:29.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:59:29.166+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:59:29.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:59:29.177+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:59:29.177+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:59:29.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T19:59:59.563+0000] {processor.py:157} INFO - Started process (PID=28699) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:59:59.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T19:59:59.566+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:59:59.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:59:59.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T19:59:59.595+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:59:59.595+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:59:59.606+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:59:59.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T19:59:59.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T20:00:30.038+0000] {processor.py:157} INFO - Started process (PID=28724) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:00:30.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:00:30.046+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:00:30.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:00:30.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:00:30.083+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:00:30.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:00:30.096+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:00:30.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:00:30.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-18T20:01:00.485+0000] {processor.py:157} INFO - Started process (PID=28749) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:01:00.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:01:00.488+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:01:00.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:01:00.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:01:00.518+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:01:00.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:01:00.528+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:01:00.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:01:00.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T20:16:46.733+0000] {processor.py:157} INFO - Started process (PID=28776) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:16:46.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:16:46.738+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:16:46.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:16:46.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:16:46.783+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:16:46.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:16:46.801+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:16:46.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:16:46.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-18T20:17:17.223+0000] {processor.py:157} INFO - Started process (PID=28801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:17:17.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:17:17.231+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:17:17.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:17:17.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:17:17.265+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:17:17.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:17:17.276+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:17:17.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:17:17.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-18T20:17:47.579+0000] {processor.py:157} INFO - Started process (PID=28826) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:17:47.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:17:47.585+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:17:47.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:17:47.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:17:47.614+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:17:47.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:17:47.626+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:17:47.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:17:47.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T20:18:18.098+0000] {processor.py:157} INFO - Started process (PID=28851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:18:18.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:18:18.103+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:18:18.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:18:18.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:18:18.133+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:18:18.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:18:18.145+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:18:18.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:18:18.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-18T20:34:02.184+0000] {processor.py:157} INFO - Started process (PID=28876) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:34:02.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:34:02.190+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:34:02.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:34:02.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:34:02.262+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:34:02.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:34:02.292+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:34:02.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:34:02.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-07-18T20:34:32.721+0000] {processor.py:157} INFO - Started process (PID=28901) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:34:32.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:34:32.726+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:34:32.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:34:32.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:34:32.757+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:34:32.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:34:32.765+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:34:32.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:34:32.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T20:35:03.214+0000] {processor.py:157} INFO - Started process (PID=28926) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:35:03.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:35:03.217+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:35:03.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:35:03.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:35:03.253+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:35:03.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:35:03.266+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:35:03.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:35:03.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-18T20:35:33.703+0000] {processor.py:157} INFO - Started process (PID=28951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:35:33.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:35:33.706+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:35:33.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:35:33.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:35:33.737+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:35:33.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:35:33.748+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:35:33.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:35:33.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T20:36:04.140+0000] {processor.py:157} INFO - Started process (PID=28976) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:36:04.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:36:04.143+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:36:04.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:36:04.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:36:04.172+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:36:04.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:36:04.182+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:36:04.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:36:04.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T20:36:34.661+0000] {processor.py:157} INFO - Started process (PID=29001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:36:34.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:36:34.668+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:36:34.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:36:34.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:36:34.697+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:36:34.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:36:34.707+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:36:34.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:36:34.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T20:37:05.113+0000] {processor.py:157} INFO - Started process (PID=29026) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:37:05.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:37:05.119+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:37:05.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:37:05.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:37:05.146+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:37:05.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:37:05.155+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:37:05.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:37:05.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T20:37:35.581+0000] {processor.py:157} INFO - Started process (PID=29051) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:37:35.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:37:35.589+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:37:35.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:37:35.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:37:35.611+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:37:35.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:37:35.620+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:37:35.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:37:35.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T20:38:06.073+0000] {processor.py:157} INFO - Started process (PID=29076) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:38:06.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:38:06.076+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:38:06.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:38:06.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:38:06.111+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:38:06.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:38:06.122+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:38:06.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:38:06.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-18T20:38:36.617+0000] {processor.py:157} INFO - Started process (PID=29101) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:38:36.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:38:36.621+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:38:36.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:38:36.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:38:36.650+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:38:36.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:38:36.661+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:38:36.661+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:38:36.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T20:39:07.137+0000] {processor.py:157} INFO - Started process (PID=29126) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:39:07.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:39:07.145+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:39:07.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:39:07.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:39:07.167+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:39:07.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:39:07.177+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:39:07.177+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:39:07.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T20:39:37.623+0000] {processor.py:157} INFO - Started process (PID=29151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:39:37.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:39:37.626+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:39:37.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:39:37.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:39:37.655+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:39:37.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:39:37.665+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:39:37.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:39:37.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T20:40:08.005+0000] {processor.py:157} INFO - Started process (PID=29176) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:40:08.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:40:08.008+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:40:08.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:40:08.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:40:08.031+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:40:08.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:40:08.040+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:40:08.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:40:08.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-18T20:40:38.459+0000] {processor.py:157} INFO - Started process (PID=29201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:40:38.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:40:38.462+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:40:38.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:40:38.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:40:38.489+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:40:38.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:40:38.498+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:40:38.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:40:38.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T20:41:08.893+0000] {processor.py:157} INFO - Started process (PID=29226) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:41:08.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:41:08.896+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:41:08.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:41:08.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:41:08.921+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:41:08.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:41:08.931+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:41:08.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:41:08.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T20:41:39.301+0000] {processor.py:157} INFO - Started process (PID=29251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:41:39.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:41:39.304+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:41:39.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:41:39.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:41:39.329+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:41:39.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:41:39.339+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:41:39.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:41:39.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T20:42:09.790+0000] {processor.py:157} INFO - Started process (PID=29276) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:42:09.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:42:09.792+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:42:09.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:42:09.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:42:09.828+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:42:09.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:42:09.838+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:42:09.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:42:09.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-18T20:42:40.288+0000] {processor.py:157} INFO - Started process (PID=29301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:42:40.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:42:40.293+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:42:40.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:42:40.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:42:40.332+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:42:40.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:42:40.341+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:42:40.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:42:40.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-18T20:43:10.695+0000] {processor.py:157} INFO - Started process (PID=29326) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:43:10.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:43:10.699+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:43:10.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:43:10.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:43:10.734+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:43:10.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:43:10.743+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:43:10.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:43:10.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-18T20:43:41.176+0000] {processor.py:157} INFO - Started process (PID=29351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:43:41.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:43:41.181+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:43:41.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:43:41.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:43:41.212+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:43:41.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:43:41.223+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:43:41.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:43:41.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-18T20:44:11.698+0000] {processor.py:157} INFO - Started process (PID=29376) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:44:11.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:44:11.701+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:44:11.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:44:11.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:44:11.729+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:44:11.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:44:11.746+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:44:11.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:44:11.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-18T20:44:42.137+0000] {processor.py:157} INFO - Started process (PID=29401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:44:42.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:44:42.141+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:44:42.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:44:42.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:44:42.172+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:44:42.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:44:42.181+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:44:42.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:44:42.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T20:45:12.570+0000] {processor.py:157} INFO - Started process (PID=29426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:45:12.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:45:12.571+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:45:12.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:45:12.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:45:12.599+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:45:12.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:45:12.608+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:45:12.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:45:12.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T20:45:42.950+0000] {processor.py:157} INFO - Started process (PID=29451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:45:42.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:45:42.953+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:45:42.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:45:42.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:45:42.981+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:45:42.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:45:42.991+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:45:42.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:45:43.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T20:46:13.443+0000] {processor.py:157} INFO - Started process (PID=29476) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:46:13.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:46:13.447+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:46:13.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:46:13.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:46:13.476+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:46:13.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:46:13.487+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:46:13.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:46:13.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T20:46:43.925+0000] {processor.py:157} INFO - Started process (PID=29501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:46:43.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:46:43.931+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:46:43.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:46:43.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:46:43.969+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:46:43.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:46:43.980+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:46:43.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:46:43.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-18T20:47:14.385+0000] {processor.py:157} INFO - Started process (PID=29526) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:47:14.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:47:14.388+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:47:14.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:47:14.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:47:14.415+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:47:14.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:47:14.425+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:47:14.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:47:14.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T20:47:44.835+0000] {processor.py:157} INFO - Started process (PID=29551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:47:44.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:47:44.840+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:47:44.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:47:44.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:47:44.867+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:47:44.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:47:44.879+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:47:44.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:47:44.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T20:48:15.277+0000] {processor.py:157} INFO - Started process (PID=29576) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:48:15.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:48:15.280+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:48:15.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:48:15.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:48:15.308+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:48:15.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:48:15.319+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:48:15.319+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:48:15.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T20:48:45.859+0000] {processor.py:157} INFO - Started process (PID=29601) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:48:45.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:48:45.867+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:48:45.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:48:45.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:48:45.891+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:48:45.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:48:45.901+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:48:45.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:48:45.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T20:49:16.371+0000] {processor.py:157} INFO - Started process (PID=29626) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:49:16.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:49:16.374+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:49:16.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:49:16.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:49:16.402+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:49:16.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:49:16.412+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:49:16.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:49:16.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T20:49:46.808+0000] {processor.py:157} INFO - Started process (PID=29651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:49:46.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:49:46.812+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:49:46.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:49:46.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:49:46.840+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:49:46.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:49:46.851+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:49:46.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:49:46.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T20:50:17.193+0000] {processor.py:157} INFO - Started process (PID=29676) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:50:17.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:50:17.196+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:50:17.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:50:17.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:50:17.222+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:50:17.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:50:17.232+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:50:17.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:50:17.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T20:50:47.676+0000] {processor.py:157} INFO - Started process (PID=29701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:50:47.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:50:47.678+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:50:47.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:50:47.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:50:47.707+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:50:47.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:50:47.717+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:50:47.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:50:47.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T20:51:18.132+0000] {processor.py:157} INFO - Started process (PID=29726) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:51:18.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:51:18.135+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:51:18.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:51:18.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:51:18.158+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:51:18.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:51:18.168+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:51:18.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:51:18.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-18T20:51:48.563+0000] {processor.py:157} INFO - Started process (PID=29751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:51:48.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:51:48.566+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:51:48.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:51:48.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:51:48.593+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:51:48.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:51:48.603+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:51:48.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:51:48.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T20:52:19.013+0000] {processor.py:157} INFO - Started process (PID=29776) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:52:19.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:52:19.018+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:52:19.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:52:19.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:52:19.043+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:52:19.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:52:19.053+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:52:19.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:52:19.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T20:52:49.476+0000] {processor.py:157} INFO - Started process (PID=29801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:52:49.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:52:49.478+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:52:49.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:52:49.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:52:49.504+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:52:49.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:52:49.514+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:52:49.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:52:49.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T20:53:19.893+0000] {processor.py:157} INFO - Started process (PID=29826) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:53:19.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:53:19.895+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:53:19.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:53:19.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:53:19.923+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:53:19.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:53:19.935+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:53:19.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:53:19.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T20:53:50.285+0000] {processor.py:157} INFO - Started process (PID=29851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:53:50.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:53:50.289+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:53:50.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:53:50.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:53:50.318+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:53:50.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:53:50.328+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:53:50.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:53:50.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T20:54:20.792+0000] {processor.py:157} INFO - Started process (PID=29876) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:54:20.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:54:20.797+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:54:20.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:54:20.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:54:20.825+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:54:20.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:54:20.834+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:54:20.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:54:20.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T20:54:51.294+0000] {processor.py:157} INFO - Started process (PID=29901) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:54:51.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:54:51.299+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:54:51.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:54:51.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:54:51.332+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:54:51.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:54:51.345+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:54:51.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:54:51.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-18T20:55:21.834+0000] {processor.py:157} INFO - Started process (PID=29926) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:55:21.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:55:21.838+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:55:21.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:55:21.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:55:21.867+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:55:21.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:55:21.877+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:55:21.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:55:21.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T20:55:52.329+0000] {processor.py:157} INFO - Started process (PID=29951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:55:52.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:55:52.336+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:55:52.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:55:52.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:55:52.359+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:55:52.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:55:52.369+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:55:52.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:55:52.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T20:56:22.881+0000] {processor.py:157} INFO - Started process (PID=29976) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:56:22.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:56:22.883+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:56:22.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:56:22.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:56:22.913+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:56:22.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:56:22.923+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:56:22.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:56:22.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T20:56:53.373+0000] {processor.py:157} INFO - Started process (PID=30001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:56:53.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:56:53.376+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:56:53.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:56:53.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:56:53.402+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:56:53.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:56:53.411+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:56:53.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:56:53.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T20:57:23.910+0000] {processor.py:157} INFO - Started process (PID=30026) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:57:23.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:57:23.913+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:57:23.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:57:23.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:57:23.943+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:57:23.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:57:23.954+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:57:23.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:57:23.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T20:57:54.337+0000] {processor.py:157} INFO - Started process (PID=30051) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:57:54.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:57:54.344+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:57:54.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:57:54.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:57:54.368+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:57:54.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:57:54.378+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:57:54.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:57:54.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T20:58:24.740+0000] {processor.py:157} INFO - Started process (PID=30076) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:58:24.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:58:24.744+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:58:24.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:58:24.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:58:24.771+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:58:24.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:58:24.781+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:58:24.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:58:24.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T20:58:55.233+0000] {processor.py:157} INFO - Started process (PID=30101) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:58:55.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:58:55.236+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:58:55.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:58:55.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:58:55.263+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:58:55.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:58:55.276+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:58:55.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:58:55.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T20:59:25.718+0000] {processor.py:157} INFO - Started process (PID=30126) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:59:25.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:59:25.721+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:59:25.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:59:25.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:59:25.747+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:59:25.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:59:25.760+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:59:25.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:59:25.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T20:59:56.190+0000] {processor.py:157} INFO - Started process (PID=30151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:59:56.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T20:59:56.193+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:59:56.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:59:56.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T20:59:56.220+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:59:56.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:59:56.229+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:59:56.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T20:59:56.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T21:00:26.669+0000] {processor.py:157} INFO - Started process (PID=30176) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:00:26.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:00:26.674+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:00:26.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:00:26.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:00:26.700+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:00:26.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:00:26.711+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:00:26.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:00:26.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T21:00:57.127+0000] {processor.py:157} INFO - Started process (PID=30201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:00:57.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:00:57.130+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:00:57.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:00:57.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:00:57.160+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:00:57.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:00:57.171+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:00:57.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:00:57.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T21:01:27.603+0000] {processor.py:157} INFO - Started process (PID=30226) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:01:27.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:01:27.607+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:01:27.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:01:27.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:01:27.634+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:01:27.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:01:27.644+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:01:27.644+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:01:27.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T21:01:58.092+0000] {processor.py:157} INFO - Started process (PID=30251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:01:58.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:01:58.097+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:01:58.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:01:58.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:01:58.125+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:01:58.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:01:58.135+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:01:58.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:01:58.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T21:02:28.516+0000] {processor.py:157} INFO - Started process (PID=30276) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:02:28.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:02:28.520+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:02:28.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:02:28.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:02:28.553+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:02:28.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:02:28.565+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:02:28.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:02:28.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-18T21:02:59.011+0000] {processor.py:157} INFO - Started process (PID=30301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:02:59.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:02:59.015+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:02:59.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:02:59.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:02:59.044+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:02:59.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:02:59.055+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:02:59.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:02:59.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T21:03:29.436+0000] {processor.py:157} INFO - Started process (PID=30326) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:03:29.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:03:29.439+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:03:29.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:03:29.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:03:29.468+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:03:29.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:03:29.477+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:03:29.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:03:29.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T21:03:59.837+0000] {processor.py:157} INFO - Started process (PID=30351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:03:59.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:03:59.841+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:03:59.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:03:59.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:03:59.870+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:03:59.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:03:59.881+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:03:59.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:03:59.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T21:04:30.362+0000] {processor.py:157} INFO - Started process (PID=30376) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:04:30.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:04:30.366+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:04:30.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:04:30.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:04:30.393+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:04:30.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:04:30.404+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:04:30.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:04:30.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T21:05:00.852+0000] {processor.py:157} INFO - Started process (PID=30401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:05:00.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:05:00.854+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:05:00.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:05:00.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:05:00.880+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:05:00.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:05:00.890+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:05:00.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:05:00.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T21:05:31.370+0000] {processor.py:157} INFO - Started process (PID=30426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:05:31.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:05:31.374+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:05:31.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:05:31.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:05:31.404+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:05:31.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:05:31.412+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:05:31.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:05:31.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T21:06:01.815+0000] {processor.py:157} INFO - Started process (PID=30451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:06:01.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:06:01.821+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:06:01.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:06:01.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:06:01.853+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:06:01.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:06:01.865+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:06:01.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:06:01.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-18T21:06:32.337+0000] {processor.py:157} INFO - Started process (PID=30476) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:06:32.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:06:32.341+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:06:32.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:06:32.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:06:32.372+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:06:32.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:06:32.383+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:06:32.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:06:32.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-18T21:07:02.876+0000] {processor.py:157} INFO - Started process (PID=30501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:07:02.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:07:02.880+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:07:02.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:07:02.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:07:02.905+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:07:02.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:07:02.915+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:07:02.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:07:02.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T21:07:33.400+0000] {processor.py:157} INFO - Started process (PID=30526) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:07:33.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:07:33.402+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:07:33.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:07:33.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:07:33.433+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:07:33.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:07:33.443+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:07:33.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:07:33.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T21:08:03.792+0000] {processor.py:157} INFO - Started process (PID=30551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:08:03.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:08:03.795+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:08:03.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:08:03.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:08:03.822+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:08:03.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:08:03.834+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:08:03.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:08:03.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T21:08:34.263+0000] {processor.py:157} INFO - Started process (PID=30576) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:08:34.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:08:34.266+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:08:34.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:08:34.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:08:34.295+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:08:34.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:08:34.306+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:08:34.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:08:34.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T21:09:04.719+0000] {processor.py:157} INFO - Started process (PID=30601) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:09:04.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:09:04.721+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:09:04.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:09:04.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:09:04.746+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:09:04.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:09:04.756+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:09:04.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:09:04.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T21:09:35.169+0000] {processor.py:157} INFO - Started process (PID=30626) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:09:35.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:09:35.172+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:09:35.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:09:35.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:09:35.204+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:09:35.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:09:35.216+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:09:35.216+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:09:35.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-18T21:10:05.732+0000] {processor.py:157} INFO - Started process (PID=30651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:10:05.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:10:05.735+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:10:05.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:10:05.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:10:05.763+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:10:05.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:10:05.773+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:10:05.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:10:05.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T21:10:36.170+0000] {processor.py:157} INFO - Started process (PID=30676) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:10:36.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:10:36.173+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:10:36.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:10:36.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:10:36.199+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:10:36.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:10:36.209+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:10:36.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:10:36.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T21:11:06.676+0000] {processor.py:157} INFO - Started process (PID=30701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:11:06.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:11:06.679+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:11:06.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:11:06.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:11:06.705+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:11:06.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:11:06.715+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:11:06.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:11:06.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T21:11:37.138+0000] {processor.py:157} INFO - Started process (PID=30726) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:11:37.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:11:37.141+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:11:37.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:11:37.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:11:37.166+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:11:37.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:11:37.175+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:11:37.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:11:37.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-18T21:12:07.640+0000] {processor.py:157} INFO - Started process (PID=30751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:12:07.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:12:07.642+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:12:07.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:12:07.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:12:07.669+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:12:07.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:12:07.680+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:12:07.680+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:12:07.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T21:12:38.118+0000] {processor.py:157} INFO - Started process (PID=30776) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:12:38.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:12:38.120+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:12:38.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:12:38.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:12:38.148+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:12:38.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:12:38.160+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:12:38.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:12:38.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T21:13:08.615+0000] {processor.py:157} INFO - Started process (PID=30801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:13:08.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:13:08.618+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:13:08.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:13:08.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:13:08.647+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:13:08.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:13:08.660+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:13:08.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:13:08.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T21:13:39.086+0000] {processor.py:157} INFO - Started process (PID=30826) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:13:39.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:13:39.089+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:13:39.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:13:39.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:13:39.118+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:13:39.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:13:39.129+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:13:39.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:13:39.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T21:14:09.550+0000] {processor.py:157} INFO - Started process (PID=30851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:14:09.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:14:09.553+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:14:09.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:14:09.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:14:09.581+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:14:09.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:14:09.591+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:14:09.591+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:14:09.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T21:14:40.099+0000] {processor.py:157} INFO - Started process (PID=30876) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:14:40.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:14:40.104+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:14:40.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:14:40.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:14:40.136+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:14:40.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:14:40.147+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:14:40.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:14:40.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T21:15:10.506+0000] {processor.py:157} INFO - Started process (PID=30901) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:15:10.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:15:10.509+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:15:10.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:15:10.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:15:10.537+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:15:10.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:15:10.547+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:15:10.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:15:10.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T21:15:40.957+0000] {processor.py:157} INFO - Started process (PID=30926) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:15:40.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:15:40.961+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:15:40.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:15:40.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:15:40.990+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:15:40.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:15:41.000+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:15:41.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:15:41.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T21:16:11.425+0000] {processor.py:157} INFO - Started process (PID=30951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:16:11.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:16:11.427+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:16:11.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:16:11.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:16:11.454+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:16:11.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:16:11.465+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:16:11.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:16:11.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T21:16:41.901+0000] {processor.py:157} INFO - Started process (PID=30976) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:16:41.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:16:41.905+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:16:41.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:16:41.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:16:41.932+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:16:41.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:16:41.944+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:16:41.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:16:41.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T21:17:12.350+0000] {processor.py:157} INFO - Started process (PID=31001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:17:12.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:17:12.352+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:17:12.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:17:12.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:17:12.377+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:17:12.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:17:12.387+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:17:12.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:17:12.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-18T21:17:42.835+0000] {processor.py:157} INFO - Started process (PID=31026) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:17:42.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:17:42.839+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:17:42.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:17:42.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:17:42.867+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:17:42.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:17:42.876+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:17:42.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:17:42.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T21:18:13.294+0000] {processor.py:157} INFO - Started process (PID=31051) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:18:13.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:18:13.299+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:18:13.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:18:13.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:18:13.326+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:18:13.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:18:13.336+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:18:13.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:18:13.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T21:18:43.791+0000] {processor.py:157} INFO - Started process (PID=31076) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:18:43.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:18:43.796+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:18:43.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:18:43.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:18:43.821+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:18:43.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:18:43.832+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:18:43.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:18:43.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T21:19:14.318+0000] {processor.py:157} INFO - Started process (PID=31101) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:19:14.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:19:14.322+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:19:14.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:19:14.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:19:14.352+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:19:14.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:19:14.364+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:19:14.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:19:14.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T21:19:44.746+0000] {processor.py:157} INFO - Started process (PID=31126) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:19:44.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:19:44.750+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:19:44.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:19:44.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:19:44.777+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:19:44.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:19:44.786+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:19:44.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:19:44.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T21:20:15.180+0000] {processor.py:157} INFO - Started process (PID=31151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:20:15.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:20:15.184+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:20:15.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:20:15.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:20:15.207+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:20:15.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:20:15.217+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:20:15.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:20:15.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T21:20:45.568+0000] {processor.py:157} INFO - Started process (PID=31176) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:20:45.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:20:45.571+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:20:45.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:20:45.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:20:45.599+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:20:45.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:20:45.610+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:20:45.610+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:20:45.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T21:21:16.031+0000] {processor.py:157} INFO - Started process (PID=31201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:21:16.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:21:16.034+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:21:16.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:21:16.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:21:16.060+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:21:16.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:21:16.073+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:21:16.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:21:16.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T21:21:46.519+0000] {processor.py:157} INFO - Started process (PID=31226) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:21:46.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:21:46.522+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:21:46.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:21:46.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:21:46.554+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:21:46.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:21:46.564+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:21:46.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:21:46.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T21:22:16.957+0000] {processor.py:157} INFO - Started process (PID=31251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:22:16.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:22:16.960+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:22:16.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:22:16.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:22:16.988+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:22:16.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:22:16.999+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:22:16.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:22:17.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T21:22:47.422+0000] {processor.py:157} INFO - Started process (PID=31276) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:22:47.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:22:47.427+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:22:47.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:22:47.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:22:47.461+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:22:47.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:22:47.472+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:22:47.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:22:47.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-18T21:23:17.808+0000] {processor.py:157} INFO - Started process (PID=31301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:23:17.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:23:17.810+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:23:17.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:23:17.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:23:17.835+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:23:17.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:23:17.845+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:23:17.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:23:17.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-18T21:23:48.246+0000] {processor.py:157} INFO - Started process (PID=31326) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:23:48.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:23:48.249+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:23:48.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:23:48.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:23:48.274+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:23:48.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:23:48.284+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:23:48.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:23:48.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T21:24:18.780+0000] {processor.py:157} INFO - Started process (PID=31351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:24:18.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:24:18.783+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:24:18.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:24:18.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:24:18.809+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:24:18.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:24:18.819+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:24:18.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:24:18.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T21:24:49.259+0000] {processor.py:157} INFO - Started process (PID=31375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:24:49.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:24:49.261+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:24:49.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:24:49.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:24:49.285+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:24:49.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:24:49.295+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:24:49.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:24:49.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-18T21:25:19.684+0000] {processor.py:157} INFO - Started process (PID=31401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:25:19.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:25:19.687+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:25:19.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:25:19.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:25:19.715+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:25:19.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:25:19.725+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:25:19.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:25:19.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T21:25:50.074+0000] {processor.py:157} INFO - Started process (PID=31426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:25:50.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:25:50.077+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:25:50.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:25:50.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:25:50.106+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:25:50.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:25:50.115+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:25:50.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:25:50.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T21:26:20.457+0000] {processor.py:157} INFO - Started process (PID=31451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:26:20.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:26:20.461+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:26:20.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:26:20.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:26:20.490+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:26:20.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:26:20.501+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:26:20.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:26:20.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T21:26:51.015+0000] {processor.py:157} INFO - Started process (PID=31476) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:26:51.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:26:51.020+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:26:51.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:26:51.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:26:51.051+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:26:51.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:26:51.064+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:26:51.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:26:51.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T21:27:21.454+0000] {processor.py:157} INFO - Started process (PID=31501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:27:21.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:27:21.457+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:27:21.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:27:21.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:27:21.487+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:27:21.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:27:21.500+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:27:21.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:27:21.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T21:27:51.924+0000] {processor.py:157} INFO - Started process (PID=31526) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:27:51.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:27:51.931+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:27:51.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:27:51.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:27:51.958+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:27:51.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:27:51.970+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:27:51.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:27:51.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T21:28:22.366+0000] {processor.py:157} INFO - Started process (PID=31551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:28:22.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:28:22.370+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:28:22.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:28:22.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:28:22.403+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:28:22.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:28:22.415+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:28:22.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:28:22.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-18T21:28:52.853+0000] {processor.py:157} INFO - Started process (PID=31576) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:28:52.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:28:52.856+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:28:52.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:28:52.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:28:52.881+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:28:52.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:28:52.893+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:28:52.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:28:52.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T21:29:23.324+0000] {processor.py:157} INFO - Started process (PID=31601) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:29:23.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:29:23.329+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:29:23.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:29:23.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:29:23.356+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:29:23.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:29:23.367+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:29:23.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:29:23.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T21:29:53.869+0000] {processor.py:157} INFO - Started process (PID=31626) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:29:53.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:29:53.872+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:29:53.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:29:53.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:29:53.902+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:29:53.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:29:53.914+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:29:53.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:29:53.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T21:30:24.324+0000] {processor.py:157} INFO - Started process (PID=31651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:30:24.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:30:24.327+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:30:24.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:30:24.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:30:24.358+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:30:24.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:30:24.370+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:30:24.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:30:24.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T21:30:54.730+0000] {processor.py:157} INFO - Started process (PID=31676) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:30:54.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:30:54.732+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:30:54.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:30:54.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:30:54.759+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:30:54.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:30:54.769+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:30:54.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:30:54.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T21:31:25.227+0000] {processor.py:157} INFO - Started process (PID=31701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:31:25.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:31:25.231+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:31:25.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:31:25.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:31:25.257+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:31:25.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:31:25.266+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:31:25.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:31:25.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T21:31:55.715+0000] {processor.py:157} INFO - Started process (PID=31726) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:31:55.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:31:55.718+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:31:55.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:31:55.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:31:55.747+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:31:55.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:31:55.757+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:31:55.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:31:55.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T21:32:26.192+0000] {processor.py:157} INFO - Started process (PID=31751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:32:26.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:32:26.194+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:32:26.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:32:26.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:32:26.216+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:32:26.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:32:26.226+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:32:26.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:32:26.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-18T21:32:56.667+0000] {processor.py:157} INFO - Started process (PID=31776) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:32:56.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:32:56.670+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:32:56.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:32:56.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:32:56.702+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:32:56.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:32:56.713+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:32:56.713+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:32:56.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T21:33:27.181+0000] {processor.py:157} INFO - Started process (PID=31801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:33:27.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:33:27.206+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:33:27.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:33:27.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:33:27.298+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:33:27.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:33:27.315+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:33:27.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:33:27.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.196 seconds
[2024-07-18T21:33:57.863+0000] {processor.py:157} INFO - Started process (PID=31826) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:33:57.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:33:57.867+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:33:57.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:33:57.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:33:57.898+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:33:57.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:33:57.910+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:33:57.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:33:57.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T21:34:28.393+0000] {processor.py:157} INFO - Started process (PID=31851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:34:28.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:34:28.396+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:34:28.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:34:28.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:34:28.428+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:34:28.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:34:28.439+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:34:28.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:34:28.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T21:34:58.849+0000] {processor.py:157} INFO - Started process (PID=31876) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:34:58.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:34:58.851+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:34:58.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:34:58.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:34:58.879+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:34:58.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:34:58.889+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:34:58.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:34:58.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T21:35:29.311+0000] {processor.py:157} INFO - Started process (PID=31900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:35:29.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:35:29.314+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:35:29.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:35:29.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:35:29.350+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:35:29.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:35:29.363+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:35:29.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:35:29.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-18T21:35:59.811+0000] {processor.py:157} INFO - Started process (PID=31926) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:35:59.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:35:59.815+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:35:59.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:35:59.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:35:59.851+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:35:59.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:35:59.863+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:35:59.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:35:59.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-18T21:36:30.273+0000] {processor.py:157} INFO - Started process (PID=31951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:36:30.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:36:30.277+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:36:30.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:36:30.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:36:30.306+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:36:30.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:36:30.318+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:36:30.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:36:30.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T21:37:00.750+0000] {processor.py:157} INFO - Started process (PID=31976) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:37:00.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:37:00.754+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:37:00.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:37:00.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:37:00.781+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:37:00.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:37:00.792+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:37:00.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:37:00.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T21:37:31.224+0000] {processor.py:157} INFO - Started process (PID=32001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:37:31.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:37:31.228+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:37:31.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:37:31.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:37:31.254+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:37:31.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:37:31.266+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:37:31.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:37:31.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T21:38:01.674+0000] {processor.py:157} INFO - Started process (PID=32026) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:38:01.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:38:01.677+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:38:01.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:38:01.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:38:01.709+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:38:01.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:38:01.720+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:38:01.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:38:01.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T21:38:32.172+0000] {processor.py:157} INFO - Started process (PID=32051) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:38:32.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:38:32.174+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:38:32.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:38:32.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:38:32.205+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:38:32.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:38:32.218+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:38:32.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:38:32.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T21:39:02.641+0000] {processor.py:157} INFO - Started process (PID=32076) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:39:02.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:39:02.643+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:39:02.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:39:02.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:39:02.669+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:39:02.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:39:02.679+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:39:02.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:39:02.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-18T21:41:50.220+0000] {processor.py:157} INFO - Started process (PID=32103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:41:50.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:41:50.226+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:41:50.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:41:50.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:41:50.276+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:41:50.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:41:50.293+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:41:50.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:41:50.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-18T21:42:20.792+0000] {processor.py:157} INFO - Started process (PID=32127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:42:20.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:42:20.797+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:42:20.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:42:20.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:42:20.831+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:42:20.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:42:20.842+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:42:20.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:42:20.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-18T21:42:51.283+0000] {processor.py:157} INFO - Started process (PID=32153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:42:51.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:42:51.288+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:42:51.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:42:51.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:42:51.319+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:42:51.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:42:51.332+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:42:51.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:42:51.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-18T21:43:21.755+0000] {processor.py:157} INFO - Started process (PID=32178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:43:21.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:43:21.759+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:43:21.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:43:21.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:43:21.790+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:43:21.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:43:21.804+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:43:21.804+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:43:21.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-18T21:43:52.252+0000] {processor.py:157} INFO - Started process (PID=32203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:43:52.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:43:52.255+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:43:52.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:43:52.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:43:52.285+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:43:52.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:43:52.296+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:43:52.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:43:52.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T21:44:22.743+0000] {processor.py:157} INFO - Started process (PID=32228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:44:22.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:44:22.746+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:44:22.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:44:22.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:44:22.775+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:44:22.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:44:22.786+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:44:22.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:44:22.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T21:44:53.175+0000] {processor.py:157} INFO - Started process (PID=32253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:44:53.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:44:53.179+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:44:53.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:44:53.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:44:53.206+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:44:53.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:44:53.217+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:44:53.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:44:53.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T21:45:23.609+0000] {processor.py:157} INFO - Started process (PID=32278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:45:23.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:45:23.612+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:45:23.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:45:23.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:45:23.638+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:45:23.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:45:23.648+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:45:23.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:45:23.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T21:45:54.072+0000] {processor.py:157} INFO - Started process (PID=32303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:45:54.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:45:54.078+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:45:54.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:45:54.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:45:54.113+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:45:54.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:45:54.125+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:45:54.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:45:54.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-18T21:46:24.607+0000] {processor.py:157} INFO - Started process (PID=32328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:46:24.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:46:24.609+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:46:24.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:46:24.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:46:24.635+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:46:24.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:46:24.645+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:46:24.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:46:24.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T21:46:55.043+0000] {processor.py:157} INFO - Started process (PID=32353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:46:55.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:46:55.047+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:46:55.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:46:55.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:46:55.077+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:46:55.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:46:55.088+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:46:55.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:46:55.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T21:47:25.438+0000] {processor.py:157} INFO - Started process (PID=32378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:47:25.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:47:25.441+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:47:25.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:47:25.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:47:25.471+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:47:25.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:47:25.484+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:47:25.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:47:25.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T21:47:55.891+0000] {processor.py:157} INFO - Started process (PID=32403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:47:55.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:47:55.895+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:47:55.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:47:55.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:47:55.922+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:47:55.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:47:55.932+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:47:55.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:47:55.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T21:48:26.392+0000] {processor.py:157} INFO - Started process (PID=32428) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:48:26.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:48:26.395+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:48:26.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:48:26.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:48:26.424+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:48:26.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:48:26.434+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:48:26.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:48:26.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T21:48:56.910+0000] {processor.py:157} INFO - Started process (PID=32453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:48:56.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:48:56.913+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:48:56.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:48:56.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:48:56.941+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:48:56.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:48:56.954+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:48:56.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:48:56.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T21:49:27.404+0000] {processor.py:157} INFO - Started process (PID=32478) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:49:27.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:49:27.407+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:49:27.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:49:27.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:49:27.434+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:49:27.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:49:27.444+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:49:27.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:49:27.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T21:49:57.925+0000] {processor.py:157} INFO - Started process (PID=32503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:49:57.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:49:57.927+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:49:57.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:49:57.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:49:57.959+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:49:57.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:49:57.969+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:49:57.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:49:57.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T21:50:28.354+0000] {processor.py:157} INFO - Started process (PID=32528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:50:28.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:50:28.358+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:50:28.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:50:28.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:50:28.389+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:50:28.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:50:28.399+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:50:28.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:50:28.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T21:50:58.883+0000] {processor.py:157} INFO - Started process (PID=32553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:50:58.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:50:58.888+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:50:58.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:50:58.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:50:58.912+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:50:58.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:50:58.922+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:50:58.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:50:58.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T21:51:29.284+0000] {processor.py:157} INFO - Started process (PID=32578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:51:29.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:51:29.287+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:51:29.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:51:29.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:51:29.314+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:51:29.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:51:29.324+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:51:29.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:51:29.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T21:51:59.757+0000] {processor.py:157} INFO - Started process (PID=32603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:51:59.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:51:59.765+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:51:59.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:51:59.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:51:59.800+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:51:59.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:51:59.813+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:51:59.813+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:51:59.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-18T21:52:30.186+0000] {processor.py:157} INFO - Started process (PID=32628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:52:30.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:52:30.190+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:52:30.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:52:30.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:52:30.218+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:52:30.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:52:30.231+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:52:30.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:52:30.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T21:53:00.735+0000] {processor.py:157} INFO - Started process (PID=32653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:53:00.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:53:00.738+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:53:00.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:53:00.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:53:00.767+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:53:00.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:53:00.776+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:53:00.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:53:00.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T21:53:31.163+0000] {processor.py:157} INFO - Started process (PID=32678) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:53:31.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:53:31.165+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:53:31.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:53:31.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:53:31.192+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:53:31.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:53:31.203+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:53:31.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:53:31.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T21:54:01.675+0000] {processor.py:157} INFO - Started process (PID=32703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:54:01.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:54:01.679+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:54:01.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:54:01.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:54:01.704+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:54:01.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:54:01.715+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:54:01.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:54:01.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T21:54:32.136+0000] {processor.py:157} INFO - Started process (PID=32728) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:54:32.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:54:32.140+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:54:32.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:54:32.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:54:32.168+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:54:32.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:54:32.181+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:54:32.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:54:32.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T21:55:02.641+0000] {processor.py:157} INFO - Started process (PID=32753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:55:02.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:55:02.644+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:55:02.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:55:02.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:55:02.675+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:55:02.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:55:02.684+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:55:02.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:55:02.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T21:55:33.131+0000] {processor.py:157} INFO - Started process (PID=32778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:55:33.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:55:33.135+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:55:33.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:55:33.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:55:33.164+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:55:33.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:55:33.176+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:55:33.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:55:33.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T21:56:03.594+0000] {processor.py:157} INFO - Started process (PID=32803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:56:03.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:56:03.598+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:56:03.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:56:03.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:56:03.630+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:56:03.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:56:03.640+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:56:03.640+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:56:03.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T21:56:34.098+0000] {processor.py:157} INFO - Started process (PID=32828) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:56:34.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T21:56:34.101+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:56:34.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:56:34.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T21:56:34.128+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:56:34.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:56:34.138+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:56:34.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T21:56:34.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T22:02:24.505+0000] {processor.py:157} INFO - Started process (PID=32854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:02:24.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:02:24.511+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:02:24.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:02:24.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:02:24.564+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:02:24.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:02:24.582+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:02:24.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:02:24.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-18T22:18:14.305+0000] {processor.py:157} INFO - Started process (PID=32880) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:18:14.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:18:14.312+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:18:14.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:18:14.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:18:14.338+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:18:14.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:18:14.352+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:18:14.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:18:14.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-18T22:18:44.785+0000] {processor.py:157} INFO - Started process (PID=32904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:18:44.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:18:44.789+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:18:44.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:18:44.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:18:44.840+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:18:44.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:18:44.853+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:18:44.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:18:44.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-18T22:19:15.314+0000] {processor.py:157} INFO - Started process (PID=32930) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:19:15.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:19:15.319+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:19:15.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:19:15.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:19:15.353+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:19:15.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:19:15.365+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:19:15.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:19:15.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-18T22:19:45.753+0000] {processor.py:157} INFO - Started process (PID=32955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:19:45.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:19:45.756+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:19:45.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:19:45.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:19:45.785+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:19:45.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:19:45.794+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:19:45.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:19:45.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T22:20:16.189+0000] {processor.py:157} INFO - Started process (PID=32980) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:20:16.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:20:16.192+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:20:16.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:20:16.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:20:16.221+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:20:16.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:20:16.231+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:20:16.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:20:16.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T22:20:46.653+0000] {processor.py:157} INFO - Started process (PID=33005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:20:46.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:20:46.656+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:20:46.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:20:46.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:20:46.684+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:20:46.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:20:46.695+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:20:46.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:20:46.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T22:21:17.062+0000] {processor.py:157} INFO - Started process (PID=33030) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:21:17.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:21:17.065+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:21:17.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:21:17.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:21:17.091+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:21:17.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:21:17.101+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:21:17.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:21:17.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T22:21:47.536+0000] {processor.py:157} INFO - Started process (PID=33055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:21:47.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:21:47.539+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:21:47.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:21:47.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:21:47.566+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:21:47.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:21:47.576+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:21:47.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:21:47.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T22:22:17.977+0000] {processor.py:157} INFO - Started process (PID=33080) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:22:17.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:22:17.982+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:22:17.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:22:17.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:22:18.011+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:22:18.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:22:18.023+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:22:18.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:22:18.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T22:22:48.435+0000] {processor.py:157} INFO - Started process (PID=33105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:22:48.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:22:48.438+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:22:48.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:22:48.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:22:48.472+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:22:48.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:22:48.484+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:22:48.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:22:48.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-18T22:23:18.909+0000] {processor.py:157} INFO - Started process (PID=33130) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:23:18.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:23:18.911+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:23:18.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:23:18.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:23:18.938+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:23:18.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:23:18.949+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:23:18.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:23:18.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T22:23:49.358+0000] {processor.py:157} INFO - Started process (PID=33155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:23:49.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:23:49.360+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:23:49.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:23:49.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:23:49.390+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:23:49.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:23:49.402+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:23:49.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:23:49.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T22:24:19.792+0000] {processor.py:157} INFO - Started process (PID=33180) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:24:19.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:24:19.794+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:24:19.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:24:19.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:24:19.823+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:24:19.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:24:19.832+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:24:19.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:24:19.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T22:24:50.264+0000] {processor.py:157} INFO - Started process (PID=33205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:24:50.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:24:50.266+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:24:50.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:24:50.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:24:50.294+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:24:50.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:24:50.303+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:24:50.303+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:24:50.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T22:25:20.742+0000] {processor.py:157} INFO - Started process (PID=33230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:25:20.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:25:20.746+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:25:20.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:25:20.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:25:20.775+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:25:20.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:25:20.786+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:25:20.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:25:20.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T22:25:51.188+0000] {processor.py:157} INFO - Started process (PID=33255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:25:51.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:25:51.192+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:25:51.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:25:51.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:25:51.220+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:25:51.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:25:51.229+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:25:51.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:25:51.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T22:26:21.628+0000] {processor.py:157} INFO - Started process (PID=33280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:26:21.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:26:21.633+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:26:21.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:26:21.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:26:21.664+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:26:21.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:26:21.674+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:26:21.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:26:21.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T22:26:52.128+0000] {processor.py:157} INFO - Started process (PID=33305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:26:52.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:26:52.132+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:26:52.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:26:52.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:26:52.159+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:26:52.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:26:52.170+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:26:52.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:26:52.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T22:27:22.554+0000] {processor.py:157} INFO - Started process (PID=33330) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:27:22.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:27:22.559+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:27:22.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:27:22.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:27:22.588+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:27:22.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:27:22.599+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:27:22.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:27:22.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T22:27:53.006+0000] {processor.py:157} INFO - Started process (PID=33355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:27:53.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:27:53.009+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:27:53.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:27:53.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:27:53.037+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:27:53.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:27:53.046+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:27:53.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:27:53.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T22:28:23.436+0000] {processor.py:157} INFO - Started process (PID=33380) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:28:23.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:28:23.438+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:28:23.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:28:23.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:28:23.471+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:28:23.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:28:23.480+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:28:23.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:28:23.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T22:28:53.867+0000] {processor.py:157} INFO - Started process (PID=33405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:28:53.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:28:53.871+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:28:53.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:28:53.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:28:53.900+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:28:53.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:28:53.911+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:28:53.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:28:53.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T22:29:24.317+0000] {processor.py:157} INFO - Started process (PID=33430) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:29:24.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:29:24.322+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:29:24.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:29:24.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:29:24.351+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:29:24.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:29:24.363+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:29:24.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:29:24.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T22:29:54.789+0000] {processor.py:157} INFO - Started process (PID=33455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:29:54.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:29:54.794+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:29:54.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:29:54.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:29:54.830+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:29:54.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:29:54.843+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:29:54.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:29:54.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-18T22:30:25.243+0000] {processor.py:157} INFO - Started process (PID=33480) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:30:25.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:30:25.246+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:30:25.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:30:25.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:30:25.284+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:30:25.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:30:25.295+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:30:25.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:30:25.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-18T22:30:55.715+0000] {processor.py:157} INFO - Started process (PID=33505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:30:55.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:30:55.719+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:30:55.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:30:55.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:30:55.748+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:30:55.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:30:55.758+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:30:55.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:30:55.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T22:31:26.159+0000] {processor.py:157} INFO - Started process (PID=33530) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:31:26.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:31:26.162+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:31:26.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:31:26.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:31:26.192+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:31:26.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:31:26.202+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:31:26.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:31:26.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T22:31:56.536+0000] {processor.py:157} INFO - Started process (PID=33555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:31:56.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:31:56.540+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:31:56.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:31:56.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:31:56.573+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:31:56.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:31:56.583+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:31:56.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:31:56.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T22:32:26.986+0000] {processor.py:157} INFO - Started process (PID=33580) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:32:26.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:32:26.988+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:32:26.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:32:26.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:32:27.017+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:32:27.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:32:27.028+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:32:27.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:32:27.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T22:32:57.460+0000] {processor.py:157} INFO - Started process (PID=33604) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:32:57.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:32:57.465+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:32:57.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:32:57.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:32:57.494+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:32:57.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:32:57.504+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:32:57.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:32:57.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T22:33:27.960+0000] {processor.py:157} INFO - Started process (PID=33630) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:33:27.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:33:27.963+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:33:27.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:33:27.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:33:27.992+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:33:27.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:33:28.004+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:33:28.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:33:28.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T22:33:58.401+0000] {processor.py:157} INFO - Started process (PID=33655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:33:58.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:33:58.404+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:33:58.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:33:58.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:33:58.436+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:33:58.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:33:58.446+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:33:58.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:33:58.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T22:34:28.865+0000] {processor.py:157} INFO - Started process (PID=33680) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:34:28.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:34:28.867+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:34:28.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:34:28.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:34:28.899+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:34:28.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:34:28.912+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:34:28.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:34:28.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-18T22:34:59.340+0000] {processor.py:157} INFO - Started process (PID=33705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:34:59.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:34:59.344+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:34:59.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:34:59.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:34:59.373+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:34:59.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:34:59.385+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:34:59.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:34:59.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T22:35:29.747+0000] {processor.py:157} INFO - Started process (PID=33730) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:35:29.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:35:29.750+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:35:29.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:35:29.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:35:29.776+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:35:29.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:35:29.786+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:35:29.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:35:29.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T22:36:00.183+0000] {processor.py:157} INFO - Started process (PID=33755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:36:00.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:36:00.187+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:36:00.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:36:00.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:36:00.214+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:36:00.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:36:00.224+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:36:00.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:36:00.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T22:36:30.635+0000] {processor.py:157} INFO - Started process (PID=33780) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:36:30.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:36:30.638+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:36:30.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:36:30.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:36:30.667+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:36:30.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:36:30.676+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:36:30.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:36:30.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T22:37:01.070+0000] {processor.py:157} INFO - Started process (PID=33805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:37:01.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:37:01.074+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:37:01.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:37:01.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:37:01.102+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:37:01.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:37:01.112+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:37:01.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:37:01.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T22:37:31.526+0000] {processor.py:157} INFO - Started process (PID=33830) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:37:31.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:37:31.531+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:37:31.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:37:31.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:37:31.561+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:37:31.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:37:31.571+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:37:31.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:37:31.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T22:38:01.972+0000] {processor.py:157} INFO - Started process (PID=33855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:38:01.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:38:01.976+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:38:01.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:38:01.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:38:02.005+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:38:02.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:38:02.015+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:38:02.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:38:02.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T22:38:32.446+0000] {processor.py:157} INFO - Started process (PID=33880) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:38:32.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:38:32.448+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:38:32.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:38:32.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:38:32.475+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:38:32.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:38:32.486+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:38:32.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:38:32.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T22:39:02.897+0000] {processor.py:157} INFO - Started process (PID=33905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:39:02.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:39:02.902+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:39:02.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:39:02.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:39:02.931+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:39:02.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:39:02.942+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:39:02.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:39:02.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T22:39:33.368+0000] {processor.py:157} INFO - Started process (PID=33930) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:39:33.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:39:33.372+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:39:33.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:39:33.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:39:33.402+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:39:33.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:39:33.413+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:39:33.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:39:33.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T22:40:03.792+0000] {processor.py:157} INFO - Started process (PID=33955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:40:03.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:40:03.795+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:40:03.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:40:03.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:40:03.821+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:40:03.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:40:03.834+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:40:03.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:40:03.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T22:40:34.250+0000] {processor.py:157} INFO - Started process (PID=33980) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:40:34.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:40:34.252+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:40:34.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:40:34.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:40:34.281+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:40:34.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:40:34.289+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:40:34.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:40:34.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T22:41:04.663+0000] {processor.py:157} INFO - Started process (PID=34005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:41:04.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:41:04.667+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:41:04.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:41:04.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:41:04.693+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:41:04.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:41:04.708+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:41:04.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:41:04.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T22:41:35.152+0000] {processor.py:157} INFO - Started process (PID=34030) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:41:35.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:41:35.156+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:41:35.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:41:35.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:41:35.186+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:41:35.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:41:35.196+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:41:35.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:41:35.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T22:42:05.598+0000] {processor.py:157} INFO - Started process (PID=34055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:42:05.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:42:05.601+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:42:05.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:42:05.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:42:05.627+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:42:05.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:42:05.639+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:42:05.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:42:05.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T22:42:36.049+0000] {processor.py:157} INFO - Started process (PID=34080) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:42:36.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:42:36.054+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:42:36.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:42:36.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:42:36.085+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:42:36.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:42:36.097+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:42:36.097+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:42:36.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-18T22:43:06.484+0000] {processor.py:157} INFO - Started process (PID=34105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:43:06.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:43:06.486+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:43:06.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:43:06.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:43:06.515+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:43:06.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:43:06.528+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:43:06.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:43:06.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T22:43:36.967+0000] {processor.py:157} INFO - Started process (PID=34129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:43:36.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:43:36.973+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:43:36.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:43:36.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:43:36.994+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:43:36.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:43:37.003+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:43:37.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:43:37.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-18T22:44:07.420+0000] {processor.py:157} INFO - Started process (PID=34155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:44:07.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:44:07.423+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:44:07.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:44:07.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:44:07.450+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:44:07.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:44:07.459+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:44:07.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:44:07.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T22:44:37.906+0000] {processor.py:157} INFO - Started process (PID=34180) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:44:37.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:44:37.909+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:44:37.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:44:37.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:44:37.937+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:44:37.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:44:37.947+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:44:37.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:44:37.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T22:45:08.395+0000] {processor.py:157} INFO - Started process (PID=34205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:45:08.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:45:08.398+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:45:08.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:45:08.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:45:08.429+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:45:08.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:45:08.439+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:45:08.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:45:08.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T22:45:38.786+0000] {processor.py:157} INFO - Started process (PID=34230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:45:38.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:45:38.788+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:45:38.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:45:38.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:45:38.812+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:45:38.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:45:38.822+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:45:38.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:45:38.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-18T22:46:09.156+0000] {processor.py:157} INFO - Started process (PID=34255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:46:09.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:46:09.159+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:46:09.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:46:09.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:46:09.188+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:46:09.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:46:09.198+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:46:09.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:46:09.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T22:46:39.594+0000] {processor.py:157} INFO - Started process (PID=34280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:46:39.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:46:39.598+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:46:39.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:46:39.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:46:39.625+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:46:39.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:46:39.635+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:46:39.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:46:39.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T22:47:10.047+0000] {processor.py:157} INFO - Started process (PID=34305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:47:10.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:47:10.051+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:47:10.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:47:10.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:47:10.080+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:47:10.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:47:10.092+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:47:10.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:47:10.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T22:47:40.473+0000] {processor.py:157} INFO - Started process (PID=34330) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:47:40.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:47:40.477+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:47:40.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:47:40.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:47:40.506+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:47:40.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:47:40.515+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:47:40.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:47:40.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T22:48:10.948+0000] {processor.py:157} INFO - Started process (PID=34355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:48:10.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:48:10.953+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:48:10.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:48:10.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:48:10.980+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:48:10.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:48:10.989+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:48:10.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:48:10.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T22:48:41.363+0000] {processor.py:157} INFO - Started process (PID=34380) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:48:41.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:48:41.366+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:48:41.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:48:41.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:48:41.395+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:48:41.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:48:41.405+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:48:41.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:48:41.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T22:49:11.831+0000] {processor.py:157} INFO - Started process (PID=34405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:49:11.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:49:11.835+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:49:11.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:49:11.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:49:11.867+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:49:11.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:49:11.877+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:49:11.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:49:11.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T22:49:42.323+0000] {processor.py:157} INFO - Started process (PID=34430) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:49:42.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:49:42.327+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:49:42.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:49:42.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:49:42.355+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:49:42.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:49:42.367+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:49:42.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:49:42.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T22:50:12.824+0000] {processor.py:157} INFO - Started process (PID=34455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:50:12.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:50:12.828+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:50:12.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:50:12.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:50:12.858+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:50:12.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:50:12.870+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:50:12.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:50:12.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-18T22:50:43.309+0000] {processor.py:157} INFO - Started process (PID=34480) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:50:43.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:50:43.314+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:50:43.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:50:43.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:50:43.348+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:50:43.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:50:43.357+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:50:43.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:50:43.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-18T22:51:13.745+0000] {processor.py:157} INFO - Started process (PID=34505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:51:13.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:51:13.747+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:51:13.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:51:13.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:51:13.776+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:51:13.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:51:13.785+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:51:13.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:51:13.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T22:51:44.217+0000] {processor.py:157} INFO - Started process (PID=34530) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:51:44.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:51:44.220+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:51:44.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:51:44.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:51:44.253+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:51:44.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:51:44.262+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:51:44.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:51:44.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T22:52:14.673+0000] {processor.py:157} INFO - Started process (PID=34555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:52:14.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:52:14.676+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:52:14.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:52:14.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:52:14.705+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:52:14.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:52:14.715+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:52:14.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:52:14.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T22:52:45.159+0000] {processor.py:157} INFO - Started process (PID=34580) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:52:45.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:52:45.162+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:52:45.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:52:45.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:52:45.190+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:52:45.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:52:45.200+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:52:45.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:52:45.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T22:53:15.617+0000] {processor.py:157} INFO - Started process (PID=34605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:53:15.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:53:15.620+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:53:15.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:53:15.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:53:15.646+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:53:15.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:53:15.657+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:53:15.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:53:15.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T22:53:46.098+0000] {processor.py:157} INFO - Started process (PID=34630) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:53:46.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:53:46.101+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:53:46.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:53:46.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:53:46.127+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:53:46.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:53:46.137+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:53:46.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:53:46.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T22:54:16.509+0000] {processor.py:157} INFO - Started process (PID=34655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:54:16.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:54:16.512+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:54:16.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:54:16.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:54:16.536+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:54:16.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:54:16.546+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:54:16.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:54:16.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-18T22:54:46.972+0000] {processor.py:157} INFO - Started process (PID=34680) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:54:46.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:54:46.975+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:54:46.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:54:46.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:54:47.000+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:54:47.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:54:47.009+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:54:47.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:54:47.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-18T22:55:17.450+0000] {processor.py:157} INFO - Started process (PID=34705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:55:17.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:55:17.455+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:55:17.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:55:17.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:55:17.487+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:55:17.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:55:17.499+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:55:17.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:55:17.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-18T22:55:47.934+0000] {processor.py:157} INFO - Started process (PID=34730) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:55:47.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:55:47.937+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:55:47.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:55:47.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:55:47.965+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:55:47.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:55:47.978+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:55:47.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:55:47.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T22:56:18.412+0000] {processor.py:157} INFO - Started process (PID=34755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:56:18.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:56:18.415+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:56:18.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:56:18.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:56:18.440+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:56:18.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:56:18.449+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:56:18.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:56:18.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T22:56:48.855+0000] {processor.py:157} INFO - Started process (PID=34780) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:56:48.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:56:48.859+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:56:48.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:56:48.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:56:48.890+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:56:48.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:56:48.901+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:56:48.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:56:48.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T22:57:19.311+0000] {processor.py:157} INFO - Started process (PID=34805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:57:19.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:57:19.318+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:57:19.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:57:19.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:57:19.345+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:57:19.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:57:19.356+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:57:19.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:57:19.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T22:57:49.779+0000] {processor.py:157} INFO - Started process (PID=34830) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:57:49.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:57:49.785+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:57:49.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:57:49.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:57:49.815+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:57:49.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:57:49.824+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:57:49.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:57:49.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T22:58:20.235+0000] {processor.py:157} INFO - Started process (PID=34855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:58:20.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:58:20.238+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:58:20.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:58:20.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:58:20.266+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:58:20.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:58:20.279+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:58:20.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:58:20.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T22:58:50.704+0000] {processor.py:157} INFO - Started process (PID=34880) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:58:50.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:58:50.707+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:58:50.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:58:50.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:58:50.736+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:58:50.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:58:50.746+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:58:50.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:58:50.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T22:59:21.150+0000] {processor.py:157} INFO - Started process (PID=34905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:59:21.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:59:21.153+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:59:21.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:59:21.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:59:21.184+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:59:21.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:59:21.196+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:59:21.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:59:21.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T22:59:51.587+0000] {processor.py:157} INFO - Started process (PID=34930) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:59:51.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T22:59:51.590+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:59:51.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:59:51.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T22:59:51.618+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:59:51.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:59:51.629+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:59:51.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T22:59:51.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T23:00:22.041+0000] {processor.py:157} INFO - Started process (PID=34955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:00:22.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:00:22.044+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:00:22.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:00:22.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:00:22.074+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:00:22.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:00:22.083+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:00:22.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:00:22.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T23:00:52.462+0000] {processor.py:157} INFO - Started process (PID=34980) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:00:52.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:00:52.469+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:00:52.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:00:52.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:00:52.500+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:00:52.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:00:52.515+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:00:52.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:00:52.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-18T23:01:22.904+0000] {processor.py:157} INFO - Started process (PID=35005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:01:22.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:01:22.908+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:01:22.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:01:22.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:01:22.933+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:01:22.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:01:22.948+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:01:22.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:01:22.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T23:01:53.344+0000] {processor.py:157} INFO - Started process (PID=35030) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:01:53.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:01:53.348+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:01:53.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:01:53.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:01:53.373+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:01:53.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:01:53.383+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:01:53.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:01:53.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-18T23:02:23.740+0000] {processor.py:157} INFO - Started process (PID=35055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:02:23.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:02:23.744+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:02:23.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:02:23.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:02:23.770+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:02:23.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:02:23.780+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:02:23.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:02:23.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T23:02:54.138+0000] {processor.py:157} INFO - Started process (PID=35080) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:02:54.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:02:54.141+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:02:54.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:02:54.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:02:54.167+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:02:54.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:02:54.177+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:02:54.177+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:02:54.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T23:03:24.636+0000] {processor.py:157} INFO - Started process (PID=35105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:03:24.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:03:24.639+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:03:24.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:03:24.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:03:24.667+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:03:24.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:03:24.678+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:03:24.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:03:24.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T23:03:55.086+0000] {processor.py:157} INFO - Started process (PID=35130) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:03:55.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:03:55.089+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:03:55.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:03:55.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:03:55.119+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:03:55.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:03:55.128+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:03:55.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:03:55.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T23:04:25.506+0000] {processor.py:157} INFO - Started process (PID=35155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:04:25.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:04:25.511+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:04:25.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:04:25.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:04:25.543+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:04:25.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:04:25.553+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:04:25.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:04:25.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-18T23:04:56.129+0000] {processor.py:157} INFO - Started process (PID=35180) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:04:56.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:04:56.134+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:04:56.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:04:56.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:04:56.175+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:04:56.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:04:56.195+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:04:56.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:04:56.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-18T23:05:26.643+0000] {processor.py:157} INFO - Started process (PID=35205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:05:26.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:05:26.646+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:05:26.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:05:26.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:05:26.673+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:05:26.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:05:26.682+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:05:26.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:05:26.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T23:05:57.081+0000] {processor.py:157} INFO - Started process (PID=35230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:05:57.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:05:57.084+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:05:57.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:05:57.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:05:57.111+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:05:57.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:05:57.123+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:05:57.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:05:57.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T23:06:27.495+0000] {processor.py:157} INFO - Started process (PID=35255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:06:27.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:06:27.498+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:06:27.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:06:27.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:06:27.526+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:06:27.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:06:27.537+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:06:27.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:06:27.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T23:06:57.947+0000] {processor.py:157} INFO - Started process (PID=35280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:06:57.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:06:57.950+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:06:57.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:06:57.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:06:57.982+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:06:57.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:06:57.994+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:06:57.994+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:06:58.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T23:07:28.394+0000] {processor.py:157} INFO - Started process (PID=35305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:07:28.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:07:28.399+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:07:28.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:07:28.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:07:28.432+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:07:28.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:07:28.446+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:07:28.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:07:28.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-18T23:07:58.853+0000] {processor.py:157} INFO - Started process (PID=35330) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:07:58.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:07:58.856+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:07:58.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:07:58.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:07:58.882+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:07:58.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:07:58.893+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:07:58.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:07:58.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T23:08:29.326+0000] {processor.py:157} INFO - Started process (PID=35355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:08:29.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:08:29.329+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:08:29.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:08:29.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:08:29.352+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:08:29.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:08:29.363+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:08:29.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:08:29.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T23:08:59.751+0000] {processor.py:157} INFO - Started process (PID=35380) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:08:59.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:08:59.754+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:08:59.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:08:59.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:08:59.783+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:08:59.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:08:59.795+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:08:59.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:08:59.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T23:09:30.198+0000] {processor.py:157} INFO - Started process (PID=35405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:09:30.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:09:30.201+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:09:30.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:09:30.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:09:30.228+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:09:30.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:09:30.241+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:09:30.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:09:30.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T23:10:00.652+0000] {processor.py:157} INFO - Started process (PID=35430) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:10:00.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:10:00.656+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:10:00.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:10:00.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:10:00.689+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:10:00.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:10:00.702+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:10:00.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:10:00.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-18T23:10:31.093+0000] {processor.py:157} INFO - Started process (PID=35455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:10:31.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:10:31.096+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:10:31.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:10:31.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:10:31.123+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:10:31.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:10:31.133+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:10:31.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:10:31.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T23:11:01.505+0000] {processor.py:157} INFO - Started process (PID=35480) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:11:01.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:11:01.507+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:11:01.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:11:01.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:11:01.537+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:11:01.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:11:01.546+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:11:01.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:11:01.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-18T23:11:31.931+0000] {processor.py:157} INFO - Started process (PID=35505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:11:31.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:11:31.934+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:11:31.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:11:31.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:11:31.959+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:11:31.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:11:31.968+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:11:31.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:11:31.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-18T23:12:02.415+0000] {processor.py:157} INFO - Started process (PID=35530) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:12:02.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:12:02.417+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:12:02.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:12:02.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:12:02.444+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:12:02.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:12:02.454+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:12:02.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:12:02.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-18T23:12:32.869+0000] {processor.py:157} INFO - Started process (PID=35555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:12:32.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:12:32.873+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:12:32.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:12:32.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:12:32.899+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:12:32.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:12:32.909+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:12:32.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:12:32.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T23:13:03.355+0000] {processor.py:157} INFO - Started process (PID=35580) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:13:03.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:13:03.359+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:13:03.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:13:03.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:13:03.390+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:13:03.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:13:03.401+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:13:03.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:13:03.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T23:13:33.764+0000] {processor.py:157} INFO - Started process (PID=35605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:13:33.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:13:33.767+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:13:33.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:13:33.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:13:33.792+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:13:33.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:13:33.802+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:13:33.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:13:33.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T23:14:04.163+0000] {processor.py:157} INFO - Started process (PID=35630) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:14:04.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:14:04.165+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:14:04.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:14:04.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:14:04.190+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:14:04.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:14:04.200+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:14:04.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:14:04.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-18T23:14:34.615+0000] {processor.py:157} INFO - Started process (PID=35655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:14:34.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:14:34.618+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:14:34.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:14:34.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:14:34.646+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:14:34.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:14:34.657+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:14:34.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:14:34.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T23:15:05.076+0000] {processor.py:157} INFO - Started process (PID=35680) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:15:05.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:15:05.079+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:15:05.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:15:05.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:15:05.104+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:15:05.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:15:05.115+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:15:05.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:15:05.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T23:15:35.555+0000] {processor.py:157} INFO - Started process (PID=35705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:15:35.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:15:35.558+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:15:35.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:15:35.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:15:35.596+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:15:35.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:15:35.611+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:15:35.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:15:35.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-18T23:16:05.977+0000] {processor.py:157} INFO - Started process (PID=35730) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:16:05.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:16:05.982+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:16:05.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:16:05.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:16:06.006+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:16:06.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:16:06.016+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:16:06.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:16:06.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T23:16:36.384+0000] {processor.py:157} INFO - Started process (PID=35755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:16:36.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:16:36.388+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:16:36.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:16:36.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:16:36.412+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:16:36.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:16:36.425+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:16:36.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:16:36.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T23:17:06.828+0000] {processor.py:157} INFO - Started process (PID=35780) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:17:06.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:17:06.830+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:17:06.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:17:06.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:17:06.858+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:17:06.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:17:06.868+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:17:06.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:17:06.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-18T23:17:37.314+0000] {processor.py:157} INFO - Started process (PID=35805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:17:37.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:17:37.317+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:17:37.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:17:37.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:17:37.348+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:17:37.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:17:37.358+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:17:37.358+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:17:37.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T23:18:07.760+0000] {processor.py:157} INFO - Started process (PID=35830) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:18:07.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:18:07.762+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:18:07.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:18:07.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:18:07.792+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:18:07.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:18:07.803+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:18:07.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:18:07.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-18T23:18:38.271+0000] {processor.py:157} INFO - Started process (PID=35855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:18:38.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:18:38.274+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:18:38.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:18:38.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:18:38.304+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:18:38.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:18:38.317+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:18:38.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:18:38.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T23:19:08.725+0000] {processor.py:157} INFO - Started process (PID=35880) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:19:08.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:19:08.729+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:19:08.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:19:08.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:19:08.758+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:19:08.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:19:08.770+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:19:08.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:19:08.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T23:19:39.139+0000] {processor.py:157} INFO - Started process (PID=35905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:19:39.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:19:39.144+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:19:39.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:19:39.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:19:39.175+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:19:39.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:19:39.185+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:19:39.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:19:39.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T23:20:09.551+0000] {processor.py:157} INFO - Started process (PID=35929) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:20:09.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:20:09.553+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:20:09.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:20:09.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:20:09.583+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:20:09.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:20:09.594+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:20:09.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:20:09.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-18T23:20:39.960+0000] {processor.py:157} INFO - Started process (PID=35955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:20:39.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:20:39.965+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:20:39.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:20:39.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:20:39.995+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:20:39.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:20:40.006+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:20:40.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:20:40.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-18T23:21:10.469+0000] {processor.py:157} INFO - Started process (PID=35980) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:21:10.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:21:10.471+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:21:10.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:21:10.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:21:10.503+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:21:10.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:21:10.513+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:21:10.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:21:10.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-18T23:21:41.012+0000] {processor.py:157} INFO - Started process (PID=36004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:21:41.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:21:41.017+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:21:41.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:21:41.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:21:41.078+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:21:41.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:21:41.091+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:21:41.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:21:41.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-18T23:33:27.003+0000] {processor.py:157} INFO - Started process (PID=36030) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:33:27.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:33:27.007+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:33:27.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:33:27.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:33:27.043+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:33:27.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:33:27.061+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:33:27.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:33:27.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-18T23:33:57.796+0000] {processor.py:157} INFO - Started process (PID=36057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:33:57.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:33:57.801+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:33:57.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:33:57.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:33:57.846+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:33:57.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:33:57.860+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:33:57.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:33:57.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-18T23:34:28.299+0000] {processor.py:157} INFO - Started process (PID=36082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:34:28.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:34:28.303+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:34:28.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:34:28.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:34:28.331+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:34:28.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:34:28.342+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:34:28.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:34:28.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-18T23:34:58.905+0000] {processor.py:157} INFO - Started process (PID=36107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:34:58.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:34:58.909+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:34:58.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:34:58.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:34:58.942+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:34:58.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:34:58.953+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:34:58.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:34:58.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-18T23:42:44.485+0000] {processor.py:157} INFO - Started process (PID=36132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:42:44.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:42:44.487+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:42:44.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:42:44.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:42:44.509+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:42:44.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:42:44.518+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:42:44.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:42:44.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-18T23:43:14.926+0000] {processor.py:157} INFO - Started process (PID=36159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:43:14.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:43:14.941+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:43:14.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:43:14.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:43:14.982+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:43:14.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:43:14.996+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:43:14.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:43:15.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-18T23:43:45.416+0000] {processor.py:157} INFO - Started process (PID=36184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:43:45.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:43:45.419+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:43:45.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:43:45.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:43:45.447+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:43:45.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:43:45.458+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:43:45.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:43:45.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-18T23:44:15.798+0000] {processor.py:157} INFO - Started process (PID=36209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:44:15.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:44:15.801+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:44:15.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:44:15.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:44:15.825+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:44:15.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:44:15.835+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:44:15.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:44:15.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-18T23:44:46.210+0000] {processor.py:157} INFO - Started process (PID=36234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:44:46.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-18T23:44:46.215+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:44:46.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:44:46.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-18T23:44:46.246+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:44:46.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:44:46.255+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:44:46.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-18T23:44:46.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
