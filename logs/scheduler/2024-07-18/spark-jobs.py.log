[2024-07-18T08:12:57.978+0000] {processor.py:157} INFO - Started process (PID=183) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:12:57.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:12:57.982+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:12:57.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:12:57.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:12:58.011+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:12:58.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:12:58.030+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:12:58.030+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:12:58.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-18T08:13:28.480+0000] {processor.py:157} INFO - Started process (PID=597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:13:28.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:13:28.489+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:13:28.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:13:28.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:13:28.579+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:13:28.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:13:28.607+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:13:28.607+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:13:28.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.157 seconds
[2024-07-18T08:13:59.216+0000] {processor.py:157} INFO - Started process (PID=621) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:13:59.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:13:59.225+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:13:59.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:13:59.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:13:59.314+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:13:59.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:13:59.337+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:13:59.337+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:13:59.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.151 seconds
[2024-07-18T08:14:29.786+0000] {processor.py:157} INFO - Started process (PID=647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:14:29.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:14:29.789+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:14:29.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:14:29.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:14:29.828+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:14:29.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:14:29.840+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:14:29.840+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:14:29.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-18T08:15:00.289+0000] {processor.py:157} INFO - Started process (PID=671) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:15:00.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:15:00.294+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:15:00.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:15:00.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:15:00.340+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:15:00.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:15:00.352+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:15:00.352+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:15:00.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-18T08:15:30.741+0000] {processor.py:157} INFO - Started process (PID=697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:15:30.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:15:30.742+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:15:30.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:15:30.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:15:30.767+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:15:30.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:15:30.776+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:15:30.775+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:15:30.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-18T08:16:01.180+0000] {processor.py:157} INFO - Started process (PID=722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:16:01.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:16:01.185+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:16:01.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:16:01.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:16:01.255+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:16:01.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:16:01.288+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:16:01.288+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:16:01.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.138 seconds
[2024-07-18T08:16:31.702+0000] {processor.py:157} INFO - Started process (PID=747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:16:31.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:16:31.704+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:16:31.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:16:31.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:16:31.745+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:16:31.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:16:31.763+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:16:31.763+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:16:31.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-18T08:17:02.232+0000] {processor.py:157} INFO - Started process (PID=771) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:17:02.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:17:02.238+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:17:02.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:17:02.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:17:02.323+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:17:02.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:17:02.363+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:17:02.363+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:17:02.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.154 seconds
[2024-07-18T08:17:32.755+0000] {processor.py:157} INFO - Started process (PID=797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:17:32.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:17:32.759+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:17:32.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:17:32.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:17:32.803+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:17:32.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:17:32.816+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:17:32.816+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:17:32.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-18T08:18:03.273+0000] {processor.py:157} INFO - Started process (PID=822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:18:03.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:18:03.277+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:18:03.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:18:03.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:18:03.318+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:18:03.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:18:03.330+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:18:03.330+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:18:03.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-18T08:18:33.693+0000] {processor.py:157} INFO - Started process (PID=847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:18:33.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:18:33.702+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:18:33.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:18:33.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:18:33.777+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:18:33.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:18:33.792+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:18:33.792+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:18:33.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.124 seconds
[2024-07-18T08:19:04.365+0000] {processor.py:157} INFO - Started process (PID=872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:19:04.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:19:04.371+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:19:04.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:19:04.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:19:04.414+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:19:04.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:19:04.427+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:19:04.427+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:19:04.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-18T08:19:34.829+0000] {processor.py:157} INFO - Started process (PID=897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:19:34.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:19:34.833+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:19:34.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:19:34.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:19:34.870+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:19:34.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:19:34.884+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:19:34.884+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:19:34.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-18T08:20:05.278+0000] {processor.py:157} INFO - Started process (PID=922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:20:05.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:20:05.283+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:20:05.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:20:05.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:20:05.330+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:20:05.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:20:05.341+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:20:05.341+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:20:05.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-18T08:20:35.823+0000] {processor.py:157} INFO - Started process (PID=946) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:20:35.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:20:35.828+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:20:35.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:20:35.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:20:35.886+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:20:35.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:20:35.909+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:20:35.909+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:20:35.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-18T08:21:06.263+0000] {processor.py:157} INFO - Started process (PID=972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:21:06.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:21:06.267+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:21:06.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:21:06.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:21:06.325+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:21:06.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:21:06.339+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:21:06.339+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:21:06.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.097 seconds
[2024-07-18T08:21:36.708+0000] {processor.py:157} INFO - Started process (PID=997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:21:36.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:21:36.712+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:21:36.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:21:36.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:21:36.767+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:21:36.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:21:36.781+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:21:36.780+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:21:36.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.089 seconds
[2024-07-18T08:22:07.183+0000] {processor.py:157} INFO - Started process (PID=1022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:22:07.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:22:07.187+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:22:07.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:22:07.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:22:07.222+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:22:07.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:22:07.235+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:22:07.235+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:22:07.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-18T08:22:37.655+0000] {processor.py:157} INFO - Started process (PID=1047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:22:37.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:22:37.662+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:22:37.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:22:37.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:22:37.726+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:22:37.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:22:37.769+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:22:37.768+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:22:37.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.133 seconds
[2024-07-18T08:23:08.180+0000] {processor.py:157} INFO - Started process (PID=1072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:23:08.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:23:08.183+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:23:08.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:23:08.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:23:08.217+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:23:08.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:23:08.230+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:23:08.230+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:23:08.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-18T08:23:38.675+0000] {processor.py:157} INFO - Started process (PID=1097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:23:38.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:23:38.691+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:23:38.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:23:38.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:23:38.750+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:23:38.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:23:38.766+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:23:38.766+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:23:38.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.115 seconds
[2024-07-18T08:24:09.210+0000] {processor.py:157} INFO - Started process (PID=1122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:24:09.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:24:09.217+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:24:09.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:24:09.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:24:09.297+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:24:09.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:24:09.320+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:24:09.319+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:24:09.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.133 seconds
[2024-07-18T08:24:39.733+0000] {processor.py:157} INFO - Started process (PID=1147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:24:39.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:24:39.735+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:24:39.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:24:39.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:24:39.772+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:24:39.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:24:39.782+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:24:39.782+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:24:39.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T08:25:10.168+0000] {processor.py:157} INFO - Started process (PID=1172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:25:10.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:25:10.171+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:25:10.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:25:10.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:25:10.200+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:25:10.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:25:10.214+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:25:10.213+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:25:10.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T08:25:40.629+0000] {processor.py:157} INFO - Started process (PID=1196) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:25:40.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:25:40.632+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:25:40.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:25:40.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:25:40.672+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:25:40.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:25:40.684+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:25:40.684+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:25:40.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-18T08:26:11.065+0000] {processor.py:157} INFO - Started process (PID=1222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:26:11.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:26:11.070+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:26:11.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:26:11.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:26:11.116+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:26:11.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:26:11.129+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:26:11.128+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:26:11.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-18T08:26:41.584+0000] {processor.py:157} INFO - Started process (PID=1247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:26:41.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:26:41.589+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:26:41.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:26:41.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:26:41.626+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:26:41.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:26:41.638+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:26:41.638+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:26:41.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-18T08:27:12.028+0000] {processor.py:157} INFO - Started process (PID=1272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:27:12.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:27:12.033+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:27:12.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:27:12.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:27:12.071+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:27:12.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:27:12.086+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:27:12.086+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:27:12.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-18T08:27:42.448+0000] {processor.py:157} INFO - Started process (PID=1297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:27:42.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:27:42.454+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:27:42.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:27:42.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:27:42.497+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:27:42.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:27:42.511+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:27:42.511+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:27:42.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-18T08:28:12.956+0000] {processor.py:157} INFO - Started process (PID=1322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:28:12.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:28:12.962+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:28:12.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:28:12.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:28:13.003+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:28:13.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:28:13.019+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:28:13.019+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:28:13.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-18T08:28:43.354+0000] {processor.py:157} INFO - Started process (PID=1347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:28:43.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:28:43.361+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:28:43.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:28:43.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:28:43.408+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:28:43.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:28:43.421+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:28:43.421+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:28:43.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.085 seconds
[2024-07-18T08:29:13.684+0000] {processor.py:157} INFO - Started process (PID=1372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:29:13.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:29:13.688+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:29:13.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:29:13.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:29:13.719+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:29:13.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:29:13.730+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:29:13.730+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:29:13.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T08:29:44.023+0000] {processor.py:157} INFO - Started process (PID=1397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:29:44.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:29:44.028+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:29:44.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:29:44.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:29:44.063+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:29:44.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:29:44.076+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:29:44.076+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:29:44.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-18T08:30:14.493+0000] {processor.py:157} INFO - Started process (PID=1422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:30:14.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:30:14.498+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:30:14.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:30:14.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:30:14.530+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:30:14.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:30:14.542+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:30:14.542+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:30:14.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-18T08:30:44.904+0000] {processor.py:157} INFO - Started process (PID=1447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:30:44.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:30:44.908+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:30:44.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:30:44.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:30:44.942+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:30:44.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:30:44.955+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:30:44.955+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:30:44.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T08:31:15.352+0000] {processor.py:157} INFO - Started process (PID=1472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:31:15.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:31:15.358+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:31:15.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:31:15.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:31:15.395+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:31:15.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:31:15.409+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:31:15.408+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:31:15.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-18T08:31:45.795+0000] {processor.py:157} INFO - Started process (PID=1497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:31:45.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:31:45.802+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:31:45.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:31:45.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:31:45.841+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:31:45.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:31:45.857+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:31:45.857+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:31:45.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-18T08:32:16.244+0000] {processor.py:157} INFO - Started process (PID=1522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:32:16.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:32:16.247+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:32:16.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:32:16.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:32:16.280+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:32:16.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:32:16.291+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:32:16.291+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:32:16.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T08:32:46.691+0000] {processor.py:157} INFO - Started process (PID=1547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:32:46.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:32:46.695+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:32:46.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:32:46.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:32:46.736+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:32:46.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:32:46.750+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:32:46.750+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:32:46.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-18T08:33:17.199+0000] {processor.py:157} INFO - Started process (PID=1572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:33:17.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:33:17.202+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:33:17.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:33:17.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:33:17.240+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:33:17.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:33:17.255+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:33:17.255+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:33:17.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-18T08:33:47.644+0000] {processor.py:157} INFO - Started process (PID=1597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:33:47.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:33:47.653+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:33:47.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:33:47.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:33:47.701+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:33:47.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:33:47.715+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:33:47.715+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:33:47.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.084 seconds
[2024-07-18T08:34:18.103+0000] {processor.py:157} INFO - Started process (PID=1622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:34:18.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:34:18.107+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:34:18.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:34:18.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:34:18.149+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:34:18.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:34:18.160+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:34:18.160+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:34:18.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-18T08:34:48.544+0000] {processor.py:157} INFO - Started process (PID=1647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:34:48.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:34:48.552+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:34:48.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:34:48.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:34:48.650+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:34:48.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:34:48.667+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:34:48.666+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:34:48.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.137 seconds
[2024-07-18T08:35:19.114+0000] {processor.py:157} INFO - Started process (PID=1672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:35:19.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:35:19.120+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:35:19.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:35:19.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:35:19.207+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:35:19.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:35:19.222+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:35:19.222+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:35:19.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.125 seconds
[2024-07-18T08:35:49.706+0000] {processor.py:157} INFO - Started process (PID=1697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:35:49.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:35:49.719+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:35:49.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:35:49.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:35:49.775+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:35:49.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:35:49.803+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:35:49.802+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:35:49.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.118 seconds
[2024-07-18T08:36:20.287+0000] {processor.py:157} INFO - Started process (PID=1721) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:36:20.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:36:20.293+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:36:20.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:36:20.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:36:20.371+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:36:20.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:36:20.387+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:36:20.387+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:36:20.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.116 seconds
[2024-07-18T08:36:50.767+0000] {processor.py:157} INFO - Started process (PID=1747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:36:50.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:36:50.775+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:36:50.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:36:50.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:36:50.844+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:36:50.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:36:50.865+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:36:50.864+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:36:50.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.117 seconds
[2024-07-18T08:37:21.440+0000] {processor.py:157} INFO - Started process (PID=1772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:37:21.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:37:21.448+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:37:21.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:37:21.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:37:21.543+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:37:21.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:37:21.561+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:37:21.561+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:37:21.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.144 seconds
[2024-07-18T08:37:51.979+0000] {processor.py:157} INFO - Started process (PID=1797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:37:51.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:37:51.983+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:37:51.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:37:52.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:37:52.019+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:37:52.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:37:52.029+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:37:52.029+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:37:52.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-18T08:38:22.477+0000] {processor.py:157} INFO - Started process (PID=1822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:38:22.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:38:22.482+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:38:22.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:38:22.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:38:22.518+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:38:22.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:38:22.533+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:38:22.533+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:38:22.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-18T08:38:52.952+0000] {processor.py:157} INFO - Started process (PID=1847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:38:52.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:38:52.956+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:38:52.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:38:52.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:38:52.993+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:38:52.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:38:53.006+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:38:53.006+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:38:53.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-18T08:39:23.362+0000] {processor.py:157} INFO - Started process (PID=1872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:39:23.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:39:23.365+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:39:23.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:39:23.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:39:23.393+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:39:23.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:39:23.404+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:39:23.404+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:39:23.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T08:39:53.772+0000] {processor.py:157} INFO - Started process (PID=1897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:39:53.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:39:53.777+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:39:53.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:39:53.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:39:53.814+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:39:53.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:39:53.827+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:39:53.827+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:39:53.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-18T08:40:24.186+0000] {processor.py:157} INFO - Started process (PID=1922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:40:24.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:40:24.189+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:40:24.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:40:24.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:40:24.260+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:40:24.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:40:24.271+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:40:24.271+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:40:24.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.098 seconds
[2024-07-18T08:40:54.661+0000] {processor.py:157} INFO - Started process (PID=1947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:40:54.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:40:54.665+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:40:54.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:40:54.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:40:54.698+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:40:54.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:40:54.708+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:40:54.708+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:40:54.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T08:41:25.127+0000] {processor.py:157} INFO - Started process (PID=1972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:41:25.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:41:25.134+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:41:25.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:41:25.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:41:25.178+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:41:25.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:41:25.190+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:41:25.190+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:41:25.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-18T08:41:55.576+0000] {processor.py:157} INFO - Started process (PID=1997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:41:55.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:41:55.579+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:41:55.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:41:55.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:41:55.618+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:41:55.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:41:55.633+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:41:55.633+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:41:55.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-18T08:42:26.004+0000] {processor.py:157} INFO - Started process (PID=2022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:42:26.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:42:26.008+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:42:26.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:42:26.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:42:26.047+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:42:26.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:42:26.060+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:42:26.060+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:42:26.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-18T08:42:56.418+0000] {processor.py:157} INFO - Started process (PID=2047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:42:56.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:42:56.428+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:42:56.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:42:56.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:42:56.466+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:42:56.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:42:56.480+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:42:56.480+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:42:56.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-18T08:43:26.940+0000] {processor.py:157} INFO - Started process (PID=2072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:43:26.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:43:26.949+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:43:26.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:43:26.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:43:26.973+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:43:26.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:43:26.983+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:43:26.983+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:43:26.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T08:43:57.378+0000] {processor.py:157} INFO - Started process (PID=2097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:43:57.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:43:57.383+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:43:57.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:43:57.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:43:57.419+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:43:57.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:43:57.431+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:43:57.431+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:43:57.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-18T08:44:27.869+0000] {processor.py:157} INFO - Started process (PID=2121) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:44:27.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:44:27.873+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:44:27.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:44:27.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:44:27.910+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:44:27.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:44:27.922+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:44:27.922+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:44:27.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-18T08:44:58.324+0000] {processor.py:157} INFO - Started process (PID=2147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:44:58.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:44:58.331+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:44:58.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:44:58.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:44:58.389+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:44:58.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:44:58.409+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:44:58.409+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:44:58.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.100 seconds
[2024-07-18T08:45:28.817+0000] {processor.py:157} INFO - Started process (PID=2172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:45:28.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:45:28.826+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:45:28.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:45:28.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:45:28.882+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:45:28.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:45:28.900+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:45:28.900+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:45:28.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.107 seconds
[2024-07-18T08:45:59.348+0000] {processor.py:157} INFO - Started process (PID=2197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:45:59.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:45:59.353+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:45:59.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:45:59.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:45:59.393+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:45:59.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:45:59.406+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:45:59.406+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:45:59.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-18T08:46:29.878+0000] {processor.py:157} INFO - Started process (PID=2222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:46:29.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:46:29.887+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:46:29.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:46:29.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:46:30.142+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:46:30.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:46:30.209+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:46:30.209+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:46:30.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.351 seconds
[2024-07-18T08:47:00.679+0000] {processor.py:157} INFO - Started process (PID=2247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:47:00.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:47:00.691+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:47:00.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:47:00.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:47:00.762+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:47:00.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:47:00.785+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:47:00.785+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:47:00.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.127 seconds
[2024-07-18T08:47:31.214+0000] {processor.py:157} INFO - Started process (PID=2272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:47:31.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:47:31.218+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:47:31.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:47:31.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:47:31.252+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:47:31.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:47:31.264+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:47:31.264+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:47:31.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-18T08:48:01.705+0000] {processor.py:157} INFO - Started process (PID=2296) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:48:01.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:48:01.711+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:48:01.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:48:01.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:48:01.759+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:48:01.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:48:01.772+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:48:01.771+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:48:01.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-18T08:48:32.222+0000] {processor.py:157} INFO - Started process (PID=2322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:48:32.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:48:32.228+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:48:32.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:48:32.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:48:32.278+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:48:32.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:48:32.291+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:48:32.291+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:48:32.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.083 seconds
[2024-07-18T08:49:02.731+0000] {processor.py:157} INFO - Started process (PID=2346) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:49:02.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:49:02.740+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:49:02.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:49:02.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:49:02.800+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:49:02.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:49:02.828+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:49:02.828+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:49:02.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.115 seconds
[2024-07-18T08:49:33.306+0000] {processor.py:157} INFO - Started process (PID=2372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:49:33.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:49:33.313+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:49:33.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:49:33.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:49:33.375+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:49:33.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:49:33.392+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:49:33.392+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:49:33.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-18T08:50:03.820+0000] {processor.py:157} INFO - Started process (PID=2397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:50:03.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:50:03.843+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:50:03.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:50:03.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:50:03.893+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:50:03.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:50:03.906+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:50:03.906+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:50:03.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-18T08:50:34.318+0000] {processor.py:157} INFO - Started process (PID=2422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:50:34.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:50:34.322+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:50:34.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:50:34.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:50:34.351+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:50:34.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:50:34.364+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:50:34.363+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:50:34.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T08:51:04.782+0000] {processor.py:157} INFO - Started process (PID=2447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:51:04.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:51:04.786+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:51:04.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:51:04.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:51:04.829+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:51:04.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:51:04.841+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:51:04.841+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:51:04.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-18T08:51:35.258+0000] {processor.py:157} INFO - Started process (PID=2472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:51:35.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:51:35.269+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:51:35.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:51:35.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:51:35.396+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:51:35.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:51:35.443+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:51:35.443+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:51:35.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.209 seconds
[2024-07-18T08:52:05.834+0000] {processor.py:157} INFO - Started process (PID=2497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:52:05.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:52:05.839+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:52:05.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:52:05.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:52:05.866+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:52:05.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:52:05.875+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:52:05.875+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:52:05.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T08:52:36.283+0000] {processor.py:157} INFO - Started process (PID=2522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:52:36.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:52:36.292+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:52:36.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:52:36.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:52:36.353+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:52:36.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:52:36.365+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:52:36.365+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:52:36.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.101 seconds
[2024-07-18T08:53:06.811+0000] {processor.py:157} INFO - Started process (PID=2547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:53:06.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:53:06.813+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:53:06.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:53:06.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:53:06.842+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:53:06.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:53:06.852+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:53:06.852+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:53:06.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T08:53:37.214+0000] {processor.py:157} INFO - Started process (PID=2572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:53:37.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:53:37.230+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:53:37.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:53:37.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:53:37.287+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:53:37.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:53:37.302+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:53:37.302+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:53:37.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.103 seconds
[2024-07-18T08:54:07.739+0000] {processor.py:157} INFO - Started process (PID=2597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:54:07.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:54:07.745+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:54:07.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:54:07.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:54:07.775+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:54:07.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:54:07.784+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:54:07.784+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:54:07.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T08:54:38.134+0000] {processor.py:157} INFO - Started process (PID=2622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:54:38.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:54:38.145+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:54:38.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:54:38.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:54:38.174+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:54:38.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:54:38.184+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:54:38.184+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:54:38.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T08:55:08.600+0000] {processor.py:157} INFO - Started process (PID=2647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:55:08.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:55:08.604+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:55:08.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:55:08.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:55:08.638+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:55:08.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:55:08.647+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:55:08.647+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:55:08.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T08:55:39.079+0000] {processor.py:157} INFO - Started process (PID=2672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:55:39.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:55:39.084+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:55:39.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:55:39.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:55:39.131+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:55:39.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:55:39.149+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:55:39.149+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:55:39.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.088 seconds
[2024-07-18T08:56:09.641+0000] {processor.py:157} INFO - Started process (PID=2697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:56:09.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:56:09.648+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:56:09.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:56:09.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:56:09.689+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:56:09.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:56:09.702+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:56:09.702+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:56:09.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-18T08:56:40.112+0000] {processor.py:157} INFO - Started process (PID=2722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:56:40.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:56:40.121+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:56:40.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:56:40.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:56:40.179+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:56:40.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:56:40.192+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:56:40.192+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:56:40.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.100 seconds
[2024-07-18T08:57:10.906+0000] {processor.py:157} INFO - Started process (PID=2747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:57:10.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:57:10.919+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:57:10.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:57:10.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:57:11.019+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:57:11.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:57:11.048+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:57:11.048+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:57:11.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.177 seconds
[2024-07-18T08:57:41.685+0000] {processor.py:157} INFO - Started process (PID=2772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:57:41.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:57:41.693+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:57:41.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:57:41.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:57:41.869+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:57:41.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:57:41.883+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:57:41.883+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:57:41.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.218 seconds
[2024-07-18T08:58:12.269+0000] {processor.py:157} INFO - Started process (PID=2797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:58:12.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:58:12.271+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:58:12.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:58:12.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:58:12.307+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:58:12.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:58:12.317+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:58:12.317+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:58:12.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T08:58:42.757+0000] {processor.py:157} INFO - Started process (PID=2822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:58:42.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:58:42.760+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:58:42.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:58:42.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:58:42.796+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:58:42.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:58:42.806+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:58:42.805+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:58:42.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-18T08:59:13.241+0000] {processor.py:157} INFO - Started process (PID=2847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:59:13.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:59:13.246+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:59:13.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:59:13.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:59:13.304+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:59:13.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:59:13.317+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:59:13.317+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:59:13.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.091 seconds
[2024-07-18T08:59:43.743+0000] {processor.py:157} INFO - Started process (PID=2872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:59:43.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T08:59:43.750+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:59:43.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:59:43.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T08:59:43.815+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:59:43.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T08:59:43.827+0000] {logging_mixin.py:151} INFO - [2024-07-18T08:59:43.827+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T08:59:43.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.098 seconds
[2024-07-18T09:00:14.233+0000] {processor.py:157} INFO - Started process (PID=2897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:00:14.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:00:14.237+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:00:14.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:00:14.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:00:14.265+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:00:14.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:00:14.280+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:00:14.280+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:00:14.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T09:00:44.701+0000] {processor.py:157} INFO - Started process (PID=2922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:00:44.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:00:44.705+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:00:44.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:00:44.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:00:44.749+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:00:44.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:00:44.762+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:00:44.762+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:00:44.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-18T09:01:15.223+0000] {processor.py:157} INFO - Started process (PID=2947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:01:15.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:01:15.226+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:01:15.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:01:15.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:01:15.253+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:01:15.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:01:15.265+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:01:15.265+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:01:15.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T09:01:45.681+0000] {processor.py:157} INFO - Started process (PID=2972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:01:45.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:01:45.685+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:01:45.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:01:45.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:01:45.721+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:01:45.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:01:45.733+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:01:45.733+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:01:45.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-18T09:02:16.382+0000] {processor.py:157} INFO - Started process (PID=2997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:02:16.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:02:16.389+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:02:16.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:02:16.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:02:16.440+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:02:16.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:02:16.454+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:02:16.454+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:02:16.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-18T09:02:46.866+0000] {processor.py:157} INFO - Started process (PID=3022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:02:46.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:02:46.869+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:02:46.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:02:46.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:02:46.898+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:02:46.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:02:46.910+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:02:46.910+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:02:46.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T09:03:17.343+0000] {processor.py:157} INFO - Started process (PID=3046) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:03:17.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:03:17.349+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:03:17.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:03:17.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:03:17.399+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:03:17.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:03:17.415+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:03:17.415+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:03:17.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.092 seconds
[2024-07-18T09:03:47.825+0000] {processor.py:157} INFO - Started process (PID=3072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:03:47.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:03:47.828+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:03:47.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:03:47.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:03:47.858+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:03:47.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:03:47.868+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:03:47.868+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:03:47.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T09:04:18.349+0000] {processor.py:157} INFO - Started process (PID=3095) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:04:18.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:04:18.355+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:04:18.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:04:18.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:04:18.402+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:04:18.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:04:18.414+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:04:18.414+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:04:18.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-18T09:04:48.836+0000] {processor.py:157} INFO - Started process (PID=3122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:04:48.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:04:48.843+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:04:48.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:04:48.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:04:48.885+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:04:48.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:04:48.898+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:04:48.897+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:04:48.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-18T09:05:19.323+0000] {processor.py:157} INFO - Started process (PID=3147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:05:19.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:05:19.333+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:05:19.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:05:19.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:05:19.363+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:05:19.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:05:19.375+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:05:19.375+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:05:19.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T09:05:49.748+0000] {processor.py:157} INFO - Started process (PID=3172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:05:49.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:05:49.752+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:05:49.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:05:49.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:05:49.779+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:05:49.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:05:49.788+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:05:49.788+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:05:49.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T09:06:20.240+0000] {processor.py:157} INFO - Started process (PID=3197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:06:20.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:06:20.246+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:06:20.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:06:20.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:06:20.297+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:06:20.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:06:20.310+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:06:20.310+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:06:20.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-18T09:06:50.717+0000] {processor.py:157} INFO - Started process (PID=3222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:06:50.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:06:50.722+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:06:50.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:06:50.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:06:50.753+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:06:50.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:06:50.763+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:06:50.763+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:06:50.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T09:07:21.188+0000] {processor.py:157} INFO - Started process (PID=3247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:07:21.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:07:21.213+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:07:21.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:07:21.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:07:21.263+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:07:21.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:07:21.288+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:07:21.287+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:07:21.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.117 seconds
[2024-07-18T09:07:51.702+0000] {processor.py:157} INFO - Started process (PID=3272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:07:51.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:07:51.708+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:07:51.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:07:51.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:07:51.769+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:07:51.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:07:51.785+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:07:51.785+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:07:51.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.099 seconds
[2024-07-18T09:08:22.165+0000] {processor.py:157} INFO - Started process (PID=3297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:08:22.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:08:22.169+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:08:22.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:08:22.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:08:22.232+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:08:22.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:08:22.243+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:08:22.243+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:08:22.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-18T09:08:52.660+0000] {processor.py:157} INFO - Started process (PID=3321) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:08:52.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:08:52.663+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:08:52.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:08:52.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:08:52.698+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:08:52.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:08:52.708+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:08:52.708+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:08:52.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-18T09:09:23.097+0000] {processor.py:157} INFO - Started process (PID=3347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:09:23.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:09:23.102+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:09:23.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:09:23.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:09:23.149+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:09:23.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:09:23.161+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:09:23.161+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:09:23.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-18T09:09:53.653+0000] {processor.py:157} INFO - Started process (PID=3372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:09:53.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:09:53.662+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:09:53.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:09:53.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:09:53.734+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:09:53.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:09:53.748+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:09:53.748+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:09:53.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.118 seconds
[2024-07-18T09:10:24.195+0000] {processor.py:157} INFO - Started process (PID=3397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:10:24.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:10:24.200+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:10:24.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:10:24.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:10:24.239+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:10:24.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:10:24.252+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:10:24.252+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:10:24.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-18T09:10:54.597+0000] {processor.py:157} INFO - Started process (PID=3422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:10:54.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:10:54.598+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:10:54.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:10:54.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:10:54.620+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:10:54.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:10:54.631+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:10:54.631+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:10:54.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-18T09:11:25.089+0000] {processor.py:157} INFO - Started process (PID=3447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:11:25.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:11:25.096+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:11:25.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:11:25.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:11:25.167+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:11:25.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:11:25.179+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:11:25.179+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:11:25.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-18T09:11:55.655+0000] {processor.py:157} INFO - Started process (PID=3472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:11:55.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:11:55.671+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:11:55.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:11:55.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:11:55.728+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:11:55.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:11:55.740+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:11:55.740+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:11:55.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.102 seconds
[2024-07-18T09:12:26.183+0000] {processor.py:157} INFO - Started process (PID=3497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:12:26.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:12:26.188+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:12:26.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:12:26.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:12:26.235+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:12:26.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:12:26.249+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:12:26.249+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:12:26.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-18T09:12:56.687+0000] {processor.py:157} INFO - Started process (PID=3522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:12:56.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:12:56.691+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:12:56.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:12:56.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:12:56.731+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:12:56.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:12:56.743+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:12:56.743+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:12:56.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-18T09:13:27.149+0000] {processor.py:157} INFO - Started process (PID=3547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:13:27.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:13:27.153+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:13:27.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:13:27.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:13:27.190+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:13:27.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:13:27.205+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:13:27.205+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:13:27.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-18T09:13:57.658+0000] {processor.py:157} INFO - Started process (PID=3572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:13:57.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:13:57.663+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:13:57.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:13:57.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:13:57.710+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:13:57.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:13:57.719+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:13:57.719+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:13:57.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-18T09:14:28.057+0000] {processor.py:157} INFO - Started process (PID=3597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:14:28.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:14:28.060+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:14:28.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:14:28.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:14:28.091+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:14:28.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:14:28.103+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:14:28.103+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:14:28.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T09:14:58.473+0000] {processor.py:157} INFO - Started process (PID=3622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:14:58.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:14:58.487+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:14:58.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:14:58.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:14:58.536+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:14:58.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:14:58.546+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:14:58.546+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:14:58.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-18T09:15:28.971+0000] {processor.py:157} INFO - Started process (PID=3647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:15:28.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:15:28.976+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:15:28.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:15:28.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:15:29.005+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:15:29.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:15:29.018+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:15:29.018+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:15:29.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T09:15:59.460+0000] {processor.py:157} INFO - Started process (PID=3672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:15:59.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:15:59.466+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:15:59.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:15:59.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:15:59.507+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:15:59.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:15:59.517+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:15:59.517+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:15:59.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-18T09:16:29.850+0000] {processor.py:157} INFO - Started process (PID=3697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:16:29.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:16:29.852+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:16:29.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:16:29.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:16:29.882+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:16:29.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:16:29.892+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:16:29.892+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:16:29.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T09:17:00.260+0000] {processor.py:157} INFO - Started process (PID=3722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:17:00.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:17:00.262+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:17:00.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:17:00.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:17:00.293+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:17:00.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:17:00.305+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:17:00.304+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:17:00.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T09:17:30.638+0000] {processor.py:157} INFO - Started process (PID=3747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:17:30.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:17:30.641+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:17:30.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:17:30.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:17:30.668+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:17:30.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:17:30.679+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:17:30.679+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:17:30.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T09:18:01.044+0000] {processor.py:157} INFO - Started process (PID=3772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:18:01.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:18:01.049+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:18:01.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:18:01.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:18:01.087+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:18:01.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:18:01.097+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:18:01.097+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:18:01.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-18T09:18:31.527+0000] {processor.py:157} INFO - Started process (PID=3797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:18:31.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:18:31.530+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:18:31.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:18:31.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:18:31.560+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:18:31.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:18:31.571+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:18:31.571+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:18:31.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T09:19:01.935+0000] {processor.py:157} INFO - Started process (PID=3822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:19:01.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:19:01.938+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:19:01.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:19:01.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:19:01.970+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:19:01.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:19:01.981+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:19:01.981+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:19:01.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T09:19:32.342+0000] {processor.py:157} INFO - Started process (PID=3847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:19:32.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:19:32.346+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:19:32.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:19:32.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:19:32.379+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:19:32.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:19:32.394+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:19:32.394+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:19:32.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-18T09:20:02.783+0000] {processor.py:157} INFO - Started process (PID=3872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:20:02.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:20:02.786+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:20:02.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:20:02.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:20:02.815+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:20:02.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:20:02.825+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:20:02.825+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:20:02.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T09:20:33.191+0000] {processor.py:157} INFO - Started process (PID=3897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:20:33.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:20:33.192+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:20:33.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:20:33.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:20:33.219+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:20:33.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:20:33.229+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:20:33.229+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:20:33.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-18T09:21:03.605+0000] {processor.py:157} INFO - Started process (PID=3922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:21:03.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:21:03.609+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:21:03.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:21:03.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:21:03.646+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:21:03.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:21:03.655+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:21:03.655+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:21:03.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-18T09:21:34.043+0000] {processor.py:157} INFO - Started process (PID=3947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:21:34.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:21:34.046+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:21:34.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:21:34.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:21:34.074+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:21:34.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:21:34.084+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:21:34.084+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:21:34.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T09:22:04.456+0000] {processor.py:157} INFO - Started process (PID=3972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:22:04.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:22:04.460+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:22:04.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:22:04.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:22:04.490+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:22:04.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:22:04.502+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:22:04.502+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:22:04.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T09:22:34.923+0000] {processor.py:157} INFO - Started process (PID=3997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:22:34.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:22:34.929+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:22:34.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:22:34.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:22:34.962+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:22:34.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:22:34.973+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:22:34.973+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:22:34.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T09:23:05.404+0000] {processor.py:157} INFO - Started process (PID=4022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:23:05.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:23:05.408+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:23:05.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:23:05.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:23:05.440+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:23:05.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:23:05.451+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:23:05.451+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:23:05.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T09:23:35.899+0000] {processor.py:157} INFO - Started process (PID=4047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:23:35.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:23:35.903+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:23:35.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:23:35.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:23:35.932+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:23:35.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:23:35.941+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:23:35.941+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:23:35.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T09:24:06.306+0000] {processor.py:157} INFO - Started process (PID=4072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:24:06.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:24:06.310+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:24:06.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:24:06.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:24:06.345+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:24:06.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:24:06.354+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:24:06.354+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:24:06.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T09:24:36.711+0000] {processor.py:157} INFO - Started process (PID=4097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:24:36.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:24:36.713+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:24:36.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:24:36.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:24:36.738+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:24:36.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:24:36.747+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:24:36.747+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:24:36.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-18T09:25:07.425+0000] {processor.py:157} INFO - Started process (PID=4122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:25:07.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:25:07.430+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:25:07.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:25:07.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:25:07.480+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:25:07.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:25:07.492+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:25:07.491+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:25:07.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-18T09:25:37.898+0000] {processor.py:157} INFO - Started process (PID=4147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:25:37.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:25:37.901+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:25:37.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:25:37.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:25:37.928+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:25:37.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:25:37.937+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:25:37.937+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:25:37.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-18T09:26:08.283+0000] {processor.py:157} INFO - Started process (PID=4172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:26:08.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:26:08.286+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:26:08.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:26:08.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:26:08.312+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:26:08.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:26:08.323+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:26:08.322+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:26:08.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T09:26:38.721+0000] {processor.py:157} INFO - Started process (PID=4197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:26:38.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:26:38.725+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:26:38.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:26:38.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:26:38.754+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:26:38.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:26:38.765+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:26:38.765+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:26:38.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T09:27:09.162+0000] {processor.py:157} INFO - Started process (PID=4222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:27:09.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:27:09.164+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:27:09.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:27:09.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:27:09.191+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:27:09.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:27:09.202+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:27:09.201+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:27:09.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T09:27:39.597+0000] {processor.py:157} INFO - Started process (PID=4247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:27:39.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:27:39.601+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:27:39.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:27:39.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:27:39.630+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:27:39.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:27:39.643+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:27:39.642+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:27:39.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T09:28:10.038+0000] {processor.py:157} INFO - Started process (PID=4272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:28:10.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:28:10.041+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:28:10.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:28:10.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:28:10.069+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:28:10.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:28:10.080+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:28:10.080+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:28:10.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T09:28:40.468+0000] {processor.py:157} INFO - Started process (PID=4297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:28:40.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:28:40.472+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:28:40.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:28:40.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:28:40.500+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:28:40.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:28:40.510+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:28:40.510+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:28:40.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T09:29:10.905+0000] {processor.py:157} INFO - Started process (PID=4322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:29:10.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:29:10.909+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:29:10.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:29:10.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:29:10.938+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:29:10.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:29:10.947+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:29:10.947+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:29:10.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T09:29:41.303+0000] {processor.py:157} INFO - Started process (PID=4347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:29:41.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:29:41.306+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:29:41.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:29:41.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:29:41.334+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:29:41.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:29:41.346+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:29:41.346+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:29:41.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T09:30:11.789+0000] {processor.py:157} INFO - Started process (PID=4372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:30:11.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:30:11.793+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:30:11.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:30:11.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:30:11.830+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:30:11.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:30:11.842+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:30:11.842+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:30:11.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-18T09:30:42.196+0000] {processor.py:157} INFO - Started process (PID=4397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:30:42.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:30:42.199+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:30:42.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:30:42.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:30:42.227+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:30:42.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:30:42.240+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:30:42.240+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:30:42.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T09:31:12.530+0000] {processor.py:157} INFO - Started process (PID=4422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:31:12.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:31:12.532+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:31:12.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:31:12.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:31:12.559+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:31:12.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:31:12.568+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:31:12.568+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:31:12.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-18T09:31:42.982+0000] {processor.py:157} INFO - Started process (PID=4447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:31:42.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:31:42.990+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:31:42.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:31:43.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:31:43.014+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:31:43.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:31:43.025+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:31:43.025+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:31:43.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T09:32:13.383+0000] {processor.py:157} INFO - Started process (PID=4472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:32:13.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:32:13.387+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:32:13.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:32:13.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:32:13.417+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:32:13.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:32:13.428+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:32:13.428+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:32:13.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T09:32:43.780+0000] {processor.py:157} INFO - Started process (PID=4497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:32:43.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:32:43.784+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:32:43.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:32:43.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:32:43.812+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:32:43.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:32:43.821+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:32:43.821+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:32:43.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T09:33:14.255+0000] {processor.py:157} INFO - Started process (PID=4522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:33:14.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:33:14.259+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:33:14.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:33:14.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:33:14.285+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:33:14.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:33:14.298+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:33:14.298+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:33:14.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T09:33:44.653+0000] {processor.py:157} INFO - Started process (PID=4547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:33:44.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:33:44.656+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:33:44.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:33:44.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:33:44.689+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:33:44.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:33:44.701+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:33:44.701+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:33:44.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T09:34:15.082+0000] {processor.py:157} INFO - Started process (PID=4572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:34:15.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:34:15.087+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:34:15.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:34:15.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:34:15.110+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:34:15.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:34:15.119+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:34:15.119+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:34:15.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-18T09:34:45.461+0000] {processor.py:157} INFO - Started process (PID=4597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:34:45.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:34:45.462+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:34:45.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:34:45.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:34:45.485+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:34:45.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:34:45.496+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:34:45.496+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:34:45.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-18T09:35:15.916+0000] {processor.py:157} INFO - Started process (PID=4622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:35:15.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:35:15.919+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:35:15.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:35:15.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:35:15.951+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:35:15.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:35:15.961+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:35:15.961+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:35:15.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T09:35:46.447+0000] {processor.py:157} INFO - Started process (PID=4647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:35:46.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:35:46.454+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:35:46.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:35:46.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:35:46.513+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:35:46.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:35:46.525+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:35:46.525+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:35:46.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.094 seconds
[2024-07-18T09:36:16.889+0000] {processor.py:157} INFO - Started process (PID=4672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:36:16.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:36:16.895+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:36:16.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:36:16.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:36:16.913+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:36:16.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:36:16.922+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:36:16.922+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:36:16.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-18T09:36:47.312+0000] {processor.py:157} INFO - Started process (PID=4697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:36:47.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:36:47.315+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:36:47.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:36:47.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:36:47.340+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:36:47.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:36:47.350+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:36:47.350+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:36:47.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T09:37:17.659+0000] {processor.py:157} INFO - Started process (PID=4722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:37:17.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:37:17.662+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:37:17.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:37:17.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:37:17.690+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:37:17.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:37:17.701+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:37:17.701+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:37:17.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T09:37:48.110+0000] {processor.py:157} INFO - Started process (PID=4747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:37:48.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:37:48.113+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:37:48.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:37:48.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:37:48.140+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:37:48.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:37:48.149+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:37:48.149+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:37:48.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T09:38:18.550+0000] {processor.py:157} INFO - Started process (PID=4772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:38:18.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:38:18.556+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:38:18.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:38:18.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:38:18.592+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:38:18.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:38:18.606+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:38:18.606+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:38:18.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-18T09:38:48.991+0000] {processor.py:157} INFO - Started process (PID=4797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:38:48.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:38:48.995+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:38:48.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:38:49.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:38:49.022+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:38:49.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:38:49.033+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:38:49.033+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:38:49.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T09:39:19.460+0000] {processor.py:157} INFO - Started process (PID=4822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:39:19.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:39:19.465+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:39:19.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:39:19.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:39:19.494+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:39:19.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:39:19.505+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:39:19.505+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:39:19.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T09:39:49.855+0000] {processor.py:157} INFO - Started process (PID=4847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:39:49.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:39:49.859+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:39:49.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:39:49.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:39:49.887+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:39:49.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:39:49.897+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:39:49.897+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:39:49.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T09:40:20.243+0000] {processor.py:157} INFO - Started process (PID=4872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:40:20.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:40:20.246+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:40:20.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:40:20.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:40:20.274+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:40:20.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:40:20.285+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:40:20.285+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:40:20.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T09:40:50.634+0000] {processor.py:157} INFO - Started process (PID=4897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:40:50.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:40:50.638+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:40:50.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:40:50.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:40:50.664+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:40:50.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:40:50.674+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:40:50.674+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:40:50.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T09:41:21.088+0000] {processor.py:157} INFO - Started process (PID=4922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:41:21.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:41:21.091+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:41:21.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:41:21.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:41:21.118+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:41:21.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:41:21.130+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:41:21.130+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:41:21.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T09:41:51.553+0000] {processor.py:157} INFO - Started process (PID=4947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:41:51.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:41:51.558+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:41:51.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:41:51.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:41:51.595+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:41:51.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:41:51.606+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:41:51.606+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:41:51.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-18T09:42:22.041+0000] {processor.py:157} INFO - Started process (PID=4972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:42:22.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:42:22.047+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:42:22.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:42:22.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:42:22.087+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:42:22.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:42:22.112+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:42:22.112+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:42:22.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-18T09:42:52.534+0000] {processor.py:157} INFO - Started process (PID=4997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:42:52.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:42:52.537+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:42:52.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:42:52.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:42:52.565+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:42:52.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:42:52.577+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:42:52.577+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:42:52.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T09:43:22.962+0000] {processor.py:157} INFO - Started process (PID=5022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:43:22.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:43:22.965+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:43:22.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:43:22.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:43:22.993+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:43:22.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:43:23.003+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:43:23.003+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:43:23.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T09:43:53.451+0000] {processor.py:157} INFO - Started process (PID=5047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:43:53.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:43:53.455+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:43:53.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:43:53.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:43:53.482+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:43:53.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:43:53.491+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:43:53.491+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:43:53.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T09:44:23.933+0000] {processor.py:157} INFO - Started process (PID=5072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:44:23.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:44:23.936+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:44:23.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:44:23.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:44:23.967+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:44:23.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:44:23.977+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:44:23.977+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:44:23.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T09:44:54.390+0000] {processor.py:157} INFO - Started process (PID=5097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:44:54.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:44:54.394+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:44:54.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:44:54.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:44:54.421+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:44:54.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:44:54.434+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:44:54.433+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:44:54.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T09:45:24.799+0000] {processor.py:157} INFO - Started process (PID=5122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:45:24.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:45:24.802+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:45:24.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:45:24.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:45:24.830+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:45:24.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:45:24.839+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:45:24.839+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:45:24.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T09:45:55.282+0000] {processor.py:157} INFO - Started process (PID=5147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:45:55.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:45:55.285+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:45:55.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:45:55.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:45:55.314+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:45:55.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:45:55.325+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:45:55.325+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:45:55.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T09:46:25.708+0000] {processor.py:157} INFO - Started process (PID=5172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:46:25.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:46:25.711+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:46:25.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:46:25.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:46:25.740+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:46:25.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:46:25.750+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:46:25.749+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:46:25.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T09:46:56.178+0000] {processor.py:157} INFO - Started process (PID=5197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:46:56.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:46:56.182+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:46:56.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:46:56.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:46:56.220+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:46:56.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:46:56.232+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:46:56.232+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:46:56.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-18T09:47:26.666+0000] {processor.py:157} INFO - Started process (PID=5222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:47:26.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:47:26.670+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:47:26.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:47:26.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:47:26.700+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:47:26.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:47:26.709+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:47:26.709+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:47:26.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T09:47:57.097+0000] {processor.py:157} INFO - Started process (PID=5247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:47:57.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:47:57.101+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:47:57.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:47:57.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:47:57.124+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:47:57.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:47:57.133+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:47:57.133+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:47:57.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-18T09:48:27.555+0000] {processor.py:157} INFO - Started process (PID=5272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:48:27.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:48:27.558+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:48:27.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:48:27.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:48:27.587+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:48:27.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:48:27.603+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:48:27.603+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:48:27.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T09:48:57.989+0000] {processor.py:157} INFO - Started process (PID=5297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:48:57.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:48:57.991+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:48:57.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:48:58.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:48:58.014+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:48:58.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:48:58.024+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:48:58.024+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:48:58.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-18T09:49:28.428+0000] {processor.py:157} INFO - Started process (PID=5322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:49:28.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:49:28.432+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:49:28.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:49:28.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:49:28.463+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:49:28.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:49:28.473+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:49:28.472+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:49:28.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T09:49:58.883+0000] {processor.py:157} INFO - Started process (PID=5347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:49:58.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:49:58.886+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:49:58.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:49:58.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:49:58.912+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:49:58.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:49:58.925+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:49:58.925+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:49:58.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T09:50:29.303+0000] {processor.py:157} INFO - Started process (PID=5372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:50:29.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:50:29.308+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:50:29.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:50:29.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:50:29.336+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:50:29.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:50:29.346+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:50:29.346+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:50:29.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T09:50:59.796+0000] {processor.py:157} INFO - Started process (PID=5397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:50:59.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:50:59.799+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:50:59.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:50:59.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:50:59.827+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:50:59.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:50:59.840+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:50:59.840+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:50:59.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T09:51:30.276+0000] {processor.py:157} INFO - Started process (PID=5422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:51:30.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:51:30.279+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:51:30.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:51:30.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:51:30.306+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:51:30.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:51:30.316+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:51:30.316+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:51:30.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T09:52:00.731+0000] {processor.py:157} INFO - Started process (PID=5447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:52:00.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:52:00.734+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:52:00.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:52:00.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:52:00.763+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:52:00.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:52:00.774+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:52:00.774+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:52:00.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T09:52:31.157+0000] {processor.py:157} INFO - Started process (PID=5472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:52:31.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:52:31.159+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:52:31.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:52:31.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:52:31.186+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:52:31.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:52:31.194+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:52:31.194+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:52:31.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-18T09:53:01.653+0000] {processor.py:157} INFO - Started process (PID=5497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:53:01.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:53:01.656+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:53:01.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:53:01.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:53:01.689+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:53:01.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:53:01.701+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:53:01.701+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:53:01.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T09:53:32.165+0000] {processor.py:157} INFO - Started process (PID=5522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:53:32.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:53:32.171+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:53:32.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:53:32.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:53:32.196+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:53:32.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:53:32.205+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:53:32.204+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:53:32.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T09:54:02.585+0000] {processor.py:157} INFO - Started process (PID=5547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:54:02.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:54:02.595+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:54:02.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:54:02.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:54:02.623+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:54:02.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:54:02.634+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:54:02.634+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:54:02.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T09:54:33.056+0000] {processor.py:157} INFO - Started process (PID=5572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:54:33.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:54:33.061+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:54:33.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:54:33.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:54:33.090+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:54:33.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:54:33.101+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:54:33.101+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:54:33.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T09:55:03.462+0000] {processor.py:157} INFO - Started process (PID=5597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:55:03.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:55:03.466+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:55:03.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:55:03.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:55:03.498+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:55:03.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:55:03.507+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:55:03.507+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:55:03.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T09:55:33.951+0000] {processor.py:157} INFO - Started process (PID=5622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:55:33.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:55:33.955+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:55:33.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:55:33.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:55:33.995+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:55:33.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:55:34.007+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:55:34.007+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:55:34.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-18T09:56:04.463+0000] {processor.py:157} INFO - Started process (PID=5647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:56:04.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:56:04.470+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:56:04.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:56:04.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:56:04.550+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:56:04.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:56:04.569+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:56:04.568+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:56:04.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.137 seconds
[2024-07-18T09:56:35.080+0000] {processor.py:157} INFO - Started process (PID=5672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:56:35.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:56:35.085+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:56:35.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:56:35.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:56:35.139+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:56:35.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:56:35.157+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:56:35.157+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:56:35.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.092 seconds
[2024-07-18T09:57:05.562+0000] {processor.py:157} INFO - Started process (PID=5696) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:57:05.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:57:05.579+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:57:05.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:57:05.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:57:05.651+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:57:05.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:57:05.667+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:57:05.667+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:57:05.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.130 seconds
[2024-07-18T09:57:36.112+0000] {processor.py:157} INFO - Started process (PID=5721) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:57:36.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:57:36.128+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:57:36.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:57:36.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:57:36.175+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:57:36.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:57:36.188+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:57:36.188+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:57:36.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-18T09:58:06.598+0000] {processor.py:157} INFO - Started process (PID=5747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:58:06.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:58:06.603+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:58:06.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:58:06.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:58:06.643+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:58:06.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:58:06.656+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:58:06.655+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:58:06.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-18T09:58:37.090+0000] {processor.py:157} INFO - Started process (PID=5772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:58:37.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:58:37.093+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:58:37.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:58:37.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:58:37.124+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:58:37.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:58:37.134+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:58:37.134+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:58:37.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T09:59:07.485+0000] {processor.py:157} INFO - Started process (PID=5797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:59:07.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:59:07.487+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:59:07.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:59:07.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:59:07.515+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:59:07.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:59:07.525+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:59:07.525+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:59:07.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T09:59:37.941+0000] {processor.py:157} INFO - Started process (PID=5822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:59:37.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T09:59:37.945+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:59:37.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:59:37.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T09:59:37.983+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:59:37.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T09:59:37.995+0000] {logging_mixin.py:151} INFO - [2024-07-18T09:59:37.995+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T09:59:38.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-18T10:00:08.380+0000] {processor.py:157} INFO - Started process (PID=5847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:00:08.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:00:08.388+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:00:08.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:00:08.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:00:08.413+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:00:08.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:00:08.425+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:00:08.425+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:00:08.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T10:00:38.759+0000] {processor.py:157} INFO - Started process (PID=5872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:00:38.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:00:38.762+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:00:38.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:00:38.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:00:38.796+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:00:38.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:00:38.808+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:00:38.808+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:00:38.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T10:01:09.249+0000] {processor.py:157} INFO - Started process (PID=5897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:01:09.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:01:09.253+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:01:09.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:01:09.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:01:09.286+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:01:09.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:01:09.297+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:01:09.296+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:01:09.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T10:01:39.698+0000] {processor.py:157} INFO - Started process (PID=5922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:01:39.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:01:39.703+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:01:39.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:01:39.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:01:39.738+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:01:39.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:01:39.751+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:01:39.751+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:01:39.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-18T10:02:10.172+0000] {processor.py:157} INFO - Started process (PID=5947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:02:10.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:02:10.178+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:02:10.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:02:10.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:02:10.200+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:02:10.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:02:10.209+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:02:10.209+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:02:10.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-18T10:02:40.520+0000] {processor.py:157} INFO - Started process (PID=5972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:02:40.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:02:40.522+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:02:40.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:02:40.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:02:40.546+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:02:40.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:02:40.557+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:02:40.556+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:02:40.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-18T10:03:10.964+0000] {processor.py:157} INFO - Started process (PID=5997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:03:10.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:03:10.966+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:03:10.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:03:10.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:03:10.994+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:03:10.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:03:11.006+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:03:11.006+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:03:11.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T10:03:41.383+0000] {processor.py:157} INFO - Started process (PID=6022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:03:41.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:03:41.386+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:03:41.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:03:41.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:03:41.415+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:03:41.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:03:41.428+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:03:41.428+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:03:41.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T10:04:11.823+0000] {processor.py:157} INFO - Started process (PID=6047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:04:11.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:04:11.825+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:04:11.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:04:11.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:04:11.854+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:04:11.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:04:11.867+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:04:11.867+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:04:11.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T10:04:42.284+0000] {processor.py:157} INFO - Started process (PID=6072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:04:42.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:04:42.287+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:04:42.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:04:42.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:04:42.314+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:04:42.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:04:42.324+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:04:42.324+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:04:42.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T10:05:12.708+0000] {processor.py:157} INFO - Started process (PID=6097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:05:12.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:05:12.710+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:05:12.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:05:12.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:05:12.735+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:05:12.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:05:12.745+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:05:12.744+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:05:12.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-18T10:05:43.113+0000] {processor.py:157} INFO - Started process (PID=6122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:05:43.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:05:43.118+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:05:43.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:05:43.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:05:43.179+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:05:43.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:05:43.191+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:05:43.191+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:05:43.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.095 seconds
[2024-07-18T10:06:13.603+0000] {processor.py:157} INFO - Started process (PID=6147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:06:13.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:06:13.606+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:06:13.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:06:13.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:06:13.645+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:06:13.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:06:13.666+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:06:13.666+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:06:13.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-18T10:06:44.122+0000] {processor.py:157} INFO - Started process (PID=6172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:06:44.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:06:44.128+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:06:44.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:06:44.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:06:44.181+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:06:44.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:06:44.195+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:06:44.195+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:06:44.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.096 seconds
[2024-07-18T10:07:14.606+0000] {processor.py:157} INFO - Started process (PID=6197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:07:14.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:07:14.611+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:07:14.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:07:14.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:07:14.651+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:07:14.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:07:14.661+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:07:14.661+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:07:14.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-18T10:07:45.129+0000] {processor.py:157} INFO - Started process (PID=6222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:07:45.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:07:45.137+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:07:45.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:07:45.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:07:45.205+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:07:45.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:07:45.241+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:07:45.241+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:07:45.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.131 seconds
[2024-07-18T10:08:15.658+0000] {processor.py:157} INFO - Started process (PID=6247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:08:15.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:08:15.666+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:08:15.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:08:15.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:08:15.710+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:08:15.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:08:15.724+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:08:15.724+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:08:15.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.083 seconds
[2024-07-18T10:08:46.156+0000] {processor.py:157} INFO - Started process (PID=6272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:08:46.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:08:46.160+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:08:46.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:08:46.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:08:46.188+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:08:46.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:08:46.198+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:08:46.198+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:08:46.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T10:09:16.615+0000] {processor.py:157} INFO - Started process (PID=6297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:09:16.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:09:16.618+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:09:16.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:09:16.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:09:16.647+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:09:16.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:09:16.658+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:09:16.658+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:09:16.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T10:09:46.966+0000] {processor.py:157} INFO - Started process (PID=6322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:09:46.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:09:46.969+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:09:46.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:09:46.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:09:46.992+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:09:46.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:09:47.002+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:09:47.002+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:09:47.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-18T10:10:17.419+0000] {processor.py:157} INFO - Started process (PID=6347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:10:17.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:10:17.422+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:10:17.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:10:17.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:10:17.448+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:10:17.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:10:17.460+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:10:17.460+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:10:17.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T10:10:47.849+0000] {processor.py:157} INFO - Started process (PID=6372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:10:47.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:10:47.852+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:10:47.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:10:47.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:10:47.877+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:10:47.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:10:47.886+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:10:47.886+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:10:47.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-18T10:11:18.270+0000] {processor.py:157} INFO - Started process (PID=6397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:11:18.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:11:18.274+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:11:18.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:11:18.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:11:18.311+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:11:18.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:11:18.324+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:11:18.324+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:11:18.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-18T10:11:48.695+0000] {processor.py:157} INFO - Started process (PID=6422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:11:48.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:11:48.698+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:11:48.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:11:48.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:11:48.727+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:11:48.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:11:48.737+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:11:48.737+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:11:48.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T10:12:19.069+0000] {processor.py:157} INFO - Started process (PID=6447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:12:19.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:12:19.073+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:12:19.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:12:19.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:12:19.102+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:12:19.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:12:19.112+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:12:19.112+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:12:19.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T10:12:49.455+0000] {processor.py:157} INFO - Started process (PID=6472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:12:49.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:12:49.458+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:12:49.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:12:49.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:12:49.485+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:12:49.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:12:49.497+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:12:49.497+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:12:49.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T10:13:19.918+0000] {processor.py:157} INFO - Started process (PID=6497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:13:19.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:13:19.921+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:13:19.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:13:19.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:13:19.950+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:13:19.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:13:19.961+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:13:19.960+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:13:19.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T10:13:50.379+0000] {processor.py:157} INFO - Started process (PID=6522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:13:50.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:13:50.382+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:13:50.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:13:50.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:13:50.411+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:13:50.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:13:50.423+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:13:50.423+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:13:50.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T10:14:20.853+0000] {processor.py:157} INFO - Started process (PID=6547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:14:20.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:14:20.856+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:14:20.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:14:20.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:14:20.884+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:14:20.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:14:20.893+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:14:20.893+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:14:20.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T10:14:51.324+0000] {processor.py:157} INFO - Started process (PID=6572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:14:51.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:14:51.326+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:14:51.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:14:51.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:14:51.351+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:14:51.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:14:51.361+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:14:51.361+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:14:51.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-18T10:15:21.728+0000] {processor.py:157} INFO - Started process (PID=6597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:15:21.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:15:21.729+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:15:21.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:15:21.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:15:21.757+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:15:21.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:15:21.769+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:15:21.769+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:15:21.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T10:15:52.164+0000] {processor.py:157} INFO - Started process (PID=6622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:15:52.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:15:52.166+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:15:52.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:15:52.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:15:52.194+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:15:52.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:15:52.206+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:15:52.206+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:15:52.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T10:16:22.589+0000] {processor.py:157} INFO - Started process (PID=6647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:16:22.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:16:22.592+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:16:22.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:16:22.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:16:22.618+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:16:22.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:16:22.631+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:16:22.630+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:16:22.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T10:16:53.027+0000] {processor.py:157} INFO - Started process (PID=6672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:16:53.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:16:53.031+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:16:53.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:16:53.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:16:53.063+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:16:53.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:16:53.075+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:16:53.075+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:16:53.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T10:17:23.487+0000] {processor.py:157} INFO - Started process (PID=6697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:17:23.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:17:23.491+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:17:23.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:17:23.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:17:23.518+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:17:23.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:17:23.529+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:17:23.529+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:17:23.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T10:17:53.932+0000] {processor.py:157} INFO - Started process (PID=6722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:17:53.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:17:53.934+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:17:53.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:17:53.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:17:53.963+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:17:53.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:17:53.972+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:17:53.972+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:17:53.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T10:18:24.424+0000] {processor.py:157} INFO - Started process (PID=6747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:18:24.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:18:24.426+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:18:24.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:18:24.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:18:24.455+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:18:24.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:18:24.465+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:18:24.465+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:18:24.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T10:18:54.904+0000] {processor.py:157} INFO - Started process (PID=6772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:18:54.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:18:54.906+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:18:54.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:18:54.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:18:54.932+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:18:54.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:18:54.941+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:18:54.941+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:18:54.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T10:19:25.341+0000] {processor.py:157} INFO - Started process (PID=6797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:19:25.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:19:25.344+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:19:25.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:19:25.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:19:25.373+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:19:25.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:19:25.384+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:19:25.384+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:19:25.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T10:19:55.794+0000] {processor.py:157} INFO - Started process (PID=6822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:19:55.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:19:55.803+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:19:55.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:19:55.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:19:55.824+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:19:55.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:19:55.836+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:19:55.836+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:19:55.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T10:20:26.251+0000] {processor.py:157} INFO - Started process (PID=6847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:20:26.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:20:26.254+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:20:26.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:20:26.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:20:26.283+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:20:26.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:20:26.293+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:20:26.293+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:20:26.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T10:20:56.690+0000] {processor.py:157} INFO - Started process (PID=6872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:20:56.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:20:56.695+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:20:56.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:20:56.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:20:56.723+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:20:56.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:20:56.732+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:20:56.732+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:20:56.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T10:21:27.185+0000] {processor.py:157} INFO - Started process (PID=6897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:21:27.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:21:27.192+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:21:27.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:21:27.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:21:27.228+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:21:27.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:21:27.242+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:21:27.242+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:21:27.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-18T10:21:57.608+0000] {processor.py:157} INFO - Started process (PID=6922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:21:57.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:21:57.610+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:21:57.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:21:57.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:21:57.635+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:21:57.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:21:57.646+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:21:57.646+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:21:57.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T10:22:28.062+0000] {processor.py:157} INFO - Started process (PID=6947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:22:28.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:22:28.065+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:22:28.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:22:28.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:22:28.090+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:22:28.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:22:28.099+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:22:28.099+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:22:28.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-18T10:22:58.505+0000] {processor.py:157} INFO - Started process (PID=6972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:22:58.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:22:58.507+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:22:58.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:22:58.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:22:58.535+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:22:58.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:22:58.546+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:22:58.546+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:22:58.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T10:23:28.930+0000] {processor.py:157} INFO - Started process (PID=6997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:23:28.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:23:28.933+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:23:28.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:23:28.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:23:28.960+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:23:28.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:23:28.969+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:23:28.969+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:23:28.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T10:23:59.372+0000] {processor.py:157} INFO - Started process (PID=7022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:23:59.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:23:59.373+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:23:59.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:23:59.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:23:59.398+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:23:59.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:23:59.409+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:23:59.409+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:23:59.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-18T10:24:29.824+0000] {processor.py:157} INFO - Started process (PID=7047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:24:29.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:24:29.827+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:24:29.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:24:29.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:24:29.854+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:24:29.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:24:29.868+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:24:29.868+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:24:29.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T10:25:00.332+0000] {processor.py:157} INFO - Started process (PID=7072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:25:00.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:25:00.334+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:25:00.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:25:00.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:25:00.361+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:25:00.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:25:00.373+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:25:00.373+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:25:00.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T10:25:30.732+0000] {processor.py:157} INFO - Started process (PID=7097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:25:30.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:25:30.740+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:25:30.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:25:30.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:25:30.763+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:25:30.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:25:30.775+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:25:30.775+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:25:30.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T10:26:01.183+0000] {processor.py:157} INFO - Started process (PID=7122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:26:01.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:26:01.185+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:26:01.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:26:01.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:26:01.213+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:26:01.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:26:01.223+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:26:01.223+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:26:01.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T10:26:31.546+0000] {processor.py:157} INFO - Started process (PID=7147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:26:31.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:26:31.548+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:26:31.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:26:31.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:26:31.573+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:26:31.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:26:31.583+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:26:31.583+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:26:31.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-18T10:27:01.999+0000] {processor.py:157} INFO - Started process (PID=7172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:27:02.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:27:02.001+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:27:02.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:27:02.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:27:02.028+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:27:02.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:27:02.038+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:27:02.038+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:27:02.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T10:27:32.491+0000] {processor.py:157} INFO - Started process (PID=7197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:27:32.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:27:32.495+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:27:32.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:27:32.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:27:32.534+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:27:32.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:27:32.545+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:27:32.545+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:27:32.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-18T10:28:02.913+0000] {processor.py:157} INFO - Started process (PID=7222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:28:02.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:28:02.916+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:28:02.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:28:02.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:28:02.943+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:28:02.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:28:02.953+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:28:02.953+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:28:02.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T10:28:33.399+0000] {processor.py:157} INFO - Started process (PID=7247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:28:33.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:28:33.402+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:28:33.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:28:33.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:28:33.430+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:28:33.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:28:33.439+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:28:33.439+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:28:33.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T10:29:03.809+0000] {processor.py:157} INFO - Started process (PID=7272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:29:03.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:29:03.811+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:29:03.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:29:03.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:29:03.839+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:29:03.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:29:03.850+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:29:03.850+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:29:03.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T10:29:34.401+0000] {processor.py:157} INFO - Started process (PID=7297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:29:34.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:29:34.406+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:29:34.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:29:34.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:29:34.451+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:29:34.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:29:34.465+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:29:34.465+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:29:34.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-18T10:30:04.858+0000] {processor.py:157} INFO - Started process (PID=7322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:30:04.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:30:04.863+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:30:04.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:30:04.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:30:04.924+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:30:04.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:30:04.944+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:30:04.944+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:30:04.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-18T10:30:35.434+0000] {processor.py:157} INFO - Started process (PID=7347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:30:35.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:30:35.439+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:30:35.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:30:35.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:30:35.498+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:30:35.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:30:35.518+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:30:35.518+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:30:35.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.103 seconds
[2024-07-18T10:31:05.924+0000] {processor.py:157} INFO - Started process (PID=7372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:31:05.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:31:05.928+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:31:05.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:31:05.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:31:05.962+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:31:05.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:31:05.976+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:31:05.975+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:31:05.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-18T10:31:36.377+0000] {processor.py:157} INFO - Started process (PID=7397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:31:36.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:31:36.383+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:31:36.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:31:36.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:31:36.453+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:31:36.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:31:36.469+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:31:36.469+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:31:36.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.110 seconds
[2024-07-18T10:32:06.982+0000] {processor.py:157} INFO - Started process (PID=7422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:32:06.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:32:06.989+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:32:06.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:32:07.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:32:07.063+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:32:07.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:32:07.082+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:32:07.081+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:32:07.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.116 seconds
[2024-07-18T10:32:37.516+0000] {processor.py:157} INFO - Started process (PID=7447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:32:37.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:32:37.519+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:32:37.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:32:37.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:32:37.553+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:32:37.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:32:37.566+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:32:37.566+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:32:37.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-18T10:33:07.983+0000] {processor.py:157} INFO - Started process (PID=7472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:33:07.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:33:07.989+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:33:07.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:33:08.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:33:08.047+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:33:08.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:33:08.081+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:33:08.081+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:33:08.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.129 seconds
[2024-07-18T10:33:38.462+0000] {processor.py:157} INFO - Started process (PID=7497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:33:38.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:33:38.464+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:33:38.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:33:38.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:33:38.496+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:33:38.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:33:38.509+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:33:38.509+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:33:38.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T10:34:08.998+0000] {processor.py:157} INFO - Started process (PID=7522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:34:08.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:34:09.003+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:34:09.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:34:09.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:34:09.054+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:34:09.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:34:09.071+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:34:09.070+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:34:09.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-18T10:34:39.465+0000] {processor.py:157} INFO - Started process (PID=7547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:34:39.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:34:39.470+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:34:39.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:34:39.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:34:39.516+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:34:39.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:34:39.531+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:34:39.531+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:34:39.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.083 seconds
[2024-07-18T10:35:09.882+0000] {processor.py:157} INFO - Started process (PID=7572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:35:09.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:35:09.885+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:35:09.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:35:09.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:35:09.922+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:35:09.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:35:09.937+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:35:09.937+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:35:09.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-18T10:35:40.420+0000] {processor.py:157} INFO - Started process (PID=7597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:35:40.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:35:40.424+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:35:40.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:35:40.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:35:40.467+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:35:40.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:35:40.482+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:35:40.482+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:35:40.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-18T10:36:11.075+0000] {processor.py:157} INFO - Started process (PID=7622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:36:11.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:36:11.078+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:36:11.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:36:11.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:36:11.128+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:36:11.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:36:11.142+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:36:11.142+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:36:11.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.083 seconds
[2024-07-18T10:36:41.496+0000] {processor.py:157} INFO - Started process (PID=7647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:36:41.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:36:41.499+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:36:41.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:36:41.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:36:41.531+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:36:41.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:36:41.545+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:36:41.545+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:36:41.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T10:37:11.945+0000] {processor.py:157} INFO - Started process (PID=7672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:37:11.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:37:11.949+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:37:11.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:37:11.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:37:11.988+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:37:11.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:37:12.003+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:37:12.003+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:37:12.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-18T10:37:42.479+0000] {processor.py:157} INFO - Started process (PID=7697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:37:42.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:37:42.483+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:37:42.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:37:42.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:37:42.559+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:37:42.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:37:42.576+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:37:42.576+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:37:42.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.111 seconds
[2024-07-18T10:38:13.027+0000] {processor.py:157} INFO - Started process (PID=7722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:38:13.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:38:13.032+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:38:13.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:38:13.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:38:13.088+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:38:13.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:38:13.103+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:38:13.103+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:38:13.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.112 seconds
[2024-07-18T10:38:43.558+0000] {processor.py:157} INFO - Started process (PID=7747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:38:43.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:38:43.564+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:38:43.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:38:43.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:38:43.613+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:38:43.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:38:43.631+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:38:43.630+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:38:43.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.089 seconds
[2024-07-18T10:39:13.978+0000] {processor.py:157} INFO - Started process (PID=7772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:39:13.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:39:13.983+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:39:13.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:39:14.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:39:14.040+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:39:14.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:39:14.058+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:39:14.058+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:39:14.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.097 seconds
[2024-07-18T10:39:44.775+0000] {processor.py:157} INFO - Started process (PID=7797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:39:44.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:39:44.780+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:39:44.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:39:44.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:39:44.840+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:39:44.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:39:44.858+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:39:44.857+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:39:44.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-18T10:40:15.288+0000] {processor.py:157} INFO - Started process (PID=7822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:40:15.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:40:15.292+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:40:15.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:40:15.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:40:15.325+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:40:15.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:40:15.338+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:40:15.338+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:40:15.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-18T10:40:45.681+0000] {processor.py:157} INFO - Started process (PID=7847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:40:45.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:40:45.684+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:40:45.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:40:45.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:40:45.720+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:40:45.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:40:45.735+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:40:45.735+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:40:45.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-18T10:41:16.186+0000] {processor.py:157} INFO - Started process (PID=7871) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:41:16.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:41:16.191+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:41:16.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:41:16.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:41:16.252+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:41:16.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:41:16.277+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:41:16.277+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:41:16.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.114 seconds
[2024-07-18T10:41:46.647+0000] {processor.py:157} INFO - Started process (PID=7897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:41:46.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:41:46.649+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:41:46.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:41:46.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:41:46.686+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:41:46.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:41:46.700+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:41:46.700+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:41:46.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-18T10:42:17.129+0000] {processor.py:157} INFO - Started process (PID=7922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:42:17.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:42:17.131+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:42:17.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:42:17.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:42:17.164+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:42:17.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:42:17.176+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:42:17.176+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:42:17.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T10:42:47.550+0000] {processor.py:157} INFO - Started process (PID=7947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:42:47.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:42:47.554+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:42:47.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:42:47.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:42:47.598+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:42:47.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:42:47.610+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:42:47.610+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:42:47.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-18T10:43:18.028+0000] {processor.py:157} INFO - Started process (PID=7972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:43:18.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:43:18.032+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:43:18.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:43:18.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:43:18.068+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:43:18.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:43:18.085+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:43:18.085+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:43:18.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-18T10:43:48.433+0000] {processor.py:157} INFO - Started process (PID=7997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:43:48.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:43:48.437+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:43:48.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:43:48.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:43:48.472+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:43:48.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:43:48.485+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:43:48.485+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:43:48.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-18T10:44:18.834+0000] {processor.py:157} INFO - Started process (PID=8022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:44:18.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:44:18.843+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:44:18.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:44:18.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:44:18.873+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:44:18.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:44:18.884+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:44:18.884+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:44:18.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T10:44:49.271+0000] {processor.py:157} INFO - Started process (PID=8047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:44:49.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:44:49.274+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:44:49.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:44:49.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:44:49.310+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:44:49.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:44:49.325+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:44:49.325+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:44:49.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-18T10:45:19.751+0000] {processor.py:157} INFO - Started process (PID=8072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:45:19.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:45:19.753+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:45:19.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:45:19.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:45:19.788+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:45:19.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:45:19.800+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:45:19.800+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:45:19.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T10:45:50.241+0000] {processor.py:157} INFO - Started process (PID=8097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:45:50.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:45:50.246+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:45:50.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:45:50.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:45:50.287+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:45:50.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:45:50.298+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:45:50.298+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:45:50.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-18T10:46:20.707+0000] {processor.py:157} INFO - Started process (PID=8122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:46:20.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:46:20.710+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:46:20.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:46:20.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:46:20.749+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:46:20.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:46:20.765+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:46:20.765+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:46:20.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-18T10:46:51.127+0000] {processor.py:157} INFO - Started process (PID=8147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:46:51.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:46:51.129+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:46:51.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:46:51.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:46:51.161+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:46:51.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:46:51.174+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:46:51.174+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:46:51.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T10:47:21.532+0000] {processor.py:157} INFO - Started process (PID=8172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:47:21.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:47:21.535+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:47:21.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:47:21.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:47:21.570+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:47:21.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:47:21.596+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:47:21.596+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:47:21.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-18T10:47:51.952+0000] {processor.py:157} INFO - Started process (PID=8197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:47:51.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:47:51.956+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:47:51.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:47:51.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:47:51.988+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:47:51.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:47:52.000+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:47:52.000+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:47:52.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T10:48:22.408+0000] {processor.py:157} INFO - Started process (PID=8222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:48:22.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:48:22.415+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:48:22.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:48:22.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:48:22.444+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:48:22.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:48:22.454+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:48:22.454+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:48:22.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T10:48:52.796+0000] {processor.py:157} INFO - Started process (PID=8247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:48:52.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:48:52.799+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:48:52.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:48:52.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:48:52.833+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:48:52.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:48:52.845+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:48:52.845+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:48:52.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T10:49:23.196+0000] {processor.py:157} INFO - Started process (PID=8272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:49:23.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:49:23.200+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:49:23.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:49:23.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:49:23.232+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:49:23.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:49:23.245+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:49:23.245+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:49:23.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T10:49:53.661+0000] {processor.py:157} INFO - Started process (PID=8297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:49:53.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:49:53.664+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:49:53.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:49:53.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:49:53.695+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:49:53.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:49:53.706+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:49:53.706+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:49:53.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T10:50:24.100+0000] {processor.py:157} INFO - Started process (PID=8322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:50:24.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:50:24.103+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:50:24.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:50:24.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:50:24.146+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:50:24.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:50:24.161+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:50:24.161+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:50:24.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-18T10:50:54.585+0000] {processor.py:157} INFO - Started process (PID=8347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:50:54.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:50:54.589+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:50:54.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:50:54.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:50:54.632+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:50:54.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:50:54.643+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:50:54.643+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:50:54.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-18T10:51:25.057+0000] {processor.py:157} INFO - Started process (PID=8372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:51:25.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:51:25.059+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:51:25.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:51:25.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:51:25.093+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:51:25.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:51:25.110+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:51:25.110+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:51:25.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-18T10:51:55.488+0000] {processor.py:157} INFO - Started process (PID=8397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:51:55.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:51:55.492+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:51:55.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:51:55.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:51:55.523+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:51:55.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:51:55.535+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:51:55.535+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:51:55.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T10:52:25.931+0000] {processor.py:157} INFO - Started process (PID=8422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:52:25.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:52:25.939+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:52:25.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:52:25.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:52:25.971+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:52:25.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:52:25.982+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:52:25.982+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:52:25.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T10:52:56.374+0000] {processor.py:157} INFO - Started process (PID=8447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:52:56.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:52:56.378+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:52:56.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:52:56.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:52:56.423+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:52:56.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:52:56.438+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:52:56.438+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:52:56.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-18T10:53:26.798+0000] {processor.py:157} INFO - Started process (PID=8472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:53:26.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:53:26.800+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:53:26.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:53:26.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:53:26.826+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:53:26.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:53:26.837+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:53:26.837+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:53:26.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-18T10:53:57.253+0000] {processor.py:157} INFO - Started process (PID=8497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:53:57.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:53:57.257+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:53:57.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:53:57.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:53:57.293+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:53:57.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:53:57.307+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:53:57.306+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:53:57.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-18T10:54:27.670+0000] {processor.py:157} INFO - Started process (PID=8522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:54:27.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:54:27.676+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:54:27.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:54:27.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:54:27.725+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:54:27.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:54:27.741+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:54:27.740+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:54:27.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-18T10:54:58.176+0000] {processor.py:157} INFO - Started process (PID=8547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:54:58.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:54:58.179+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:54:58.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:54:58.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:54:58.214+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:54:58.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:54:58.228+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:54:58.228+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:54:58.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-18T10:55:28.573+0000] {processor.py:157} INFO - Started process (PID=8572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:55:28.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:55:28.578+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:55:28.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:55:28.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:55:28.615+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:55:28.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:55:28.625+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:55:28.625+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:55:28.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-18T10:55:59.039+0000] {processor.py:157} INFO - Started process (PID=8597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:55:59.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:55:59.042+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:55:59.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:55:59.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:55:59.079+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:55:59.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:55:59.096+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:55:59.096+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:55:59.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-18T10:56:29.511+0000] {processor.py:157} INFO - Started process (PID=8622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:56:29.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:56:29.515+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:56:29.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:56:29.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:56:29.549+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:56:29.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:56:29.562+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:56:29.562+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:56:29.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-18T10:56:59.966+0000] {processor.py:157} INFO - Started process (PID=8647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:56:59.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:56:59.969+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:56:59.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:56:59.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:57:00.001+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:57:00.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:57:00.014+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:57:00.014+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:57:00.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T10:57:30.427+0000] {processor.py:157} INFO - Started process (PID=8672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:57:30.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:57:30.430+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:57:30.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:57:30.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:57:30.461+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:57:30.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:57:30.475+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:57:30.475+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:57:30.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T10:58:00.827+0000] {processor.py:157} INFO - Started process (PID=8697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:58:00.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:58:00.829+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:58:00.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:58:00.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:58:00.861+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:58:00.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:58:00.875+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:58:00.875+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:58:00.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T10:58:31.268+0000] {processor.py:157} INFO - Started process (PID=8722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:58:31.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:58:31.271+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:58:31.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:58:31.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:58:31.305+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:58:31.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:58:31.314+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:58:31.314+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:58:31.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T10:59:01.669+0000] {processor.py:157} INFO - Started process (PID=8747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:59:01.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:59:01.677+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:59:01.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:59:01.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:59:01.711+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:59:01.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:59:01.721+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:59:01.721+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:59:01.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-18T10:59:32.073+0000] {processor.py:157} INFO - Started process (PID=8772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:59:32.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T10:59:32.077+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:59:32.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:59:32.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T10:59:32.114+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:59:32.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T10:59:32.124+0000] {logging_mixin.py:151} INFO - [2024-07-18T10:59:32.124+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T10:59:32.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-18T11:00:02.538+0000] {processor.py:157} INFO - Started process (PID=8797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:00:02.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:00:02.543+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:00:02.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:00:02.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:00:02.583+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:00:02.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:00:02.599+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:00:02.599+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:00:02.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-18T11:00:32.954+0000] {processor.py:157} INFO - Started process (PID=8822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:00:32.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:00:32.961+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:00:32.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:00:32.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:00:32.991+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:00:32.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:00:33.002+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:00:33.002+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:00:33.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-18T11:01:03.411+0000] {processor.py:157} INFO - Started process (PID=8847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:01:03.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:01:03.414+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:01:03.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:01:03.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:01:03.447+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:01:03.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:01:03.461+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:01:03.461+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:01:03.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-18T11:01:33.807+0000] {processor.py:157} INFO - Started process (PID=8872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:01:33.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:01:33.809+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:01:33.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:01:33.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:01:33.842+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:01:33.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:01:33.855+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:01:33.855+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:01:33.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T11:02:04.190+0000] {processor.py:157} INFO - Started process (PID=8897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:02:04.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:02:04.193+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:02:04.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:02:04.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:02:04.224+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:02:04.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:02:04.236+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:02:04.236+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:02:04.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T11:02:34.583+0000] {processor.py:157} INFO - Started process (PID=8922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:02:34.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:02:34.586+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:02:34.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:02:34.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:02:34.617+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:02:34.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:02:34.628+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:02:34.628+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:02:34.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T11:03:05.051+0000] {processor.py:157} INFO - Started process (PID=8947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:03:05.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:03:05.056+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:03:05.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:03:05.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:03:05.089+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:03:05.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:03:05.101+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:03:05.101+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:03:05.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-18T11:03:35.558+0000] {processor.py:157} INFO - Started process (PID=8972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:03:35.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:03:35.567+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:03:35.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:03:35.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:03:35.625+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:03:35.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:03:35.642+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:03:35.642+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:03:35.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.101 seconds
[2024-07-18T11:04:05.980+0000] {processor.py:157} INFO - Started process (PID=8997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:04:05.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:04:05.985+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:04:05.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:04:06.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:04:06.019+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:04:06.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:04:06.033+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:04:06.032+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:04:06.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-18T11:04:36.375+0000] {processor.py:157} INFO - Started process (PID=9022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:04:36.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:04:36.380+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:04:36.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:04:36.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:04:36.417+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:04:36.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:04:36.429+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:04:36.429+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:04:36.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-18T11:05:06.881+0000] {processor.py:157} INFO - Started process (PID=9047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:05:06.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:05:06.886+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:05:06.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:05:06.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:05:06.946+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:05:06.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:05:06.969+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:05:06.969+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:05:06.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.115 seconds
[2024-07-18T11:05:37.526+0000] {processor.py:157} INFO - Started process (PID=9072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:05:37.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:05:37.547+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:05:37.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:05:37.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:05:37.674+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:05:37.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:05:37.688+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:05:37.688+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:05:37.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.179 seconds
[2024-07-18T11:06:08.331+0000] {processor.py:157} INFO - Started process (PID=9097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:06:08.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:06:08.336+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:06:08.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:06:08.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:06:08.405+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:06:08.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:06:08.425+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:06:08.425+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:06:08.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.111 seconds
[2024-07-18T11:06:38.910+0000] {processor.py:157} INFO - Started process (PID=9122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:06:38.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:06:38.921+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:06:38.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:06:38.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:06:38.984+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:06:38.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:06:39.008+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:06:39.008+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:06:39.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.125 seconds
[2024-07-18T11:07:09.438+0000] {processor.py:157} INFO - Started process (PID=9147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:07:09.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:07:09.441+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:07:09.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:07:09.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:07:09.475+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:07:09.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:07:09.487+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:07:09.487+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:07:09.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-18T11:07:39.856+0000] {processor.py:157} INFO - Started process (PID=9172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:07:39.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:07:39.863+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:07:39.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:07:39.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:07:39.906+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:07:39.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:07:39.921+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:07:39.921+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:07:39.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-18T11:08:10.290+0000] {processor.py:157} INFO - Started process (PID=9197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:08:10.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:08:10.293+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:08:10.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:08:10.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:08:10.332+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:08:10.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:08:10.346+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:08:10.346+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:08:10.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-18T11:08:40.771+0000] {processor.py:157} INFO - Started process (PID=9222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:08:40.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:08:40.779+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:08:40.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:08:40.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:08:40.853+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:08:40.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:08:40.878+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:08:40.878+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:08:40.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.135 seconds
[2024-07-18T11:09:11.363+0000] {processor.py:157} INFO - Started process (PID=9247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:09:11.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:09:11.385+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:09:11.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:09:11.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:09:11.449+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:09:11.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:09:11.469+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:09:11.468+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:09:11.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.130 seconds
[2024-07-18T11:09:41.961+0000] {processor.py:157} INFO - Started process (PID=9272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:09:41.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:09:41.966+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:09:41.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:09:41.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:09:42.044+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:09:42.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:09:42.062+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:09:42.062+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:09:42.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.127 seconds
[2024-07-18T11:10:12.533+0000] {processor.py:157} INFO - Started process (PID=9297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:10:12.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:10:12.553+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:10:12.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:10:12.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:10:12.614+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:10:12.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:10:12.632+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:10:12.632+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:10:12.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.120 seconds
[2024-07-18T11:10:43.203+0000] {processor.py:157} INFO - Started process (PID=9322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:10:43.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:10:43.210+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:10:43.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:10:43.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:10:43.268+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:10:43.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:10:43.294+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:10:43.294+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:10:43.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-18T11:11:13.730+0000] {processor.py:157} INFO - Started process (PID=9347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:11:13.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:11:13.735+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:11:13.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:11:13.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:11:13.794+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:11:13.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:11:13.828+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:11:13.828+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:11:13.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.120 seconds
[2024-07-18T11:11:44.239+0000] {processor.py:157} INFO - Started process (PID=9372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:11:44.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:11:44.246+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:11:44.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:11:44.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:11:44.314+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:11:44.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:11:44.332+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:11:44.332+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:11:44.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.115 seconds
[2024-07-18T11:12:14.803+0000] {processor.py:157} INFO - Started process (PID=9397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:12:14.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:12:14.814+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:12:14.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:12:14.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:12:14.879+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:12:14.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:12:14.900+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:12:14.899+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:12:14.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.121 seconds
[2024-07-18T11:12:45.345+0000] {processor.py:157} INFO - Started process (PID=9422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:12:45.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:12:45.352+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:12:45.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:12:45.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:12:45.412+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:12:45.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:12:45.431+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:12:45.431+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:12:45.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.108 seconds
[2024-07-18T11:13:15.916+0000] {processor.py:157} INFO - Started process (PID=9447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:13:15.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:13:15.919+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:13:15.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:13:15.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:13:15.954+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:13:15.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:13:15.968+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:13:15.968+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:13:15.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-18T11:13:46.488+0000] {processor.py:157} INFO - Started process (PID=9472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:13:46.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:13:46.509+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:13:46.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:13:46.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:13:46.590+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:13:46.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:13:46.606+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:13:46.606+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:13:46.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.139 seconds
[2024-07-18T11:14:17.143+0000] {processor.py:157} INFO - Started process (PID=9497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:14:17.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:14:17.151+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:14:17.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:14:17.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:14:17.226+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:14:17.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:14:17.245+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:14:17.245+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:14:17.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.136 seconds
[2024-07-18T11:14:47.715+0000] {processor.py:157} INFO - Started process (PID=9522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:14:47.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:14:47.721+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:14:47.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:14:47.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:14:47.780+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:14:47.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:14:47.795+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:14:47.795+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:14:47.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.100 seconds
[2024-07-18T11:15:18.228+0000] {processor.py:157} INFO - Started process (PID=9547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:15:18.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:15:18.237+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:15:18.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:15:18.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:15:18.290+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:15:18.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:15:18.312+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:15:18.312+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:15:18.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.103 seconds
[2024-07-18T11:15:48.839+0000] {processor.py:157} INFO - Started process (PID=9572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:15:48.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:15:48.847+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:15:48.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:15:48.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:15:48.906+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:15:48.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:15:48.925+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:15:48.925+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:15:48.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-18T11:16:19.277+0000] {processor.py:157} INFO - Started process (PID=9596) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:16:19.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:16:19.281+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:16:19.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:16:19.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:16:19.311+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:16:19.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:16:19.324+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:16:19.324+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:16:19.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T11:16:49.817+0000] {processor.py:157} INFO - Started process (PID=9622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:16:49.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:16:49.824+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:16:49.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:16:49.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:16:49.900+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:16:49.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:16:49.922+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:16:49.922+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:16:49.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.127 seconds
[2024-07-18T11:17:20.367+0000] {processor.py:157} INFO - Started process (PID=9647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:17:20.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:17:20.370+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:17:20.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:17:20.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:17:20.410+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:17:20.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:17:20.428+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:17:20.428+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:17:20.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-18T11:17:50.864+0000] {processor.py:157} INFO - Started process (PID=9672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:17:50.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:17:50.872+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:17:50.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:17:50.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:17:50.950+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:17:50.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:17:50.971+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:17:50.971+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:17:50.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.124 seconds
[2024-07-18T11:18:21.402+0000] {processor.py:157} INFO - Started process (PID=9697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:18:21.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:18:21.408+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:18:21.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:18:21.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:18:21.478+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:18:21.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:18:21.503+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:18:21.503+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:18:21.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-18T11:18:52.263+0000] {processor.py:157} INFO - Started process (PID=9722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:18:52.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:18:52.270+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:18:52.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:18:52.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:18:52.341+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:18:52.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:18:52.357+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:18:52.357+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:18:52.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.113 seconds
[2024-07-18T11:19:22.836+0000] {processor.py:157} INFO - Started process (PID=9747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:19:22.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:19:22.844+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:19:22.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:19:22.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:19:22.917+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:19:22.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:19:22.934+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:19:22.934+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:19:22.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.118 seconds
[2024-07-18T11:19:53.428+0000] {processor.py:157} INFO - Started process (PID=9771) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:19:53.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:19:53.434+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:19:53.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:19:53.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:19:53.498+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:19:53.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:19:53.540+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:19:53.540+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:19:53.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.131 seconds
[2024-07-18T11:20:23.972+0000] {processor.py:157} INFO - Started process (PID=9797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:20:23.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:20:23.976+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:20:23.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:20:23.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:20:24.016+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:20:24.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:20:24.029+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:20:24.029+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:20:24.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-18T11:20:54.346+0000] {processor.py:157} INFO - Started process (PID=9822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:20:54.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:20:54.354+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:20:54.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:20:54.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:20:54.377+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:20:54.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:20:54.388+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:20:54.388+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:20:54.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T11:21:24.735+0000] {processor.py:157} INFO - Started process (PID=9847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:21:24.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:21:24.738+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:21:24.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:21:24.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:21:24.773+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:21:24.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:21:24.783+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:21:24.782+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:21:24.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-18T11:21:55.143+0000] {processor.py:157} INFO - Started process (PID=9872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:21:55.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:21:55.148+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:21:55.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:21:55.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:21:55.188+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:21:55.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:21:55.201+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:21:55.201+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:21:55.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-18T11:22:25.568+0000] {processor.py:157} INFO - Started process (PID=9897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:22:25.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:22:25.570+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:22:25.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:22:25.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:22:25.600+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:22:25.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:22:25.613+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:22:25.613+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:22:25.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T11:22:55.968+0000] {processor.py:157} INFO - Started process (PID=9922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:22:55.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:22:55.983+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:22:55.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:22:56.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:22:56.038+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:22:56.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:22:56.055+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:22:56.055+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:22:56.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-18T11:23:26.470+0000] {processor.py:157} INFO - Started process (PID=9947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:23:26.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:23:26.473+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:23:26.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:23:26.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:23:26.506+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:23:26.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:23:26.523+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:23:26.523+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:23:26.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-18T11:23:56.954+0000] {processor.py:157} INFO - Started process (PID=9972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:23:56.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:23:56.959+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:23:56.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:23:56.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:23:57.017+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:23:57.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:23:57.043+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:23:57.043+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:23:57.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-18T11:24:27.457+0000] {processor.py:157} INFO - Started process (PID=9997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:24:27.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:24:27.460+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:24:27.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:24:27.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:24:27.494+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:24:27.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:24:27.508+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:24:27.508+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:24:27.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-18T11:24:57.860+0000] {processor.py:157} INFO - Started process (PID=10022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:24:57.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:24:57.864+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:24:57.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:24:57.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:24:57.908+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:24:57.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:24:57.926+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:24:57.926+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:24:57.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.084 seconds
[2024-07-18T11:25:28.271+0000] {processor.py:157} INFO - Started process (PID=10047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:25:28.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:25:28.276+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:25:28.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:25:28.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:25:28.317+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:25:28.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:25:28.330+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:25:28.330+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:25:28.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-18T11:25:58.686+0000] {processor.py:157} INFO - Started process (PID=10072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:25:58.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:25:58.696+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:25:58.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:25:58.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:25:58.745+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:25:58.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:25:58.772+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:25:58.771+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:25:58.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.108 seconds
[2024-07-18T11:26:29.155+0000] {processor.py:157} INFO - Started process (PID=10097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:26:29.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:26:29.159+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:26:29.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:26:29.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:26:29.204+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:26:29.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:26:29.219+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:26:29.219+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:26:29.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.083 seconds
[2024-07-18T11:26:59.688+0000] {processor.py:157} INFO - Started process (PID=10122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:26:59.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:26:59.696+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:26:59.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:26:59.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:26:59.746+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:26:59.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:26:59.769+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:26:59.769+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:26:59.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.113 seconds
[2024-07-18T11:27:30.234+0000] {processor.py:157} INFO - Started process (PID=10145) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:27:30.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:27:30.241+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:27:30.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:27:30.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:27:30.309+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:27:30.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:27:30.331+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:27:30.331+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:27:30.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.114 seconds
[2024-07-18T11:28:00.790+0000] {processor.py:157} INFO - Started process (PID=10172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:28:00.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:28:00.796+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:28:00.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:28:00.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:28:00.865+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:28:00.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:28:00.881+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:28:00.881+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:28:00.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.112 seconds
[2024-07-18T11:28:31.285+0000] {processor.py:157} INFO - Started process (PID=10197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:28:31.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:28:31.290+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:28:31.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:28:31.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:28:31.343+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:28:31.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:28:31.361+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:28:31.361+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:28:31.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-18T11:29:01.807+0000] {processor.py:157} INFO - Started process (PID=10222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:29:01.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:29:01.812+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:29:01.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:29:01.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:29:01.863+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:29:01.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:29:01.877+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:29:01.877+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:29:01.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-18T11:29:32.270+0000] {processor.py:157} INFO - Started process (PID=10247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:29:32.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:29:32.275+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:29:32.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:29:32.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:29:32.319+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:29:32.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:29:32.335+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:29:32.335+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:29:32.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-18T11:30:02.782+0000] {processor.py:157} INFO - Started process (PID=10272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:30:02.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:30:02.784+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:30:02.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:30:02.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:30:02.829+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:30:02.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:30:02.847+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:30:02.846+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:30:02.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-18T11:30:33.225+0000] {processor.py:157} INFO - Started process (PID=10296) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:30:33.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:30:33.248+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:30:33.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:30:33.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:30:33.307+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:30:33.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:30:33.322+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:30:33.322+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:30:33.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.119 seconds
[2024-07-18T11:31:03.773+0000] {processor.py:157} INFO - Started process (PID=10322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:31:03.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:31:03.781+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:31:03.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:31:03.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:31:03.840+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:31:03.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:31:03.858+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:31:03.858+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:31:03.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.101 seconds
[2024-07-18T11:31:34.301+0000] {processor.py:157} INFO - Started process (PID=10346) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:31:34.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:31:34.307+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:31:34.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:31:34.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:31:34.373+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:31:34.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:31:34.392+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:31:34.392+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:31:34.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.113 seconds
[2024-07-18T11:32:04.787+0000] {processor.py:157} INFO - Started process (PID=10372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:32:04.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:32:04.793+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:32:04.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:32:04.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:32:04.840+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:32:04.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:32:04.855+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:32:04.855+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:32:04.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.084 seconds
[2024-07-18T11:32:35.267+0000] {processor.py:157} INFO - Started process (PID=10397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:32:35.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:32:35.273+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:32:35.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:32:35.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:32:35.323+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:32:35.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:32:35.340+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:32:35.340+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:32:35.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.088 seconds
[2024-07-18T11:33:05.905+0000] {processor.py:157} INFO - Started process (PID=10422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:33:05.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:33:05.912+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:33:05.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:33:05.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:33:05.992+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:33:05.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:33:06.013+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:33:06.013+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:33:06.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-18T11:33:36.455+0000] {processor.py:157} INFO - Started process (PID=10447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:33:36.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:33:36.467+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:33:36.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:33:36.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:33:36.533+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:33:36.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:33:36.551+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:33:36.551+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:33:36.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-18T11:34:07.053+0000] {processor.py:157} INFO - Started process (PID=10472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:34:07.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:34:07.061+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:34:07.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:34:07.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:34:07.167+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:34:07.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:34:07.189+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:34:07.189+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:34:07.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.169 seconds
[2024-07-18T11:34:37.660+0000] {processor.py:157} INFO - Started process (PID=10497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:34:37.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:34:37.666+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:34:37.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:34:37.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:34:37.742+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:34:37.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:34:37.762+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:34:37.762+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:34:37.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.123 seconds
[2024-07-18T11:35:08.311+0000] {processor.py:157} INFO - Started process (PID=10522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:35:08.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:35:08.317+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:35:08.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:35:08.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:35:08.389+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:35:08.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:35:08.406+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:35:08.406+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:35:08.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.113 seconds
[2024-07-18T11:35:38.819+0000] {processor.py:157} INFO - Started process (PID=10547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:35:38.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:35:38.823+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:35:38.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:35:38.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:35:38.856+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:35:38.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:35:38.867+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:35:38.866+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:35:38.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-18T11:36:09.242+0000] {processor.py:157} INFO - Started process (PID=10572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:36:09.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:36:09.246+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:36:09.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:36:09.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:36:09.278+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:36:09.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:36:09.292+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:36:09.292+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:36:09.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T11:36:39.661+0000] {processor.py:157} INFO - Started process (PID=10597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:36:39.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:36:39.666+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:36:39.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:36:39.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:36:39.709+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:36:39.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:36:39.724+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:36:39.724+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:36:39.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-18T11:37:10.082+0000] {processor.py:157} INFO - Started process (PID=10622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:37:10.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:37:10.084+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:37:10.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:37:10.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:37:10.120+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:37:10.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:37:10.131+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:37:10.131+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:37:10.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-18T11:37:40.490+0000] {processor.py:157} INFO - Started process (PID=10647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:37:40.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:37:40.499+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:37:40.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:37:40.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:37:40.532+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:37:40.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:37:40.545+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:37:40.545+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:37:40.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-18T11:38:10.965+0000] {processor.py:157} INFO - Started process (PID=10672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:38:10.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:38:10.970+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:38:10.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:38:10.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:38:11.017+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:38:11.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:38:11.033+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:38:11.033+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:38:11.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.088 seconds
[2024-07-18T11:38:41.484+0000] {processor.py:157} INFO - Started process (PID=10697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:38:41.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:38:41.488+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:38:41.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:38:41.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:38:41.519+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:38:41.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:38:41.530+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:38:41.530+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:38:41.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T11:39:11.934+0000] {processor.py:157} INFO - Started process (PID=10722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:39:11.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:39:11.936+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:39:11.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:39:11.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:39:11.963+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:39:11.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:39:11.974+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:39:11.974+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:39:11.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T11:39:42.378+0000] {processor.py:157} INFO - Started process (PID=10747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:39:42.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:39:42.392+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:39:42.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:39:42.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:39:42.447+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:39:42.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:39:42.467+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:39:42.467+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:39:42.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-18T11:40:12.979+0000] {processor.py:157} INFO - Started process (PID=10772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:40:12.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:40:12.985+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:40:12.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:40:13.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:40:13.056+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:40:13.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:40:13.073+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:40:13.073+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:40:13.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.112 seconds
[2024-07-18T11:40:43.492+0000] {processor.py:157} INFO - Started process (PID=10797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:40:43.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:40:43.494+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:40:43.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:40:43.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:40:43.529+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:40:43.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:40:43.541+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:40:43.541+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:40:43.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-18T11:41:13.931+0000] {processor.py:157} INFO - Started process (PID=10822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:41:13.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:41:13.936+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:41:13.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:41:13.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:41:13.983+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:41:13.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:41:13.996+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:41:13.996+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:41:14.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.083 seconds
[2024-07-18T11:41:44.420+0000] {processor.py:157} INFO - Started process (PID=10847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:41:44.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:41:44.427+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:41:44.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:41:44.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:41:44.497+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:41:44.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:41:44.514+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:41:44.514+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:41:44.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.112 seconds
[2024-07-18T11:42:14.913+0000] {processor.py:157} INFO - Started process (PID=10872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:42:14.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:42:14.917+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:42:14.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:42:14.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:42:14.949+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:42:14.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:42:14.961+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:42:14.961+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:42:14.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T11:42:45.282+0000] {processor.py:157} INFO - Started process (PID=10897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:42:45.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:42:45.285+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:42:45.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:42:45.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:42:45.314+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:42:45.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:42:45.327+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:42:45.326+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:42:45.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T11:43:15.716+0000] {processor.py:157} INFO - Started process (PID=10922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:43:15.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:43:15.720+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:43:15.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:43:15.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:43:15.756+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:43:15.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:43:15.767+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:43:15.767+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:43:15.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-18T11:43:46.164+0000] {processor.py:157} INFO - Started process (PID=10947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:43:46.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:43:46.168+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:43:46.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:43:46.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:43:46.202+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:43:46.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:43:46.213+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:43:46.213+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:43:46.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T11:44:16.568+0000] {processor.py:157} INFO - Started process (PID=10972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:44:16.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:44:16.572+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:44:16.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:44:16.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:44:16.615+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:44:16.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:44:16.630+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:44:16.629+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:44:16.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-18T11:44:46.984+0000] {processor.py:157} INFO - Started process (PID=10997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:44:46.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:44:46.987+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:44:46.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:44:47.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:44:47.024+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:44:47.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:44:47.037+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:44:47.037+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:44:47.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-18T11:45:17.393+0000] {processor.py:157} INFO - Started process (PID=11022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:45:17.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:45:17.396+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:45:17.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:45:17.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:45:17.433+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:45:17.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:45:17.443+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:45:17.443+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:45:17.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T11:45:47.772+0000] {processor.py:157} INFO - Started process (PID=11047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:45:47.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:45:47.777+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:45:47.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:45:47.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:45:47.809+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:45:47.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:45:47.819+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:45:47.819+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:45:47.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T11:46:18.164+0000] {processor.py:157} INFO - Started process (PID=11072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:46:18.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:46:18.166+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:46:18.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:46:18.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:46:18.199+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:46:18.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:46:18.210+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:46:18.210+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:46:18.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T11:46:48.634+0000] {processor.py:157} INFO - Started process (PID=11097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:46:48.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:46:48.637+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:46:48.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:46:48.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:46:48.667+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:46:48.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:46:48.679+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:46:48.678+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:46:48.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T11:47:19.035+0000] {processor.py:157} INFO - Started process (PID=11122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:47:19.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:47:19.039+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:47:19.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:47:19.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:47:19.073+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:47:19.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:47:19.086+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:47:19.086+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:47:19.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-18T11:47:49.430+0000] {processor.py:157} INFO - Started process (PID=11147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:47:49.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:47:49.435+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:47:49.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:47:49.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:47:49.471+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:47:49.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:47:49.481+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:47:49.481+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:47:49.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T11:48:19.900+0000] {processor.py:157} INFO - Started process (PID=11172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:48:19.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:48:19.903+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:48:19.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:48:19.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:48:19.937+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:48:19.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:48:19.949+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:48:19.949+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:48:19.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T11:48:50.278+0000] {processor.py:157} INFO - Started process (PID=11197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:48:50.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:48:50.282+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:48:50.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:48:50.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:48:50.313+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:48:50.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:48:50.325+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:48:50.325+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:48:50.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-18T11:49:20.682+0000] {processor.py:157} INFO - Started process (PID=11222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:49:20.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:49:20.687+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:49:20.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:49:20.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:49:20.724+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:49:20.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:49:20.738+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:49:20.737+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:49:20.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-18T11:49:51.133+0000] {processor.py:157} INFO - Started process (PID=11247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:49:51.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:49:51.137+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:49:51.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:49:51.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:49:51.171+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:49:51.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:49:51.184+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:49:51.184+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:49:51.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-18T11:50:21.540+0000] {processor.py:157} INFO - Started process (PID=11272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:50:21.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:50:21.543+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:50:21.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:50:21.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:50:21.575+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:50:21.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:50:21.589+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:50:21.588+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:50:21.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-18T11:50:52.006+0000] {processor.py:157} INFO - Started process (PID=11297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:50:52.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:50:52.010+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:50:52.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:50:52.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:50:52.047+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:50:52.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:50:52.060+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:50:52.060+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:50:52.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-18T11:51:22.391+0000] {processor.py:157} INFO - Started process (PID=11322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:51:22.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:51:22.395+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:51:22.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:51:22.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:51:22.427+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:51:22.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:51:22.440+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:51:22.439+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:51:22.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T11:51:52.851+0000] {processor.py:157} INFO - Started process (PID=11347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:51:52.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:51:52.857+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:51:52.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:51:52.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:51:52.889+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:51:52.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:51:52.898+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:51:52.898+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:51:52.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T11:52:23.253+0000] {processor.py:157} INFO - Started process (PID=11372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:52:23.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:52:23.257+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:52:23.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:52:23.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:52:23.292+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:52:23.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:52:23.305+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:52:23.305+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:52:23.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-18T11:52:53.690+0000] {processor.py:157} INFO - Started process (PID=11397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:52:53.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:52:53.692+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:52:53.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:52:53.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:52:53.724+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:52:53.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:52:53.735+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:52:53.735+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:52:53.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T11:53:24.098+0000] {processor.py:157} INFO - Started process (PID=11421) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:53:24.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:53:24.100+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:53:24.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:53:24.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:53:24.128+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:53:24.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:53:24.140+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:53:24.140+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:53:24.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T11:53:54.508+0000] {processor.py:157} INFO - Started process (PID=11447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:53:54.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:53:54.515+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:53:54.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:53:54.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:53:54.556+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:53:54.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:53:54.569+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:53:54.568+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:53:54.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-18T11:54:24.976+0000] {processor.py:157} INFO - Started process (PID=11472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:54:24.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:54:24.979+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:54:24.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:54:24.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:54:25.012+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:54:25.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:54:25.026+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:54:25.026+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:54:25.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T11:54:55.410+0000] {processor.py:157} INFO - Started process (PID=11497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:54:55.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:54:55.414+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:54:55.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:54:55.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:54:55.445+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:54:55.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:54:55.456+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:54:55.456+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:54:55.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T11:55:25.871+0000] {processor.py:157} INFO - Started process (PID=11522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:55:25.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:55:25.876+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:55:25.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:55:25.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:55:25.913+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:55:25.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:55:25.926+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:55:25.926+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:55:25.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-18T11:55:56.279+0000] {processor.py:157} INFO - Started process (PID=11547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:55:56.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:55:56.289+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:55:56.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:55:56.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:55:56.321+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:55:56.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:55:56.333+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:55:56.333+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:55:56.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-18T11:56:26.662+0000] {processor.py:157} INFO - Started process (PID=11572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:56:26.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:56:26.666+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:56:26.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:56:26.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:56:26.703+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:56:26.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:56:26.714+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:56:26.714+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:56:26.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-18T11:56:57.140+0000] {processor.py:157} INFO - Started process (PID=11597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:56:57.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:56:57.144+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:56:57.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:56:57.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:56:57.193+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:56:57.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:56:57.209+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:56:57.209+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:56:57.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.085 seconds
[2024-07-18T11:57:27.653+0000] {processor.py:157} INFO - Started process (PID=11622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:57:27.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:57:27.658+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:57:27.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:57:27.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:57:27.711+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:57:27.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:57:27.727+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:57:27.727+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:57:27.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.088 seconds
[2024-07-18T11:57:58.145+0000] {processor.py:157} INFO - Started process (PID=11647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:57:58.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:57:58.150+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:57:58.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:57:58.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:57:58.190+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:57:58.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:57:58.205+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:57:58.205+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:57:58.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-18T11:58:28.586+0000] {processor.py:157} INFO - Started process (PID=11672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:58:28.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:58:28.591+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:58:28.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:58:28.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:58:28.628+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:58:28.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:58:28.641+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:58:28.641+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:58:28.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-18T11:58:59.061+0000] {processor.py:157} INFO - Started process (PID=11696) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:58:59.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:58:59.073+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:58:59.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:58:59.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:58:59.129+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:58:59.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:58:59.146+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:58:59.146+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:58:59.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.107 seconds
[2024-07-18T11:59:29.506+0000] {processor.py:157} INFO - Started process (PID=11722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:59:29.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:59:29.510+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:59:29.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:59:29.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:59:29.553+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:59:29.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T11:59:29.569+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:59:29.569+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T11:59:29.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.092 seconds
[2024-07-18T11:59:59.934+0000] {processor.py:157} INFO - Started process (PID=11747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:59:59.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T11:59:59.938+0000] {logging_mixin.py:151} INFO - [2024-07-18T11:59:59.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T11:59:59.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:00:00.000+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:00:00.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:00:00.014+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:00:00.014+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T12:00:00.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.096 seconds
[2024-07-18T12:00:30.489+0000] {processor.py:157} INFO - Started process (PID=11772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:00:30.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:00:30.493+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:00:30.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:00:30.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:00:30.531+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:00:30.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:00:30.548+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:00:30.548+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T12:00:30.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-18T12:01:00.963+0000] {processor.py:157} INFO - Started process (PID=11797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:01:00.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:01:00.967+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:01:00.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:01:00.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:01:01.005+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:01:01.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:01:01.020+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:01:01.019+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T12:01:01.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-18T12:01:31.426+0000] {processor.py:157} INFO - Started process (PID=11822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:01:31.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:01:31.429+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:01:31.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:01:31.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:01:31.464+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:01:31.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:01:31.478+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:01:31.477+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T12:01:31.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-18T12:02:01.892+0000] {processor.py:157} INFO - Started process (PID=11847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:02:01.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:02:01.897+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:02:01.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:02:01.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:02:01.943+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:02:01.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:02:01.961+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:02:01.961+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T12:02:01.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.084 seconds
[2024-07-18T12:02:32.401+0000] {processor.py:157} INFO - Started process (PID=11872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:02:32.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:02:32.406+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:02:32.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:02:32.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:02:32.451+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:02:32.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:02:32.467+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:02:32.467+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T12:02:32.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-18T12:03:02.885+0000] {processor.py:157} INFO - Started process (PID=11897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:03:02.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:03:02.889+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:03:02.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:03:02.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:03:02.926+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:03:02.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:03:02.940+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:03:02.940+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T12:03:02.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-18T12:03:33.374+0000] {processor.py:157} INFO - Started process (PID=11922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:03:33.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:03:33.377+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:03:33.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:03:33.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:03:33.412+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:03:33.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:03:33.426+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:03:33.426+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T12:03:33.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-18T12:04:03.834+0000] {processor.py:157} INFO - Started process (PID=11947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:04:03.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:04:03.843+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:04:03.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:04:03.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:04:03.904+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:04:03.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:04:03.924+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:04:03.924+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T12:04:03.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.110 seconds
[2024-07-18T12:04:34.275+0000] {processor.py:157} INFO - Started process (PID=11972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:04:34.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:04:34.279+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:04:34.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:04:34.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:04:34.313+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:04:34.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:04:34.329+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:04:34.329+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T12:04:34.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-18T12:05:04.708+0000] {processor.py:157} INFO - Started process (PID=11997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:05:04.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:05:04.715+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:05:04.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:05:04.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:05:04.771+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:05:04.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:05:04.805+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:05:04.805+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T12:05:04.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.125 seconds
[2024-07-18T12:05:35.230+0000] {processor.py:157} INFO - Started process (PID=12022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:05:35.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:05:35.234+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:05:35.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:05:35.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:05:35.267+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:05:35.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:05:35.281+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:05:35.281+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T12:05:35.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-18T12:06:05.651+0000] {processor.py:157} INFO - Started process (PID=12047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:06:05.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:06:05.658+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:06:05.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:06:05.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:06:05.694+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:06:05.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:06:05.711+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:06:05.710+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T12:06:05.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-18T12:06:36.176+0000] {processor.py:157} INFO - Started process (PID=12072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:06:36.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:06:36.182+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:06:36.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:06:36.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:06:36.263+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:06:36.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:06:36.283+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:06:36.283+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T12:06:36.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.124 seconds
[2024-07-18T12:07:06.723+0000] {processor.py:157} INFO - Started process (PID=12097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:07:06.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:07:06.745+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:07:06.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:07:06.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:07:06.798+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:07:06.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:07:06.816+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:07:06.816+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T12:07:06.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.108 seconds
[2024-07-18T12:07:37.233+0000] {processor.py:157} INFO - Started process (PID=12122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:07:37.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:07:37.239+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:07:37.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:07:37.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:07:37.305+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:07:37.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:07:37.323+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:07:37.323+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-17T00:30:00+00:00, run_after=2024-07-18T00:30:00+00:00
[2024-07-18T12:07:37.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-18T12:08:07.725+0000] {processor.py:157} INFO - Started process (PID=12150) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:08:07.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:08:07.732+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:08:07.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:08:07.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:08:07.793+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:08:07.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:08:07.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-18T12:08:38.185+0000] {processor.py:157} INFO - Started process (PID=12175) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:08:38.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:08:38.188+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:08:38.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:08:38.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:08:38.226+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:08:38.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:08:38.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-18T12:09:08.706+0000] {processor.py:157} INFO - Started process (PID=12200) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:09:08.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:09:08.715+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:09:08.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:09:08.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:09:08.773+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:09:08.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:09:08.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.113 seconds
[2024-07-18T12:09:16.017+0000] {processor.py:157} INFO - Started process (PID=12222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:09:16.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:09:16.019+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:09:16.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:09:16.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:09:16.100+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:09:16.100+0000] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:data_pipeline' as access control is unset.
[2024-07-18T12:09:16.100+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:09:16.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:09:16.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.102 seconds
[2024-07-18T12:09:18.057+0000] {processor.py:157} INFO - Started process (PID=12227) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:09:18.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:09:18.061+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:09:18.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:09:18.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:09:18.086+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:09:18.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:09:18.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T12:09:48.825+0000] {processor.py:157} INFO - Started process (PID=12297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:09:48.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:09:48.868+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:09:48.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:09:48.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:09:49.009+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:09:49.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:09:49.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.275 seconds
[2024-07-18T12:10:19.246+0000] {processor.py:157} INFO - Started process (PID=12676) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:10:19.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:10:19.249+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:10:19.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:10:19.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:10:19.275+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:10:19.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:10:19.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T12:10:49.768+0000] {processor.py:157} INFO - Started process (PID=12701) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:10:49.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:10:49.771+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:10:49.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:10:49.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:10:49.796+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:10:49.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:10:49.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-18T12:11:20.349+0000] {processor.py:157} INFO - Started process (PID=12726) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:11:20.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:11:20.354+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:11:20.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:11:20.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:11:20.388+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:11:20.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:11:20.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T12:11:50.885+0000] {processor.py:157} INFO - Started process (PID=12751) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:11:50.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:11:50.889+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:11:50.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:11:50.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:11:50.923+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:11:50.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:11:50.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T12:12:21.288+0000] {processor.py:157} INFO - Started process (PID=13171) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:12:21.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:12:21.292+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:12:21.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:12:21.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:12:21.343+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:12:21.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:12:21.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.083 seconds
[2024-07-18T12:12:51.802+0000] {processor.py:157} INFO - Started process (PID=13198) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:12:51.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:12:51.807+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:12:51.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:12:51.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:12:51.841+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:12:51.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:12:51.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-18T12:13:22.338+0000] {processor.py:157} INFO - Started process (PID=13223) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:13:22.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:13:22.341+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:13:22.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:13:22.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:13:22.373+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:13:22.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:13:22.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T12:13:52.835+0000] {processor.py:157} INFO - Started process (PID=13248) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:13:52.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:13:52.839+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:13:52.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:13:52.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:13:52.872+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:13:52.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:13:52.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-18T12:14:23.249+0000] {processor.py:157} INFO - Started process (PID=13276) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:14:23.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:14:23.254+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:14:23.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:14:23.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:14:23.329+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:14:23.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:14:23.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.115 seconds
[2024-07-18T12:14:53.746+0000] {processor.py:157} INFO - Started process (PID=13699) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:14:53.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:14:53.752+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:14:53.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:14:53.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:14:53.789+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:14:53.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:14:53.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-18T12:15:24.236+0000] {processor.py:157} INFO - Started process (PID=13724) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:15:24.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:15:24.240+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:15:24.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:15:24.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:15:24.273+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:15:24.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:15:24.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T12:15:55.149+0000] {processor.py:157} INFO - Started process (PID=13749) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:15:55.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:15:55.154+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:15:55.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:15:55.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:15:55.201+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:15:55.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:15:55.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-18T12:16:25.542+0000] {processor.py:157} INFO - Started process (PID=13774) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:16:25.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:16:25.546+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:16:25.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:16:25.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:16:25.580+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:16:25.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:16:25.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T12:16:55.966+0000] {processor.py:157} INFO - Started process (PID=13802) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:16:55.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:16:55.968+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:16:55.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:16:55.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:16:56.000+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:16:56.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:16:56.011+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:16:56.011+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:16:56.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T12:17:26.312+0000] {processor.py:157} INFO - Started process (PID=13827) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:17:26.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:17:26.316+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:17:26.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:17:26.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:17:26.349+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:17:26.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:17:26.360+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:17:26.360+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:17:26.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T12:17:56.770+0000] {processor.py:157} INFO - Started process (PID=13852) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:17:56.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:17:56.774+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:17:56.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:17:56.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:17:56.808+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:17:56.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:17:56.820+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:17:56.820+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:17:56.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T12:18:27.200+0000] {processor.py:157} INFO - Started process (PID=13877) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:18:27.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:18:27.204+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:18:27.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:18:27.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:18:27.236+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:18:27.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:18:27.247+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:18:27.247+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:18:27.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T12:18:57.631+0000] {processor.py:157} INFO - Started process (PID=13902) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:18:57.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:18:57.634+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:18:57.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:18:57.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:18:57.667+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:18:57.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:18:57.682+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:18:57.682+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:18:57.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-18T12:19:28.037+0000] {processor.py:157} INFO - Started process (PID=13927) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:19:28.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:19:28.039+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:19:28.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:19:28.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:19:28.072+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:19:28.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:19:28.087+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:19:28.086+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:19:28.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-18T12:19:58.450+0000] {processor.py:157} INFO - Started process (PID=13952) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:19:58.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:19:58.454+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:19:58.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:19:58.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:19:58.486+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:19:58.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:19:58.497+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:19:58.497+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:19:58.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T12:20:28.852+0000] {processor.py:157} INFO - Started process (PID=13977) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:20:28.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:20:28.855+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:20:28.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:20:28.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:20:28.889+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:20:28.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:20:28.900+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:20:28.900+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:20:28.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T12:20:59.295+0000] {processor.py:157} INFO - Started process (PID=14002) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:20:59.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:20:59.299+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:20:59.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:20:59.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:20:59.340+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:20:59.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:20:59.350+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:20:59.349+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:20:59.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-18T12:22:03.161+0000] {processor.py:157} INFO - Started process (PID=14009) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:22:03.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:22:03.166+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:22:03.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:22:03.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:22:03.193+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:22:03.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:22:03.206+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:22:03.206+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:22:03.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T12:22:33.711+0000] {processor.py:157} INFO - Started process (PID=14034) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:22:33.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:22:33.717+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:22:33.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:22:33.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:22:33.751+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:22:33.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:22:33.763+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:22:33.763+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:22:33.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-18T12:23:04.535+0000] {processor.py:157} INFO - Started process (PID=14059) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:23:04.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:23:04.539+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:23:04.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:23:04.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:23:04.567+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:23:04.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:23:04.578+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:23:04.578+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:23:04.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T12:41:06.902+0000] {processor.py:157} INFO - Started process (PID=14084) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:41:06.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:41:06.908+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:41:06.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:41:06.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:41:06.947+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:41:06.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:41:06.961+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:41:06.961+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:41:06.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-18T12:41:37.342+0000] {processor.py:157} INFO - Started process (PID=14109) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:41:37.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:41:37.347+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:41:37.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:41:37.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:41:37.401+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:41:37.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:41:37.418+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:41:37.417+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:41:37.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.091 seconds
[2024-07-18T12:42:07.959+0000] {processor.py:157} INFO - Started process (PID=14134) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:42:07.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:42:07.963+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:42:07.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:42:07.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:42:08.000+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:42:08.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:42:08.012+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:42:08.012+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:42:08.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-18T12:42:38.470+0000] {processor.py:157} INFO - Started process (PID=14159) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:42:38.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:42:38.472+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:42:38.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:42:38.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:42:38.499+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:42:38.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:42:38.511+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:42:38.511+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:42:38.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T12:43:08.928+0000] {processor.py:157} INFO - Started process (PID=14184) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:43:08.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:43:08.932+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:43:08.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:43:08.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:43:08.961+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:43:08.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:43:08.972+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:43:08.972+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:43:08.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T12:43:39.345+0000] {processor.py:157} INFO - Started process (PID=14209) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:43:39.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:43:39.348+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:43:39.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:43:39.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:43:39.377+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:43:39.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:43:39.386+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:43:39.386+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:43:39.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T12:44:09.845+0000] {processor.py:157} INFO - Started process (PID=14234) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:44:09.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:44:09.849+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:44:09.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:44:09.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:44:09.885+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:44:09.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:44:09.898+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:44:09.897+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:44:09.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-18T12:44:40.286+0000] {processor.py:157} INFO - Started process (PID=14259) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:44:40.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:44:40.289+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:44:40.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:44:40.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:44:40.318+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:44:40.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:44:40.327+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:44:40.327+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:44:40.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T12:45:10.712+0000] {processor.py:157} INFO - Started process (PID=14284) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:45:10.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:45:10.717+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:45:10.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:45:10.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:45:10.747+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:45:10.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:45:10.756+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:45:10.756+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:45:10.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T12:45:41.185+0000] {processor.py:157} INFO - Started process (PID=14309) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:45:41.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:45:41.188+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:45:41.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:45:41.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:45:41.220+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:45:41.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:45:41.230+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:45:41.230+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:45:41.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T12:46:11.653+0000] {processor.py:157} INFO - Started process (PID=14334) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:46:11.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:46:11.656+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:46:11.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:46:11.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:46:11.686+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:46:11.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:46:11.695+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:46:11.695+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:46:11.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T12:46:42.186+0000] {processor.py:157} INFO - Started process (PID=14359) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:46:42.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:46:42.189+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:46:42.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:46:42.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:46:42.219+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:46:42.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:46:42.230+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:46:42.229+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:46:42.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T12:47:12.632+0000] {processor.py:157} INFO - Started process (PID=14384) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:47:12.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:47:12.635+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:47:12.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:47:12.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:47:12.664+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:47:12.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:47:12.674+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:47:12.674+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:47:12.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T12:47:43.204+0000] {processor.py:157} INFO - Started process (PID=14409) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:47:43.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:47:43.208+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:47:43.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:47:43.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:47:43.238+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:47:43.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:47:43.248+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:47:43.248+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:47:43.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T12:48:13.664+0000] {processor.py:157} INFO - Started process (PID=14434) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:48:13.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:48:13.666+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:48:13.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:48:13.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:48:13.697+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:48:13.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:48:13.707+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:48:13.706+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:48:13.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T12:48:44.079+0000] {processor.py:157} INFO - Started process (PID=14459) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:48:44.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:48:44.083+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:48:44.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:48:44.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:48:44.117+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:48:44.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:48:44.127+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:48:44.127+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:48:44.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T12:49:14.610+0000] {processor.py:157} INFO - Started process (PID=14484) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:49:14.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:49:14.612+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:49:14.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:49:14.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:49:14.640+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:49:14.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:49:14.651+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:49:14.650+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:49:14.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T12:49:45.049+0000] {processor.py:157} INFO - Started process (PID=14509) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:49:45.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:49:45.056+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:49:45.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:49:45.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:49:45.093+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:49:45.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:49:45.104+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:49:45.104+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:49:45.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-18T12:50:15.493+0000] {processor.py:157} INFO - Started process (PID=14534) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:50:15.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:50:15.498+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:50:15.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:50:15.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:50:15.549+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:50:15.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:50:15.565+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:50:15.565+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:50:15.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-18T12:50:46.035+0000] {processor.py:157} INFO - Started process (PID=14559) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:50:46.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:50:46.045+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:50:46.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:50:46.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:50:46.075+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:50:46.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:50:46.086+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:50:46.086+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:50:46.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-18T12:51:16.484+0000] {processor.py:157} INFO - Started process (PID=14584) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:51:16.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:51:16.487+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:51:16.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:51:16.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:51:16.515+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:51:16.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:51:16.526+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:51:16.526+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:51:16.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T12:51:46.890+0000] {processor.py:157} INFO - Started process (PID=14609) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:51:46.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:51:46.892+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:51:46.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:51:46.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:51:46.921+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:51:46.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:51:46.931+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:51:46.931+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:51:46.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T12:52:17.348+0000] {processor.py:157} INFO - Started process (PID=14634) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:52:17.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:52:17.352+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:52:17.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:52:17.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:52:17.384+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:52:17.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:52:17.393+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:52:17.393+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:52:17.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T12:52:47.861+0000] {processor.py:157} INFO - Started process (PID=14659) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:52:47.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:52:47.865+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:52:47.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:52:47.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:52:47.896+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:52:47.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:52:47.908+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:52:47.908+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:52:47.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T12:53:18.267+0000] {processor.py:157} INFO - Started process (PID=14684) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:53:18.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:53:18.271+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:53:18.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:53:18.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:53:18.298+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:53:18.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:53:18.308+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:53:18.308+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:53:18.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T12:53:48.828+0000] {processor.py:157} INFO - Started process (PID=14709) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:53:48.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:53:48.833+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:53:48.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:53:48.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:53:48.865+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:53:48.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:53:48.876+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:53:48.876+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:53:48.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T12:54:19.371+0000] {processor.py:157} INFO - Started process (PID=14734) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:54:19.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:54:19.376+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:54:19.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:54:19.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:54:19.425+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:54:19.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:54:19.449+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:54:19.449+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:54:19.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.101 seconds
[2024-07-18T12:54:49.875+0000] {processor.py:157} INFO - Started process (PID=14759) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:54:49.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:54:49.878+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:54:49.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:54:49.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:54:49.910+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:54:49.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:54:49.922+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:54:49.922+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:54:49.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T12:55:20.280+0000] {processor.py:157} INFO - Started process (PID=14784) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:55:20.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:55:20.282+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:55:20.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:55:20.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:55:20.310+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:55:20.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:55:20.320+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:55:20.320+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:55:20.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T12:55:50.730+0000] {processor.py:157} INFO - Started process (PID=14809) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:55:50.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:55:50.734+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:55:50.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:55:50.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:55:50.765+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:55:50.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:55:50.774+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:55:50.774+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:55:50.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T12:56:21.134+0000] {processor.py:157} INFO - Started process (PID=14834) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:56:21.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:56:21.138+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:56:21.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:56:21.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:56:21.167+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:56:21.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:56:21.177+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:56:21.176+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:56:21.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T12:56:51.565+0000] {processor.py:157} INFO - Started process (PID=14859) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:56:51.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:56:51.568+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:56:51.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:56:51.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:56:51.594+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:56:51.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:56:51.604+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:56:51.604+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:56:51.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T12:57:22.000+0000] {processor.py:157} INFO - Started process (PID=14884) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:57:22.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:57:22.003+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:57:22.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:57:22.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:57:22.031+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:57:22.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:57:22.041+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:57:22.041+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:57:22.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T12:57:52.391+0000] {processor.py:157} INFO - Started process (PID=14909) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:57:52.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:57:52.395+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:57:52.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:57:52.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:57:52.422+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:57:52.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:57:52.432+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:57:52.432+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:57:52.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T12:58:22.806+0000] {processor.py:157} INFO - Started process (PID=14934) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:58:22.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:58:22.809+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:58:22.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:58:22.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:58:22.840+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:58:22.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:58:22.850+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:58:22.850+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:58:22.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T12:58:53.271+0000] {processor.py:157} INFO - Started process (PID=14959) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:58:53.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:58:53.275+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:58:53.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:58:53.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:58:53.304+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:58:53.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:58:53.315+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:58:53.315+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:58:53.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T12:59:23.713+0000] {processor.py:157} INFO - Started process (PID=14984) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:59:23.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:59:23.716+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:59:23.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:59:23.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:59:23.745+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:59:23.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:59:23.755+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:59:23.755+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:59:23.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T12:59:54.140+0000] {processor.py:157} INFO - Started process (PID=15009) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:59:54.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T12:59:54.143+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:59:54.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:59:54.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T12:59:54.173+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:59:54.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T12:59:54.184+0000] {logging_mixin.py:151} INFO - [2024-07-18T12:59:54.184+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T12:59:54.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T13:00:24.630+0000] {processor.py:157} INFO - Started process (PID=15034) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:00:24.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:00:24.637+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:00:24.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:00:24.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:00:24.679+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:00:24.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:00:24.694+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:00:24.693+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:00:24.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-18T13:00:55.133+0000] {processor.py:157} INFO - Started process (PID=15059) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:00:55.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:00:55.136+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:00:55.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:00:55.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:00:55.165+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:00:55.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:00:55.175+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:00:55.175+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:00:55.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T13:01:25.645+0000] {processor.py:157} INFO - Started process (PID=15084) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:01:25.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:01:25.648+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:01:25.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:01:25.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:01:25.676+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:01:25.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:01:25.688+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:01:25.688+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:01:25.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T13:01:56.101+0000] {processor.py:157} INFO - Started process (PID=15109) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:01:56.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:01:56.104+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:01:56.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:01:56.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:01:56.130+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:01:56.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:01:56.143+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:01:56.143+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:01:56.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T13:02:26.463+0000] {processor.py:157} INFO - Started process (PID=15134) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:02:26.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:02:26.466+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:02:26.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:02:26.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:02:26.493+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:02:26.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:02:26.504+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:02:26.504+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:02:26.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T13:02:56.998+0000] {processor.py:157} INFO - Started process (PID=15159) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:02:56.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:02:57.002+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:02:57.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:02:57.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:02:57.031+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:02:57.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:02:57.043+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:02:57.043+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:02:57.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T13:03:27.396+0000] {processor.py:157} INFO - Started process (PID=15184) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:03:27.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:03:27.399+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:03:27.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:03:27.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:03:27.423+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:03:27.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:03:27.432+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:03:27.432+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:03:27.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-18T13:04:06.299+0000] {processor.py:157} INFO - Started process (PID=15209) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:04:06.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:04:06.302+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:04:06.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:04:06.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:04:06.327+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:04:06.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:04:06.336+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:04:06.336+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:04:06.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-18T13:04:36.761+0000] {processor.py:157} INFO - Started process (PID=15236) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:04:36.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:04:36.764+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:04:36.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:04:36.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:04:36.792+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:04:36.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:04:36.803+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:04:36.803+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:04:36.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T13:12:35.821+0000] {processor.py:157} INFO - Started process (PID=15263) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:12:35.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:12:35.823+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:12:35.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:12:35.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:12:35.852+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:12:35.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:12:35.861+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:12:35.861+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:12:35.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T13:13:06.234+0000] {processor.py:157} INFO - Started process (PID=15288) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:13:06.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:13:06.242+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:13:06.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:13:06.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:13:06.283+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:13:06.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:13:06.295+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:13:06.295+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:13:06.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-18T13:28:36.406+0000] {processor.py:157} INFO - Started process (PID=15315) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:28:36.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:28:36.409+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:28:36.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:28:36.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:28:36.459+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:28:36.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:28:36.471+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:28:36.471+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:28:36.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.091 seconds
[2024-07-18T13:45:19.216+0000] {processor.py:157} INFO - Started process (PID=15340) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:45:19.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:45:19.221+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:45:19.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:45:19.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:45:19.249+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:45:19.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:45:19.260+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:45:19.260+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:45:19.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T13:45:49.689+0000] {processor.py:157} INFO - Started process (PID=15365) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:45:49.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:45:49.695+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:45:49.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:45:49.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:45:49.748+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:45:49.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:45:49.769+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:45:49.768+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:45:49.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.095 seconds
[2024-07-18T13:46:20.155+0000] {processor.py:157} INFO - Started process (PID=15390) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:46:20.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:46:20.159+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:46:20.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:46:20.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:46:20.185+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:46:20.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:46:20.196+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:46:20.196+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:46:20.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T13:46:50.685+0000] {processor.py:157} INFO - Started process (PID=15415) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:46:50.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:46:50.689+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:46:50.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:46:50.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:46:50.716+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:46:50.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:46:50.725+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:46:50.725+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:46:50.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T13:47:21.130+0000] {processor.py:157} INFO - Started process (PID=15440) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:47:21.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:47:21.132+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:47:21.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:47:21.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:47:21.164+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:47:21.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:47:21.174+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:47:21.174+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:47:21.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T13:47:51.542+0000] {processor.py:157} INFO - Started process (PID=15465) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:47:51.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:47:51.545+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:47:51.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:47:51.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:47:51.574+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:47:51.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:47:51.585+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:47:51.584+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:47:51.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T13:48:21.989+0000] {processor.py:157} INFO - Started process (PID=15490) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:48:21.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:48:21.992+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:48:21.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:48:22.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:48:22.021+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:48:22.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:48:22.030+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:48:22.030+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:48:22.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T13:48:52.401+0000] {processor.py:157} INFO - Started process (PID=15515) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:48:52.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:48:52.405+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:48:52.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:48:52.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:48:52.434+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:48:52.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:48:52.443+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:48:52.443+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:48:52.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T13:49:22.848+0000] {processor.py:157} INFO - Started process (PID=15540) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:49:22.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:49:22.853+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:49:22.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:49:22.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:49:22.884+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:49:22.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:49:22.893+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:49:22.893+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:49:22.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T13:49:53.266+0000] {processor.py:157} INFO - Started process (PID=15565) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:49:53.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:49:53.271+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:49:53.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:49:53.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:49:53.310+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:49:53.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:49:53.326+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:49:53.326+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:49:53.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-18T13:50:23.759+0000] {processor.py:157} INFO - Started process (PID=15590) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:50:23.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:50:23.761+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:50:23.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:50:23.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:50:23.789+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:50:23.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:50:23.799+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:50:23.799+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:50:23.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T13:50:54.212+0000] {processor.py:157} INFO - Started process (PID=15615) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:50:54.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:50:54.216+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:50:54.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:50:54.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:50:54.244+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:50:54.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:50:54.254+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:50:54.254+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:50:54.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T13:51:24.595+0000] {processor.py:157} INFO - Started process (PID=15640) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:51:24.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:51:24.598+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:51:24.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:51:24.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:51:24.628+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:51:24.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:51:24.639+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:51:24.639+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:51:24.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T13:51:55.001+0000] {processor.py:157} INFO - Started process (PID=15665) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:51:55.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:51:55.004+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:51:55.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:51:55.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:51:55.033+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:51:55.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:51:55.042+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:51:55.042+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:51:55.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T13:52:25.415+0000] {processor.py:157} INFO - Started process (PID=15690) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:52:25.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:52:25.418+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:52:25.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:52:25.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:52:25.445+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:52:25.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:52:25.455+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:52:25.455+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:52:25.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T13:52:55.842+0000] {processor.py:157} INFO - Started process (PID=15715) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:52:55.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:52:55.847+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:52:55.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:52:55.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:52:55.880+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:52:55.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:52:55.891+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:52:55.891+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:52:55.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-18T13:53:26.278+0000] {processor.py:157} INFO - Started process (PID=15740) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:53:26.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:53:26.284+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:53:26.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:53:26.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:53:26.315+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:53:26.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:53:26.325+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:53:26.325+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:53:26.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T13:53:56.766+0000] {processor.py:157} INFO - Started process (PID=15765) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:53:56.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:53:56.770+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:53:56.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:53:56.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:53:56.798+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:53:56.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:53:56.809+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:53:56.809+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:53:56.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T13:54:27.153+0000] {processor.py:157} INFO - Started process (PID=15790) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:54:27.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:54:27.155+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:54:27.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:54:27.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:54:27.182+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:54:27.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:54:27.192+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:54:27.192+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:54:27.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T13:54:57.537+0000] {processor.py:157} INFO - Started process (PID=15815) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:54:57.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:54:57.539+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:54:57.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:54:57.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:54:57.568+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:54:57.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:54:57.581+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:54:57.581+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:54:57.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T13:55:28.004+0000] {processor.py:157} INFO - Started process (PID=15840) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:55:28.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:55:28.008+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:55:28.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:55:28.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:55:28.037+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:55:28.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:55:28.046+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:55:28.046+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:55:28.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T13:55:58.428+0000] {processor.py:157} INFO - Started process (PID=15865) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:55:58.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:55:58.432+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:55:58.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:55:58.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:55:58.458+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:55:58.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:55:58.468+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:55:58.468+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:55:58.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T13:56:28.856+0000] {processor.py:157} INFO - Started process (PID=15890) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:56:28.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:56:28.860+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:56:28.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:56:28.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:56:28.886+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:56:28.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:56:28.898+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:56:28.898+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:56:28.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T13:56:59.323+0000] {processor.py:157} INFO - Started process (PID=15915) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:56:59.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:56:59.331+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:56:59.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:56:59.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:56:59.368+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:56:59.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:56:59.379+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:56:59.379+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:56:59.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-18T13:57:29.786+0000] {processor.py:157} INFO - Started process (PID=15940) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:57:29.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:57:29.789+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:57:29.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:57:29.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:57:29.816+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:57:29.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:57:29.827+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:57:29.827+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:57:29.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T13:58:00.219+0000] {processor.py:157} INFO - Started process (PID=15965) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:58:00.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:58:00.223+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:58:00.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:58:00.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:58:00.256+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:58:00.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:58:00.268+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:58:00.268+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:58:00.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-18T13:58:30.670+0000] {processor.py:157} INFO - Started process (PID=15990) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:58:30.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:58:30.675+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:58:30.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:58:30.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:58:30.701+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:58:30.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:58:30.710+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:58:30.710+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:58:30.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T13:59:01.108+0000] {processor.py:157} INFO - Started process (PID=16015) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:59:01.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:59:01.112+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:59:01.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:59:01.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:59:01.142+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:59:01.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:59:01.158+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:59:01.157+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:59:01.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T13:59:31.574+0000] {processor.py:157} INFO - Started process (PID=16040) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:59:31.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T13:59:31.577+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:59:31.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:59:31.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T13:59:31.604+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:59:31.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T13:59:31.614+0000] {logging_mixin.py:151} INFO - [2024-07-18T13:59:31.614+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T13:59:31.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T14:00:02.029+0000] {processor.py:157} INFO - Started process (PID=16065) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:00:02.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:00:02.033+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:00:02.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:00:02.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:00:02.060+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:00:02.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:00:02.070+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:00:02.070+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:00:02.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T14:00:32.520+0000] {processor.py:157} INFO - Started process (PID=16090) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:00:32.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:00:32.526+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:00:32.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:00:32.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:00:32.552+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:00:32.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:00:32.561+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:00:32.561+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:00:32.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T14:01:03.050+0000] {processor.py:157} INFO - Started process (PID=16115) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:01:03.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:01:03.053+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:01:03.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:01:03.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:01:03.083+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:01:03.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:01:03.091+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:01:03.091+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:01:03.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T14:01:33.465+0000] {processor.py:157} INFO - Started process (PID=16140) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:01:33.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:01:33.467+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:01:33.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:01:33.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:01:33.495+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:01:33.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:01:33.504+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:01:33.504+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:01:33.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T14:02:03.932+0000] {processor.py:157} INFO - Started process (PID=16165) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:02:03.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:02:03.938+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:02:03.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:02:03.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:02:03.962+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:02:03.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:02:03.973+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:02:03.972+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:02:03.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T14:02:34.390+0000] {processor.py:157} INFO - Started process (PID=16190) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:02:34.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:02:34.394+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:02:34.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:02:34.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:02:34.423+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:02:34.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:02:34.434+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:02:34.434+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:02:34.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T14:03:04.897+0000] {processor.py:157} INFO - Started process (PID=16215) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:03:04.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:03:04.901+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:03:04.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:03:04.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:03:04.929+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:03:04.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:03:04.941+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:03:04.941+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:03:04.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T14:03:35.367+0000] {processor.py:157} INFO - Started process (PID=16240) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:03:35.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:03:35.371+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:03:35.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:03:35.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:03:35.398+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:03:35.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:03:35.411+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:03:35.411+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:03:35.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T14:04:05.797+0000] {processor.py:157} INFO - Started process (PID=16265) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:04:05.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:04:05.802+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:04:05.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:04:05.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:04:05.829+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:04:05.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:04:05.839+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:04:05.839+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:04:05.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T14:04:36.280+0000] {processor.py:157} INFO - Started process (PID=16290) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:04:36.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:04:36.283+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:04:36.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:04:36.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:04:36.311+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:04:36.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:04:36.322+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:04:36.322+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:04:36.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T14:05:06.756+0000] {processor.py:157} INFO - Started process (PID=16315) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:05:06.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:05:06.760+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:05:06.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:05:06.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:05:06.791+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:05:06.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:05:06.801+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:05:06.801+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:05:06.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T14:05:37.188+0000] {processor.py:157} INFO - Started process (PID=16340) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:05:37.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:05:37.190+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:05:37.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:05:37.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:05:37.218+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:05:37.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:05:37.228+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:05:37.228+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:05:37.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T14:06:07.602+0000] {processor.py:157} INFO - Started process (PID=16365) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:06:07.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:06:07.605+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:06:07.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:06:07.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:06:07.632+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:06:07.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:06:07.641+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:06:07.641+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:06:07.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T14:06:38.075+0000] {processor.py:157} INFO - Started process (PID=16390) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:06:38.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:06:38.079+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:06:38.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:06:38.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:06:38.108+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:06:38.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:06:38.118+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:06:38.118+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:06:38.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T14:07:08.531+0000] {processor.py:157} INFO - Started process (PID=16415) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:07:08.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:07:08.534+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:07:08.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:07:08.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:07:08.558+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:07:08.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:07:08.568+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:07:08.568+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:07:08.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T14:07:39.011+0000] {processor.py:157} INFO - Started process (PID=16440) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:07:39.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:07:39.014+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:07:39.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:07:39.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:07:39.039+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:07:39.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:07:39.050+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:07:39.050+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:07:39.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T14:08:09.424+0000] {processor.py:157} INFO - Started process (PID=16465) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:08:09.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:08:09.427+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:08:09.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:08:09.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:08:09.450+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:08:09.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:08:09.459+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:08:09.459+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:08:09.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-18T14:08:39.902+0000] {processor.py:157} INFO - Started process (PID=16490) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:08:39.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:08:39.904+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:08:39.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:08:39.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:08:39.931+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:08:39.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:08:39.941+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:08:39.940+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:08:39.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T14:09:10.443+0000] {processor.py:157} INFO - Started process (PID=16515) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:09:10.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:09:10.447+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:09:10.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:09:10.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:09:10.475+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:09:10.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:09:10.485+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:09:10.485+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:09:10.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T14:09:40.846+0000] {processor.py:157} INFO - Started process (PID=16540) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:09:40.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:09:40.851+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:09:40.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:09:40.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:09:40.890+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:09:40.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:09:40.901+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:09:40.901+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:09:40.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-18T14:10:11.302+0000] {processor.py:157} INFO - Started process (PID=16565) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:10:11.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:10:11.306+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:10:11.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:10:11.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:10:11.334+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:10:11.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:10:11.343+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:10:11.343+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:10:11.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T14:10:41.759+0000] {processor.py:157} INFO - Started process (PID=16590) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:10:41.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:10:41.763+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:10:41.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:10:41.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:10:41.797+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:10:41.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:10:41.807+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:10:41.807+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:10:41.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T14:11:12.223+0000] {processor.py:157} INFO - Started process (PID=16615) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:11:12.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:11:12.229+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:11:12.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:11:12.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:11:12.260+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:11:12.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:11:12.270+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:11:12.269+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:11:12.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T14:11:42.700+0000] {processor.py:157} INFO - Started process (PID=16640) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:11:42.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:11:42.704+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:11:42.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:11:42.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:11:42.733+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:11:42.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:11:42.743+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:11:42.743+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:11:42.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T14:12:13.181+0000] {processor.py:157} INFO - Started process (PID=16665) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:12:13.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:12:13.185+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:12:13.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:12:13.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:12:13.212+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:12:13.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:12:13.221+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:12:13.221+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:12:13.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T14:12:43.609+0000] {processor.py:157} INFO - Started process (PID=16690) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:12:43.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:12:43.611+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:12:43.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:12:43.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:12:43.638+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:12:43.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:12:43.648+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:12:43.648+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:12:43.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T14:13:13.971+0000] {processor.py:157} INFO - Started process (PID=16715) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:13:13.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:13:13.975+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:13:13.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:13:13.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:13:14.002+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:13:14.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:13:14.013+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:13:14.013+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:13:14.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T14:13:44.445+0000] {processor.py:157} INFO - Started process (PID=16740) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:13:44.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:13:44.448+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:13:44.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:13:44.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:13:44.481+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:13:44.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:13:44.492+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:13:44.492+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:13:44.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T14:14:14.926+0000] {processor.py:157} INFO - Started process (PID=16765) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:14:14.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:14:14.928+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:14:14.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:14:14.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:14:14.953+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:14:14.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:14:14.964+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:14:14.964+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:14:14.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-18T14:14:45.442+0000] {processor.py:157} INFO - Started process (PID=16790) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:14:45.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:14:45.447+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:14:45.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:14:45.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:14:45.474+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:14:45.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:14:45.485+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:14:45.485+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:14:45.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T14:15:15.942+0000] {processor.py:157} INFO - Started process (PID=16815) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:15:15.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:15:15.945+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:15:15.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:15:15.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:15:15.974+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:15:15.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:15:15.987+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:15:15.987+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:15:15.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T14:15:46.459+0000] {processor.py:157} INFO - Started process (PID=16840) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:15:46.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:15:46.463+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:15:46.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:15:46.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:15:46.491+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:15:46.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:15:46.501+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:15:46.501+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:15:46.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T14:16:16.885+0000] {processor.py:157} INFO - Started process (PID=16865) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:16:16.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:16:16.891+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:16:16.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:16:16.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:16:16.916+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:16:16.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:16:16.930+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:16:16.930+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:16:16.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T14:16:47.367+0000] {processor.py:157} INFO - Started process (PID=16890) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:16:47.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:16:47.373+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:16:47.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:16:47.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:16:47.416+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:16:47.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:16:47.427+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:16:47.427+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:16:47.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-18T14:17:17.871+0000] {processor.py:157} INFO - Started process (PID=16915) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:17:17.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:17:17.876+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:17:17.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:17:17.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:17:17.907+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:17:17.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:17:17.921+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:17:17.921+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:17:17.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T14:17:48.300+0000] {processor.py:157} INFO - Started process (PID=16940) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:17:48.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:17:48.304+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:17:48.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:17:48.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:17:48.333+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:17:48.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:17:48.345+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:17:48.345+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:17:48.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T14:18:18.712+0000] {processor.py:157} INFO - Started process (PID=16965) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:18:18.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:18:18.716+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:18:18.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:18:18.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:18:18.745+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:18:18.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:18:18.755+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:18:18.754+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:18:18.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T14:18:49.157+0000] {processor.py:157} INFO - Started process (PID=16990) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:18:49.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:18:49.161+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:18:49.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:18:49.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:18:49.189+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:18:49.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:18:49.201+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:18:49.201+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:18:49.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T14:19:19.617+0000] {processor.py:157} INFO - Started process (PID=17015) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:19:19.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:19:19.622+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:19:19.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:19:19.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:19:19.652+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:19:19.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:19:19.664+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:19:19.664+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:19:19.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T14:19:50.067+0000] {processor.py:157} INFO - Started process (PID=17040) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:19:50.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:19:50.070+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:19:50.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:19:50.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:19:50.098+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:19:50.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:19:50.107+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:19:50.107+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:19:50.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T14:20:20.534+0000] {processor.py:157} INFO - Started process (PID=17065) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:20:20.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:20:20.537+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:20:20.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:20:20.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:20:20.564+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:20:20.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:20:20.574+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:20:20.574+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:20:20.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T14:20:50.972+0000] {processor.py:157} INFO - Started process (PID=17090) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:20:50.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:20:50.976+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:20:50.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:20:50.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:20:51.006+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:20:51.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:20:51.017+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:20:51.016+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:20:51.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T14:21:21.464+0000] {processor.py:157} INFO - Started process (PID=17115) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:21:21.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:21:21.467+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:21:21.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:21:21.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:21:21.497+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:21:21.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:21:21.509+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:21:21.509+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:21:21.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T14:21:51.882+0000] {processor.py:157} INFO - Started process (PID=17140) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:21:51.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:21:51.884+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:21:51.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:21:51.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:21:51.911+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:21:51.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:21:51.922+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:21:51.922+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:21:51.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T14:22:22.352+0000] {processor.py:157} INFO - Started process (PID=17165) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:22:22.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:22:22.356+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:22:22.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:22:22.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:22:22.387+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:22:22.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:22:22.398+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:22:22.398+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:22:22.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T14:22:52.830+0000] {processor.py:157} INFO - Started process (PID=17190) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:22:52.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:22:52.835+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:22:52.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:22:52.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:22:52.862+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:22:52.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:22:52.873+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:22:52.873+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:22:52.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T14:23:23.207+0000] {processor.py:157} INFO - Started process (PID=17215) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:23:23.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:23:23.210+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:23:23.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:23:23.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:23:23.237+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:23:23.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:23:23.247+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:23:23.247+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:23:23.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T14:23:53.660+0000] {processor.py:157} INFO - Started process (PID=17240) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:23:53.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:23:53.662+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:23:53.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:23:53.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:23:53.686+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:23:53.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:23:53.699+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:23:53.699+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:23:53.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T14:24:24.138+0000] {processor.py:157} INFO - Started process (PID=17265) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:24:24.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:24:24.142+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:24:24.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:24:24.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:24:24.170+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:24:24.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:24:24.179+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:24:24.179+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:24:24.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T14:24:54.552+0000] {processor.py:157} INFO - Started process (PID=17290) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:24:54.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:24:54.556+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:24:54.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:24:54.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:24:54.585+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:24:54.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:24:54.595+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:24:54.595+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:24:54.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T14:25:25.050+0000] {processor.py:157} INFO - Started process (PID=17315) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:25:25.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:25:25.054+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:25:25.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:25:25.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:25:25.081+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:25:25.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:25:25.090+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:25:25.090+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:25:25.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T14:25:55.459+0000] {processor.py:157} INFO - Started process (PID=17340) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:25:55.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:25:55.463+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:25:55.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:25:55.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:25:55.492+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:25:55.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:25:55.502+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:25:55.502+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:25:55.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T14:26:25.857+0000] {processor.py:157} INFO - Started process (PID=17365) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:26:25.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:26:25.860+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:26:25.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:26:25.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:26:25.889+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:26:25.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:26:25.902+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:26:25.901+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:26:25.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T14:26:56.270+0000] {processor.py:157} INFO - Started process (PID=17390) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:26:56.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:26:56.273+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:26:56.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:26:56.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:26:56.302+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:26:56.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:26:56.312+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:26:56.312+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:26:56.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T14:27:26.671+0000] {processor.py:157} INFO - Started process (PID=17415) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:27:26.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:27:26.674+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:27:26.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:27:26.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:27:26.703+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:27:26.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:27:26.715+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:27:26.715+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:27:26.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T14:27:57.135+0000] {processor.py:157} INFO - Started process (PID=17440) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:27:57.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:27:57.139+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:27:57.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:27:57.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:27:57.167+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:27:57.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:27:57.180+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:27:57.180+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:27:57.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T14:28:27.587+0000] {processor.py:157} INFO - Started process (PID=17465) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:28:27.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:28:27.590+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:28:27.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:28:27.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:28:27.611+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:28:27.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:28:27.620+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:28:27.620+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:28:27.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-18T14:28:57.989+0000] {processor.py:157} INFO - Started process (PID=17490) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:28:57.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:28:57.991+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:28:57.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:28:58.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:28:58.016+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:28:58.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:28:58.025+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:28:58.025+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:28:58.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-18T14:29:28.427+0000] {processor.py:157} INFO - Started process (PID=17515) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:29:28.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:29:28.430+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:29:28.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:29:28.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:29:28.457+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:29:28.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:29:28.469+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:29:28.469+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:29:28.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T14:29:58.822+0000] {processor.py:157} INFO - Started process (PID=17540) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:29:58.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:29:58.826+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:29:58.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:29:58.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:29:58.858+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:29:58.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:29:58.869+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:29:58.869+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:29:58.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T14:30:29.329+0000] {processor.py:157} INFO - Started process (PID=17565) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:30:29.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:30:29.332+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:30:29.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:30:29.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:30:29.360+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:30:29.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:30:29.370+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:30:29.369+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:30:29.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T14:30:59.792+0000] {processor.py:157} INFO - Started process (PID=17590) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:30:59.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:30:59.795+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:30:59.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:30:59.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:30:59.824+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:30:59.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:30:59.834+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:30:59.834+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:30:59.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T14:31:30.232+0000] {processor.py:157} INFO - Started process (PID=17615) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:31:30.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:31:30.236+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:31:30.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:31:30.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:31:30.261+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:31:30.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:31:30.271+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:31:30.271+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:31:30.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T14:32:00.559+0000] {processor.py:157} INFO - Started process (PID=17640) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:32:00.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:32:00.567+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:32:00.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:32:00.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:32:00.604+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:32:00.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:32:00.616+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:32:00.615+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:32:00.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-18T14:32:31.009+0000] {processor.py:157} INFO - Started process (PID=17665) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:32:31.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:32:31.013+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:32:31.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:32:31.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:32:31.040+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:32:31.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:32:31.050+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:32:31.049+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:32:31.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T14:33:01.471+0000] {processor.py:157} INFO - Started process (PID=17690) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:33:01.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:33:01.474+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:33:01.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:33:01.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:33:01.501+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:33:01.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:33:01.511+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:33:01.511+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:33:01.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T14:33:31.851+0000] {processor.py:157} INFO - Started process (PID=17715) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:33:31.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:33:31.855+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:33:31.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:33:31.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:33:31.885+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:33:31.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:33:31.894+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:33:31.894+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:33:31.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T14:34:02.310+0000] {processor.py:157} INFO - Started process (PID=17740) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:34:02.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:34:02.313+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:34:02.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:34:02.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:34:02.339+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:34:02.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:34:02.349+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:34:02.349+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:34:02.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T14:34:32.715+0000] {processor.py:157} INFO - Started process (PID=17765) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:34:32.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:34:32.719+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:34:32.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:34:32.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:34:32.748+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:34:32.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:34:32.757+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:34:32.757+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:34:32.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T14:35:03.168+0000] {processor.py:157} INFO - Started process (PID=17790) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:35:03.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:35:03.171+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:35:03.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:35:03.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:35:03.204+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:35:03.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:35:03.214+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:35:03.214+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:35:03.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T14:35:33.620+0000] {processor.py:157} INFO - Started process (PID=17815) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:35:33.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:35:33.623+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:35:33.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:35:33.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:35:33.649+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:35:33.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:35:33.659+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:35:33.659+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:35:33.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T14:36:04.095+0000] {processor.py:157} INFO - Started process (PID=17840) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:36:04.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:36:04.099+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:36:04.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:36:04.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:36:04.127+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:36:04.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:36:04.137+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:36:04.137+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:36:04.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T14:36:34.566+0000] {processor.py:157} INFO - Started process (PID=17865) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:36:34.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:36:34.570+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:36:34.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:36:34.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:36:34.595+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:36:34.595+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:36:34.604+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:36:34.604+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:36:34.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T14:37:04.994+0000] {processor.py:157} INFO - Started process (PID=17890) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:37:04.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:37:04.998+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:37:04.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:37:05.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:37:05.023+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:37:05.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:37:05.035+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:37:05.035+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:37:05.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T14:37:35.391+0000] {processor.py:157} INFO - Started process (PID=17915) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:37:35.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:37:35.394+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:37:35.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:37:35.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:37:35.424+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:37:35.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:37:35.433+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:37:35.433+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:37:35.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T14:38:05.868+0000] {processor.py:157} INFO - Started process (PID=17940) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:38:05.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:38:05.872+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:38:05.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:38:05.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:38:05.902+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:38:05.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:38:05.913+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:38:05.912+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:38:05.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T14:38:36.322+0000] {processor.py:157} INFO - Started process (PID=17965) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:38:36.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:38:36.325+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:38:36.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:38:36.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:38:36.356+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:38:36.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:38:36.367+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:38:36.367+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:38:36.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T14:39:06.780+0000] {processor.py:157} INFO - Started process (PID=17990) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:39:06.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:39:06.784+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:39:06.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:39:06.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:39:06.812+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:39:06.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:39:06.825+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:39:06.825+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:39:06.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T14:39:37.258+0000] {processor.py:157} INFO - Started process (PID=18015) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:39:37.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:39:37.263+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:39:37.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:39:37.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:39:37.289+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:39:37.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:39:37.299+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:39:37.299+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:39:37.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T14:40:07.729+0000] {processor.py:157} INFO - Started process (PID=18040) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:40:07.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:40:07.733+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:40:07.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:40:07.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:40:07.760+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:40:07.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:40:07.770+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:40:07.770+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:40:07.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T14:40:38.151+0000] {processor.py:157} INFO - Started process (PID=18065) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:40:38.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:40:38.155+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:40:38.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:40:38.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:40:38.187+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:40:38.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:40:38.196+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:40:38.196+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:40:38.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T14:41:08.667+0000] {processor.py:157} INFO - Started process (PID=18090) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:41:08.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:41:08.669+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:41:08.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:41:08.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:41:08.698+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:41:08.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:41:08.708+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:41:08.708+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:41:08.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T14:41:39.076+0000] {processor.py:157} INFO - Started process (PID=18115) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:41:39.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:41:39.078+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:41:39.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:41:39.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:41:39.109+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:41:39.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:41:39.119+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:41:39.119+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:41:39.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T14:42:09.499+0000] {processor.py:157} INFO - Started process (PID=18140) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:42:09.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:42:09.502+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:42:09.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:42:09.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:42:09.527+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:42:09.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:42:09.538+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:42:09.538+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:42:09.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T14:42:39.938+0000] {processor.py:157} INFO - Started process (PID=18165) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:42:39.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:42:39.941+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:42:39.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:42:39.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:42:39.968+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:42:39.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:42:39.981+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:42:39.980+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:42:39.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T14:43:10.269+0000] {processor.py:157} INFO - Started process (PID=18190) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:43:10.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:43:10.273+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:43:10.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:43:10.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:43:10.296+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:43:10.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:43:10.306+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:43:10.306+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:43:10.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-18T14:43:40.728+0000] {processor.py:157} INFO - Started process (PID=18215) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:43:40.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:43:40.733+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:43:40.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:43:40.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:43:40.758+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:43:40.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:43:40.769+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:43:40.769+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:43:40.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T14:44:11.172+0000] {processor.py:157} INFO - Started process (PID=18240) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:44:11.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:44:11.175+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:44:11.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:44:11.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:44:11.196+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:44:11.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:44:11.206+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:44:11.206+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:44:11.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-18T14:44:41.576+0000] {processor.py:157} INFO - Started process (PID=18265) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:44:41.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:44:41.580+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:44:41.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:44:41.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:44:41.608+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:44:41.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:44:41.618+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:44:41.618+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:44:41.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T14:45:12.055+0000] {processor.py:157} INFO - Started process (PID=18290) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:45:12.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:45:12.059+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:45:12.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:45:12.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:45:12.087+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:45:12.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:45:12.098+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:45:12.097+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:45:12.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T14:45:42.445+0000] {processor.py:157} INFO - Started process (PID=18315) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:45:42.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:45:42.449+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:45:42.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:45:42.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:45:42.477+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:45:42.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:45:42.487+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:45:42.487+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:45:42.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T14:46:12.942+0000] {processor.py:157} INFO - Started process (PID=18340) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:46:12.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:46:12.945+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:46:12.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:46:12.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:46:12.976+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:46:12.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:46:12.986+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:46:12.985+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:46:12.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T14:46:43.339+0000] {processor.py:157} INFO - Started process (PID=18365) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:46:43.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:46:43.342+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:46:43.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:46:43.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:46:43.372+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:46:43.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:46:43.384+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:46:43.384+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:46:43.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T14:47:13.975+0000] {processor.py:157} INFO - Started process (PID=18390) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:47:13.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:47:13.978+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:47:13.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:47:13.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:47:14.007+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:47:14.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:47:14.018+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:47:14.018+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:47:14.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T14:47:44.498+0000] {processor.py:157} INFO - Started process (PID=18415) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:47:44.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:47:44.501+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:47:44.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:47:44.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:47:44.529+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:47:44.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:47:44.538+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:47:44.538+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:47:44.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T14:48:14.926+0000] {processor.py:157} INFO - Started process (PID=18440) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:48:14.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:48:14.929+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:48:14.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:48:14.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:48:14.954+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:48:14.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:48:14.966+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:48:14.966+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:48:14.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T14:48:45.380+0000] {processor.py:157} INFO - Started process (PID=18465) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:48:45.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:48:45.387+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:48:45.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:48:45.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:48:45.424+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:48:45.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:48:45.434+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:48:45.433+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:48:45.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-18T14:49:15.845+0000] {processor.py:157} INFO - Started process (PID=18490) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:49:15.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:49:15.849+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:49:15.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:49:15.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:49:15.879+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:49:15.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:49:15.893+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:49:15.893+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:49:15.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T14:49:46.260+0000] {processor.py:157} INFO - Started process (PID=18515) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:49:46.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:49:46.263+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:49:46.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:49:46.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:49:46.292+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:49:46.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:49:46.301+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:49:46.301+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:49:46.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T14:50:16.705+0000] {processor.py:157} INFO - Started process (PID=18540) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:50:16.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:50:16.707+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:50:16.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:50:16.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:50:16.729+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:50:16.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:50:16.741+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:50:16.741+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:50:16.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-18T14:50:47.144+0000] {processor.py:157} INFO - Started process (PID=18565) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:50:47.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:50:47.148+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:50:47.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:50:47.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:50:47.177+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:50:47.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:50:47.187+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:50:47.187+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:50:47.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T14:51:17.583+0000] {processor.py:157} INFO - Started process (PID=18590) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:51:17.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:51:17.586+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:51:17.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:51:17.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:51:17.612+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:51:17.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:51:17.621+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:51:17.621+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:51:17.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T14:51:48.082+0000] {processor.py:157} INFO - Started process (PID=18615) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:51:48.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:51:48.085+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:51:48.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:51:48.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:51:48.113+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:51:48.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:51:48.122+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:51:48.122+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:51:48.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T14:52:18.531+0000] {processor.py:157} INFO - Started process (PID=18640) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:52:18.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:52:18.534+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:52:18.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:52:18.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:52:18.563+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:52:18.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:52:18.573+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:52:18.573+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:52:18.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T14:52:48.946+0000] {processor.py:157} INFO - Started process (PID=18665) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:52:48.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:52:48.949+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:52:48.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:52:48.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:52:48.978+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:52:48.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:52:48.990+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:52:48.990+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:52:49.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T14:53:19.382+0000] {processor.py:157} INFO - Started process (PID=18690) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:53:19.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:53:19.389+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:53:19.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:53:19.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:53:19.418+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:53:19.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:53:19.431+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:53:19.430+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:53:19.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T14:53:49.832+0000] {processor.py:157} INFO - Started process (PID=18715) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:53:49.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:53:49.835+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:53:49.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:53:49.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:53:49.863+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:53:49.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:53:49.875+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:53:49.875+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:53:49.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T14:54:20.233+0000] {processor.py:157} INFO - Started process (PID=18740) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:54:20.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:54:20.235+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:54:20.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:54:20.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:54:20.262+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:54:20.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:54:20.271+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:54:20.271+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:54:20.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T14:54:50.730+0000] {processor.py:157} INFO - Started process (PID=18765) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:54:50.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:54:50.734+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:54:50.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:54:50.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:54:50.764+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:54:50.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:54:50.776+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:54:50.776+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:54:50.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T14:55:21.151+0000] {processor.py:157} INFO - Started process (PID=18790) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:55:21.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:55:21.154+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:55:21.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:55:21.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:55:21.181+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:55:21.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:55:21.191+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:55:21.191+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:55:21.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T14:55:51.589+0000] {processor.py:157} INFO - Started process (PID=18815) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:55:51.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:55:51.593+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:55:51.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:55:51.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:55:51.620+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:55:51.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:55:51.630+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:55:51.630+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:55:51.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T14:56:22.069+0000] {processor.py:157} INFO - Started process (PID=18840) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:56:22.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:56:22.073+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:56:22.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:56:22.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:56:22.104+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:56:22.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:56:22.115+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:56:22.115+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:56:22.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T14:56:52.454+0000] {processor.py:157} INFO - Started process (PID=18865) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:56:52.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:56:52.457+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:56:52.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:56:52.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:56:52.484+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:56:52.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:56:52.494+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:56:52.494+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:56:52.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T14:57:22.917+0000] {processor.py:157} INFO - Started process (PID=18890) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:57:22.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:57:22.920+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:57:22.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:57:22.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:57:22.946+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:57:22.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:57:22.961+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:57:22.961+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:57:22.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T14:57:53.393+0000] {processor.py:157} INFO - Started process (PID=18915) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:57:53.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:57:53.396+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:57:53.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:57:53.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:57:53.425+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:57:53.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:57:53.434+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:57:53.434+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:57:53.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T14:58:23.823+0000] {processor.py:157} INFO - Started process (PID=18940) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:58:23.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:58:23.827+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:58:23.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:58:23.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:58:23.857+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:58:23.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:58:23.869+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:58:23.869+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:58:23.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T14:58:54.313+0000] {processor.py:157} INFO - Started process (PID=18965) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:58:54.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:58:54.316+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:58:54.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:58:54.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:58:54.344+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:58:54.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:58:54.354+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:58:54.354+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:58:54.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T14:59:24.751+0000] {processor.py:157} INFO - Started process (PID=18990) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:59:24.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:59:24.755+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:59:24.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:59:24.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:59:24.783+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:59:24.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:59:24.794+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:59:24.794+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:59:24.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T14:59:55.176+0000] {processor.py:157} INFO - Started process (PID=19015) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:59:55.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T14:59:55.179+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:59:55.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:59:55.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T14:59:55.207+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:59:55.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T14:59:55.217+0000] {logging_mixin.py:151} INFO - [2024-07-18T14:59:55.217+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T14:59:55.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T15:00:25.665+0000] {processor.py:157} INFO - Started process (PID=19040) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:00:25.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:00:25.671+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:00:25.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:00:25.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:00:25.703+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:00:25.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:00:25.715+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:00:25.714+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:00:25.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-18T15:00:56.129+0000] {processor.py:157} INFO - Started process (PID=19065) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:00:56.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:00:56.134+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:00:56.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:00:56.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:00:56.164+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:00:56.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:00:56.173+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:00:56.173+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:00:56.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T15:01:26.643+0000] {processor.py:157} INFO - Started process (PID=19090) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:01:26.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:01:26.646+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:01:26.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:01:26.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:01:26.675+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:01:26.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:01:26.687+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:01:26.687+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:01:26.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T15:01:57.127+0000] {processor.py:157} INFO - Started process (PID=19115) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:01:57.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:01:57.130+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:01:57.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:01:57.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:01:57.163+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:01:57.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:01:57.177+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:01:57.177+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:01:57.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-18T15:02:27.587+0000] {processor.py:157} INFO - Started process (PID=19140) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:02:27.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:02:27.591+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:02:27.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:02:27.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:02:27.621+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:02:27.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:02:27.630+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:02:27.630+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:02:27.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T15:02:58.029+0000] {processor.py:157} INFO - Started process (PID=19165) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:02:58.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:02:58.034+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:02:58.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:02:58.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:02:58.065+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:02:58.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:02:58.076+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:02:58.076+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:02:58.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T15:03:28.431+0000] {processor.py:157} INFO - Started process (PID=19190) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:03:28.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:03:28.435+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:03:28.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:03:28.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:03:28.462+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:03:28.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:03:28.472+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:03:28.472+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:03:28.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T15:03:58.932+0000] {processor.py:157} INFO - Started process (PID=19215) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:03:58.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:03:58.936+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:03:58.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:03:58.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:03:58.963+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:03:58.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:03:58.972+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:03:58.972+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:03:58.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T15:04:29.370+0000] {processor.py:157} INFO - Started process (PID=19240) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:04:29.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:04:29.374+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:04:29.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:04:29.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:04:29.404+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:04:29.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:04:29.417+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:04:29.416+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:04:29.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T15:04:59.802+0000] {processor.py:157} INFO - Started process (PID=19265) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:04:59.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:04:59.805+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:04:59.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:04:59.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:04:59.835+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:04:59.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:04:59.844+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:04:59.844+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:04:59.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T15:05:30.218+0000] {processor.py:157} INFO - Started process (PID=19290) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:05:30.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:05:30.222+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:05:30.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:05:30.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:05:30.252+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:05:30.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:05:30.264+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:05:30.264+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:05:30.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T15:06:00.665+0000] {processor.py:157} INFO - Started process (PID=19315) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:06:00.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:06:00.670+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:06:00.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:06:00.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:06:00.708+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:06:00.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:06:00.720+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:06:00.720+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:06:00.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-18T15:06:31.168+0000] {processor.py:157} INFO - Started process (PID=19340) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:06:31.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:06:31.171+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:06:31.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:06:31.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:06:31.199+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:06:31.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:06:31.209+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:06:31.209+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:06:31.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T15:07:01.590+0000] {processor.py:157} INFO - Started process (PID=19365) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:07:01.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:07:01.593+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:07:01.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:07:01.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:07:01.624+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:07:01.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:07:01.635+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:07:01.635+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:07:01.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T15:07:32.013+0000] {processor.py:157} INFO - Started process (PID=19390) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:07:32.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:07:32.017+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:07:32.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:07:32.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:07:32.047+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:07:32.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:07:32.059+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:07:32.059+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:07:32.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T15:08:02.468+0000] {processor.py:157} INFO - Started process (PID=19415) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:08:02.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:08:02.472+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:08:02.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:08:02.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:08:02.503+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:08:02.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:08:02.515+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:08:02.515+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:08:02.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T15:08:32.958+0000] {processor.py:157} INFO - Started process (PID=19440) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:08:32.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:08:32.963+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:08:32.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:08:32.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:08:32.993+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:08:32.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:08:33.003+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:08:33.003+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:08:33.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T15:09:03.424+0000] {processor.py:157} INFO - Started process (PID=19465) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:09:03.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:09:03.429+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:09:03.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:09:03.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:09:03.452+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:09:03.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:09:03.462+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:09:03.462+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:09:03.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T15:09:33.894+0000] {processor.py:157} INFO - Started process (PID=19490) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:09:33.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:09:33.899+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:09:33.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:09:33.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:09:33.929+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:09:33.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:09:33.941+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:09:33.941+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:09:33.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T15:10:04.314+0000] {processor.py:157} INFO - Started process (PID=19515) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:10:04.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:10:04.317+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:10:04.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:10:04.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:10:04.347+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:10:04.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:10:04.357+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:10:04.357+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:10:04.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T15:10:34.750+0000] {processor.py:157} INFO - Started process (PID=19540) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:10:34.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:10:34.753+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:10:34.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:10:34.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:10:34.779+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:10:34.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:10:34.792+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:10:34.792+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:10:34.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T15:11:05.186+0000] {processor.py:157} INFO - Started process (PID=19565) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:11:05.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:11:05.190+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:11:05.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:11:05.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:11:05.222+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:11:05.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:11:05.234+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:11:05.234+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:11:05.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T15:11:35.667+0000] {processor.py:157} INFO - Started process (PID=19590) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:11:35.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:11:35.672+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:11:35.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:11:35.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:11:35.702+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:11:35.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:11:35.712+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:11:35.712+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:11:35.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T15:12:06.147+0000] {processor.py:157} INFO - Started process (PID=19615) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:12:06.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:12:06.151+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:12:06.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:12:06.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:12:06.179+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:12:06.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:12:06.188+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:12:06.188+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:12:06.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T15:12:36.577+0000] {processor.py:157} INFO - Started process (PID=19640) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:12:36.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:12:36.582+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:12:36.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:12:36.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:12:36.613+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:12:36.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:12:36.623+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:12:36.623+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:12:36.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T15:13:07.024+0000] {processor.py:157} INFO - Started process (PID=19665) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:13:07.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:13:07.028+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:13:07.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:13:07.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:13:07.056+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:13:07.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:13:07.067+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:13:07.066+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:13:07.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T15:13:37.504+0000] {processor.py:157} INFO - Started process (PID=19690) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:13:37.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:13:37.506+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:13:37.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:13:37.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:13:37.530+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:13:37.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:13:37.542+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:13:37.542+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:13:37.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T15:14:07.901+0000] {processor.py:157} INFO - Started process (PID=19715) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:14:07.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:14:07.904+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:14:07.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:14:07.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:14:07.928+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:14:07.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:14:07.938+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:14:07.938+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:14:07.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T15:14:38.356+0000] {processor.py:157} INFO - Started process (PID=19740) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:14:38.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:14:38.360+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:14:38.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:14:38.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:14:38.391+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:14:38.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:14:38.400+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:14:38.400+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:14:38.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T15:15:08.887+0000] {processor.py:157} INFO - Started process (PID=19765) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:15:08.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:15:08.891+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:15:08.891+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:15:08.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:15:08.924+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:15:08.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:15:08.933+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:15:08.933+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:15:08.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T15:15:39.340+0000] {processor.py:157} INFO - Started process (PID=19790) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:15:39.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:15:39.345+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:15:39.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:15:39.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:15:39.375+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:15:39.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:15:39.387+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:15:39.387+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:15:39.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T15:16:09.809+0000] {processor.py:157} INFO - Started process (PID=19815) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:16:09.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:16:09.812+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:16:09.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:16:09.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:16:09.843+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:16:09.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:16:09.853+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:16:09.853+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:16:09.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T15:16:40.277+0000] {processor.py:157} INFO - Started process (PID=19840) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:16:40.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:16:40.282+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:16:40.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:16:40.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:16:40.339+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:16:40.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:16:40.354+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:16:40.354+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:16:40.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.096 seconds
[2024-07-18T15:17:10.703+0000] {processor.py:157} INFO - Started process (PID=19865) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:17:10.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:17:10.708+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:17:10.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:17:10.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:17:10.756+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:17:10.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:17:10.773+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:17:10.773+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:17:10.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.097 seconds
[2024-07-18T15:17:41.165+0000] {processor.py:157} INFO - Started process (PID=19890) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:17:41.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:17:41.170+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:17:41.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:17:41.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:17:41.197+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:17:41.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:17:41.209+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:17:41.209+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:17:41.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T15:18:11.628+0000] {processor.py:157} INFO - Started process (PID=19915) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:18:11.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:18:11.636+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:18:11.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:18:11.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:18:11.678+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:18:11.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:18:11.690+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:18:11.690+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:18:11.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-18T15:18:42.047+0000] {processor.py:157} INFO - Started process (PID=19940) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:18:42.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:18:42.054+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:18:42.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:18:42.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:18:42.085+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:18:42.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:18:42.096+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:18:42.096+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:18:42.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-18T15:19:12.476+0000] {processor.py:157} INFO - Started process (PID=19965) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:19:12.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:19:12.480+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:19:12.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:19:12.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:19:12.509+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:19:12.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:19:12.519+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:19:12.519+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:19:12.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T15:19:42.869+0000] {processor.py:157} INFO - Started process (PID=19990) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:19:42.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:19:42.871+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:19:42.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:19:42.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:19:42.904+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:19:42.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:19:42.917+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:19:42.917+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:19:42.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T15:20:13.336+0000] {processor.py:157} INFO - Started process (PID=20015) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:20:13.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:20:13.343+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:20:13.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:20:13.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:20:13.389+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:20:13.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:20:13.400+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:20:13.400+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:20:13.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.084 seconds
[2024-07-18T15:20:43.863+0000] {processor.py:157} INFO - Started process (PID=20040) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:20:43.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:20:43.867+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:20:43.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:20:43.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:20:43.895+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:20:43.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:20:43.906+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:20:43.906+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:20:43.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T15:21:14.374+0000] {processor.py:157} INFO - Started process (PID=20065) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:21:14.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:21:14.381+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:21:14.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:21:14.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:21:14.441+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:21:14.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:21:14.455+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:21:14.455+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:21:14.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-18T15:21:44.864+0000] {processor.py:157} INFO - Started process (PID=20090) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:21:44.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:21:44.874+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:21:44.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:21:44.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:21:44.919+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:21:44.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:21:44.931+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:21:44.931+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:21:44.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-18T15:22:15.314+0000] {processor.py:157} INFO - Started process (PID=20115) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:22:15.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:22:15.317+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:22:15.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:22:15.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:22:15.347+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:22:15.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:22:15.359+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:22:15.359+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:22:15.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T15:22:45.770+0000] {processor.py:157} INFO - Started process (PID=20140) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:22:45.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:22:45.775+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:22:45.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:22:45.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:22:45.802+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:22:45.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:22:45.812+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:22:45.811+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:22:45.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T15:23:16.152+0000] {processor.py:157} INFO - Started process (PID=20165) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:23:16.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:23:16.154+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:23:16.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:23:16.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:23:16.178+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:23:16.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:23:16.191+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:23:16.191+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:23:16.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T15:23:46.919+0000] {processor.py:157} INFO - Started process (PID=20190) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:23:46.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:23:46.928+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:23:46.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:23:46.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:23:47.009+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:23:47.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:23:47.027+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:23:47.026+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:23:47.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.141 seconds
[2024-07-18T15:24:17.436+0000] {processor.py:157} INFO - Started process (PID=20215) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:24:17.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:24:17.446+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:24:17.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:24:17.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:24:17.514+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:24:17.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:24:17.551+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:24:17.551+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:24:17.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.142 seconds
[2024-07-18T15:24:47.958+0000] {processor.py:157} INFO - Started process (PID=20240) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:24:47.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:24:47.967+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:24:47.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:24:47.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:24:48.025+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:24:48.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:24:48.042+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:24:48.042+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:24:48.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.101 seconds
[2024-07-18T15:25:18.464+0000] {processor.py:157} INFO - Started process (PID=20265) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:25:18.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:25:18.471+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:25:18.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:25:18.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:25:18.535+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:25:18.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:25:18.553+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:25:18.552+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:25:18.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.108 seconds
[2024-07-18T15:25:49.103+0000] {processor.py:157} INFO - Started process (PID=20290) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:25:49.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:25:49.113+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:25:49.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:25:49.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:25:49.156+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:25:49.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:25:49.169+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:25:49.168+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:25:49.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-18T15:26:19.554+0000] {processor.py:157} INFO - Started process (PID=20315) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:26:19.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:26:19.558+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:26:19.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:26:19.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:26:19.585+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:26:19.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:26:19.594+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:26:19.594+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:26:19.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-18T15:26:49.934+0000] {processor.py:157} INFO - Started process (PID=20340) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:26:49.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:26:49.938+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:26:49.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:26:49.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:26:49.968+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:26:49.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:26:49.978+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:26:49.978+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:26:49.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T15:27:20.379+0000] {processor.py:157} INFO - Started process (PID=20365) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:27:20.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:27:20.383+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:27:20.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:27:20.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:27:20.413+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:27:20.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:27:20.426+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:27:20.426+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:27:20.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T15:27:50.812+0000] {processor.py:157} INFO - Started process (PID=20390) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:27:50.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:27:50.817+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:27:50.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:27:50.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:27:50.856+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:27:50.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:27:50.869+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:27:50.869+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:27:50.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-18T15:28:21.283+0000] {processor.py:157} INFO - Started process (PID=20415) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:28:21.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:28:21.286+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:28:21.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:28:21.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:28:21.315+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:28:21.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:28:21.328+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:28:21.328+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:28:21.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T15:28:51.731+0000] {processor.py:157} INFO - Started process (PID=20440) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:28:51.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:28:51.739+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:28:51.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:28:51.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:28:51.769+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:28:51.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:28:51.779+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:28:51.779+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:28:51.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T15:29:22.128+0000] {processor.py:157} INFO - Started process (PID=20465) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:29:22.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:29:22.134+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:29:22.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:29:22.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:29:22.170+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:29:22.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:29:22.186+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:29:22.185+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:29:22.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-18T15:29:52.603+0000] {processor.py:157} INFO - Started process (PID=20490) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:29:52.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:29:52.607+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:29:52.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:29:52.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:29:52.634+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:29:52.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:29:52.644+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:29:52.644+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:29:52.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T15:30:23.057+0000] {processor.py:157} INFO - Started process (PID=20515) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:30:23.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:30:23.063+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:30:23.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:30:23.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:30:23.089+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:30:23.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:30:23.103+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:30:23.103+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:30:23.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T15:30:53.492+0000] {processor.py:157} INFO - Started process (PID=20540) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:30:53.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:30:53.496+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:30:53.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:30:53.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:30:53.526+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:30:53.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:30:53.535+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:30:53.535+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:30:53.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T15:31:23.881+0000] {processor.py:157} INFO - Started process (PID=20565) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:31:23.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:31:23.883+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:31:23.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:31:23.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:31:23.910+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:31:23.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:31:23.920+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:31:23.920+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:31:23.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-18T15:31:54.271+0000] {processor.py:157} INFO - Started process (PID=20590) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:31:54.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:31:54.276+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:31:54.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:31:54.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:31:54.307+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:31:54.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:31:54.318+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:31:54.318+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:31:54.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T15:32:24.762+0000] {processor.py:157} INFO - Started process (PID=20615) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:32:24.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:32:24.764+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:32:24.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:32:24.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:32:24.793+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:32:24.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:32:24.804+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:32:24.804+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:32:24.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T15:32:55.204+0000] {processor.py:157} INFO - Started process (PID=20640) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:32:55.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:32:55.208+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:32:55.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:32:55.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:32:55.236+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:32:55.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:32:55.247+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:32:55.246+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:32:55.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T15:33:25.647+0000] {processor.py:157} INFO - Started process (PID=20665) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:33:25.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:33:25.653+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:33:25.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:33:25.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:33:25.681+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:33:25.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:33:25.691+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:33:25.691+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:33:25.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T15:33:56.094+0000] {processor.py:157} INFO - Started process (PID=20690) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:33:56.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:33:56.100+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:33:56.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:33:56.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:33:56.130+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:33:56.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:33:56.141+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:33:56.141+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:33:56.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T15:34:26.538+0000] {processor.py:157} INFO - Started process (PID=20715) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:34:26.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:34:26.544+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:34:26.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:34:26.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:34:26.583+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:34:26.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:34:26.597+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:34:26.597+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:34:26.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-18T15:34:56.936+0000] {processor.py:157} INFO - Started process (PID=20740) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:34:56.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:34:56.940+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:34:56.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:34:56.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:34:56.965+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:34:56.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:34:56.975+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:34:56.975+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:34:56.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T15:35:27.358+0000] {processor.py:157} INFO - Started process (PID=20765) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:35:27.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:35:27.361+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:35:27.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:35:27.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:35:27.391+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:35:27.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:35:27.401+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:35:27.401+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:35:27.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T15:35:57.801+0000] {processor.py:157} INFO - Started process (PID=20790) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:35:57.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:35:57.806+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:35:57.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:35:57.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:35:57.849+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:35:57.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:35:57.866+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:35:57.866+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:35:57.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.095 seconds
[2024-07-18T15:36:28.248+0000] {processor.py:157} INFO - Started process (PID=20815) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:36:28.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:36:28.250+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:36:28.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:36:28.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:36:28.276+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:36:28.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:36:28.289+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:36:28.289+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:36:28.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T15:36:58.675+0000] {processor.py:157} INFO - Started process (PID=20840) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:36:58.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:36:58.677+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:36:58.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:36:58.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:36:58.706+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:36:58.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:36:58.715+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:36:58.715+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:36:58.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T15:37:29.071+0000] {processor.py:157} INFO - Started process (PID=20865) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:37:29.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:37:29.075+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:37:29.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:37:29.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:37:29.106+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:37:29.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:37:29.117+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:37:29.117+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:37:29.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T15:37:59.490+0000] {processor.py:157} INFO - Started process (PID=20890) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:37:59.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:37:59.494+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:37:59.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:37:59.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:37:59.523+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:37:59.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:37:59.534+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:37:59.534+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:37:59.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T15:38:30.110+0000] {processor.py:157} INFO - Started process (PID=20915) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:38:30.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:38:30.148+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:38:30.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:38:30.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:38:30.225+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:38:30.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:38:30.254+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:38:30.254+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:38:30.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.202 seconds
[2024-07-18T15:39:00.684+0000] {processor.py:157} INFO - Started process (PID=20940) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:39:00.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:39:00.691+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:39:00.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:39:00.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:39:00.748+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:39:00.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:39:00.766+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:39:00.766+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:39:00.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.099 seconds
[2024-07-18T15:39:31.161+0000] {processor.py:157} INFO - Started process (PID=20965) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:39:31.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:39:31.164+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:39:31.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:39:31.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:39:31.192+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:39:31.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:39:31.202+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:39:31.202+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:39:31.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T15:40:01.573+0000] {processor.py:157} INFO - Started process (PID=20990) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:40:01.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:40:01.577+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:40:01.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:40:01.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:40:01.605+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:40:01.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:40:01.614+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:40:01.614+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:40:01.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T15:40:32.001+0000] {processor.py:157} INFO - Started process (PID=21015) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:40:32.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:40:32.005+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:40:32.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:40:32.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:40:32.031+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:40:32.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:40:32.044+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:40:32.044+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:40:32.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T15:41:02.418+0000] {processor.py:157} INFO - Started process (PID=21040) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:41:02.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:41:02.423+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:41:02.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:41:02.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:41:02.453+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:41:02.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:41:02.463+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:41:02.463+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:41:02.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T15:41:32.882+0000] {processor.py:157} INFO - Started process (PID=21065) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:41:32.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:41:32.886+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:41:32.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:41:32.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:41:32.913+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:41:32.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:41:32.926+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:41:32.926+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:41:32.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T15:42:03.318+0000] {processor.py:157} INFO - Started process (PID=21090) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:42:03.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:42:03.323+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:42:03.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:42:03.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:42:03.351+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:42:03.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:42:03.365+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:42:03.365+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:42:03.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T15:42:33.786+0000] {processor.py:157} INFO - Started process (PID=21115) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:42:33.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:42:33.793+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:42:33.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:42:33.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:42:33.835+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:42:33.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:42:33.849+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:42:33.849+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:42:33.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-18T15:43:04.275+0000] {processor.py:157} INFO - Started process (PID=21140) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:43:04.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:43:04.278+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:43:04.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:43:04.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:43:04.306+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:43:04.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:43:04.317+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:43:04.317+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:43:04.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T15:43:34.681+0000] {processor.py:157} INFO - Started process (PID=21165) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:43:34.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:43:34.684+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:43:34.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:43:34.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:43:34.710+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:43:34.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:43:34.720+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:43:34.720+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:43:34.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T15:44:05.114+0000] {processor.py:157} INFO - Started process (PID=21190) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:44:05.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:44:05.117+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:44:05.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:44:05.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:44:05.147+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:44:05.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:44:05.158+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:44:05.158+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:44:05.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T15:44:35.701+0000] {processor.py:157} INFO - Started process (PID=21215) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:44:35.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:44:35.707+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:44:35.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:44:35.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:44:35.753+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:44:35.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:44:35.768+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:44:35.768+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:44:35.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.084 seconds
[2024-07-18T15:45:06.158+0000] {processor.py:157} INFO - Started process (PID=21240) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:45:06.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:45:06.160+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:45:06.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:45:06.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:45:06.184+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:45:06.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:45:06.204+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:45:06.204+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:45:06.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T15:45:36.643+0000] {processor.py:157} INFO - Started process (PID=21265) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:45:36.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:45:36.648+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:45:36.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:45:36.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:45:36.686+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:45:36.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:45:36.698+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:45:36.697+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:45:36.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-18T15:46:07.093+0000] {processor.py:157} INFO - Started process (PID=21290) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:46:07.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:46:07.097+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:46:07.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:46:07.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:46:07.128+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:46:07.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:46:07.137+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:46:07.137+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:46:07.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T15:46:37.490+0000] {processor.py:157} INFO - Started process (PID=21315) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:46:37.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:46:37.493+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:46:37.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:46:37.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:46:37.522+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:46:37.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:46:37.531+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:46:37.531+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:46:37.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T15:47:07.880+0000] {processor.py:157} INFO - Started process (PID=21340) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:47:07.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:47:07.884+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:47:07.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:47:07.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:47:07.914+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:47:07.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:47:07.926+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:47:07.925+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:47:07.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T15:47:38.331+0000] {processor.py:157} INFO - Started process (PID=21365) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:47:38.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:47:38.334+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:47:38.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:47:38.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:47:38.366+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:47:38.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:47:38.376+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:47:38.376+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:47:38.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T15:48:08.788+0000] {processor.py:157} INFO - Started process (PID=21390) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:48:08.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:48:08.791+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:48:08.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:48:08.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:48:08.817+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:48:08.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:48:08.827+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:48:08.827+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:48:08.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T15:48:39.181+0000] {processor.py:157} INFO - Started process (PID=21415) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:48:39.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:48:39.184+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:48:39.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:48:39.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:48:39.213+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:48:39.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:48:39.223+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:48:39.223+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:48:39.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T15:49:09.603+0000] {processor.py:157} INFO - Started process (PID=21440) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:49:09.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:49:09.607+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:49:09.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:49:09.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:49:09.636+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:49:09.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:49:09.646+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:49:09.646+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:49:09.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T15:49:40.057+0000] {processor.py:157} INFO - Started process (PID=21465) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:49:40.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:49:40.063+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:49:40.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:49:40.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:49:40.098+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:49:40.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:49:40.114+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:49:40.114+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:49:40.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-18T15:50:10.541+0000] {processor.py:157} INFO - Started process (PID=21490) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:50:10.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:50:10.545+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:50:10.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:50:10.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:50:10.575+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:50:10.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:50:10.587+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:50:10.587+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:50:10.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T15:50:41.046+0000] {processor.py:157} INFO - Started process (PID=21515) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:50:41.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:50:41.050+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:50:41.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:50:41.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:50:41.081+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:50:41.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:50:41.093+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:50:41.093+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:50:41.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T15:51:11.510+0000] {processor.py:157} INFO - Started process (PID=21540) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:51:11.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:51:11.513+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:51:11.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:51:11.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:51:11.540+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:51:11.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:51:11.550+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:51:11.550+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:51:11.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T15:51:41.903+0000] {processor.py:157} INFO - Started process (PID=21565) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:51:41.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:51:41.907+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:51:41.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:51:41.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:51:41.933+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:51:41.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:51:41.942+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:51:41.942+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:51:41.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T15:52:12.308+0000] {processor.py:157} INFO - Started process (PID=21590) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:52:12.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:52:12.312+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:52:12.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:52:12.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:52:12.342+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:52:12.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:52:12.352+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:52:12.352+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:52:12.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T15:52:42.756+0000] {processor.py:157} INFO - Started process (PID=21615) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:52:42.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:52:42.760+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:52:42.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:52:42.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:52:42.794+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:52:42.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:52:42.804+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:52:42.804+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:52:42.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T15:53:13.221+0000] {processor.py:157} INFO - Started process (PID=21640) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:53:13.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:53:13.228+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:53:13.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:53:13.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:53:13.283+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:53:13.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:53:13.300+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:53:13.300+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:53:13.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.097 seconds
[2024-07-18T15:53:43.861+0000] {processor.py:157} INFO - Started process (PID=21665) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:53:43.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:53:43.866+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:53:43.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:53:43.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:53:43.923+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:53:43.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:53:43.937+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:53:43.937+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:53:43.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.096 seconds
[2024-07-18T15:54:14.363+0000] {processor.py:157} INFO - Started process (PID=21690) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:54:14.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:54:14.371+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:54:14.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:54:14.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:54:14.425+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:54:14.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:54:14.440+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:54:14.440+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:54:14.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.100 seconds
[2024-07-18T15:54:44.882+0000] {processor.py:157} INFO - Started process (PID=21715) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:54:44.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:54:44.888+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:54:44.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:54:44.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:54:44.932+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:54:44.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:54:44.947+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:54:44.947+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:54:44.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-18T15:55:15.377+0000] {processor.py:157} INFO - Started process (PID=21740) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:55:15.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:55:15.380+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:55:15.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:55:15.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:55:15.407+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:55:15.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:55:15.417+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:55:15.417+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:55:15.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T15:55:45.811+0000] {processor.py:157} INFO - Started process (PID=21765) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:55:45.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:55:45.815+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:55:45.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:55:45.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:55:45.845+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:55:45.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:55:45.857+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:55:45.857+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:55:45.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T15:56:16.286+0000] {processor.py:157} INFO - Started process (PID=21790) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:56:16.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:56:16.292+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:56:16.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:56:16.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:56:16.353+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:56:16.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:56:16.370+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:56:16.370+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:56:16.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-18T15:56:46.754+0000] {processor.py:157} INFO - Started process (PID=21815) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:56:46.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:56:46.757+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:56:46.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:56:46.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:56:46.780+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:56:46.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:56:46.795+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:56:46.795+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:56:46.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T15:57:17.217+0000] {processor.py:157} INFO - Started process (PID=21840) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:57:17.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:57:17.220+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:57:17.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:57:17.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:57:17.246+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:57:17.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:57:17.256+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:57:17.256+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:57:17.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-18T15:57:47.601+0000] {processor.py:157} INFO - Started process (PID=21865) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:57:47.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:57:47.604+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:57:47.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:57:47.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:57:47.630+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:57:47.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:57:47.640+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:57:47.640+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:57:47.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T15:58:18.011+0000] {processor.py:157} INFO - Started process (PID=21890) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:58:18.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:58:18.015+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:58:18.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:58:18.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:58:18.044+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:58:18.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:58:18.056+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:58:18.055+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:58:18.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T15:58:48.405+0000] {processor.py:157} INFO - Started process (PID=21915) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:58:48.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:58:48.410+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:58:48.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:58:48.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:58:48.446+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:58:48.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:58:48.459+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:58:48.458+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:58:48.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-18T15:59:18.814+0000] {processor.py:157} INFO - Started process (PID=21940) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:59:18.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:59:18.820+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:59:18.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:59:18.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:59:18.872+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:59:18.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:59:18.892+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:59:18.892+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:59:18.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.094 seconds
[2024-07-18T15:59:49.367+0000] {processor.py:157} INFO - Started process (PID=21965) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:59:49.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T15:59:49.372+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:59:49.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:59:49.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T15:59:49.402+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:59:49.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T15:59:49.414+0000] {logging_mixin.py:151} INFO - [2024-07-18T15:59:49.414+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T15:59:49.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-18T16:00:19.823+0000] {processor.py:157} INFO - Started process (PID=21990) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:00:19.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:00:19.827+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:00:19.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:00:19.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:00:19.866+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:00:19.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:00:19.879+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:00:19.879+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:00:19.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-18T16:00:50.319+0000] {processor.py:157} INFO - Started process (PID=22015) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:00:50.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:00:50.323+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:00:50.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:00:50.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:00:50.350+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:00:50.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:00:50.360+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:00:50.360+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:00:50.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T16:01:20.799+0000] {processor.py:157} INFO - Started process (PID=22040) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:01:20.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:01:20.802+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:01:20.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:01:20.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:01:20.827+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:01:20.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:01:20.842+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:01:20.842+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:01:20.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T16:01:51.198+0000] {processor.py:157} INFO - Started process (PID=22065) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:01:51.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:01:51.201+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:01:51.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:01:51.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:01:51.227+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:01:51.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:01:51.236+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:01:51.236+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:01:51.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T16:02:21.635+0000] {processor.py:157} INFO - Started process (PID=22090) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:02:21.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:02:21.637+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:02:21.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:02:21.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:02:21.663+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:02:21.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:02:21.677+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:02:21.677+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:02:21.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T16:02:52.073+0000] {processor.py:157} INFO - Started process (PID=22115) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:02:52.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:02:52.079+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:02:52.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:02:52.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:02:52.108+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:02:52.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:02:52.118+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:02:52.118+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:02:52.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T16:03:22.489+0000] {processor.py:157} INFO - Started process (PID=22140) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:03:22.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:03:22.493+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:03:22.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:03:22.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:03:22.521+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:03:22.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:03:22.532+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:03:22.532+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:03:22.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T16:03:52.891+0000] {processor.py:157} INFO - Started process (PID=22165) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:03:52.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:03:52.898+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:03:52.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:03:52.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:03:52.935+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:03:52.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:03:52.948+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:03:52.948+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:03:52.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-18T16:04:23.361+0000] {processor.py:157} INFO - Started process (PID=22190) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:04:23.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:04:23.366+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:04:23.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:04:23.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:04:23.404+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:04:23.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:04:23.417+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:04:23.417+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:04:23.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-18T16:04:53.862+0000] {processor.py:157} INFO - Started process (PID=22215) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:04:53.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:04:53.865+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:04:53.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:04:53.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:04:53.891+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:04:53.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:04:53.903+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:04:53.903+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:04:53.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T16:05:24.339+0000] {processor.py:157} INFO - Started process (PID=22240) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:05:24.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:05:24.343+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:05:24.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:05:24.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:05:24.386+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:05:24.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:05:24.399+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:05:24.399+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:05:24.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-18T16:05:54.807+0000] {processor.py:157} INFO - Started process (PID=22265) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:05:54.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:05:54.813+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:05:54.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:05:54.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:05:54.841+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:05:54.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:05:54.851+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:05:54.851+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:05:54.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T16:06:25.202+0000] {processor.py:157} INFO - Started process (PID=22290) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:06:25.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:06:25.205+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:06:25.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:06:25.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:06:25.231+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:06:25.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:06:25.241+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:06:25.241+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:06:25.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T16:06:55.589+0000] {processor.py:157} INFO - Started process (PID=22315) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:06:55.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:06:55.595+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:06:55.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:06:55.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:06:55.634+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:06:55.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:06:55.651+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:06:55.651+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:06:55.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-18T16:07:26.079+0000] {processor.py:157} INFO - Started process (PID=22340) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:07:26.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:07:26.082+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:07:26.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:07:26.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:07:26.110+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:07:26.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:07:26.121+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:07:26.120+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:07:26.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T16:07:56.513+0000] {processor.py:157} INFO - Started process (PID=22365) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:07:56.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:07:56.516+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:07:56.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:07:56.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:07:56.542+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:07:56.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:07:56.552+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:07:56.551+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:07:56.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T16:08:26.964+0000] {processor.py:157} INFO - Started process (PID=22390) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:08:26.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:08:26.967+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:08:26.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:08:26.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:08:26.993+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:08:26.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:08:27.004+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:08:27.004+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:08:27.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T16:08:57.408+0000] {processor.py:157} INFO - Started process (PID=22415) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:08:57.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:08:57.411+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:08:57.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:08:57.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:08:57.443+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:08:57.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:08:57.452+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:08:57.452+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:08:57.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T16:09:27.809+0000] {processor.py:157} INFO - Started process (PID=22440) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:09:27.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:09:27.813+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:09:27.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:09:27.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:09:27.850+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:09:27.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:09:27.863+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:09:27.863+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:09:27.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-18T16:09:58.264+0000] {processor.py:157} INFO - Started process (PID=22465) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:09:58.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:09:58.267+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:09:58.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:09:58.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:09:58.295+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:09:58.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:09:58.305+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:09:58.305+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:09:58.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T16:10:28.709+0000] {processor.py:157} INFO - Started process (PID=22490) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:10:28.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:10:28.713+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:10:28.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:10:28.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:10:28.738+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:10:28.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:10:28.753+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:10:28.753+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:10:28.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T16:10:59.156+0000] {processor.py:157} INFO - Started process (PID=22515) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:10:59.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:10:59.160+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:10:59.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:10:59.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:10:59.188+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:10:59.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:10:59.199+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:10:59.199+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:10:59.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T16:11:29.614+0000] {processor.py:157} INFO - Started process (PID=22540) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:11:29.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:11:29.616+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:11:29.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:11:29.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:11:29.645+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:11:29.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:11:29.655+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:11:29.655+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:11:29.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T16:11:59.976+0000] {processor.py:157} INFO - Started process (PID=22565) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:11:59.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:11:59.978+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:11:59.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:11:59.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:12:00.004+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:12:00.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:12:00.013+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:12:00.013+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:12:00.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-18T16:12:30.391+0000] {processor.py:157} INFO - Started process (PID=22590) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:12:30.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:12:30.395+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:12:30.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:12:30.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:12:30.426+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:12:30.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:12:30.436+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:12:30.436+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:12:30.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T16:13:00.838+0000] {processor.py:157} INFO - Started process (PID=22615) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:13:00.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:13:00.841+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:13:00.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:13:00.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:13:00.872+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:13:00.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:13:00.882+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:13:00.882+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:13:00.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T16:13:31.240+0000] {processor.py:157} INFO - Started process (PID=22640) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:13:31.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:13:31.243+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:13:31.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:13:31.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:13:31.272+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:13:31.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:13:31.284+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:13:31.284+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:13:31.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T16:14:01.698+0000] {processor.py:157} INFO - Started process (PID=22665) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:14:01.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:14:01.702+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:14:01.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:14:01.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:14:01.731+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:14:01.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:14:01.741+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:14:01.741+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:14:01.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T16:14:32.122+0000] {processor.py:157} INFO - Started process (PID=22690) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:14:32.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:14:32.125+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:14:32.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:14:32.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:14:32.153+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:14:32.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:14:32.162+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:14:32.162+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:14:32.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T16:15:02.514+0000] {processor.py:157} INFO - Started process (PID=22715) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:15:02.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:15:02.517+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:15:02.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:15:02.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:15:02.546+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:15:02.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:15:02.557+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:15:02.557+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:15:02.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T16:15:32.948+0000] {processor.py:157} INFO - Started process (PID=22740) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:15:32.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:15:32.951+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:15:32.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:15:32.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:15:32.985+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:15:32.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:15:32.998+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:15:32.998+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:15:33.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T16:16:03.426+0000] {processor.py:157} INFO - Started process (PID=22765) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:16:03.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:16:03.429+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:16:03.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:16:03.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:16:03.455+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:16:03.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:16:03.467+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:16:03.467+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:16:03.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T16:16:33.838+0000] {processor.py:157} INFO - Started process (PID=22790) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:16:33.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:16:33.842+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:16:33.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:16:33.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:16:33.868+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:16:33.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:16:33.878+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:16:33.878+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:16:33.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T16:17:04.228+0000] {processor.py:157} INFO - Started process (PID=22815) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:17:04.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:17:04.233+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:17:04.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:17:04.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:17:04.270+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:17:04.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:17:04.282+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:17:04.282+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:17:04.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-18T16:17:34.768+0000] {processor.py:157} INFO - Started process (PID=22840) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:17:34.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:17:34.773+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:17:34.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:17:34.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:17:34.804+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:17:34.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:17:34.818+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:17:34.817+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:17:34.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-18T16:18:05.219+0000] {processor.py:157} INFO - Started process (PID=22865) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:18:05.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:18:05.224+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:18:05.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:18:05.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:18:05.251+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:18:05.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:18:05.261+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:18:05.261+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:18:05.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T16:18:35.628+0000] {processor.py:157} INFO - Started process (PID=22890) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:18:35.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:18:35.631+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:18:35.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:18:35.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:18:35.661+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:18:35.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:18:35.671+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:18:35.671+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:18:35.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T16:19:06.090+0000] {processor.py:157} INFO - Started process (PID=22915) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:19:06.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:19:06.095+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:19:06.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:19:06.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:19:06.132+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:19:06.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:19:06.146+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:19:06.146+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:19:06.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-18T16:19:36.519+0000] {processor.py:157} INFO - Started process (PID=22940) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:19:36.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:19:36.525+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:19:36.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:19:36.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:19:36.592+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:19:36.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:19:36.611+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:19:36.611+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:19:36.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.114 seconds
[2024-07-18T16:20:06.987+0000] {processor.py:157} INFO - Started process (PID=22965) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:20:06.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:20:06.989+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:20:06.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:20:07.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:20:07.020+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:20:07.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:20:07.034+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:20:07.034+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:20:07.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T16:20:37.478+0000] {processor.py:157} INFO - Started process (PID=22990) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:20:37.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:20:37.484+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:20:37.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:20:37.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:20:37.518+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:20:37.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:20:37.530+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:20:37.530+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:20:37.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-18T16:21:07.953+0000] {processor.py:157} INFO - Started process (PID=23015) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:21:07.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:21:07.957+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:21:07.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:21:07.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:21:07.987+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:21:07.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:21:07.999+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:21:07.998+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:21:08.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T16:21:38.344+0000] {processor.py:157} INFO - Started process (PID=23040) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:21:38.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:21:38.347+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:21:38.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:21:38.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:21:38.375+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:21:38.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:21:38.385+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:21:38.385+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:21:38.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T16:22:08.786+0000] {processor.py:157} INFO - Started process (PID=23065) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:22:08.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:22:08.790+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:22:08.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:22:08.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:22:08.819+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:22:08.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:22:08.831+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:22:08.831+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:22:08.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T16:22:39.218+0000] {processor.py:157} INFO - Started process (PID=23090) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:22:39.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:22:39.222+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:22:39.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:22:39.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:22:39.255+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:22:39.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:22:39.264+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:22:39.264+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:22:39.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T16:23:09.650+0000] {processor.py:157} INFO - Started process (PID=23115) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:23:09.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:23:09.653+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:23:09.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:23:09.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:23:09.681+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:23:09.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:23:09.690+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:23:09.690+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:23:09.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T16:23:40.061+0000] {processor.py:157} INFO - Started process (PID=23140) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:23:40.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:23:40.066+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:23:40.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:23:40.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:23:40.093+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:23:40.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:23:40.103+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:23:40.103+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:23:40.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T16:24:10.453+0000] {processor.py:157} INFO - Started process (PID=23165) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:24:10.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:24:10.456+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:24:10.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:24:10.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:24:10.484+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:24:10.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:24:10.494+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:24:10.494+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:24:10.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T16:24:40.956+0000] {processor.py:157} INFO - Started process (PID=23190) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:24:40.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:24:40.960+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:24:40.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:24:40.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:24:40.989+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:24:40.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:24:41.003+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:24:41.003+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:24:41.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T16:25:11.377+0000] {processor.py:157} INFO - Started process (PID=23215) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:25:11.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:25:11.380+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:25:11.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:25:11.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:25:11.407+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:25:11.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:25:11.416+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:25:11.416+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:25:11.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T16:25:41.867+0000] {processor.py:157} INFO - Started process (PID=23240) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:25:41.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:25:41.871+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:25:41.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:25:41.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:25:41.906+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:25:41.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:25:41.920+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:25:41.920+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:25:41.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-18T16:26:12.310+0000] {processor.py:157} INFO - Started process (PID=23265) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:26:12.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:26:12.315+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:26:12.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:26:12.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:26:12.345+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:26:12.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:26:12.356+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:26:12.356+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:26:12.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T16:26:42.780+0000] {processor.py:157} INFO - Started process (PID=23290) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:26:42.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:26:42.783+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:26:42.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:26:42.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:26:42.812+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:26:42.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:26:42.824+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:26:42.824+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:26:42.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T16:27:13.197+0000] {processor.py:157} INFO - Started process (PID=23315) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:27:13.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:27:13.199+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:27:13.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:27:13.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:27:13.224+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:27:13.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:27:13.238+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:27:13.238+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:27:13.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T16:27:43.575+0000] {processor.py:157} INFO - Started process (PID=23340) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:27:43.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:27:43.578+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:27:43.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:27:43.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:27:43.605+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:27:43.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:27:43.615+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:27:43.615+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:27:43.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T16:28:14.034+0000] {processor.py:157} INFO - Started process (PID=23365) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:28:14.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:28:14.038+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:28:14.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:28:14.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:28:14.067+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:28:14.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:28:14.077+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:28:14.077+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:28:14.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T16:28:44.462+0000] {processor.py:157} INFO - Started process (PID=23390) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:28:44.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:28:44.466+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:28:44.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:28:44.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:28:44.490+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:28:44.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:28:44.501+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:28:44.501+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:28:44.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T16:29:14.895+0000] {processor.py:157} INFO - Started process (PID=23415) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:29:14.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:29:14.900+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:29:14.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:29:14.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:29:14.930+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:29:14.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:29:14.940+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:29:14.940+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:29:14.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T16:29:45.337+0000] {processor.py:157} INFO - Started process (PID=23440) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:29:45.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:29:45.343+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:29:45.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:29:45.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:29:45.369+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:29:45.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:29:45.381+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:29:45.381+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:29:45.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T16:30:15.804+0000] {processor.py:157} INFO - Started process (PID=23465) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:30:15.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:30:15.808+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:30:15.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:30:15.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:30:15.837+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:30:15.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:30:15.850+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:30:15.850+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:30:15.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T16:30:46.279+0000] {processor.py:157} INFO - Started process (PID=23490) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:30:46.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:30:46.283+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:30:46.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:30:46.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:30:46.320+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:30:46.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:30:46.333+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:30:46.333+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:30:46.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-18T16:31:16.653+0000] {processor.py:157} INFO - Started process (PID=23515) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:31:16.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:31:16.658+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:31:16.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:31:16.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:31:16.685+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:31:16.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:31:16.694+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:31:16.694+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:31:16.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T16:31:47.065+0000] {processor.py:157} INFO - Started process (PID=23540) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:31:47.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:31:47.068+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:31:47.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:31:47.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:31:47.097+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:31:47.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:31:47.107+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:31:47.107+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:31:47.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T16:32:17.466+0000] {processor.py:157} INFO - Started process (PID=23565) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:32:17.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:32:17.469+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:32:17.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:32:17.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:32:17.494+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:32:17.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:32:17.504+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:32:17.504+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:32:17.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T16:32:47.859+0000] {processor.py:157} INFO - Started process (PID=23590) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:32:47.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:32:47.864+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:32:47.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:32:47.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:32:47.892+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:32:47.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:32:47.902+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:32:47.902+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:32:47.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T16:33:18.290+0000] {processor.py:157} INFO - Started process (PID=23615) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:33:18.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:33:18.293+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:33:18.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:33:18.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:33:18.318+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:33:18.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:33:18.330+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:33:18.330+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:33:18.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T16:33:48.746+0000] {processor.py:157} INFO - Started process (PID=23640) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:33:48.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:33:48.752+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:33:48.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:33:48.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:33:48.786+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:33:48.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:33:48.797+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:33:48.797+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:33:48.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-18T16:34:19.200+0000] {processor.py:157} INFO - Started process (PID=23665) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:34:19.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:34:19.204+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:34:19.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:34:19.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:34:19.232+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:34:19.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:34:19.243+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:34:19.243+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:34:19.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T16:34:49.618+0000] {processor.py:157} INFO - Started process (PID=23690) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:34:49.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:34:49.621+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:34:49.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:34:49.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:34:49.653+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:34:49.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:34:49.663+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:34:49.663+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:34:49.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T16:35:20.063+0000] {processor.py:157} INFO - Started process (PID=23715) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:35:20.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:35:20.068+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:35:20.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:35:20.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:35:20.108+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:35:20.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:35:20.121+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:35:20.121+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:35:20.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-18T16:35:50.534+0000] {processor.py:157} INFO - Started process (PID=23740) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:35:50.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:35:50.539+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:35:50.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:35:50.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:35:50.570+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:35:50.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:35:50.583+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:35:50.582+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:35:50.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T16:36:20.950+0000] {processor.py:157} INFO - Started process (PID=23765) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:36:20.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:36:20.956+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:36:20.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:36:20.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:36:20.983+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:36:20.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:36:20.996+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:36:20.996+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:36:21.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T16:36:51.411+0000] {processor.py:157} INFO - Started process (PID=23790) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:36:51.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:36:51.415+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:36:51.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:36:51.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:36:51.443+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:36:51.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:36:51.454+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:36:51.454+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:36:51.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T16:37:21.860+0000] {processor.py:157} INFO - Started process (PID=23815) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:37:21.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:37:21.865+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:37:21.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:37:21.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:37:21.927+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:37:21.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:37:21.945+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:37:21.945+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:37:21.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-18T16:37:52.383+0000] {processor.py:157} INFO - Started process (PID=23840) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:37:52.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:37:52.385+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:37:52.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:37:52.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:37:52.414+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:37:52.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:37:52.424+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:37:52.424+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:37:52.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T16:38:22.777+0000] {processor.py:157} INFO - Started process (PID=23865) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:38:22.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:38:22.782+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:38:22.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:38:22.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:38:22.818+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:38:22.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:38:22.831+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:38:22.831+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:38:22.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-18T16:38:53.240+0000] {processor.py:157} INFO - Started process (PID=23890) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:38:53.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:38:53.243+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:38:53.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:38:53.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:38:53.273+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:38:53.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:38:53.284+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:38:53.284+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:38:53.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T16:39:23.698+0000] {processor.py:157} INFO - Started process (PID=23915) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:39:23.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:39:23.702+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:39:23.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:39:23.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:39:23.731+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:39:23.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:39:23.741+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:39:23.741+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:39:23.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T16:39:54.111+0000] {processor.py:157} INFO - Started process (PID=23940) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:39:54.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:39:54.115+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:39:54.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:39:54.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:39:54.143+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:39:54.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:39:54.153+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:39:54.153+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:39:54.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T16:40:24.557+0000] {processor.py:157} INFO - Started process (PID=23965) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:40:24.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:40:24.562+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:40:24.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:40:24.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:40:24.590+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:40:24.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:40:24.601+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:40:24.601+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:40:24.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T16:40:54.974+0000] {processor.py:157} INFO - Started process (PID=23990) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:40:54.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:40:54.979+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:40:54.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:40:54.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:40:55.007+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:40:55.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:40:55.017+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:40:55.017+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:40:55.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T16:41:25.432+0000] {processor.py:157} INFO - Started process (PID=24015) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:41:25.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:41:25.436+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:41:25.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:41:25.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:41:25.461+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:41:25.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:41:25.473+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:41:25.473+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:41:25.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T16:41:55.886+0000] {processor.py:157} INFO - Started process (PID=24040) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:41:55.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:41:55.891+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:41:55.891+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:41:55.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:41:55.928+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:41:55.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:41:55.938+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:41:55.938+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:41:55.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-18T16:42:26.367+0000] {processor.py:157} INFO - Started process (PID=24065) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:42:26.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:42:26.372+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:42:26.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:42:26.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:42:26.407+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:42:26.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:42:26.420+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:42:26.420+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:42:26.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-18T16:42:56.843+0000] {processor.py:157} INFO - Started process (PID=24090) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:42:56.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:42:56.845+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:42:56.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:42:56.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:42:56.866+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:42:56.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:42:56.875+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:42:56.875+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:42:56.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.041 seconds
[2024-07-18T16:43:27.239+0000] {processor.py:157} INFO - Started process (PID=24115) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:43:27.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:43:27.244+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:43:27.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:43:27.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:43:27.271+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:43:27.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:43:27.280+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:43:27.280+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:43:27.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T16:43:57.589+0000] {processor.py:157} INFO - Started process (PID=24140) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:43:57.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:43:57.592+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:43:57.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:43:57.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:43:57.619+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:43:57.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:43:57.629+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:43:57.629+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:43:57.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T16:44:28.012+0000] {processor.py:157} INFO - Started process (PID=24165) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:44:28.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:44:28.017+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:44:28.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:44:28.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:44:28.046+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:44:28.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:44:28.059+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:44:28.059+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:44:28.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T16:44:58.476+0000] {processor.py:157} INFO - Started process (PID=24190) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:44:58.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:44:58.481+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:44:58.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:44:58.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:44:58.507+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:44:58.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:44:58.518+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:44:58.518+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:44:58.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T16:45:28.936+0000] {processor.py:157} INFO - Started process (PID=24215) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:45:28.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:45:28.939+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:45:28.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:45:28.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:45:28.967+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:45:28.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:45:28.977+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:45:28.976+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:45:28.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T16:45:59.351+0000] {processor.py:157} INFO - Started process (PID=24240) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:45:59.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:45:59.354+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:45:59.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:45:59.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:45:59.381+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:45:59.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:45:59.392+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:45:59.392+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:45:59.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T16:46:29.736+0000] {processor.py:157} INFO - Started process (PID=24265) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:46:29.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:46:29.740+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:46:29.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:46:29.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:46:29.765+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:46:29.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:46:29.775+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:46:29.775+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:46:29.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T16:47:00.172+0000] {processor.py:157} INFO - Started process (PID=24290) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:47:00.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:47:00.175+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:47:00.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:47:00.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:47:00.200+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:47:00.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:47:00.210+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:47:00.210+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:47:00.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T16:47:30.667+0000] {processor.py:157} INFO - Started process (PID=24315) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:47:30.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:47:30.672+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:47:30.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:47:30.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:47:30.698+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:47:30.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:47:30.711+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:47:30.711+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:47:30.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T16:48:01.135+0000] {processor.py:157} INFO - Started process (PID=24340) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:48:01.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:48:01.138+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:48:01.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:48:01.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:48:01.166+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:48:01.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:48:01.176+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:48:01.176+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:48:01.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T16:48:31.554+0000] {processor.py:157} INFO - Started process (PID=24365) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:48:31.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:48:31.557+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:48:31.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:48:31.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:48:31.582+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:48:31.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:48:31.592+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:48:31.592+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:48:31.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T16:49:02.030+0000] {processor.py:157} INFO - Started process (PID=24390) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:49:02.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:49:02.033+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:49:02.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:49:02.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:49:02.063+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:49:02.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:49:02.075+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:49:02.075+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:49:02.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T16:49:32.477+0000] {processor.py:157} INFO - Started process (PID=24415) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:49:32.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:49:32.480+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:49:32.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:49:32.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:49:32.507+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:49:32.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:49:32.518+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:49:32.518+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:49:32.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T16:50:02.981+0000] {processor.py:157} INFO - Started process (PID=24440) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:50:02.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:50:02.985+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:50:02.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:50:02.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:50:03.014+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:50:03.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:50:03.027+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:50:03.027+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:50:03.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T16:50:33.446+0000] {processor.py:157} INFO - Started process (PID=24465) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:50:33.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:50:33.449+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:50:33.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:50:33.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:50:33.478+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:50:33.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:50:33.489+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:50:33.489+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:50:33.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T16:51:03.879+0000] {processor.py:157} INFO - Started process (PID=24490) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:51:03.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:51:03.883+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:51:03.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:51:03.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:51:03.915+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:51:03.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:51:03.926+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:51:03.926+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:51:03.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T16:51:34.327+0000] {processor.py:157} INFO - Started process (PID=24515) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:51:34.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:51:34.330+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:51:34.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:51:34.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:51:34.362+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:51:34.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:51:34.376+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:51:34.376+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:51:34.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-18T16:52:04.831+0000] {processor.py:157} INFO - Started process (PID=24540) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:52:04.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:52:04.836+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:52:04.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:52:04.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:52:04.874+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:52:04.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:52:04.886+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:52:04.886+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:52:04.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-18T16:52:35.302+0000] {processor.py:157} INFO - Started process (PID=24565) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:52:35.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:52:35.305+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:52:35.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:52:35.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:52:35.337+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:52:35.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:52:35.348+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:52:35.348+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:52:35.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T16:53:05.776+0000] {processor.py:157} INFO - Started process (PID=24590) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:53:05.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:53:05.779+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:53:05.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:53:05.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:53:05.807+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:53:05.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:53:05.822+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:53:05.822+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:53:05.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T16:53:36.188+0000] {processor.py:157} INFO - Started process (PID=24615) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:53:36.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:53:36.191+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:53:36.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:53:36.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:53:36.225+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:53:36.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:53:36.236+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:53:36.236+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:53:36.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-18T16:54:06.620+0000] {processor.py:157} INFO - Started process (PID=24640) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:54:06.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:54:06.624+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:54:06.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:54:06.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:54:06.651+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:54:06.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:54:06.660+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:54:06.660+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:54:06.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T16:54:37.001+0000] {processor.py:157} INFO - Started process (PID=24665) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:54:37.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:54:37.003+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:54:37.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:54:37.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:54:37.027+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:54:37.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:54:37.037+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:54:37.037+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:54:37.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-18T16:55:07.461+0000] {processor.py:157} INFO - Started process (PID=24690) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:55:07.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:55:07.466+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:55:07.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:55:07.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:55:07.493+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:55:07.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:55:07.502+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:55:07.502+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:55:07.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T16:55:37.975+0000] {processor.py:157} INFO - Started process (PID=24715) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:55:37.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:55:37.978+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:55:37.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:55:37.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:55:38.008+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:55:38.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:55:38.018+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:55:38.018+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:55:38.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T16:56:08.431+0000] {processor.py:157} INFO - Started process (PID=24740) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:56:08.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:56:08.434+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:56:08.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:56:08.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:56:08.460+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:56:08.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:56:08.471+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:56:08.471+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:56:08.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T16:56:38.893+0000] {processor.py:157} INFO - Started process (PID=24765) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:56:38.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:56:38.898+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:56:38.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:56:38.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:56:38.927+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:56:38.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:56:38.940+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:56:38.940+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:56:38.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T16:57:09.263+0000] {processor.py:157} INFO - Started process (PID=24790) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:57:09.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:57:09.266+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:57:09.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:57:09.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:57:09.297+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:57:09.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:57:09.306+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:57:09.306+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:57:09.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T16:57:39.706+0000] {processor.py:157} INFO - Started process (PID=24815) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:57:39.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:57:39.708+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:57:39.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:57:39.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:57:39.733+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:57:39.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:57:39.745+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:57:39.745+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:57:39.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T16:58:10.151+0000] {processor.py:157} INFO - Started process (PID=24840) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:58:10.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:58:10.156+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:58:10.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:58:10.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:58:10.185+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:58:10.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:58:10.197+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:58:10.197+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:58:10.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T16:58:40.569+0000] {processor.py:157} INFO - Started process (PID=24865) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:58:40.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:58:40.573+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:58:40.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:58:40.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:58:40.605+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:58:40.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:58:40.616+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:58:40.615+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:58:40.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T16:59:11.066+0000] {processor.py:157} INFO - Started process (PID=24890) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:59:11.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:59:11.070+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:59:11.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:59:11.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:59:11.100+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:59:11.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:59:11.111+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:59:11.111+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:59:11.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T16:59:41.498+0000] {processor.py:157} INFO - Started process (PID=24915) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:59:41.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T16:59:41.501+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:59:41.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:59:41.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T16:59:41.531+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:59:41.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T16:59:41.540+0000] {logging_mixin.py:151} INFO - [2024-07-18T16:59:41.540+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T16:59:41.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T17:00:11.905+0000] {processor.py:157} INFO - Started process (PID=24940) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:00:11.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T17:00:11.910+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:00:11.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:00:11.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:00:11.950+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:00:11.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:00:11.962+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:00:11.962+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T17:00:11.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-18T17:00:42.356+0000] {processor.py:157} INFO - Started process (PID=24965) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:00:42.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T17:00:42.360+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:00:42.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:00:42.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:00:42.390+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:00:42.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:00:42.402+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:00:42.402+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T17:00:42.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T17:01:12.718+0000] {processor.py:157} INFO - Started process (PID=24990) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:01:12.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T17:01:12.720+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:01:12.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:01:12.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:01:12.751+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:01:12.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:01:12.762+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:01:12.762+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T17:01:12.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T17:01:43.176+0000] {processor.py:157} INFO - Started process (PID=25015) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:01:43.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T17:01:43.181+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:01:43.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:01:43.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:01:43.208+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:01:43.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:01:43.218+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:01:43.218+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T17:01:43.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T17:02:13.581+0000] {processor.py:157} INFO - Started process (PID=25040) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:02:13.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T17:02:13.586+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:02:13.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:02:13.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:02:13.616+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:02:13.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:02:13.626+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:02:13.626+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T17:02:13.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T17:02:44.087+0000] {processor.py:157} INFO - Started process (PID=25065) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:02:44.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T17:02:44.094+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:02:44.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:02:44.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:02:44.152+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:02:44.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:02:44.177+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:02:44.177+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T17:02:44.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.109 seconds
[2024-07-18T17:03:20.065+0000] {processor.py:157} INFO - Started process (PID=25092) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:03:20.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T17:03:20.068+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:03:20.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:03:20.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:03:20.095+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:03:20.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:03:20.108+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:03:20.107+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T17:03:20.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T17:03:50.519+0000] {processor.py:157} INFO - Started process (PID=25117) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:03:50.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T17:03:50.524+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:03:50.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:03:50.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:03:50.554+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:03:50.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:03:50.567+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:03:50.567+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T17:03:50.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T17:19:19.030+0000] {processor.py:157} INFO - Started process (PID=25142) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:19:19.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T17:19:19.033+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:19:19.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:19:19.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:19:19.061+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:19:19.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:19:19.072+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:19:19.072+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T17:19:19.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T17:19:49.434+0000] {processor.py:157} INFO - Started process (PID=25167) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:19:49.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T17:19:49.438+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:19:49.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:19:49.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:19:49.473+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:19:49.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:19:49.485+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:19:49.485+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T17:19:49.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-18T17:20:19.886+0000] {processor.py:157} INFO - Started process (PID=25192) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:20:19.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T17:20:19.890+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:20:19.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:20:19.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:20:19.930+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:20:19.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:20:19.941+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:20:19.941+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T17:20:19.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-18T17:20:50.351+0000] {processor.py:157} INFO - Started process (PID=25217) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:20:50.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T17:20:50.354+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:20:50.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:20:50.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:20:50.383+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:20:50.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:20:50.392+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:20:50.392+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T17:20:50.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T17:21:20.811+0000] {processor.py:157} INFO - Started process (PID=25242) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:21:20.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T17:21:20.813+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:21:20.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:21:20.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:21:20.839+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:21:20.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:21:20.850+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:21:20.850+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T17:21:20.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T17:21:51.242+0000] {processor.py:157} INFO - Started process (PID=25267) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:21:51.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T17:21:51.245+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:21:51.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:21:51.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:21:51.276+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:21:51.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:21:51.288+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:21:51.288+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T17:21:51.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T17:37:17.323+0000] {processor.py:157} INFO - Started process (PID=25292) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:37:17.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T17:37:17.332+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:37:17.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:37:17.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:37:17.405+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:37:17.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:37:17.430+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:37:17.430+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T17:37:17.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.148 seconds
[2024-07-18T17:53:02.674+0000] {processor.py:157} INFO - Started process (PID=25319) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:53:02.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T17:53:02.678+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:53:02.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:53:02.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:53:02.707+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:53:02.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:53:02.722+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:53:02.722+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T17:53:02.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-18T17:53:33.149+0000] {processor.py:157} INFO - Started process (PID=25344) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:53:33.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T17:53:33.154+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:53:33.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:53:33.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:53:33.192+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:53:33.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:53:33.204+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:53:33.204+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T17:53:33.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-18T17:54:03.650+0000] {processor.py:157} INFO - Started process (PID=25369) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:54:03.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T17:54:03.652+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:54:03.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:54:03.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T17:54:03.679+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:54:03.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T17:54:03.688+0000] {logging_mixin.py:151} INFO - [2024-07-18T17:54:03.688+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T17:54:03.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-18T18:09:50.309+0000] {processor.py:157} INFO - Started process (PID=25394) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:09:50.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:09:50.316+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:09:50.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:09:50.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:09:50.361+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:09:50.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:09:50.396+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:09:50.396+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:09:50.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.107 seconds
[2024-07-18T18:26:10.965+0000] {processor.py:157} INFO - Started process (PID=25419) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:26:10.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:26:10.970+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:26:10.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:26:10.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:26:11.007+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:26:11.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:26:11.027+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:26:11.027+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:26:11.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-18T18:26:41.537+0000] {processor.py:157} INFO - Started process (PID=25444) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:26:41.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:26:41.543+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:26:41.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:26:41.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:26:41.575+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:26:41.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:26:41.590+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:26:41.589+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:26:41.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-18T18:27:11.955+0000] {processor.py:157} INFO - Started process (PID=25469) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:27:11.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:27:11.958+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:27:11.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:27:11.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:27:11.984+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:27:11.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:27:11.994+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:27:11.994+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:27:12.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T18:27:42.312+0000] {processor.py:157} INFO - Started process (PID=25494) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:27:42.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:27:42.315+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:27:42.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:27:42.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:27:42.341+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:27:42.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:27:42.352+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:27:42.352+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:27:42.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T18:28:12.821+0000] {processor.py:157} INFO - Started process (PID=25519) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:28:12.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:28:12.824+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:28:12.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:28:12.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:28:12.852+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:28:12.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:28:12.862+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:28:12.861+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:28:12.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T18:40:19.741+0000] {processor.py:157} INFO - Started process (PID=25544) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:40:19.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:40:19.745+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:40:19.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:40:19.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:40:19.783+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:40:19.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:40:19.798+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:40:19.798+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:40:19.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-18T18:40:50.346+0000] {processor.py:157} INFO - Started process (PID=25569) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:40:50.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:40:50.369+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:40:50.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:40:50.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:40:50.418+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:40:50.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:40:50.431+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:40:50.431+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:40:50.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.102 seconds
[2024-07-18T18:41:20.835+0000] {processor.py:157} INFO - Started process (PID=25594) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:41:20.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:41:20.837+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:41:20.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:41:20.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:41:20.864+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:41:20.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:41:20.879+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:41:20.879+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:41:20.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T18:41:51.270+0000] {processor.py:157} INFO - Started process (PID=25619) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:41:51.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:41:51.273+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:41:51.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:41:51.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:41:51.303+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:41:51.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:41:51.313+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:41:51.313+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:41:51.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T18:42:21.767+0000] {processor.py:157} INFO - Started process (PID=25644) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:42:21.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:42:21.771+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:42:21.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:42:21.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:42:21.800+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:42:21.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:42:21.811+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:42:21.811+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:42:21.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T18:42:52.229+0000] {processor.py:157} INFO - Started process (PID=25669) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:42:52.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:42:52.236+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:42:52.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:42:52.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:42:52.273+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:42:52.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:42:52.286+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:42:52.286+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:42:52.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-18T18:43:22.713+0000] {processor.py:157} INFO - Started process (PID=25694) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:43:22.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:43:22.715+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:43:22.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:43:22.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:43:22.745+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:43:22.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:43:22.756+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:43:22.756+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:43:22.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T18:43:53.134+0000] {processor.py:157} INFO - Started process (PID=25719) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:43:53.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:43:53.138+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:43:53.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:43:53.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:43:53.165+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:43:53.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:43:53.178+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:43:53.178+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:43:53.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T18:44:23.670+0000] {processor.py:157} INFO - Started process (PID=25744) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:44:23.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:44:23.673+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:44:23.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:44:23.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:44:23.704+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:44:23.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:44:23.715+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:44:23.715+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:44:23.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T18:44:54.217+0000] {processor.py:157} INFO - Started process (PID=25769) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:44:54.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:44:54.222+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:44:54.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:44:54.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:44:54.251+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:44:54.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:44:54.262+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:44:54.262+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:44:54.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T18:45:24.702+0000] {processor.py:157} INFO - Started process (PID=25794) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:45:24.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:45:24.707+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:45:24.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:45:24.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:45:24.731+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:45:24.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:45:24.741+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:45:24.741+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:45:24.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T18:45:55.222+0000] {processor.py:157} INFO - Started process (PID=25819) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:45:55.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:45:55.227+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:45:55.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:45:55.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:45:55.253+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:45:55.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:45:55.263+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:45:55.263+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:45:55.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T18:46:25.688+0000] {processor.py:157} INFO - Started process (PID=25844) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:46:25.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:46:25.693+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:46:25.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:46:25.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:46:25.720+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:46:25.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:46:25.730+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:46:25.730+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:46:25.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T18:46:56.087+0000] {processor.py:157} INFO - Started process (PID=25869) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:46:56.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:46:56.090+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:46:56.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:46:56.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:46:56.121+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:46:56.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:46:56.131+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:46:56.131+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:46:56.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T18:47:26.582+0000] {processor.py:157} INFO - Started process (PID=25894) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:47:26.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:47:26.584+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:47:26.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:47:26.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:47:26.610+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:47:26.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:47:26.621+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:47:26.621+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:47:26.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T18:47:57.011+0000] {processor.py:157} INFO - Started process (PID=25919) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:47:57.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:47:57.014+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:47:57.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:47:57.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:47:57.037+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:47:57.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:47:57.046+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:47:57.046+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:47:57.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-18T18:48:27.517+0000] {processor.py:157} INFO - Started process (PID=25944) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:48:27.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:48:27.520+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:48:27.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:48:27.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:48:27.548+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:48:27.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:48:27.559+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:48:27.559+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:48:27.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T18:48:57.966+0000] {processor.py:157} INFO - Started process (PID=25969) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:48:57.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:48:57.969+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:48:57.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:48:57.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:48:58.000+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:48:58.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:48:58.010+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:48:58.010+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:48:58.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T18:49:28.416+0000] {processor.py:157} INFO - Started process (PID=25994) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:49:28.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:49:28.423+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:49:28.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:49:28.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:49:28.450+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:49:28.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:49:28.462+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:49:28.462+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:49:28.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T18:49:58.919+0000] {processor.py:157} INFO - Started process (PID=26019) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:49:58.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:49:58.922+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:49:58.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:49:58.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:49:58.953+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:49:58.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:49:58.963+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:49:58.963+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:49:58.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T18:50:29.397+0000] {processor.py:157} INFO - Started process (PID=26044) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:50:29.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:50:29.400+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:50:29.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:50:29.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:50:29.428+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:50:29.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:50:29.438+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:50:29.437+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:50:29.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T18:50:59.828+0000] {processor.py:157} INFO - Started process (PID=26069) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:50:59.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:50:59.832+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:50:59.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:50:59.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:50:59.861+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:50:59.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:50:59.871+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:50:59.871+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:50:59.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T18:51:30.269+0000] {processor.py:157} INFO - Started process (PID=26094) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:51:30.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:51:30.272+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:51:30.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:51:30.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:51:30.298+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:51:30.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:51:30.311+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:51:30.311+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:51:30.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T18:52:00.773+0000] {processor.py:157} INFO - Started process (PID=26119) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:52:00.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:52:00.776+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:52:00.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:52:00.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:52:00.806+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:52:00.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:52:00.815+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:52:00.815+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:52:00.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T18:52:31.241+0000] {processor.py:157} INFO - Started process (PID=26144) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:52:31.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:52:31.244+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:52:31.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:52:31.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:52:31.276+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:52:31.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:52:31.286+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:52:31.286+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:52:31.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T18:53:01.722+0000] {processor.py:157} INFO - Started process (PID=26169) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:53:01.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:53:01.725+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:53:01.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:53:01.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:53:01.753+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:53:01.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:53:01.762+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:53:01.762+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:53:01.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T18:53:32.207+0000] {processor.py:157} INFO - Started process (PID=26194) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:53:32.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:53:32.210+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:53:32.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:53:32.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:53:32.241+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:53:32.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:53:32.251+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:53:32.251+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:53:32.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T18:54:02.624+0000] {processor.py:157} INFO - Started process (PID=26219) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:54:02.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:54:02.628+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:54:02.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:54:02.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:54:02.652+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:54:02.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:54:02.662+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:54:02.662+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:54:02.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-18T18:54:33.130+0000] {processor.py:157} INFO - Started process (PID=26244) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:54:33.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:54:33.132+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:54:33.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:54:33.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:54:33.157+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:54:33.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:54:33.166+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:54:33.166+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:54:33.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T18:55:03.627+0000] {processor.py:157} INFO - Started process (PID=26269) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:55:03.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:55:03.630+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:55:03.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:55:03.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:55:03.656+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:55:03.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:55:03.665+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:55:03.665+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:55:03.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T18:55:34.223+0000] {processor.py:157} INFO - Started process (PID=26294) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:55:34.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:55:34.230+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:55:34.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:55:34.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:55:34.315+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:55:34.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:55:34.332+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:55:34.332+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:55:34.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.137 seconds
[2024-07-18T18:56:04.822+0000] {processor.py:157} INFO - Started process (PID=26319) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:56:04.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:56:04.826+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:56:04.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:56:04.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:56:04.856+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:56:04.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:56:04.871+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:56:04.871+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:56:04.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-18T18:56:35.391+0000] {processor.py:157} INFO - Started process (PID=26344) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:56:35.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:56:35.399+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:56:35.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:56:35.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:56:35.431+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:56:35.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:56:35.441+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:56:35.441+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:56:35.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-18T18:57:05.828+0000] {processor.py:157} INFO - Started process (PID=26369) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:57:05.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:57:05.833+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:57:05.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:57:05.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:57:05.862+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:57:05.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:57:05.873+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:57:05.873+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:57:05.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T18:57:36.379+0000] {processor.py:157} INFO - Started process (PID=26394) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:57:36.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:57:36.383+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:57:36.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:57:36.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:57:36.415+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:57:36.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:57:36.429+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:57:36.429+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:57:36.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-18T18:58:06.866+0000] {processor.py:157} INFO - Started process (PID=26419) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:58:06.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:58:06.869+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:58:06.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:58:06.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:58:06.895+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:58:06.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:58:06.907+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:58:06.907+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:58:06.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T18:58:37.322+0000] {processor.py:157} INFO - Started process (PID=26444) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:58:37.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:58:37.325+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:58:37.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:58:37.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:58:37.355+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:58:37.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:58:37.368+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:58:37.368+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:58:37.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T18:59:07.742+0000] {processor.py:157} INFO - Started process (PID=26469) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:59:07.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:59:07.745+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:59:07.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:59:07.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:59:07.778+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:59:07.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:59:07.790+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:59:07.790+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:59:07.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T18:59:38.183+0000] {processor.py:157} INFO - Started process (PID=26494) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:59:38.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T18:59:38.187+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:59:38.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:59:38.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T18:59:38.220+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:59:38.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T18:59:38.230+0000] {logging_mixin.py:151} INFO - [2024-07-18T18:59:38.230+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T18:59:38.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T19:00:08.606+0000] {processor.py:157} INFO - Started process (PID=26519) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:00:08.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:00:08.609+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:00:08.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:00:08.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:00:08.640+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:00:08.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:00:08.650+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:00:08.650+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:00:08.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T19:00:39.016+0000] {processor.py:157} INFO - Started process (PID=26544) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:00:39.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:00:39.018+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:00:39.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:00:39.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:00:39.045+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:00:39.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:00:39.058+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:00:39.058+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:00:39.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T19:01:09.488+0000] {processor.py:157} INFO - Started process (PID=26569) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:01:09.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:01:09.493+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:01:09.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:01:09.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:01:09.521+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:01:09.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:01:09.532+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:01:09.531+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:01:09.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T19:01:39.861+0000] {processor.py:157} INFO - Started process (PID=26594) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:01:39.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:01:39.865+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:01:39.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:01:39.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:01:39.893+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:01:39.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:01:39.903+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:01:39.903+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:01:39.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T19:02:10.378+0000] {processor.py:157} INFO - Started process (PID=26619) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:02:10.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:02:10.380+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:02:10.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:02:10.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:02:10.409+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:02:10.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:02:10.419+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:02:10.419+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:02:10.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T19:02:40.833+0000] {processor.py:157} INFO - Started process (PID=26644) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:02:40.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:02:40.837+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:02:40.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:02:40.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:02:40.865+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:02:40.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:02:40.875+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:02:40.875+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:02:40.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T19:03:11.301+0000] {processor.py:157} INFO - Started process (PID=26669) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:03:11.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:03:11.305+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:03:11.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:03:11.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:03:11.335+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:03:11.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:03:11.346+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:03:11.346+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:03:11.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T19:03:41.779+0000] {processor.py:157} INFO - Started process (PID=26694) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:03:41.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:03:41.783+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:03:41.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:03:41.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:03:41.811+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:03:41.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:03:41.824+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:03:41.824+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:03:41.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T19:04:12.218+0000] {processor.py:157} INFO - Started process (PID=26719) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:04:12.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:04:12.221+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:04:12.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:04:12.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:04:12.251+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:04:12.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:04:12.263+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:04:12.263+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:04:12.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T19:04:42.774+0000] {processor.py:157} INFO - Started process (PID=26744) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:04:42.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:04:42.779+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:04:42.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:04:42.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:04:42.806+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:04:42.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:04:42.817+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:04:42.817+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:04:42.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T19:05:13.190+0000] {processor.py:157} INFO - Started process (PID=26769) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:05:13.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:05:13.193+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:05:13.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:05:13.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:05:13.221+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:05:13.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:05:13.232+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:05:13.232+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:05:13.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T19:05:43.722+0000] {processor.py:157} INFO - Started process (PID=26794) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:05:43.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:05:43.726+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:05:43.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:05:43.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:05:43.752+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:05:43.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:05:43.763+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:05:43.763+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:05:43.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T19:06:14.108+0000] {processor.py:157} INFO - Started process (PID=26819) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:06:14.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:06:14.111+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:06:14.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:06:14.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:06:14.132+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:06:14.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:06:14.143+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:06:14.143+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:06:14.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-18T19:06:44.549+0000] {processor.py:157} INFO - Started process (PID=26844) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:06:44.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:06:44.554+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:06:44.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:06:44.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:06:44.588+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:06:44.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:06:44.598+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:06:44.598+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:06:44.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T19:07:15.025+0000] {processor.py:157} INFO - Started process (PID=26869) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:07:15.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:07:15.029+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:07:15.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:07:15.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:07:15.061+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:07:15.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:07:15.072+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:07:15.072+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:07:15.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T19:07:45.467+0000] {processor.py:157} INFO - Started process (PID=26894) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:07:45.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:07:45.472+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:07:45.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:07:45.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:07:45.510+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:07:45.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:07:45.521+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:07:45.521+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:07:45.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-18T19:08:15.977+0000] {processor.py:157} INFO - Started process (PID=26919) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:08:15.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:08:15.980+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:08:15.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:08:15.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:08:16.010+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:08:16.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:08:16.020+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:08:16.020+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:08:16.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T19:08:46.430+0000] {processor.py:157} INFO - Started process (PID=26944) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:08:46.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:08:46.433+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:08:46.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:08:46.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:08:46.466+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:08:46.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:08:46.476+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:08:46.476+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:08:46.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T19:09:16.896+0000] {processor.py:157} INFO - Started process (PID=26969) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:09:16.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:09:16.899+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:09:16.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:09:16.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:09:16.929+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:09:16.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:09:16.939+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:09:16.939+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:09:16.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T19:09:47.398+0000] {processor.py:157} INFO - Started process (PID=26994) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:09:47.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:09:47.400+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:09:47.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:09:47.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:09:47.429+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:09:47.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:09:47.439+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:09:47.439+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:09:47.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T19:10:17.885+0000] {processor.py:157} INFO - Started process (PID=27019) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:10:17.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:10:17.888+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:10:17.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:10:17.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:10:17.919+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:10:17.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:10:17.928+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:10:17.928+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:10:17.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T19:10:48.336+0000] {processor.py:157} INFO - Started process (PID=27044) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:10:48.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:10:48.340+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:10:48.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:10:48.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:10:48.369+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:10:48.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:10:48.380+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:10:48.380+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:10:48.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T19:11:18.820+0000] {processor.py:157} INFO - Started process (PID=27069) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:11:18.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:11:18.826+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:11:18.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:11:18.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:11:18.854+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:11:18.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:11:18.864+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:11:18.864+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:11:18.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T19:11:49.287+0000] {processor.py:157} INFO - Started process (PID=27094) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:11:49.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:11:49.291+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:11:49.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:11:49.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:11:49.316+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:11:49.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:11:49.326+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:11:49.326+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:11:49.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T19:12:19.787+0000] {processor.py:157} INFO - Started process (PID=27119) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:12:19.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:12:19.790+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:12:19.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:12:19.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:12:19.819+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:12:19.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:12:19.829+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:12:19.829+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:12:19.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T19:12:50.245+0000] {processor.py:157} INFO - Started process (PID=27144) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:12:50.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:12:50.248+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:12:50.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:12:50.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:12:50.278+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:12:50.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:12:50.290+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:12:50.290+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:12:50.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T19:13:20.770+0000] {processor.py:157} INFO - Started process (PID=27169) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:13:20.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:13:20.774+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:13:20.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:13:20.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:13:20.801+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:13:20.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:13:20.811+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:13:20.811+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:13:20.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T19:13:51.204+0000] {processor.py:157} INFO - Started process (PID=27194) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:13:51.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:13:51.208+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:13:51.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:13:51.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:13:51.239+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:13:51.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:13:51.249+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:13:51.249+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:13:51.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T19:14:21.633+0000] {processor.py:157} INFO - Started process (PID=27219) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:14:21.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:14:21.637+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:14:21.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:14:21.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:14:21.665+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:14:21.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:14:21.674+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:14:21.674+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:14:21.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T19:14:52.071+0000] {processor.py:157} INFO - Started process (PID=27244) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:14:52.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:14:52.077+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:14:52.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:14:52.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:14:52.104+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:14:52.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:14:52.114+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:14:52.114+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:14:52.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T19:15:22.555+0000] {processor.py:157} INFO - Started process (PID=27269) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:15:22.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:15:22.559+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:15:22.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:15:22.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:15:22.583+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:15:22.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:15:22.594+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:15:22.594+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:15:22.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-18T19:15:53.030+0000] {processor.py:157} INFO - Started process (PID=27294) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:15:53.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:15:53.033+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:15:53.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:15:53.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:15:53.061+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:15:53.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:15:53.074+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:15:53.074+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:15:53.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T19:16:23.451+0000] {processor.py:157} INFO - Started process (PID=27319) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:16:23.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:16:23.455+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:16:23.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:16:23.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:16:23.481+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:16:23.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:16:23.493+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:16:23.493+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:16:23.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T19:16:53.850+0000] {processor.py:157} INFO - Started process (PID=27344) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:16:53.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:16:53.853+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:16:53.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:16:53.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:16:53.882+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:16:53.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:16:53.892+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:16:53.892+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:16:53.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T19:17:24.331+0000] {processor.py:157} INFO - Started process (PID=27369) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:17:24.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:17:24.334+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:17:24.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:17:24.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:17:24.365+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:17:24.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:17:24.374+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:17:24.374+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:17:24.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T19:17:54.795+0000] {processor.py:157} INFO - Started process (PID=27394) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:17:54.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:17:54.801+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:17:54.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:17:54.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:17:54.836+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:17:54.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:17:54.846+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:17:54.845+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:17:54.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-18T19:18:25.292+0000] {processor.py:157} INFO - Started process (PID=27419) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:18:25.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:18:25.297+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:18:25.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:18:25.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:18:25.334+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:18:25.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:18:25.347+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:18:25.347+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:18:25.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-18T19:18:55.804+0000] {processor.py:157} INFO - Started process (PID=27444) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:18:55.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:18:55.807+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:18:55.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:18:55.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:18:55.837+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:18:55.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:18:55.847+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:18:55.847+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:18:55.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T19:19:26.299+0000] {processor.py:157} INFO - Started process (PID=27469) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:19:26.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:19:26.302+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:19:26.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:19:26.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:19:26.327+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:19:26.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:19:26.337+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:19:26.337+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:19:26.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T19:19:56.756+0000] {processor.py:157} INFO - Started process (PID=27494) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:19:56.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:19:56.759+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:19:56.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:19:56.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:19:56.788+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:19:56.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:19:56.801+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:19:56.801+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:19:56.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T19:20:27.242+0000] {processor.py:157} INFO - Started process (PID=27519) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:20:27.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:20:27.244+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:20:27.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:20:27.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:20:27.269+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:20:27.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:20:27.279+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:20:27.279+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:20:27.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-18T19:20:57.683+0000] {processor.py:157} INFO - Started process (PID=27544) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:20:57.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:20:57.686+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:20:57.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:20:57.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:20:57.718+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:20:57.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:20:57.730+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:20:57.730+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:20:57.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T19:21:28.171+0000] {processor.py:157} INFO - Started process (PID=27569) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:21:28.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:21:28.176+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:21:28.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:21:28.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:21:28.203+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:21:28.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:21:28.214+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:21:28.214+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:21:28.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T19:21:58.546+0000] {processor.py:157} INFO - Started process (PID=27594) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:21:58.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:21:58.550+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:21:58.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:21:58.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:21:58.580+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:21:58.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:21:58.590+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:21:58.589+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:21:58.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T19:22:29.004+0000] {processor.py:157} INFO - Started process (PID=27619) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:22:29.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:22:29.007+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:22:29.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:22:29.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:22:29.033+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:22:29.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:22:29.042+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:22:29.042+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:22:29.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T19:22:59.494+0000] {processor.py:157} INFO - Started process (PID=27644) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:22:59.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:22:59.496+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:22:59.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:22:59.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:22:59.523+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:22:59.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:22:59.535+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:22:59.534+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:22:59.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T19:23:29.902+0000] {processor.py:157} INFO - Started process (PID=27669) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:23:29.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:23:29.905+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:23:29.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:23:29.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:23:29.931+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:23:29.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:23:29.946+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:23:29.946+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:23:29.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T19:24:00.356+0000] {processor.py:157} INFO - Started process (PID=27694) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:24:00.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:24:00.359+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:24:00.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:24:00.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:24:00.385+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:24:00.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:24:00.395+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:24:00.395+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:24:00.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T19:24:30.881+0000] {processor.py:157} INFO - Started process (PID=27719) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:24:30.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:24:30.885+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:24:30.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:24:30.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:24:30.912+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:24:30.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:24:30.924+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:24:30.924+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:24:30.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T19:25:01.383+0000] {processor.py:157} INFO - Started process (PID=27744) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:25:01.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:25:01.387+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:25:01.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:25:01.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:25:01.415+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:25:01.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:25:01.427+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:25:01.427+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:25:01.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T19:25:31.884+0000] {processor.py:157} INFO - Started process (PID=27769) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:25:31.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:25:31.888+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:25:31.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:25:31.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:25:31.916+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:25:31.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:25:31.929+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:25:31.929+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:25:31.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-18T19:26:02.338+0000] {processor.py:157} INFO - Started process (PID=27794) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:26:02.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:26:02.341+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:26:02.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:26:02.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:26:02.369+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:26:02.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:26:02.378+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:26:02.378+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:26:02.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T19:26:32.786+0000] {processor.py:157} INFO - Started process (PID=27819) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:26:32.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:26:32.790+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:26:32.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:26:32.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:26:32.820+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:26:32.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:26:32.831+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:26:32.831+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:26:32.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T19:27:03.241+0000] {processor.py:157} INFO - Started process (PID=27844) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:27:03.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:27:03.245+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:27:03.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:27:03.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:27:03.277+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:27:03.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:27:03.287+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:27:03.287+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:27:03.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T19:27:33.734+0000] {processor.py:157} INFO - Started process (PID=27869) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:27:33.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:27:33.737+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:27:33.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:27:33.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:27:33.763+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:27:33.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:27:33.772+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:27:33.772+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:27:33.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T19:28:04.223+0000] {processor.py:157} INFO - Started process (PID=27894) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:28:04.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:28:04.228+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:28:04.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:28:04.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:28:04.256+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:28:04.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:28:04.267+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:28:04.267+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:28:04.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T19:28:34.705+0000] {processor.py:157} INFO - Started process (PID=27919) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:28:34.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:28:34.709+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:28:34.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:28:34.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:28:34.738+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:28:34.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:28:34.749+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:28:34.749+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:28:34.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T19:29:05.166+0000] {processor.py:157} INFO - Started process (PID=27944) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:29:05.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:29:05.169+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:29:05.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:29:05.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:29:05.192+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:29:05.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:29:05.202+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:29:05.202+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:29:05.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-18T19:29:35.587+0000] {processor.py:157} INFO - Started process (PID=27969) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:29:35.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:29:35.592+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:29:35.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:29:35.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:29:35.617+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:29:35.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:29:35.627+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:29:35.627+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:29:35.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T19:30:06.087+0000] {processor.py:157} INFO - Started process (PID=27994) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:30:06.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:30:06.090+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:30:06.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:30:06.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:30:06.116+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:30:06.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:30:06.127+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:30:06.127+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:30:06.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T19:30:36.606+0000] {processor.py:157} INFO - Started process (PID=28019) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:30:36.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:30:36.609+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:30:36.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:30:36.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:30:36.638+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:30:36.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:30:36.648+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:30:36.648+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:30:36.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T19:31:07.054+0000] {processor.py:157} INFO - Started process (PID=28044) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:31:07.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:31:07.059+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:31:07.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:31:07.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:31:07.093+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:31:07.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:31:07.103+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:31:07.102+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:31:07.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-18T19:31:37.522+0000] {processor.py:157} INFO - Started process (PID=28069) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:31:37.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:31:37.527+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:31:37.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:31:37.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:31:37.557+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:31:37.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:31:37.569+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:31:37.569+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:31:37.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T19:32:07.988+0000] {processor.py:157} INFO - Started process (PID=28094) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:32:07.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:32:07.991+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:32:07.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:32:08.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:32:08.020+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:32:08.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:32:08.035+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:32:08.035+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:32:08.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T19:32:38.484+0000] {processor.py:157} INFO - Started process (PID=28119) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:32:38.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:32:38.487+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:32:38.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:32:38.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:32:38.511+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:32:38.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:32:38.521+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:32:38.521+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:32:38.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-18T19:33:08.995+0000] {processor.py:157} INFO - Started process (PID=28144) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:33:08.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:33:09.000+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:33:09.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:33:09.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:33:09.028+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:33:09.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:33:09.038+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:33:09.038+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:33:09.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T19:33:39.454+0000] {processor.py:157} INFO - Started process (PID=28169) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:33:39.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:33:39.457+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:33:39.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:33:39.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:33:39.482+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:33:39.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:33:39.492+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:33:39.492+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:33:39.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T19:34:09.883+0000] {processor.py:157} INFO - Started process (PID=28194) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:34:09.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:34:09.886+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:34:09.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:34:09.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:34:09.921+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:34:09.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:34:09.933+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:34:09.933+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:34:09.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-18T19:34:40.393+0000] {processor.py:157} INFO - Started process (PID=28219) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:34:40.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:34:40.396+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:34:40.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:34:40.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:34:40.430+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:34:40.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:34:40.440+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:34:40.440+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:34:40.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T19:35:10.836+0000] {processor.py:157} INFO - Started process (PID=28244) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:35:10.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:35:10.839+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:35:10.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:35:10.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:35:10.871+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:35:10.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:35:10.883+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:35:10.883+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:35:10.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T19:35:41.300+0000] {processor.py:157} INFO - Started process (PID=28269) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:35:41.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:35:41.304+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:35:41.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:35:41.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:35:41.329+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:35:41.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:35:41.340+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:35:41.340+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:35:41.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T19:36:11.753+0000] {processor.py:157} INFO - Started process (PID=28294) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:36:11.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:36:11.758+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:36:11.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:36:11.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:36:11.786+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:36:11.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:36:11.797+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:36:11.797+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:36:11.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T19:36:42.183+0000] {processor.py:157} INFO - Started process (PID=28319) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:36:42.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:36:42.188+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:36:42.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:36:42.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:36:42.218+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:36:42.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:36:42.228+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:36:42.228+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:36:42.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T19:37:12.600+0000] {processor.py:157} INFO - Started process (PID=28344) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:37:12.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:37:12.602+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:37:12.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:37:12.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:37:12.631+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:37:12.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:37:12.645+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:37:12.645+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:37:12.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T19:37:42.987+0000] {processor.py:157} INFO - Started process (PID=28369) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:37:42.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:37:42.990+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:37:42.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:37:43.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:37:43.019+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:37:43.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:37:43.031+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:37:43.031+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:37:43.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T19:38:13.452+0000] {processor.py:157} INFO - Started process (PID=28394) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:38:13.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:38:13.456+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:38:13.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:38:13.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:38:13.483+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:38:13.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:38:13.493+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:38:13.493+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:38:13.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T19:38:43.852+0000] {processor.py:157} INFO - Started process (PID=28419) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:38:43.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:38:43.857+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:38:43.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:38:43.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:38:43.886+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:38:43.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:38:43.896+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:38:43.896+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:38:43.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T19:39:14.283+0000] {processor.py:157} INFO - Started process (PID=28444) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:39:14.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:39:14.287+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:39:14.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:39:14.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:39:14.317+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:39:14.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:39:14.327+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:39:14.327+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:39:14.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T19:39:44.687+0000] {processor.py:157} INFO - Started process (PID=28469) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:39:44.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:39:44.694+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:39:44.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:39:44.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:39:44.726+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:39:44.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:39:44.738+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:39:44.738+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:39:44.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T19:40:15.160+0000] {processor.py:157} INFO - Started process (PID=28494) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:40:15.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:40:15.164+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:40:15.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:40:15.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:40:15.194+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:40:15.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:40:15.204+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:40:15.204+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:40:15.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T19:40:45.633+0000] {processor.py:157} INFO - Started process (PID=28519) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:40:45.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:40:45.636+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:40:45.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:40:45.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:40:45.665+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:40:45.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:40:45.675+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:40:45.675+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:40:45.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T19:41:19.127+0000] {processor.py:157} INFO - Started process (PID=28546) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:41:19.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:41:19.129+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:41:19.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:41:19.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:41:19.153+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:41:19.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:41:19.162+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:41:19.162+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:41:19.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-18T19:41:49.605+0000] {processor.py:157} INFO - Started process (PID=28571) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:41:49.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:41:49.610+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:41:49.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:41:49.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:41:49.637+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:41:49.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:41:49.650+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:41:49.650+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:41:49.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T19:57:57.460+0000] {processor.py:157} INFO - Started process (PID=28596) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:57:57.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:57:57.463+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:57:57.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:57:57.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:57:57.505+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:57:57.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:57:57.515+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:57:57.515+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:57:57.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-18T19:58:28.108+0000] {processor.py:157} INFO - Started process (PID=28621) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:58:28.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:58:28.113+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:58:28.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:58:28.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:58:28.149+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:58:28.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:58:28.160+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:58:28.160+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:58:28.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-18T19:58:58.607+0000] {processor.py:157} INFO - Started process (PID=28646) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:58:58.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:58:58.612+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:58:58.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:58:58.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:58:58.639+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:58:58.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:58:58.649+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:58:58.649+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:58:58.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T19:59:29.133+0000] {processor.py:157} INFO - Started process (PID=28671) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:59:29.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:59:29.136+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:59:29.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:59:29.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:59:29.164+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:59:29.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:59:29.174+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:59:29.174+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:59:29.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T19:59:59.561+0000] {processor.py:157} INFO - Started process (PID=28696) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:59:59.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T19:59:59.565+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:59:59.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:59:59.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T19:59:59.593+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:59:59.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T19:59:59.603+0000] {logging_mixin.py:151} INFO - [2024-07-18T19:59:59.602+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T19:59:59.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T20:00:30.038+0000] {processor.py:157} INFO - Started process (PID=28721) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:00:30.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:00:30.046+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:00:30.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:00:30.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:00:30.083+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:00:30.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:00:30.095+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:00:30.094+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:00:30.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-18T20:01:00.481+0000] {processor.py:157} INFO - Started process (PID=28746) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:01:00.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:01:00.485+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:01:00.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:01:00.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:01:00.512+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:01:00.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:01:00.526+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:01:00.526+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:01:00.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T20:16:46.721+0000] {processor.py:157} INFO - Started process (PID=28773) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:16:46.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:16:46.733+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:16:46.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:16:46.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:16:46.781+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:16:46.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:16:46.800+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:16:46.800+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:16:46.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.107 seconds
[2024-07-18T20:17:17.223+0000] {processor.py:157} INFO - Started process (PID=28798) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:17:17.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:17:17.228+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:17:17.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:17:17.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:17:17.265+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:17:17.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:17:17.276+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:17:17.276+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:17:17.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-18T20:17:47.577+0000] {processor.py:157} INFO - Started process (PID=28823) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:17:47.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:17:47.585+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:17:47.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:17:47.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:17:47.611+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:17:47.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:17:47.622+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:17:47.622+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:17:47.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T20:18:18.097+0000] {processor.py:157} INFO - Started process (PID=28848) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:18:18.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:18:18.101+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:18:18.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:18:18.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:18:18.132+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:18:18.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:18:18.142+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:18:18.142+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:18:18.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T20:34:02.178+0000] {processor.py:157} INFO - Started process (PID=28873) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:34:02.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:34:02.185+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:34:02.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:34:02.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:34:02.261+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:34:02.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:34:02.279+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:34:02.279+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:34:02.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.131 seconds
[2024-07-18T20:34:32.719+0000] {processor.py:157} INFO - Started process (PID=28898) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:34:32.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:34:32.724+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:34:32.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:34:32.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:34:32.752+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:34:32.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:34:32.765+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:34:32.765+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:34:32.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T20:35:03.211+0000] {processor.py:157} INFO - Started process (PID=28923) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:35:03.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:35:03.217+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:35:03.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:35:03.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:35:03.246+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:35:03.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:35:03.263+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:35:03.263+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:35:03.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-18T20:35:33.701+0000] {processor.py:157} INFO - Started process (PID=28948) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:35:33.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:35:33.706+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:35:33.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:35:33.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:35:33.735+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:35:33.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:35:33.745+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:35:33.745+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:35:33.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T20:36:04.136+0000] {processor.py:157} INFO - Started process (PID=28973) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:36:04.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:36:04.141+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:36:04.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:36:04.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:36:04.173+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:36:04.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:36:04.186+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:36:04.186+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:36:04.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-18T20:36:34.661+0000] {processor.py:157} INFO - Started process (PID=28998) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:36:34.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:36:34.666+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:36:34.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:36:34.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:36:34.697+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:36:34.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:36:34.710+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:36:34.710+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:36:34.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-18T20:37:05.107+0000] {processor.py:157} INFO - Started process (PID=29023) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:37:05.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:37:05.110+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:37:05.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:37:05.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:37:05.137+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:37:05.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:37:05.149+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:37:05.148+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:37:05.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T20:37:35.575+0000] {processor.py:157} INFO - Started process (PID=29048) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:37:35.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:37:35.578+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:37:35.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:37:35.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:37:35.604+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:37:35.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:37:35.616+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:37:35.616+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:37:35.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T20:38:06.070+0000] {processor.py:157} INFO - Started process (PID=29073) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:38:06.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:38:06.074+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:38:06.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:38:06.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:38:06.110+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:38:06.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:38:06.123+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:38:06.123+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:38:06.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-18T20:38:36.614+0000] {processor.py:157} INFO - Started process (PID=29098) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:38:36.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:38:36.620+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:38:36.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:38:36.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:38:36.647+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:38:36.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:38:36.657+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:38:36.657+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:38:36.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T20:39:07.132+0000] {processor.py:157} INFO - Started process (PID=29123) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:39:07.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:39:07.135+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:39:07.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:39:07.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:39:07.161+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:39:07.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:39:07.174+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:39:07.174+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:39:07.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T20:39:37.618+0000] {processor.py:157} INFO - Started process (PID=29148) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:39:37.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:39:37.622+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:39:37.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:39:37.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:39:37.650+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:39:37.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:39:37.662+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:39:37.662+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:39:37.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T20:40:08.003+0000] {processor.py:157} INFO - Started process (PID=29173) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:40:08.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:40:08.007+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:40:08.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:40:08.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:40:08.031+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:40:08.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:40:08.043+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:40:08.043+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:40:08.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T20:40:38.458+0000] {processor.py:157} INFO - Started process (PID=29198) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:40:38.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:40:38.461+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:40:38.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:40:38.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:40:38.490+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:40:38.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:40:38.502+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:40:38.502+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:40:38.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T20:41:08.893+0000] {processor.py:157} INFO - Started process (PID=29223) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:41:08.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:41:08.896+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:41:08.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:41:08.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:41:08.923+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:41:08.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:41:08.935+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:41:08.934+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:41:08.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T20:41:39.297+0000] {processor.py:157} INFO - Started process (PID=29248) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:41:39.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:41:39.301+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:41:39.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:41:39.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:41:39.330+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:41:39.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:41:39.342+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:41:39.342+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:41:39.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T20:42:09.785+0000] {processor.py:157} INFO - Started process (PID=29273) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:42:09.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:42:09.789+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:42:09.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:42:09.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:42:09.821+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:42:09.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:42:09.836+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:42:09.836+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:42:09.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-18T20:42:40.287+0000] {processor.py:157} INFO - Started process (PID=29298) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:42:40.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:42:40.292+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:42:40.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:42:40.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:42:40.325+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:42:40.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:42:40.334+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:42:40.334+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:42:40.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T20:43:10.695+0000] {processor.py:157} INFO - Started process (PID=29323) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:43:10.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:43:10.698+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:43:10.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:43:10.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:43:10.726+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:43:10.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:43:10.741+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:43:10.741+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:43:10.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T20:43:41.175+0000] {processor.py:157} INFO - Started process (PID=29348) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:43:41.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:43:41.180+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:43:41.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:43:41.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:43:41.215+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:43:41.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:43:41.228+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:43:41.228+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:43:41.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-18T20:44:11.694+0000] {processor.py:157} INFO - Started process (PID=29373) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:44:11.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:44:11.700+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:44:11.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:44:11.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:44:11.729+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:44:11.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:44:11.742+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:44:11.742+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:44:11.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T20:44:42.135+0000] {processor.py:157} INFO - Started process (PID=29398) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:44:42.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:44:42.140+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:44:42.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:44:42.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:44:42.168+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:44:42.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:44:42.178+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:44:42.178+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:44:42.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T20:45:12.565+0000] {processor.py:157} INFO - Started process (PID=29423) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:45:12.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:45:12.569+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:45:12.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:45:12.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:45:12.596+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:45:12.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:45:12.609+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:45:12.609+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:45:12.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T20:45:42.947+0000] {processor.py:157} INFO - Started process (PID=29448) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:45:42.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:45:42.949+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:45:42.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:45:42.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:45:42.979+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:45:42.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:45:42.988+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:45:42.988+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:45:42.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T20:46:13.441+0000] {processor.py:157} INFO - Started process (PID=29473) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:46:13.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:46:13.445+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:46:13.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:46:13.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:46:13.470+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:46:13.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:46:13.483+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:46:13.483+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:46:13.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T20:46:43.922+0000] {processor.py:157} INFO - Started process (PID=29498) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:46:43.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:46:43.929+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:46:43.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:46:43.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:46:43.966+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:46:43.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:46:43.977+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:46:43.977+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:46:43.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-18T20:47:14.380+0000] {processor.py:157} INFO - Started process (PID=29523) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:47:14.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:47:14.384+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:47:14.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:47:14.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:47:14.415+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:47:14.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:47:14.425+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:47:14.425+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:47:14.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T20:47:44.832+0000] {processor.py:157} INFO - Started process (PID=29548) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:47:44.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:47:44.838+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:47:44.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:47:44.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:47:44.866+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:47:44.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:47:44.876+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:47:44.876+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:47:44.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T20:48:15.276+0000] {processor.py:157} INFO - Started process (PID=29573) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:48:15.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:48:15.280+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:48:15.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:48:15.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:48:15.306+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:48:15.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:48:15.316+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:48:15.316+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:48:15.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T20:48:45.854+0000] {processor.py:157} INFO - Started process (PID=29598) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:48:45.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:48:45.856+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:48:45.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:48:45.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:48:45.883+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:48:45.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:48:45.894+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:48:45.894+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:48:45.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T20:49:16.370+0000] {processor.py:157} INFO - Started process (PID=29623) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:49:16.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:49:16.373+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:49:16.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:49:16.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:49:16.399+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:49:16.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:49:16.409+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:49:16.409+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:49:16.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T20:49:46.806+0000] {processor.py:157} INFO - Started process (PID=29648) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:49:46.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:49:46.812+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:49:46.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:49:46.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:49:46.841+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:49:46.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:49:46.854+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:49:46.854+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:49:46.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T20:50:17.189+0000] {processor.py:157} INFO - Started process (PID=29673) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:50:17.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:50:17.194+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:50:17.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:50:17.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:50:17.222+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:50:17.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:50:17.233+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:50:17.232+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:50:17.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T20:50:47.673+0000] {processor.py:157} INFO - Started process (PID=29698) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:50:47.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:50:47.676+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:50:47.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:50:47.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:50:47.706+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:50:47.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:50:47.717+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:50:47.716+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:50:47.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T20:51:18.131+0000] {processor.py:157} INFO - Started process (PID=29723) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:51:18.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:51:18.135+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:51:18.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:51:18.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:51:18.161+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:51:18.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:51:18.171+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:51:18.171+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:51:18.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T20:51:48.562+0000] {processor.py:157} INFO - Started process (PID=29748) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:51:48.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:51:48.566+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:51:48.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:51:48.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:51:48.594+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:51:48.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:51:48.606+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:51:48.606+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:51:48.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T20:52:19.013+0000] {processor.py:157} INFO - Started process (PID=29773) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:52:19.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:52:19.017+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:52:19.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:52:19.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:52:19.043+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:52:19.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:52:19.052+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:52:19.052+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:52:19.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T20:52:49.474+0000] {processor.py:157} INFO - Started process (PID=29798) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:52:49.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:52:49.478+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:52:49.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:52:49.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:52:49.504+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:52:49.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:52:49.514+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:52:49.514+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:52:49.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T20:53:19.891+0000] {processor.py:157} INFO - Started process (PID=29823) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:53:19.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:53:19.895+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:53:19.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:53:19.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:53:19.922+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:53:19.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:53:19.932+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:53:19.932+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:53:19.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T20:53:50.284+0000] {processor.py:157} INFO - Started process (PID=29848) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:53:50.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:53:50.289+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:53:50.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:53:50.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:53:50.320+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:53:50.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:53:50.330+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:53:50.330+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:53:50.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T20:54:20.791+0000] {processor.py:157} INFO - Started process (PID=29873) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:54:20.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:54:20.796+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:54:20.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:54:20.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:54:20.826+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:54:20.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:54:20.837+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:54:20.837+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:54:20.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T20:54:51.293+0000] {processor.py:157} INFO - Started process (PID=29898) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:54:51.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:54:51.299+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:54:51.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:54:51.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:54:51.333+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:54:51.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:54:51.345+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:54:51.345+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:54:51.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-18T20:55:21.834+0000] {processor.py:157} INFO - Started process (PID=29923) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:55:21.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:55:21.838+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:55:21.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:55:21.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:55:21.868+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:55:21.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:55:21.879+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:55:21.879+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:55:21.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T20:55:52.323+0000] {processor.py:157} INFO - Started process (PID=29948) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:55:52.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:55:52.326+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:55:52.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:55:52.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:55:52.353+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:55:52.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:55:52.367+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:55:52.367+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:55:52.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T20:56:22.877+0000] {processor.py:157} INFO - Started process (PID=29973) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:56:22.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:56:22.880+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:56:22.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:56:22.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:56:22.911+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:56:22.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:56:22.922+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:56:22.922+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:56:22.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T20:56:53.369+0000] {processor.py:157} INFO - Started process (PID=29998) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:56:53.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:56:53.374+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:56:53.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:56:53.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:56:53.402+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:56:53.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:56:53.414+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:56:53.414+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:56:53.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T20:57:23.908+0000] {processor.py:157} INFO - Started process (PID=30023) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:57:23.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:57:23.912+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:57:23.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:57:23.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:57:23.941+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:57:23.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:57:23.951+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:57:23.951+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:57:23.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T20:57:54.331+0000] {processor.py:157} INFO - Started process (PID=30048) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:57:54.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:57:54.336+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:57:54.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:57:54.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:57:54.364+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:57:54.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:57:54.374+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:57:54.374+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:57:54.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T20:58:24.738+0000] {processor.py:157} INFO - Started process (PID=30073) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:58:24.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:58:24.744+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:58:24.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:58:24.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:58:24.771+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:58:24.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:58:24.781+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:58:24.781+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:58:24.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T20:58:55.230+0000] {processor.py:157} INFO - Started process (PID=30098) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:58:55.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:58:55.233+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:58:55.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:58:55.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:58:55.263+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:58:55.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:58:55.273+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:58:55.273+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:58:55.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T20:59:25.715+0000] {processor.py:157} INFO - Started process (PID=30123) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:59:25.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:59:25.720+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:59:25.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:59:25.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:59:25.747+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:59:25.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:59:25.756+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:59:25.756+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:59:25.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T20:59:56.187+0000] {processor.py:157} INFO - Started process (PID=30148) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:59:56.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T20:59:56.190+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:59:56.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:59:56.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T20:59:56.217+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:59:56.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T20:59:56.228+0000] {logging_mixin.py:151} INFO - [2024-07-18T20:59:56.228+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T20:59:56.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T21:00:26.667+0000] {processor.py:157} INFO - Started process (PID=30173) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:00:26.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:00:26.674+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:00:26.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:00:26.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:00:26.699+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:00:26.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:00:26.708+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:00:26.708+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:00:26.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T21:00:57.124+0000] {processor.py:157} INFO - Started process (PID=30198) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:00:57.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:00:57.128+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:00:57.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:00:57.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:00:57.159+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:00:57.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:00:57.170+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:00:57.170+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:00:57.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T21:01:27.602+0000] {processor.py:157} INFO - Started process (PID=30223) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:01:27.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:01:27.606+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:01:27.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:01:27.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:01:27.631+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:01:27.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:01:27.644+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:01:27.644+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:01:27.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T21:01:58.090+0000] {processor.py:157} INFO - Started process (PID=30248) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:01:58.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:01:58.096+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:01:58.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:01:58.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:01:58.127+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:01:58.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:01:58.139+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:01:58.139+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:01:58.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-18T21:02:28.512+0000] {processor.py:157} INFO - Started process (PID=30273) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:02:28.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:02:28.517+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:02:28.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:02:28.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:02:28.554+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:02:28.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:02:28.565+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:02:28.565+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:02:28.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-18T21:02:59.011+0000] {processor.py:157} INFO - Started process (PID=30298) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:02:59.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:02:59.014+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:02:59.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:02:59.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:02:59.043+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:02:59.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:02:59.052+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:02:59.052+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:02:59.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T21:03:29.433+0000] {processor.py:157} INFO - Started process (PID=30323) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:03:29.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:03:29.437+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:03:29.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:03:29.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:03:29.463+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:03:29.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:03:29.475+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:03:29.475+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:03:29.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T21:03:59.835+0000] {processor.py:157} INFO - Started process (PID=30348) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:03:59.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:03:59.841+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:03:59.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:03:59.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:03:59.871+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:03:59.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:03:59.884+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:03:59.884+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:03:59.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T21:04:30.359+0000] {processor.py:157} INFO - Started process (PID=30373) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:04:30.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:04:30.366+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:04:30.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:04:30.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:04:30.396+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:04:30.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:04:30.408+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:04:30.408+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:04:30.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T21:05:00.849+0000] {processor.py:157} INFO - Started process (PID=30398) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:05:00.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:05:00.852+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:05:00.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:05:00.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:05:00.877+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:05:00.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:05:00.888+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:05:00.888+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:05:00.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T21:05:31.368+0000] {processor.py:157} INFO - Started process (PID=30423) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:05:31.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:05:31.373+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:05:31.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:05:31.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:05:31.399+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:05:31.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:05:31.412+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:05:31.412+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:05:31.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T21:06:01.814+0000] {processor.py:157} INFO - Started process (PID=30448) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:06:01.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:06:01.821+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:06:01.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:06:01.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:06:01.857+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:06:01.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:06:01.868+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:06:01.868+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:06:01.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-18T21:06:32.335+0000] {processor.py:157} INFO - Started process (PID=30473) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:06:32.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:06:32.340+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:06:32.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:06:32.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:06:32.372+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:06:32.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:06:32.384+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:06:32.384+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:06:32.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T21:07:02.873+0000] {processor.py:157} INFO - Started process (PID=30498) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:07:02.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:07:02.880+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:07:02.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:07:02.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:07:02.907+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:07:02.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:07:02.918+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:07:02.918+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:07:02.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T21:07:33.396+0000] {processor.py:157} INFO - Started process (PID=30523) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:07:33.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:07:33.400+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:07:33.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:07:33.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:07:33.426+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:07:33.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:07:33.437+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:07:33.437+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:07:33.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T21:08:03.789+0000] {processor.py:157} INFO - Started process (PID=30548) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:08:03.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:08:03.792+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:08:03.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:08:03.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:08:03.821+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:08:03.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:08:03.831+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:08:03.831+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:08:03.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T21:08:34.263+0000] {processor.py:157} INFO - Started process (PID=30573) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:08:34.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:08:34.265+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:08:34.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:08:34.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:08:34.294+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:08:34.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:08:34.303+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:08:34.303+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:08:34.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T21:09:04.716+0000] {processor.py:157} INFO - Started process (PID=30598) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:09:04.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:09:04.721+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:09:04.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:09:04.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:09:04.749+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:09:04.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:09:04.759+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:09:04.759+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:09:04.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T21:09:35.168+0000] {processor.py:157} INFO - Started process (PID=30623) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:09:35.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:09:35.172+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:09:35.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:09:35.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:09:35.205+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:09:35.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:09:35.216+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:09:35.216+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:09:35.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T21:10:05.729+0000] {processor.py:157} INFO - Started process (PID=30648) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:10:05.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:10:05.732+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:10:05.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:10:05.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:10:05.764+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:10:05.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:10:05.776+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:10:05.776+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:10:05.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T21:10:36.170+0000] {processor.py:157} INFO - Started process (PID=30673) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:10:36.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:10:36.173+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:10:36.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:10:36.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:10:36.199+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:10:36.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:10:36.209+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:10:36.209+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:10:36.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T21:11:06.673+0000] {processor.py:157} INFO - Started process (PID=30698) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:11:06.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:11:06.677+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:11:06.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:11:06.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:11:06.706+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:11:06.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:11:06.719+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:11:06.719+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:11:06.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T21:11:37.137+0000] {processor.py:157} INFO - Started process (PID=30723) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:11:37.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:11:37.140+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:11:37.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:11:37.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:11:37.166+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:11:37.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:11:37.177+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:11:37.176+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:11:37.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T21:12:07.637+0000] {processor.py:157} INFO - Started process (PID=30748) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:12:07.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:12:07.640+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:12:07.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:12:07.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:12:07.669+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:12:07.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:12:07.679+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:12:07.679+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:12:07.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T21:12:38.115+0000] {processor.py:157} INFO - Started process (PID=30773) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:12:38.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:12:38.118+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:12:38.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:12:38.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:12:38.146+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:12:38.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:12:38.158+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:12:38.158+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:12:38.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T21:13:08.612+0000] {processor.py:157} INFO - Started process (PID=30798) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:13:08.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:13:08.615+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:13:08.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:13:08.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:13:08.644+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:13:08.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:13:08.654+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:13:08.654+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:13:08.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T21:13:39.083+0000] {processor.py:157} INFO - Started process (PID=30823) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:13:39.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:13:39.088+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:13:39.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:13:39.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:13:39.117+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:13:39.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:13:39.126+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:13:39.126+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:13:39.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T21:14:09.545+0000] {processor.py:157} INFO - Started process (PID=30848) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:14:09.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:14:09.553+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:14:09.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:14:09.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:14:09.584+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:14:09.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:14:09.594+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:14:09.594+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:14:09.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-18T21:14:40.097+0000] {processor.py:157} INFO - Started process (PID=30873) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:14:40.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:14:40.102+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:14:40.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:14:40.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:14:40.133+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:14:40.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:14:40.143+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:14:40.143+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:14:40.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T21:15:10.503+0000] {processor.py:157} INFO - Started process (PID=30898) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:15:10.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:15:10.506+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:15:10.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:15:10.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:15:10.534+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:15:10.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:15:10.544+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:15:10.544+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:15:10.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T21:15:40.954+0000] {processor.py:157} INFO - Started process (PID=30923) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:15:40.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:15:40.961+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:15:40.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:15:40.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:15:40.986+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:15:40.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:15:40.999+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:15:40.999+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:15:41.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T21:16:11.423+0000] {processor.py:157} INFO - Started process (PID=30948) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:16:11.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:16:11.425+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:16:11.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:16:11.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:16:11.452+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:16:11.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:16:11.462+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:16:11.461+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:16:11.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T21:16:41.901+0000] {processor.py:157} INFO - Started process (PID=30973) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:16:41.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:16:41.904+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:16:41.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:16:41.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:16:41.931+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:16:41.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:16:41.940+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:16:41.940+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:16:41.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T21:17:12.347+0000] {processor.py:157} INFO - Started process (PID=30998) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:17:12.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:17:12.350+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:17:12.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:17:12.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:17:12.379+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:17:12.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:17:12.390+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:17:12.389+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:17:12.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T21:17:42.831+0000] {processor.py:157} INFO - Started process (PID=31023) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:17:42.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:17:42.837+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:17:42.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:17:42.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:17:42.864+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:17:42.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:17:42.873+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:17:42.873+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:17:42.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T21:18:13.292+0000] {processor.py:157} INFO - Started process (PID=31048) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:18:13.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:18:13.298+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:18:13.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:18:13.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:18:13.327+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:18:13.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:18:13.339+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:18:13.339+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:18:13.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T21:18:43.789+0000] {processor.py:157} INFO - Started process (PID=31073) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:18:43.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:18:43.794+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:18:43.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:18:43.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:18:43.826+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:18:43.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:18:43.836+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:18:43.836+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:18:43.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T21:19:14.316+0000] {processor.py:157} INFO - Started process (PID=31098) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:19:14.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:19:14.321+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:19:14.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:19:14.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:19:14.346+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:19:14.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:19:14.360+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:19:14.360+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:19:14.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T21:19:44.745+0000] {processor.py:157} INFO - Started process (PID=31123) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:19:44.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:19:44.750+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:19:44.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:19:44.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:19:44.778+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:19:44.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:19:44.789+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:19:44.789+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:19:44.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T21:20:15.178+0000] {processor.py:157} INFO - Started process (PID=31148) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:20:15.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:20:15.183+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:20:15.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:20:15.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:20:15.211+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:20:15.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:20:15.221+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:20:15.221+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:20:15.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T21:20:45.566+0000] {processor.py:157} INFO - Started process (PID=31173) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:20:45.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:20:45.571+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:20:45.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:20:45.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:20:45.597+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:20:45.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:20:45.607+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:20:45.607+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:20:45.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T21:21:16.027+0000] {processor.py:157} INFO - Started process (PID=31198) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:21:16.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:21:16.032+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:21:16.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:21:16.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:21:16.059+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:21:16.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:21:16.070+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:21:16.070+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:21:16.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T21:21:46.515+0000] {processor.py:157} INFO - Started process (PID=31223) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:21:46.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:21:46.519+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:21:46.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:21:46.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:21:46.548+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:21:46.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:21:46.560+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:21:46.560+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:21:46.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T21:22:16.954+0000] {processor.py:157} INFO - Started process (PID=31248) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:22:16.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:22:16.958+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:22:16.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:22:16.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:22:16.988+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:22:16.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:22:16.997+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:22:16.997+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:22:17.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T21:22:47.419+0000] {processor.py:157} INFO - Started process (PID=31273) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:22:47.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:22:47.426+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:22:47.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:22:47.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:22:47.461+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:22:47.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:22:47.472+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:22:47.472+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:22:47.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-18T21:23:17.808+0000] {processor.py:157} INFO - Started process (PID=31298) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:23:17.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:23:17.811+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:23:17.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:23:17.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:23:17.840+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:23:17.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:23:17.851+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:23:17.851+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:23:17.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T21:23:48.246+0000] {processor.py:157} INFO - Started process (PID=31323) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:23:48.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:23:48.249+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:23:48.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:23:48.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:23:48.279+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:23:48.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:23:48.289+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:23:48.289+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:23:48.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T21:24:18.777+0000] {processor.py:157} INFO - Started process (PID=31348) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:24:18.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:24:18.779+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:24:18.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:24:18.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:24:18.810+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:24:18.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:24:18.822+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:24:18.822+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:24:18.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T21:24:49.257+0000] {processor.py:157} INFO - Started process (PID=31373) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:24:49.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:24:49.261+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:24:49.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:24:49.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:24:49.286+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:24:49.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:24:49.295+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:24:49.295+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:24:49.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T21:25:19.682+0000] {processor.py:157} INFO - Started process (PID=31398) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:25:19.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:25:19.687+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:25:19.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:25:19.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:25:19.713+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:25:19.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:25:19.722+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:25:19.722+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:25:19.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T21:25:50.071+0000] {processor.py:157} INFO - Started process (PID=31423) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:25:50.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:25:50.074+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:25:50.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:25:50.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:25:50.101+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:25:50.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:25:50.113+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:25:50.113+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:25:50.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T21:26:20.456+0000] {processor.py:157} INFO - Started process (PID=31448) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:26:20.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:26:20.460+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:26:20.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:26:20.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:26:20.491+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:26:20.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:26:20.502+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:26:20.501+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:26:20.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T21:26:51.013+0000] {processor.py:157} INFO - Started process (PID=31473) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:26:51.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:26:51.019+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:26:51.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:26:51.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:26:51.049+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:26:51.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:26:51.060+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:26:51.060+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:26:51.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T21:27:21.454+0000] {processor.py:157} INFO - Started process (PID=31498) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:27:21.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:27:21.457+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:27:21.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:27:21.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:27:21.486+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:27:21.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:27:21.496+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:27:21.496+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:27:21.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T21:27:51.921+0000] {processor.py:157} INFO - Started process (PID=31523) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:27:51.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:27:51.929+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:27:51.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:27:51.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:27:51.958+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:27:51.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:27:51.968+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:27:51.968+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:27:51.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T21:28:22.363+0000] {processor.py:157} INFO - Started process (PID=31548) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:28:22.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:28:22.369+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:28:22.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:28:22.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:28:22.403+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:28:22.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:28:22.418+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:28:22.418+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:28:22.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-18T21:28:52.851+0000] {processor.py:157} INFO - Started process (PID=31573) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:28:52.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:28:52.855+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:28:52.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:28:52.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:28:52.879+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:28:52.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:28:52.891+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:28:52.891+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:28:52.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T21:29:23.321+0000] {processor.py:157} INFO - Started process (PID=31598) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:29:23.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:29:23.328+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:29:23.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:29:23.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:29:23.354+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:29:23.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:29:23.364+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:29:23.363+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:29:23.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T21:29:53.866+0000] {processor.py:157} INFO - Started process (PID=31623) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:29:53.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:29:53.870+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:29:53.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:29:53.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:29:53.900+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:29:53.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:29:53.911+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:29:53.910+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:29:53.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T21:30:24.320+0000] {processor.py:157} INFO - Started process (PID=31648) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:30:24.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:30:24.324+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:30:24.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:30:24.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:30:24.356+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:30:24.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:30:24.366+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:30:24.366+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:30:24.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T21:30:54.727+0000] {processor.py:157} INFO - Started process (PID=31673) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:30:54.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:30:54.730+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:30:54.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:30:54.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:30:54.756+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:30:54.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:30:54.766+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:30:54.766+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:30:54.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T21:31:25.227+0000] {processor.py:157} INFO - Started process (PID=31698) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:31:25.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:31:25.231+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:31:25.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:31:25.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:31:25.258+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:31:25.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:31:25.269+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:31:25.269+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:31:25.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T21:31:55.712+0000] {processor.py:157} INFO - Started process (PID=31723) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:31:55.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:31:55.716+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:31:55.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:31:55.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:31:55.744+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:31:55.744+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:31:55.754+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:31:55.754+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:31:55.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T21:32:26.191+0000] {processor.py:157} INFO - Started process (PID=31748) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:32:26.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:32:26.193+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:32:26.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:32:26.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:32:26.214+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:32:26.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:32:26.223+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:32:26.223+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:32:26.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.042 seconds
[2024-07-18T21:32:56.663+0000] {processor.py:157} INFO - Started process (PID=31773) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:32:56.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:32:56.667+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:32:56.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:32:56.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:32:56.697+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:32:56.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:32:56.709+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:32:56.709+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:32:56.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T21:33:27.171+0000] {processor.py:157} INFO - Started process (PID=31798) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:33:27.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:33:27.206+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:33:27.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:33:27.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:33:27.299+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:33:27.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:33:27.317+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:33:27.316+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:33:27.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.216 seconds
[2024-07-18T21:33:57.863+0000] {processor.py:157} INFO - Started process (PID=31823) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:33:57.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:33:57.867+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:33:57.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:33:57.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:33:57.898+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:33:57.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:33:57.911+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:33:57.911+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:33:57.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T21:34:28.391+0000] {processor.py:157} INFO - Started process (PID=31848) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:34:28.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:34:28.394+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:34:28.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:34:28.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:34:28.430+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:34:28.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:34:28.443+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:34:28.443+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:34:28.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-18T21:34:58.848+0000] {processor.py:157} INFO - Started process (PID=31873) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:34:58.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:34:58.850+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:34:58.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:34:58.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:34:58.875+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:34:58.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:34:58.886+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:34:58.886+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:34:58.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-18T21:35:29.311+0000] {processor.py:157} INFO - Started process (PID=31898) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:35:29.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:35:29.315+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:35:29.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:35:29.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:35:29.350+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:35:29.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:35:29.364+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:35:29.364+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:35:29.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-18T21:35:59.807+0000] {processor.py:157} INFO - Started process (PID=31923) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:35:59.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:35:59.814+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:35:59.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:35:59.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:35:59.845+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:35:59.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:35:59.860+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:35:59.860+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:35:59.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-18T21:36:30.270+0000] {processor.py:157} INFO - Started process (PID=31948) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:36:30.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:36:30.276+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:36:30.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:36:30.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:36:30.304+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:36:30.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:36:30.314+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:36:30.314+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:36:30.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T21:37:00.750+0000] {processor.py:157} INFO - Started process (PID=31973) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:37:00.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:37:00.754+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:37:00.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:37:00.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:37:00.785+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:37:00.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:37:00.795+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:37:00.795+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:37:00.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T21:37:31.223+0000] {processor.py:157} INFO - Started process (PID=31998) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:37:31.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:37:31.227+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:37:31.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:37:31.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:37:31.253+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:37:31.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:37:31.263+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:37:31.262+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:37:31.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T21:38:01.672+0000] {processor.py:157} INFO - Started process (PID=32023) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:38:01.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:38:01.675+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:38:01.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:38:01.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:38:01.709+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:38:01.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:38:01.720+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:38:01.720+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:38:01.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-18T21:38:32.168+0000] {processor.py:157} INFO - Started process (PID=32048) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:38:32.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:38:32.172+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:38:32.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:38:32.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:38:32.203+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:38:32.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:38:32.213+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:38:32.213+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:38:32.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T21:39:02.638+0000] {processor.py:157} INFO - Started process (PID=32073) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:39:02.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:39:02.642+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:39:02.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:39:02.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:39:02.669+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:39:02.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:39:02.682+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:39:02.681+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:39:02.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T21:41:50.214+0000] {processor.py:157} INFO - Started process (PID=32100) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:41:50.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:41:50.223+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:41:50.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:41:50.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:41:50.279+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:41:50.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:41:50.306+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:41:50.306+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:41:50.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.116 seconds
[2024-07-18T21:42:20.792+0000] {processor.py:157} INFO - Started process (PID=32125) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:42:20.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:42:20.797+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:42:20.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:42:20.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:42:20.831+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:42:20.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:42:20.842+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:42:20.842+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:42:20.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-18T21:42:51.282+0000] {processor.py:157} INFO - Started process (PID=32150) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:42:51.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:42:51.287+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:42:51.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:42:51.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:42:51.318+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:42:51.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:42:51.328+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:42:51.328+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:42:51.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T21:43:21.754+0000] {processor.py:157} INFO - Started process (PID=32175) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:43:21.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:43:21.758+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:43:21.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:43:21.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:43:21.788+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:43:21.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:43:21.800+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:43:21.800+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:43:21.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T21:43:52.251+0000] {processor.py:157} INFO - Started process (PID=32200) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:43:52.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:43:52.255+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:43:52.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:43:52.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:43:52.286+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:43:52.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:43:52.299+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:43:52.299+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:43:52.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T21:44:22.741+0000] {processor.py:157} INFO - Started process (PID=32225) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:44:22.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:44:22.744+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:44:22.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:44:22.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:44:22.774+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:44:22.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:44:22.783+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:44:22.783+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:44:22.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T21:44:53.175+0000] {processor.py:157} INFO - Started process (PID=32250) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:44:53.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:44:53.179+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:44:53.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:44:53.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:44:53.205+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:44:53.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:44:53.214+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:44:53.214+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:44:53.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T21:45:23.607+0000] {processor.py:157} INFO - Started process (PID=32275) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:45:23.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:45:23.611+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:45:23.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:45:23.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:45:23.638+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:45:23.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:45:23.648+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:45:23.648+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:45:23.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T21:45:54.071+0000] {processor.py:157} INFO - Started process (PID=32300) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:45:54.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:45:54.078+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:45:54.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:45:54.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:45:54.112+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:45:54.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:45:54.123+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:45:54.123+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:45:54.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-18T21:46:24.604+0000] {processor.py:157} INFO - Started process (PID=32325) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:46:24.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:46:24.609+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:46:24.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:46:24.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:46:24.635+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:46:24.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:46:24.648+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:46:24.648+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:46:24.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T21:46:55.041+0000] {processor.py:157} INFO - Started process (PID=32350) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:46:55.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:46:55.045+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:46:55.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:46:55.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:46:55.074+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:46:55.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:46:55.085+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:46:55.085+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:46:55.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T21:47:25.436+0000] {processor.py:157} INFO - Started process (PID=32375) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:47:25.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:47:25.439+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:47:25.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:47:25.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:47:25.469+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:47:25.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:47:25.480+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:47:25.480+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:47:25.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T21:47:55.889+0000] {processor.py:157} INFO - Started process (PID=32400) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:47:55.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:47:55.893+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:47:55.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:47:55.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:47:55.922+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:47:55.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:47:55.932+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:47:55.932+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:47:55.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T21:48:26.392+0000] {processor.py:157} INFO - Started process (PID=32425) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:48:26.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:48:26.396+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:48:26.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:48:26.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:48:26.424+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:48:26.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:48:26.433+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:48:26.433+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:48:26.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T21:48:56.906+0000] {processor.py:157} INFO - Started process (PID=32450) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:48:56.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:48:56.910+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:48:56.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:48:56.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:48:56.940+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:48:56.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:48:56.950+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:48:56.950+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:48:56.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T21:49:27.403+0000] {processor.py:157} INFO - Started process (PID=32475) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:49:27.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:49:27.407+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:49:27.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:49:27.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:49:27.435+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:49:27.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:49:27.448+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:49:27.448+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:49:27.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T21:49:57.924+0000] {processor.py:157} INFO - Started process (PID=32500) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:49:57.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:49:57.927+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:49:57.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:49:57.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:49:57.961+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:49:57.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:49:57.972+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:49:57.972+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:49:57.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T21:50:28.353+0000] {processor.py:157} INFO - Started process (PID=32525) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:50:28.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:50:28.357+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:50:28.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:50:28.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:50:28.385+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:50:28.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:50:28.397+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:50:28.397+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:50:28.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T21:50:58.883+0000] {processor.py:157} INFO - Started process (PID=32550) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:50:58.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:50:58.888+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:50:58.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:50:58.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:50:58.913+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:50:58.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:50:58.925+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:50:58.925+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:50:58.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T21:51:29.282+0000] {processor.py:157} INFO - Started process (PID=32575) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:51:29.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:51:29.286+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:51:29.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:51:29.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:51:29.316+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:51:29.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:51:29.327+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:51:29.327+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:51:29.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T21:51:59.757+0000] {processor.py:157} INFO - Started process (PID=32600) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:51:59.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:51:59.765+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:51:59.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:51:59.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:51:59.800+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:51:59.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:51:59.813+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:51:59.813+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:51:59.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-18T21:52:30.185+0000] {processor.py:157} INFO - Started process (PID=32625) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:52:30.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:52:30.189+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:52:30.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:52:30.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:52:30.216+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:52:30.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:52:30.227+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:52:30.227+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:52:30.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T21:53:00.733+0000] {processor.py:157} INFO - Started process (PID=32650) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:53:00.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:53:00.737+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:53:00.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:53:00.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:53:00.767+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:53:00.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:53:00.780+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:53:00.780+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:53:00.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T21:53:31.160+0000] {processor.py:157} INFO - Started process (PID=32675) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:53:31.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:53:31.163+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:53:31.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:53:31.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:53:31.192+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:53:31.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:53:31.202+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:53:31.202+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:53:31.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T21:54:01.675+0000] {processor.py:157} INFO - Started process (PID=32700) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:54:01.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:54:01.679+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:54:01.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:54:01.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:54:01.706+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:54:01.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:54:01.718+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:54:01.718+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:54:01.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T21:54:32.135+0000] {processor.py:157} INFO - Started process (PID=32725) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:54:32.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:54:32.140+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:54:32.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:54:32.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:54:32.166+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:54:32.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:54:32.177+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:54:32.177+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:54:32.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T21:55:02.638+0000] {processor.py:157} INFO - Started process (PID=32750) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:55:02.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:55:02.641+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:55:02.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:55:02.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:55:02.670+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:55:02.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:55:02.684+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:55:02.683+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:55:02.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T21:55:33.131+0000] {processor.py:157} INFO - Started process (PID=32775) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:55:33.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:55:33.135+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:55:33.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:55:33.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:55:33.164+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:55:33.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:55:33.173+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:55:33.173+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:55:33.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T21:56:03.593+0000] {processor.py:157} INFO - Started process (PID=32800) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:56:03.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:56:03.597+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:56:03.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:56:03.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:56:03.630+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:56:03.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:56:03.640+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:56:03.640+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:56:03.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T21:56:34.096+0000] {processor.py:157} INFO - Started process (PID=32825) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:56:34.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T21:56:34.100+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:56:34.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:56:34.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T21:56:34.128+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:56:34.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T21:56:34.139+0000] {logging_mixin.py:151} INFO - [2024-07-18T21:56:34.138+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T21:56:34.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T22:02:24.503+0000] {processor.py:157} INFO - Started process (PID=32852) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:02:24.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:02:24.510+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:02:24.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:02:24.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:02:24.564+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:02:24.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:02:24.585+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:02:24.585+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:02:24.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.103 seconds
[2024-07-18T22:18:14.304+0000] {processor.py:157} INFO - Started process (PID=32877) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:18:14.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:18:14.310+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:18:14.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:18:14.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:18:14.338+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:18:14.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:18:14.349+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:18:14.349+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:18:14.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T22:18:44.785+0000] {processor.py:157} INFO - Started process (PID=32902) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:18:44.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:18:44.789+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:18:44.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:18:44.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:18:44.840+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:18:44.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:18:44.852+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:18:44.852+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:18:44.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-18T22:19:15.314+0000] {processor.py:157} INFO - Started process (PID=32927) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:19:15.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:19:15.319+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:19:15.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:19:15.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:19:15.349+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:19:15.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:19:15.361+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:19:15.361+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:19:15.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T22:19:45.751+0000] {processor.py:157} INFO - Started process (PID=32952) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:19:45.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:19:45.754+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:19:45.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:19:45.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:19:45.784+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:19:45.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:19:45.795+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:19:45.794+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:19:45.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T22:20:16.188+0000] {processor.py:157} INFO - Started process (PID=32977) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:20:16.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:20:16.192+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:20:16.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:20:16.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:20:16.221+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:20:16.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:20:16.232+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:20:16.231+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:20:16.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T22:20:46.651+0000] {processor.py:157} INFO - Started process (PID=33002) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:20:46.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:20:46.653+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:20:46.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:20:46.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:20:46.680+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:20:46.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:20:46.692+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:20:46.692+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:20:46.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T22:21:17.060+0000] {processor.py:157} INFO - Started process (PID=33027) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:21:17.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:21:17.064+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:21:17.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:21:17.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:21:17.091+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:21:17.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:21:17.101+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:21:17.101+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:21:17.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T22:21:47.535+0000] {processor.py:157} INFO - Started process (PID=33052) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:21:47.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:21:47.539+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:21:47.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:21:47.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:21:47.566+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:21:47.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:21:47.580+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:21:47.580+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:21:47.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T22:22:17.976+0000] {processor.py:157} INFO - Started process (PID=33077) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:22:17.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:22:17.982+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:22:17.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:22:17.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:22:18.010+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:22:18.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:22:18.019+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:22:18.019+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:22:18.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T22:22:48.432+0000] {processor.py:157} INFO - Started process (PID=33102) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:22:48.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:22:48.436+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:22:48.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:22:48.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:22:48.474+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:22:48.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:22:48.489+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:22:48.489+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:22:48.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-18T22:23:18.909+0000] {processor.py:157} INFO - Started process (PID=33127) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:23:18.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:23:18.912+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:23:18.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:23:18.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:23:18.940+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:23:18.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:23:18.953+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:23:18.953+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:23:18.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T22:23:49.355+0000] {processor.py:157} INFO - Started process (PID=33152) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:23:49.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:23:49.358+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:23:49.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:23:49.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:23:49.389+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:23:49.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:23:49.399+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:23:49.399+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:23:49.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T22:24:19.789+0000] {processor.py:157} INFO - Started process (PID=33177) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:24:19.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:24:19.792+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:24:19.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:24:19.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:24:19.819+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:24:19.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:24:19.829+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:24:19.829+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:24:19.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T22:24:50.262+0000] {processor.py:157} INFO - Started process (PID=33202) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:24:50.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:24:50.265+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:24:50.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:24:50.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:24:50.296+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:24:50.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:24:50.306+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:24:50.306+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:24:50.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T22:25:20.740+0000] {processor.py:157} INFO - Started process (PID=33227) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:25:20.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:25:20.743+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:25:20.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:25:20.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:25:20.774+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:25:20.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:25:20.783+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:25:20.783+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:25:20.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T22:25:51.185+0000] {processor.py:157} INFO - Started process (PID=33252) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:25:51.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:25:51.192+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:25:51.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:25:51.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:25:51.215+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:25:51.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:25:51.229+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:25:51.229+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:25:51.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T22:26:21.627+0000] {processor.py:157} INFO - Started process (PID=33277) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:26:21.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:26:21.633+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:26:21.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:26:21.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:26:21.664+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:26:21.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:26:21.675+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:26:21.675+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:26:21.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T22:26:52.127+0000] {processor.py:157} INFO - Started process (PID=33302) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:26:52.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:26:52.131+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:26:52.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:26:52.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:26:52.160+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:26:52.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:26:52.173+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:26:52.173+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:26:52.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T22:27:22.552+0000] {processor.py:157} INFO - Started process (PID=33327) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:27:22.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:27:22.556+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:27:22.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:27:22.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:27:22.585+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:27:22.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:27:22.595+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:27:22.595+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:27:22.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T22:27:53.006+0000] {processor.py:157} INFO - Started process (PID=33352) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:27:53.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:27:53.010+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:27:53.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:27:53.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:27:53.037+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:27:53.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:27:53.049+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:27:53.049+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:27:53.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T22:28:23.433+0000] {processor.py:157} INFO - Started process (PID=33377) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:28:23.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:28:23.436+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:28:23.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:28:23.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:28:23.467+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:28:23.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:28:23.476+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:28:23.476+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:28:23.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T22:28:53.866+0000] {processor.py:157} INFO - Started process (PID=33402) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:28:53.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:28:53.870+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:28:53.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:28:53.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:28:53.898+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:28:53.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:28:53.907+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:28:53.907+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:28:53.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T22:29:24.316+0000] {processor.py:157} INFO - Started process (PID=33427) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:29:24.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:29:24.322+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:29:24.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:29:24.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:29:24.354+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:29:24.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:29:24.365+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:29:24.365+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:29:24.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-18T22:29:54.789+0000] {processor.py:157} INFO - Started process (PID=33452) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:29:54.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:29:54.794+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:29:54.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:29:54.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:29:54.830+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:29:54.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:29:54.845+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:29:54.844+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:29:54.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-18T22:30:25.243+0000] {processor.py:157} INFO - Started process (PID=33477) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:30:25.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:30:25.245+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:30:25.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:30:25.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:30:25.275+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:30:25.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:30:25.289+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:30:25.289+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:30:25.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-18T22:30:55.712+0000] {processor.py:157} INFO - Started process (PID=33502) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:30:55.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:30:55.718+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:30:55.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:30:55.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:30:55.751+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:30:55.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:30:55.761+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:30:55.761+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:30:55.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-18T22:31:26.157+0000] {processor.py:157} INFO - Started process (PID=33527) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:31:26.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:31:26.160+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:31:26.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:31:26.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:31:26.189+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:31:26.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:31:26.198+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:31:26.198+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:31:26.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T22:31:56.536+0000] {processor.py:157} INFO - Started process (PID=33552) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:31:56.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:31:56.539+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:31:56.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:31:56.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:31:56.567+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:31:56.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:31:56.579+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:31:56.579+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:31:56.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T22:32:26.983+0000] {processor.py:157} INFO - Started process (PID=33577) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:32:26.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:32:26.986+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:32:26.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:32:26.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:32:27.017+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:32:27.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:32:27.027+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:32:27.027+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:32:27.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T22:32:57.460+0000] {processor.py:157} INFO - Started process (PID=33602) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:32:57.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:32:57.463+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:32:57.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:32:57.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:32:57.496+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:32:57.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:32:57.508+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:32:57.508+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:32:57.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T22:33:27.957+0000] {processor.py:157} INFO - Started process (PID=33627) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:33:27.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:33:27.963+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:33:27.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:33:27.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:33:27.987+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:33:27.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:33:27.998+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:33:27.998+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:33:28.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T22:33:58.398+0000] {processor.py:157} INFO - Started process (PID=33652) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:33:58.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:33:58.404+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:33:58.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:33:58.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:33:58.438+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:33:58.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:33:58.449+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:33:58.449+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:33:58.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-18T22:34:28.862+0000] {processor.py:157} INFO - Started process (PID=33677) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:34:28.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:34:28.867+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:34:28.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:34:28.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:34:28.895+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:34:28.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:34:28.907+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:34:28.907+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:34:28.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T22:34:59.340+0000] {processor.py:157} INFO - Started process (PID=33702) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:34:59.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:34:59.342+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:34:59.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:34:59.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:34:59.369+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:34:59.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:34:59.382+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:34:59.382+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:34:59.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T22:35:29.747+0000] {processor.py:157} INFO - Started process (PID=33727) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:35:29.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:35:29.750+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:35:29.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:35:29.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:35:29.777+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:35:29.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:35:29.790+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:35:29.789+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:35:29.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T22:36:00.183+0000] {processor.py:157} INFO - Started process (PID=33752) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:36:00.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:36:00.187+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:36:00.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:36:00.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:36:00.217+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:36:00.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:36:00.227+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:36:00.227+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:36:00.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T22:36:30.633+0000] {processor.py:157} INFO - Started process (PID=33777) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:36:30.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:36:30.637+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:36:30.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:36:30.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:36:30.661+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:36:30.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:36:30.672+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:36:30.672+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:36:30.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T22:37:01.070+0000] {processor.py:157} INFO - Started process (PID=33802) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:37:01.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:37:01.074+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:37:01.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:37:01.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:37:01.102+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:37:01.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:37:01.112+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:37:01.112+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:37:01.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T22:37:31.525+0000] {processor.py:157} INFO - Started process (PID=33827) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:37:31.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:37:31.530+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:37:31.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:37:31.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:37:31.561+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:37:31.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:37:31.572+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:37:31.572+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:37:31.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T22:38:01.971+0000] {processor.py:157} INFO - Started process (PID=33852) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:38:01.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:38:01.975+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:38:01.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:38:01.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:38:02.005+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:38:02.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:38:02.016+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:38:02.016+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:38:02.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T22:38:32.443+0000] {processor.py:157} INFO - Started process (PID=33877) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:38:32.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:38:32.446+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:38:32.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:38:32.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:38:32.475+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:38:32.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:38:32.486+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:38:32.486+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:38:32.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T22:39:02.897+0000] {processor.py:157} INFO - Started process (PID=33902) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:39:02.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:39:02.900+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:39:02.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:39:02.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:39:02.930+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:39:02.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:39:02.939+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:39:02.939+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:39:02.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T22:39:33.367+0000] {processor.py:157} INFO - Started process (PID=33927) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:39:33.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:39:33.371+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:39:33.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:39:33.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:39:33.404+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:39:33.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:39:33.416+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:39:33.416+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:39:33.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T22:40:03.790+0000] {processor.py:157} INFO - Started process (PID=33952) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:40:03.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:40:03.794+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:40:03.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:40:03.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:40:03.820+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:40:03.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:40:03.830+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:40:03.829+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:40:03.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T22:40:34.247+0000] {processor.py:157} INFO - Started process (PID=33977) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:40:34.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:40:34.250+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:40:34.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:40:34.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:40:34.276+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:40:34.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:40:34.286+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:40:34.286+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:40:34.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T22:41:04.663+0000] {processor.py:157} INFO - Started process (PID=34002) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:41:04.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:41:04.667+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:41:04.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:41:04.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:41:04.697+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:41:04.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:41:04.708+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:41:04.708+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:41:04.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T22:41:35.152+0000] {processor.py:157} INFO - Started process (PID=34027) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:41:35.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:41:35.154+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:41:35.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:41:35.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:41:35.182+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:41:35.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:41:35.192+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:41:35.192+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:41:35.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T22:42:05.598+0000] {processor.py:157} INFO - Started process (PID=34052) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:42:05.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:42:05.601+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:42:05.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:42:05.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:42:05.627+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:42:05.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:42:05.636+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:42:05.636+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:42:05.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T22:42:36.048+0000] {processor.py:157} INFO - Started process (PID=34077) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:42:36.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:42:36.054+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:42:36.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:42:36.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:42:36.086+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:42:36.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:42:36.097+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:42:36.097+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:42:36.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T22:43:06.480+0000] {processor.py:157} INFO - Started process (PID=34102) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:43:06.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:43:06.483+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:43:06.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:43:06.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:43:06.514+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:43:06.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:43:06.525+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:43:06.525+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:43:06.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T22:43:36.962+0000] {processor.py:157} INFO - Started process (PID=34127) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:43:36.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:43:36.964+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:43:36.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:43:36.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:43:36.989+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:43:36.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:43:37.002+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:43:37.001+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:43:37.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T22:44:07.417+0000] {processor.py:157} INFO - Started process (PID=34152) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:44:07.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:44:07.420+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:44:07.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:44:07.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:44:07.447+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:44:07.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:44:07.459+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:44:07.459+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:44:07.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T22:44:37.904+0000] {processor.py:157} INFO - Started process (PID=34177) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:44:37.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:44:37.906+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:44:37.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:44:37.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:44:37.936+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:44:37.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:44:37.947+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:44:37.947+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:44:37.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T22:45:08.391+0000] {processor.py:157} INFO - Started process (PID=34202) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:45:08.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:45:08.394+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:45:08.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:45:08.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:45:08.426+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:45:08.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:45:08.436+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:45:08.436+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:45:08.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T22:45:38.783+0000] {processor.py:157} INFO - Started process (PID=34227) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:45:38.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:45:38.786+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:45:38.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:45:38.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:45:38.812+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:45:38.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:45:38.822+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:45:38.822+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:45:38.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T22:46:09.154+0000] {processor.py:157} INFO - Started process (PID=34252) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:46:09.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:46:09.159+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:46:09.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:46:09.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:46:09.189+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:46:09.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:46:09.199+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:46:09.199+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:46:09.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T22:46:39.594+0000] {processor.py:157} INFO - Started process (PID=34277) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:46:39.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:46:39.598+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:46:39.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:46:39.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:46:39.625+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:46:39.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:46:39.636+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:46:39.636+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:46:39.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T22:47:10.046+0000] {processor.py:157} INFO - Started process (PID=34302) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:47:10.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:47:10.051+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:47:10.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:47:10.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:47:10.082+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:47:10.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:47:10.095+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:47:10.095+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:47:10.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T22:47:40.472+0000] {processor.py:157} INFO - Started process (PID=34327) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:47:40.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:47:40.476+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:47:40.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:47:40.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:47:40.504+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:47:40.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:47:40.514+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:47:40.514+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:47:40.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T22:48:10.947+0000] {processor.py:157} INFO - Started process (PID=34352) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:48:10.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:48:10.951+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:48:10.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:48:10.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:48:10.980+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:48:10.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:48:10.991+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:48:10.991+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:48:11.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T22:48:41.362+0000] {processor.py:157} INFO - Started process (PID=34377) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:48:41.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:48:41.366+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:48:41.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:48:41.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:48:41.394+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:48:41.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:48:41.404+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:48:41.404+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:48:41.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T22:49:11.830+0000] {processor.py:157} INFO - Started process (PID=34402) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:49:11.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:49:11.835+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:49:11.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:49:11.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:49:11.867+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:49:11.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:49:11.877+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:49:11.877+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:49:11.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-18T22:49:42.322+0000] {processor.py:157} INFO - Started process (PID=34427) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:49:42.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:49:42.326+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:49:42.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:49:42.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:49:42.357+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:49:42.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:49:42.370+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:49:42.370+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:49:42.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-18T22:50:12.824+0000] {processor.py:157} INFO - Started process (PID=34452) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:50:12.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:50:12.829+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:50:12.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:50:12.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:50:12.859+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:50:12.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:50:12.875+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:50:12.874+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:50:12.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-18T22:50:43.308+0000] {processor.py:157} INFO - Started process (PID=34477) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:50:43.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:50:43.313+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:50:43.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:50:43.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:50:43.344+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:50:43.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:50:43.354+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:50:43.354+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:50:43.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T22:51:13.742+0000] {processor.py:157} INFO - Started process (PID=34502) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:51:13.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:51:13.747+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:51:13.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:51:13.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:51:13.777+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:51:13.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:51:13.788+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:51:13.788+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:51:13.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T22:51:44.214+0000] {processor.py:157} INFO - Started process (PID=34527) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:51:44.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:51:44.217+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:51:44.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:51:44.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:51:44.248+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:51:44.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:51:44.258+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:51:44.258+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:51:44.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T22:52:14.671+0000] {processor.py:157} INFO - Started process (PID=34552) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:52:14.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:52:14.676+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:52:14.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:52:14.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:52:14.705+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:52:14.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:52:14.718+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:52:14.718+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:52:14.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T22:52:45.159+0000] {processor.py:157} INFO - Started process (PID=34577) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:52:45.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:52:45.162+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:52:45.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:52:45.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:52:45.190+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:52:45.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:52:45.200+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:52:45.200+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:52:45.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T22:53:15.615+0000] {processor.py:157} INFO - Started process (PID=34602) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:53:15.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:53:15.619+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:53:15.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:53:15.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:53:15.647+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:53:15.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:53:15.659+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:53:15.659+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:53:15.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T22:53:46.096+0000] {processor.py:157} INFO - Started process (PID=34627) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:53:46.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:53:46.100+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:53:46.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:53:46.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:53:46.125+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:53:46.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:53:46.134+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:53:46.134+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:53:46.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T22:54:16.506+0000] {processor.py:157} INFO - Started process (PID=34652) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:54:16.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:54:16.512+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:54:16.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:54:16.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:54:16.536+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:54:16.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:54:16.549+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:54:16.549+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:54:16.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T22:54:46.971+0000] {processor.py:157} INFO - Started process (PID=34677) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:54:46.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:54:46.975+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:54:46.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:54:46.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:54:47.000+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:54:47.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:54:47.010+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:54:47.010+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:54:47.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T22:55:17.449+0000] {processor.py:157} INFO - Started process (PID=34702) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:55:17.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:55:17.454+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:55:17.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:55:17.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:55:17.487+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:55:17.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:55:17.500+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:55:17.500+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:55:17.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-18T22:55:47.931+0000] {processor.py:157} INFO - Started process (PID=34727) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:55:47.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:55:47.934+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:55:47.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:55:47.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:55:47.963+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:55:47.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:55:47.974+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:55:47.974+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:55:47.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T22:56:18.412+0000] {processor.py:157} INFO - Started process (PID=34752) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:56:18.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:56:18.415+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:56:18.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:56:18.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:56:18.440+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:56:18.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:56:18.452+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:56:18.452+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:56:18.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-18T22:56:48.854+0000] {processor.py:157} INFO - Started process (PID=34777) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:56:48.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:56:48.859+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:56:48.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:56:48.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:56:48.885+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:56:48.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:56:48.894+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:56:48.894+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:56:48.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T22:57:19.311+0000] {processor.py:157} INFO - Started process (PID=34802) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:57:19.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:57:19.316+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:57:19.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:57:19.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:57:19.345+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:57:19.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:57:19.356+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:57:19.356+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:57:19.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T22:57:49.779+0000] {processor.py:157} INFO - Started process (PID=34827) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:57:49.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:57:49.784+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:57:49.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:57:49.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:57:49.815+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:57:49.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:57:49.828+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:57:49.827+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:57:49.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-18T22:58:20.233+0000] {processor.py:157} INFO - Started process (PID=34852) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:58:20.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:58:20.236+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:58:20.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:58:20.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:58:20.265+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:58:20.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:58:20.275+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:58:20.275+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:58:20.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T22:58:50.703+0000] {processor.py:157} INFO - Started process (PID=34877) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:58:50.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:58:50.706+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:58:50.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:58:50.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:58:50.731+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:58:50.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:58:50.744+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:58:50.744+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:58:50.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T22:59:21.149+0000] {processor.py:157} INFO - Started process (PID=34902) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:59:21.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:59:21.153+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:59:21.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:59:21.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:59:21.181+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:59:21.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:59:21.193+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:59:21.193+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:59:21.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T22:59:51.584+0000] {processor.py:157} INFO - Started process (PID=34927) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:59:51.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T22:59:51.587+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:59:51.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:59:51.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T22:59:51.617+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:59:51.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T22:59:51.627+0000] {logging_mixin.py:151} INFO - [2024-07-18T22:59:51.627+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T22:59:51.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T23:00:22.037+0000] {processor.py:157} INFO - Started process (PID=34952) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:00:22.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:00:22.041+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:00:22.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:00:22.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:00:22.068+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:00:22.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:00:22.079+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:00:22.079+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:00:22.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T23:00:52.462+0000] {processor.py:157} INFO - Started process (PID=34977) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:00:52.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:00:52.467+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:00:52.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:00:52.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:00:52.499+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:00:52.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:00:52.511+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:00:52.511+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:00:52.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-18T23:01:22.904+0000] {processor.py:157} INFO - Started process (PID=35002) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:01:22.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:01:22.908+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:01:22.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:01:22.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:01:22.937+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:01:22.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:01:22.947+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:01:22.947+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:01:22.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T23:01:53.344+0000] {processor.py:157} INFO - Started process (PID=35027) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:01:53.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:01:53.349+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:01:53.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:01:53.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:01:53.376+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:01:53.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:01:53.386+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:01:53.386+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:01:53.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T23:02:23.739+0000] {processor.py:157} INFO - Started process (PID=35052) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:02:23.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:02:23.743+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:02:23.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:02:23.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:02:23.772+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:02:23.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:02:23.783+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:02:23.783+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:02:23.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T23:02:54.137+0000] {processor.py:157} INFO - Started process (PID=35077) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:02:54.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:02:54.140+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:02:54.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:02:54.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:02:54.169+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:02:54.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:02:54.180+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:02:54.180+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:02:54.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T23:03:24.634+0000] {processor.py:157} INFO - Started process (PID=35102) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:03:24.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:03:24.637+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:03:24.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:03:24.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:03:24.665+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:03:24.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:03:24.675+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:03:24.675+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:03:24.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T23:03:55.084+0000] {processor.py:157} INFO - Started process (PID=35127) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:03:55.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:03:55.087+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:03:55.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:03:55.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:03:55.114+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:03:55.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:03:55.124+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:03:55.124+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:03:55.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T23:04:25.505+0000] {processor.py:157} INFO - Started process (PID=35152) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:04:25.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:04:25.510+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:04:25.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:04:25.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:04:25.539+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:04:25.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:04:25.551+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:04:25.551+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:04:25.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T23:04:56.127+0000] {processor.py:157} INFO - Started process (PID=35177) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:04:56.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:04:56.132+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:04:56.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:04:56.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:04:56.170+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:04:56.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:04:56.194+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:04:56.193+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:04:56.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-18T23:05:26.640+0000] {processor.py:157} INFO - Started process (PID=35202) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:05:26.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:05:26.643+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:05:26.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:05:26.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:05:26.674+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:05:26.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:05:26.686+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:05:26.686+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:05:26.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T23:05:57.076+0000] {processor.py:157} INFO - Started process (PID=35227) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:05:57.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:05:57.081+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:05:57.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:05:57.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:05:57.109+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:05:57.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:05:57.118+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:05:57.118+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:05:57.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T23:06:27.492+0000] {processor.py:157} INFO - Started process (PID=35252) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:06:27.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:06:27.495+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:06:27.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:06:27.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:06:27.528+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:06:27.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:06:27.540+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:06:27.539+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:06:27.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-18T23:06:57.946+0000] {processor.py:157} INFO - Started process (PID=35277) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:06:57.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:06:57.950+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:06:57.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:06:57.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:06:57.981+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:06:57.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:06:57.990+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:06:57.990+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:06:58.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T23:07:28.394+0000] {processor.py:157} INFO - Started process (PID=35302) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:07:28.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:07:28.398+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:07:28.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:07:28.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:07:28.432+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:07:28.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:07:28.446+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:07:28.446+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:07:28.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-18T23:07:58.849+0000] {processor.py:157} INFO - Started process (PID=35327) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:07:58.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:07:58.856+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:07:58.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:07:58.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:07:58.882+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:07:58.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:07:58.892+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:07:58.892+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:07:58.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T23:08:29.326+0000] {processor.py:157} INFO - Started process (PID=35352) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:08:29.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:08:29.328+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:08:29.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:08:29.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:08:29.350+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:08:29.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:08:29.359+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:08:29.359+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:08:29.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-18T23:08:59.748+0000] {processor.py:157} INFO - Started process (PID=35377) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:08:59.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:08:59.752+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:08:59.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:08:59.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:08:59.778+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:08:59.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:08:59.788+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:08:59.788+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:08:59.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-18T23:09:30.195+0000] {processor.py:157} INFO - Started process (PID=35402) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:09:30.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:09:30.198+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:09:30.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:09:30.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:09:30.228+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:09:30.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:09:30.240+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:09:30.240+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:09:30.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T23:10:00.652+0000] {processor.py:157} INFO - Started process (PID=35427) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:10:00.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:10:00.656+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:10:00.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:10:00.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:10:00.688+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:10:00.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:10:00.698+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:10:00.698+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:10:00.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-18T23:10:31.091+0000] {processor.py:157} INFO - Started process (PID=35452) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:10:31.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:10:31.094+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:10:31.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:10:31.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:10:31.125+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:10:31.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:10:31.135+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:10:31.135+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:10:31.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T23:11:01.505+0000] {processor.py:157} INFO - Started process (PID=35477) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:11:01.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:11:01.508+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:11:01.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:11:01.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:11:01.537+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:11:01.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:11:01.547+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:11:01.547+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:11:01.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T23:11:31.928+0000] {processor.py:157} INFO - Started process (PID=35502) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:11:31.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:11:31.934+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:11:31.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:11:31.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:11:31.958+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:11:31.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:11:31.968+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:11:31.968+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:11:31.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T23:12:02.412+0000] {processor.py:157} INFO - Started process (PID=35527) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:12:02.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:12:02.415+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:12:02.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:12:02.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:12:02.442+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:12:02.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:12:02.451+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:12:02.451+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:12:02.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T23:12:32.869+0000] {processor.py:157} INFO - Started process (PID=35552) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:12:32.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:12:32.872+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:12:32.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:12:32.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:12:32.902+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:12:32.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:12:32.914+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:12:32.913+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:12:32.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T23:13:03.351+0000] {processor.py:157} INFO - Started process (PID=35577) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:13:03.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:13:03.358+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:13:03.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:13:03.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:13:03.390+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:13:03.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:13:03.400+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:13:03.400+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:13:03.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-18T23:13:33.763+0000] {processor.py:157} INFO - Started process (PID=35602) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:13:33.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:13:33.765+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:13:33.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:13:33.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:13:33.792+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:13:33.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:13:33.801+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:13:33.801+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:13:33.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T23:14:04.160+0000] {processor.py:157} INFO - Started process (PID=35627) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:14:04.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:14:04.163+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:14:04.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:14:04.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:14:04.190+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:14:04.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:14:04.200+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:14:04.200+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:14:04.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-18T23:14:34.614+0000] {processor.py:157} INFO - Started process (PID=35652) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:14:34.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:14:34.617+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:14:34.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:14:34.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:14:34.641+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:14:34.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:14:34.655+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:14:34.655+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:14:34.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T23:15:05.074+0000] {processor.py:157} INFO - Started process (PID=35677) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:15:05.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:15:05.076+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:15:05.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:15:05.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:15:05.105+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:15:05.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:15:05.115+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:15:05.115+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:15:05.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T23:15:35.553+0000] {processor.py:157} INFO - Started process (PID=35702) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:15:35.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:15:35.558+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:15:35.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:15:35.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:15:35.593+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:15:35.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:15:35.607+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:15:35.607+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:15:35.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-18T23:16:05.977+0000] {processor.py:157} INFO - Started process (PID=35727) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:16:05.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:16:05.980+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:16:05.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:16:05.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:16:06.008+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:16:06.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:16:06.019+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:16:06.019+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:16:06.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T23:16:36.384+0000] {processor.py:157} INFO - Started process (PID=35752) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:16:36.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:16:36.389+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:16:36.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:16:36.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:16:36.418+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:16:36.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:16:36.427+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:16:36.427+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:16:36.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T23:17:06.824+0000] {processor.py:157} INFO - Started process (PID=35777) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:17:06.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:17:06.827+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:17:06.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:17:06.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:17:06.860+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:17:06.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:17:06.871+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:17:06.871+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:17:06.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-18T23:17:37.314+0000] {processor.py:157} INFO - Started process (PID=35802) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:17:37.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:17:37.317+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:17:37.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:17:37.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:17:37.344+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:17:37.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:17:37.354+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:17:37.354+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:17:37.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T23:18:07.757+0000] {processor.py:157} INFO - Started process (PID=35827) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:18:07.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:18:07.760+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:18:07.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:18:07.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:18:07.793+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:18:07.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:18:07.806+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:18:07.806+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:18:07.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-18T23:18:38.270+0000] {processor.py:157} INFO - Started process (PID=35852) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:18:38.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:18:38.274+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:18:38.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:18:38.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:18:38.303+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:18:38.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:18:38.313+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:18:38.313+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:18:38.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-18T23:19:08.723+0000] {processor.py:157} INFO - Started process (PID=35877) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:19:08.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:19:08.727+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:19:08.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:19:08.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:19:08.757+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:19:08.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:19:08.768+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:19:08.767+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:19:08.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T23:19:39.138+0000] {processor.py:157} INFO - Started process (PID=35902) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:19:39.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:19:39.143+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:19:39.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:19:39.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:19:39.172+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:19:39.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:19:39.181+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:19:39.181+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:19:39.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T23:20:09.549+0000] {processor.py:157} INFO - Started process (PID=35927) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:20:09.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:20:09.553+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:20:09.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:20:09.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:20:09.582+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:20:09.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:20:09.591+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:20:09.591+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:20:09.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-18T23:20:39.960+0000] {processor.py:157} INFO - Started process (PID=35952) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:20:39.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:20:39.964+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:20:39.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:20:39.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:20:39.993+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:20:39.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:20:40.003+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:20:40.003+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:20:40.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T23:21:10.465+0000] {processor.py:157} INFO - Started process (PID=35977) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:21:10.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:21:10.469+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:21:10.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:21:10.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:21:10.496+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:21:10.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:21:10.509+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:21:10.509+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:21:10.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-18T23:21:41.012+0000] {processor.py:157} INFO - Started process (PID=36002) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:21:41.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:21:41.017+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:21:41.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:21:41.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:21:41.078+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:21:41.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:21:41.091+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:21:41.091+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:21:41.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.096 seconds
[2024-07-18T23:33:27.002+0000] {processor.py:157} INFO - Started process (PID=36027) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:33:27.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:33:27.005+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:33:27.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:33:27.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:33:27.040+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:33:27.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:33:27.062+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:33:27.062+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:33:27.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-18T23:33:57.796+0000] {processor.py:157} INFO - Started process (PID=36054) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:33:57.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:33:57.801+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:33:57.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:33:57.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:33:57.846+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:33:57.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:33:57.861+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:33:57.861+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:33:57.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-18T23:34:28.299+0000] {processor.py:157} INFO - Started process (PID=36079) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:34:28.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:34:28.303+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:34:28.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:34:28.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:34:28.331+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:34:28.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:34:28.345+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:34:28.345+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:34:28.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-18T23:34:58.903+0000] {processor.py:157} INFO - Started process (PID=36104) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:34:58.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:34:58.907+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:34:58.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:34:58.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:34:58.938+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:34:58.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:34:58.948+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:34:58.948+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:34:58.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-18T23:42:44.484+0000] {processor.py:157} INFO - Started process (PID=36129) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:42:44.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:42:44.487+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:42:44.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:42:44.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:42:44.510+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:42:44.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:42:44.522+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:42:44.522+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:42:44.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-18T23:43:14.927+0000] {processor.py:157} INFO - Started process (PID=36156) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:43:14.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:43:14.941+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:43:14.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:43:14.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:43:14.983+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:43:14.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:43:14.997+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:43:14.997+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:43:15.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.088 seconds
[2024-07-18T23:43:45.414+0000] {processor.py:157} INFO - Started process (PID=36181) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:43:45.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:43:45.418+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:43:45.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:43:45.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:43:45.445+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:43:45.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:43:45.455+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:43:45.455+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:43:45.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-18T23:44:15.797+0000] {processor.py:157} INFO - Started process (PID=36206) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:44:15.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:44:15.800+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:44:15.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:44:15.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:44:15.827+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:44:15.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:44:15.838+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:44:15.838+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:44:15.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-18T23:44:46.210+0000] {processor.py:157} INFO - Started process (PID=36231) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:44:46.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-18T23:44:46.214+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:44:46.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:44:46.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-18T23:44:46.241+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:44:46.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-18T23:44:46.251+0000] {logging_mixin.py:151} INFO - [2024-07-18T23:44:46.251+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-18T00:30:00+00:00, run_after=2024-07-19T00:30:00+00:00
[2024-07-18T23:44:46.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
