[2024-07-30T00:05:59.360+0000] {processor.py:157} INFO - Started process (PID=51060) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:05:59.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T00:05:59.365+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:05:59.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:05:59.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:05:59.417+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:05:59.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T00:05:59.434+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:05:59.434+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-30T00:05:59.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.089 seconds
[2024-07-30T00:06:30.121+0000] {processor.py:157} INFO - Started process (PID=51086) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:06:30.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T00:06:30.126+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:06:30.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:06:30.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:06:30.207+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:06:30.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T00:06:30.221+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:06:30.221+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-30T00:06:30.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.118 seconds
[2024-07-30T00:07:00.627+0000] {processor.py:157} INFO - Started process (PID=51111) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:07:00.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T00:07:00.633+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:07:00.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:07:00.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:07:00.664+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:07:00.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T00:07:00.676+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:07:00.676+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-30T00:07:00.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-30T00:07:31.119+0000] {processor.py:157} INFO - Started process (PID=51136) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:07:31.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T00:07:31.124+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:07:31.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:07:31.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:07:31.152+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:07:31.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T00:07:31.161+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:07:31.161+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-30T00:07:31.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-30T00:23:37.481+0000] {processor.py:157} INFO - Started process (PID=51163) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:23:37.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T00:23:37.498+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:23:37.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:23:37.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:23:37.594+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:23:37.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T00:23:37.630+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:23:37.629+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-30T00:23:37.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.184 seconds
[2024-07-30T00:24:08.247+0000] {processor.py:157} INFO - Started process (PID=51188) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:24:08.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T00:24:08.252+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:24:08.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:24:08.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:24:08.292+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:24:08.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T00:24:08.304+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:24:08.304+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-30T00:24:08.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-30T00:24:38.688+0000] {processor.py:157} INFO - Started process (PID=51213) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:24:38.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T00:24:38.692+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:24:38.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:24:38.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:24:38.724+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:24:38.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T00:24:38.735+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:24:38.735+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-30T00:24:38.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-30T00:25:09.101+0000] {processor.py:157} INFO - Started process (PID=51238) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:25:09.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T00:25:09.105+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:25:09.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:25:09.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:25:09.144+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:25:09.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T00:25:09.156+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:25:09.156+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-30T00:25:09.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-30T00:25:39.602+0000] {processor.py:157} INFO - Started process (PID=51263) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:25:39.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T00:25:39.609+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:25:39.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:25:39.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:25:39.651+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:25:39.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T00:25:39.664+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:25:39.664+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-30T00:25:39.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-30T00:42:51.591+0000] {processor.py:157} INFO - Started process (PID=51288) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:42:51.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T00:42:51.604+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:42:51.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:42:51.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:42:51.680+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:42:51.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T00:42:51.742+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:42:51.741+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-30T00:42:51.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.183 seconds
[2024-07-30T00:43:22.245+0000] {processor.py:157} INFO - Started process (PID=51715) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:43:22.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T00:43:22.256+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:43:22.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:43:22.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:43:22.297+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:43:22.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T00:43:22.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.085 seconds
[2024-07-30T00:43:52.774+0000] {processor.py:157} INFO - Started process (PID=51740) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:43:52.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T00:43:52.785+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:43:52.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:43:52.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:43:52.844+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:43:52.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T00:43:52.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.094 seconds
[2024-07-30T00:44:23.210+0000] {processor.py:157} INFO - Started process (PID=51765) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:44:23.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T00:44:23.214+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:44:23.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:44:23.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:44:23.246+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:44:23.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T00:44:23.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T00:44:53.680+0000] {processor.py:157} INFO - Started process (PID=51790) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:44:53.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T00:44:53.685+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:44:53.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:44:53.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T00:44:53.755+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:44:53.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T00:44:53.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.101 seconds
[2024-07-30T01:02:35.292+0000] {processor.py:157} INFO - Started process (PID=51820) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:02:35.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T01:02:35.304+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:02:35.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:02:35.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:02:35.386+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:02:35.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:02:35.398+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:02:35.398+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T01:02:35.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.142 seconds
[2024-07-30T01:03:05.916+0000] {processor.py:157} INFO - Started process (PID=52236) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:03:05.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T01:03:05.936+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:03:05.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:03:05.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:03:05.980+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:03:05.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:03:06.001+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:03:06.001+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T01:03:06.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.108 seconds
[2024-07-30T01:03:36.392+0000] {processor.py:157} INFO - Started process (PID=52261) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:03:36.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T01:03:36.395+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:03:36.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:03:36.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:03:36.423+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:03:36.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:03:36.437+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:03:36.437+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T01:03:36.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T01:04:06.809+0000] {processor.py:157} INFO - Started process (PID=52286) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:04:06.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T01:04:06.812+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:04:06.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:04:06.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:04:06.844+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:04:06.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:04:06.857+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:04:06.857+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T01:04:06.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-30T01:04:37.290+0000] {processor.py:157} INFO - Started process (PID=52311) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:04:37.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T01:04:37.298+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:04:37.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:04:37.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:04:37.333+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:04:37.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:04:37.344+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:04:37.343+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T01:04:37.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-30T01:06:35.288+0000] {processor.py:157} INFO - Started process (PID=52336) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:06:35.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T01:06:35.293+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:06:35.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:06:35.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:06:35.339+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:06:35.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:06:35.354+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:06:35.354+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T01:06:35.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-30T01:07:05.810+0000] {processor.py:157} INFO - Started process (PID=52363) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:07:05.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T01:07:05.816+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:07:05.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:07:05.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:07:05.855+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:07:05.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:07:05.867+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:07:05.867+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T01:07:05.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-30T01:07:36.244+0000] {processor.py:157} INFO - Started process (PID=52388) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:07:36.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T01:07:36.246+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:07:36.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:07:36.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:07:36.278+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:07:36.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:07:36.287+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:07:36.287+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T01:07:36.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-30T01:08:06.676+0000] {processor.py:157} INFO - Started process (PID=52413) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:08:06.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T01:08:06.680+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:08:06.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:08:06.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:08:06.713+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:08:06.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:08:06.723+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:08:06.723+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T01:08:06.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T01:08:37.116+0000] {processor.py:157} INFO - Started process (PID=52438) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:08:37.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T01:08:37.120+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:08:37.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:08:37.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:08:37.161+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:08:37.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:08:37.173+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:08:37.173+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T01:08:37.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-30T01:25:57.723+0000] {processor.py:157} INFO - Started process (PID=52465) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:25:57.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T01:25:57.729+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:25:57.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:25:57.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:25:57.779+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:25:57.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:25:57.796+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:25:57.796+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T01:25:57.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.094 seconds
[2024-07-30T01:26:28.236+0000] {processor.py:157} INFO - Started process (PID=52490) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:26:28.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T01:26:28.247+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:26:28.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:26:28.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:26:28.293+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:26:28.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:26:28.312+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:26:28.312+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T01:26:28.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.102 seconds
[2024-07-30T01:26:58.751+0000] {processor.py:157} INFO - Started process (PID=52515) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:26:58.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T01:26:58.756+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:26:58.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:26:58.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:26:58.786+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:26:58.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:26:58.796+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:26:58.796+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T01:26:58.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T01:27:29.213+0000] {processor.py:157} INFO - Started process (PID=52540) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:27:29.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T01:27:29.218+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:27:29.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:27:29.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:27:29.246+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:27:29.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:27:29.255+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:27:29.255+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T01:27:29.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T01:27:59.611+0000] {processor.py:157} INFO - Started process (PID=52565) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:27:59.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T01:27:59.614+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:27:59.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:27:59.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:27:59.642+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:27:59.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:27:59.652+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:27:59.652+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T01:27:59.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-30T01:43:46.874+0000] {processor.py:157} INFO - Started process (PID=52592) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:43:46.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T01:43:46.879+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:43:46.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:43:46.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:43:46.948+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:43:46.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:43:46.972+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:43:46.971+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T01:43:46.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.127 seconds
[2024-07-30T01:44:17.668+0000] {processor.py:157} INFO - Started process (PID=52617) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:44:17.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T01:44:17.673+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:44:17.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:44:17.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:44:17.730+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:44:17.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:44:17.744+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:44:17.744+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T01:44:17.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.092 seconds
[2024-07-30T01:44:48.106+0000] {processor.py:157} INFO - Started process (PID=52642) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:44:48.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T01:44:48.108+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:44:48.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:44:48.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:44:48.141+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:44:48.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:44:48.152+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:44:48.152+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T01:44:48.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-30T01:45:18.492+0000] {processor.py:157} INFO - Started process (PID=52667) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:45:18.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T01:45:18.495+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:45:18.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:45:18.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:45:18.522+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:45:18.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:45:18.532+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:45:18.532+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T01:45:18.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-30T01:45:48.991+0000] {processor.py:157} INFO - Started process (PID=52692) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:45:48.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T01:45:48.995+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:45:48.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:45:49.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:45:49.022+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:45:49.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:45:49.032+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:45:49.032+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T01:45:49.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-30T01:46:19.406+0000] {processor.py:157} INFO - Started process (PID=52717) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:46:19.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T01:46:19.412+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:46:19.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:46:19.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:46:19.437+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:46:19.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:46:19.449+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:46:19.449+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T01:46:19.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T01:46:49.858+0000] {processor.py:157} INFO - Started process (PID=52742) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:46:49.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T01:46:49.863+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:46:49.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:46:49.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:46:49.899+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:46:49.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:46:49.910+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:46:49.910+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T01:46:49.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-30T01:47:20.237+0000] {processor.py:157} INFO - Started process (PID=52767) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:47:20.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T01:47:20.241+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:47:20.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:47:20.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:47:20.275+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:47:20.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:47:20.287+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:47:20.286+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T01:47:20.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.088 seconds
[2024-07-30T01:47:50.666+0000] {processor.py:157} INFO - Started process (PID=52792) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:47:50.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T01:47:50.672+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:47:50.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:47:50.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T01:47:50.713+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:47:50.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:47:50.726+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:47:50.725+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T01:47:50.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-30T02:03:45.928+0000] {processor.py:157} INFO - Started process (PID=52819) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:03:45.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T02:03:45.941+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:03:45.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:03:45.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:03:46.006+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:03:46.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:03:46.040+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:03:46.040+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T02:03:46.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.141 seconds
[2024-07-30T02:04:16.673+0000] {processor.py:157} INFO - Started process (PID=52844) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:04:16.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T02:04:16.687+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:04:16.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:04:16.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:04:16.738+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:04:16.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:04:16.750+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:04:16.750+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T02:04:16.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.099 seconds
[2024-07-30T02:04:47.164+0000] {processor.py:157} INFO - Started process (PID=52869) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:04:47.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T02:04:47.166+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:04:47.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:04:47.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:04:47.190+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:04:47.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:04:47.198+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:04:47.198+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T02:04:47.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-30T02:05:17.608+0000] {processor.py:157} INFO - Started process (PID=52894) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:05:17.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T02:05:17.612+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:05:17.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:05:17.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:05:17.643+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:05:17.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:05:17.655+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:05:17.655+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T02:05:17.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T02:07:44.429+0000] {processor.py:157} INFO - Started process (PID=52919) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:07:44.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T02:07:44.441+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:07:44.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:07:44.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:07:44.502+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:07:44.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:07:44.529+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:07:44.529+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T02:07:44.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.125 seconds
[2024-07-30T02:08:14.976+0000] {processor.py:157} INFO - Started process (PID=52944) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:08:14.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T02:08:14.984+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:08:14.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:08:14.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:08:15.018+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:08:15.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:08:15.028+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:08:15.028+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T02:08:15.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-30T02:08:45.405+0000] {processor.py:157} INFO - Started process (PID=52969) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:08:45.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T02:08:45.410+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:08:45.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:08:45.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:08:45.441+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:08:45.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:08:45.454+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:08:45.454+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T02:08:45.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-30T02:09:15.826+0000] {processor.py:157} INFO - Started process (PID=52994) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:09:15.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T02:09:15.829+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:09:15.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:09:15.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:09:15.853+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:09:15.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:09:15.864+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:09:15.864+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T02:09:15.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-30T02:09:46.207+0000] {processor.py:157} INFO - Started process (PID=53019) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:09:46.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T02:09:46.209+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:09:46.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:09:46.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:09:46.238+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:09:46.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:09:46.251+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:09:46.251+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T02:09:46.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T02:27:05.360+0000] {processor.py:157} INFO - Started process (PID=53044) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:27:05.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T02:27:05.366+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:27:05.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:27:05.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:27:05.453+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:27:05.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:27:05.474+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:27:05.474+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T02:27:05.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.146 seconds
[2024-07-30T02:27:35.993+0000] {processor.py:157} INFO - Started process (PID=53069) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:27:35.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T02:27:35.998+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:27:35.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:27:36.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:27:36.030+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:27:36.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:27:36.042+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:27:36.042+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T02:27:36.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T02:28:06.455+0000] {processor.py:157} INFO - Started process (PID=53094) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:28:06.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T02:28:06.461+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:28:06.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:28:06.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:28:06.495+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:28:06.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:28:06.507+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:28:06.507+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T02:28:06.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-30T02:28:36.920+0000] {processor.py:157} INFO - Started process (PID=53119) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:28:36.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T02:28:36.924+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:28:36.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:28:36.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:28:36.958+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:28:36.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:28:36.970+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:28:36.970+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T02:28:36.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T02:29:07.408+0000] {processor.py:157} INFO - Started process (PID=53144) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:29:07.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T02:29:07.415+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:29:07.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:29:07.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:29:07.443+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:29:07.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:29:07.453+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:29:07.453+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T02:29:07.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T02:29:37.859+0000] {processor.py:157} INFO - Started process (PID=53169) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:29:37.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T02:29:37.863+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:29:37.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:29:37.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:29:37.893+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:29:37.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:29:37.903+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:29:37.903+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T02:29:37.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T02:45:35.556+0000] {processor.py:157} INFO - Started process (PID=53194) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:45:35.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T02:45:35.561+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:45:35.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:45:35.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:45:35.609+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:45:35.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:45:35.634+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:45:35.634+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T02:45:35.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.096 seconds
[2024-07-30T02:46:06.200+0000] {processor.py:157} INFO - Started process (PID=53219) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:46:06.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T02:46:06.206+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:46:06.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:46:06.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:46:06.246+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:46:06.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:46:06.258+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:46:06.258+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T02:46:06.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-30T02:46:36.723+0000] {processor.py:157} INFO - Started process (PID=53244) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:46:36.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T02:46:36.726+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:46:36.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:46:36.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:46:36.752+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:46:36.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:46:36.761+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:46:36.761+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T02:46:36.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-30T02:47:07.208+0000] {processor.py:157} INFO - Started process (PID=53269) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:47:07.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T02:47:07.212+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:47:07.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:47:07.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:47:07.240+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:47:07.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:47:07.250+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:47:07.250+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T02:47:07.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-30T02:56:32.030+0000] {processor.py:157} INFO - Started process (PID=53296) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:56:32.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T02:56:32.038+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:56:32.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:56:32.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:56:32.093+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:56:32.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:56:32.117+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:56:32.117+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T02:56:32.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.111 seconds
[2024-07-30T02:57:02.684+0000] {processor.py:157} INFO - Started process (PID=53321) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:57:02.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T02:57:02.690+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:57:02.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:57:02.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:57:02.720+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:57:02.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:57:02.734+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:57:02.734+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T02:57:02.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-30T02:57:33.171+0000] {processor.py:157} INFO - Started process (PID=53346) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:57:33.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T02:57:33.178+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:57:33.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:57:33.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:57:33.217+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:57:33.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:57:33.233+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:57:33.233+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T02:57:33.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-30T02:58:03.698+0000] {processor.py:157} INFO - Started process (PID=53371) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:58:03.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T02:58:03.703+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:58:03.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:58:03.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:58:03.737+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:58:03.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:58:03.748+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:58:03.748+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T02:58:03.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-30T02:58:34.150+0000] {processor.py:157} INFO - Started process (PID=53396) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:58:34.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T02:58:34.154+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:58:34.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:58:34.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T02:58:34.180+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:58:34.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:58:34.190+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:58:34.190+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T02:58:34.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-30T03:06:37.390+0000] {processor.py:157} INFO - Started process (PID=53423) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:06:37.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:06:37.407+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:06:37.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:06:37.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:06:37.489+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:06:37.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:06:37.521+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:06:37.520+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:06:37.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.156 seconds
[2024-07-30T03:07:07.976+0000] {processor.py:157} INFO - Started process (PID=53448) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:07:07.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:07:07.984+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:07:07.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:07:08.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:07:08.030+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:07:08.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:07:08.041+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:07:08.041+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:07:08.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.092 seconds
[2024-07-30T03:07:38.560+0000] {processor.py:157} INFO - Started process (PID=53473) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:07:38.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:07:38.568+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:07:38.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:07:38.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:07:38.645+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:07:38.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:07:38.666+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:07:38.666+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:07:38.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.130 seconds
[2024-07-30T03:08:09.069+0000] {processor.py:157} INFO - Started process (PID=53498) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:08:09.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:08:09.075+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:08:09.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:08:09.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:08:09.119+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:08:09.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:08:09.132+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:08:09.132+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:08:09.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.083 seconds
[2024-07-30T03:08:39.497+0000] {processor.py:157} INFO - Started process (PID=53523) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:08:39.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:08:39.500+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:08:39.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:08:39.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:08:39.530+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:08:39.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:08:39.539+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:08:39.539+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:08:39.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T03:09:09.872+0000] {processor.py:157} INFO - Started process (PID=53548) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:09:09.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:09:09.878+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:09:09.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:09:09.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:09:09.906+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:09:09.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:09:09.917+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:09:09.917+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:09:09.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T03:09:40.305+0000] {processor.py:157} INFO - Started process (PID=53573) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:09:40.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:09:40.314+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:09:40.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:09:40.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:09:40.377+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:09:40.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:09:40.391+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:09:40.391+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:09:40.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.107 seconds
[2024-07-30T03:10:10.919+0000] {processor.py:157} INFO - Started process (PID=53598) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:10:10.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:10:10.925+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:10:10.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:10:10.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:10:11.002+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:10:11.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:10:11.025+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:10:11.025+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:10:11.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.158 seconds
[2024-07-30T03:10:41.596+0000] {processor.py:157} INFO - Started process (PID=53623) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:10:41.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:10:41.609+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:10:41.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:10:41.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:10:41.714+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:10:41.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:10:41.734+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:10:41.734+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:10:41.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.164 seconds
[2024-07-30T03:11:12.152+0000] {processor.py:157} INFO - Started process (PID=53648) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:11:12.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:11:12.177+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:11:12.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:11:12.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:11:12.226+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:11:12.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:11:12.242+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:11:12.242+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:11:12.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.114 seconds
[2024-07-30T03:11:42.753+0000] {processor.py:157} INFO - Started process (PID=53673) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:11:42.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:11:42.769+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:11:42.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:11:42.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:11:42.863+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:11:42.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:11:42.885+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:11:42.885+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:11:42.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.160 seconds
[2024-07-30T03:12:13.347+0000] {processor.py:157} INFO - Started process (PID=53698) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:12:13.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:12:13.354+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:12:13.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:12:13.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:12:13.407+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:12:13.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:12:13.420+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:12:13.420+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:12:13.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.107 seconds
[2024-07-30T03:12:43.886+0000] {processor.py:157} INFO - Started process (PID=53723) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:12:43.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:12:43.896+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:12:43.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:12:43.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:12:43.978+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:12:43.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:12:43.994+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:12:43.993+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:12:44.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.133 seconds
[2024-07-30T03:13:14.391+0000] {processor.py:157} INFO - Started process (PID=53748) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:13:14.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:13:14.404+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:13:14.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:13:14.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:13:14.467+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:13:14.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:13:14.484+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:13:14.484+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:13:14.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.127 seconds
[2024-07-30T03:13:45.030+0000] {processor.py:157} INFO - Started process (PID=53773) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:13:45.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:13:45.037+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:13:45.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:13:45.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:13:45.097+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:13:45.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:13:45.116+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:13:45.116+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:13:45.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-30T03:14:15.534+0000] {processor.py:157} INFO - Started process (PID=53798) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:14:15.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:14:15.546+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:14:15.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:14:15.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:14:15.609+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:14:15.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:14:15.625+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:14:15.624+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:14:15.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.116 seconds
[2024-07-30T03:14:46.147+0000] {processor.py:157} INFO - Started process (PID=53823) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:14:46.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:14:46.154+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:14:46.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:14:46.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:14:46.210+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:14:46.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:14:46.222+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:14:46.222+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:14:46.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.094 seconds
[2024-07-30T03:15:16.738+0000] {processor.py:157} INFO - Started process (PID=53848) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:15:16.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:15:16.767+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:15:16.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:15:16.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:15:16.827+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:15:16.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:15:16.840+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:15:16.840+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:15:16.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.148 seconds
[2024-07-30T03:15:47.316+0000] {processor.py:157} INFO - Started process (PID=53873) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:15:47.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:15:47.325+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:15:47.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:15:47.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:15:47.378+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:15:47.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:15:47.391+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:15:47.391+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:15:47.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-30T03:16:17.911+0000] {processor.py:157} INFO - Started process (PID=53898) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:16:17.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:16:17.922+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:16:17.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:16:17.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:16:18.027+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:16:18.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:16:18.050+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:16:18.050+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:16:18.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.163 seconds
[2024-07-30T03:16:48.603+0000] {processor.py:157} INFO - Started process (PID=53923) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:16:48.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:16:48.611+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:16:48.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:16:48.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:16:48.671+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:16:48.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:16:48.684+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:16:48.684+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:16:48.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.114 seconds
[2024-07-30T03:17:19.099+0000] {processor.py:157} INFO - Started process (PID=53948) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:17:19.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:17:19.102+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:17:19.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:17:19.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:17:19.137+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:17:19.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:17:19.150+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:17:19.150+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:17:19.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-30T03:17:49.613+0000] {processor.py:157} INFO - Started process (PID=53973) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:17:49.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:17:49.619+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:17:49.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:17:49.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:17:49.683+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:17:49.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:17:49.695+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:17:49.695+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:17:49.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.099 seconds
[2024-07-30T03:18:20.116+0000] {processor.py:157} INFO - Started process (PID=53998) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:18:20.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:18:20.123+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:18:20.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:18:20.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:18:20.165+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:18:20.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:18:20.178+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:18:20.178+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:18:20.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-30T03:18:50.630+0000] {processor.py:157} INFO - Started process (PID=54023) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:18:50.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:18:50.634+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:18:50.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:18:50.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:18:50.694+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:18:50.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:18:50.707+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:18:50.706+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:18:50.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.100 seconds
[2024-07-30T03:19:21.196+0000] {processor.py:157} INFO - Started process (PID=54048) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:19:21.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:19:21.210+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:19:21.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:19:21.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:19:21.288+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:19:21.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:19:21.306+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:19:21.306+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:19:21.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.129 seconds
[2024-07-30T03:19:51.821+0000] {processor.py:157} INFO - Started process (PID=54073) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:19:51.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:19:51.847+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:19:51.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:19:51.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:19:51.894+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:19:51.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:19:51.908+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:19:51.908+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:19:51.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.106 seconds
[2024-07-30T03:20:22.344+0000] {processor.py:157} INFO - Started process (PID=54098) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:20:22.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:20:22.351+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:20:22.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:20:22.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:20:22.404+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:20:22.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:20:22.427+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:20:22.427+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:20:22.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.101 seconds
[2024-07-30T03:20:52.931+0000] {processor.py:157} INFO - Started process (PID=54123) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:20:52.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:20:52.939+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:20:52.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:20:52.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:20:53.003+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:20:53.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:20:53.018+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:20:53.017+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:20:53.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.110 seconds
[2024-07-30T03:21:23.488+0000] {processor.py:157} INFO - Started process (PID=54148) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:21:23.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:21:23.496+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:21:23.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:21:23.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:21:23.575+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:21:23.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:21:23.591+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:21:23.590+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:21:23.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.131 seconds
[2024-07-30T03:21:54.145+0000] {processor.py:157} INFO - Started process (PID=54173) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:21:54.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:21:54.153+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:21:54.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:21:54.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:21:54.241+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:21:54.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:21:54.260+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:21:54.260+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:21:54.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.144 seconds
[2024-07-30T03:22:24.799+0000] {processor.py:157} INFO - Started process (PID=54198) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:22:24.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:22:24.806+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:22:24.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:22:24.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:22:24.869+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:22:24.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:22:24.882+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:22:24.882+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:22:24.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-30T03:22:55.358+0000] {processor.py:157} INFO - Started process (PID=54223) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:22:55.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:22:55.366+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:22:55.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:22:55.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:22:55.423+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:22:55.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:22:55.435+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:22:55.434+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:22:55.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.097 seconds
[2024-07-30T03:23:25.872+0000] {processor.py:157} INFO - Started process (PID=54248) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:23:25.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:23:25.880+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:23:25.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:23:25.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:23:25.937+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:23:25.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:23:25.952+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:23:25.952+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:23:25.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.098 seconds
[2024-07-30T03:23:56.422+0000] {processor.py:157} INFO - Started process (PID=54273) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:23:56.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:23:56.438+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:23:56.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:23:56.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:23:56.490+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:23:56.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:23:56.504+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:23:56.503+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:23:56.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.103 seconds
[2024-07-30T03:24:26.908+0000] {processor.py:157} INFO - Started process (PID=54298) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:24:26.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:24:26.916+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:24:26.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:24:26.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:24:26.979+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:24:26.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:24:26.993+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:24:26.993+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:24:27.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.101 seconds
[2024-07-30T03:24:57.473+0000] {processor.py:157} INFO - Started process (PID=54323) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:24:57.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:24:57.479+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:24:57.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:24:57.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:24:57.539+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:24:57.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:24:57.553+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:24:57.553+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:24:57.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.096 seconds
[2024-07-30T03:25:28.050+0000] {processor.py:157} INFO - Started process (PID=54348) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:25:28.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:25:28.059+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:25:28.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:25:28.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:25:28.106+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:25:28.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:25:28.117+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:25:28.117+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:25:28.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-30T03:25:58.568+0000] {processor.py:157} INFO - Started process (PID=54373) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:25:58.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:25:58.575+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:25:58.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:25:58.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:25:58.625+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:25:58.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:25:58.643+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:25:58.643+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:25:58.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.101 seconds
[2024-07-30T03:26:29.135+0000] {processor.py:157} INFO - Started process (PID=54398) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:26:29.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:26:29.142+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:26:29.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:26:29.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:26:29.219+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:26:29.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:26:29.238+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:26:29.238+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:26:29.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.125 seconds
[2024-07-30T03:26:59.704+0000] {processor.py:157} INFO - Started process (PID=54423) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:26:59.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:26:59.712+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:26:59.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:26:59.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:26:59.775+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:26:59.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:26:59.789+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:26:59.789+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:26:59.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.107 seconds
[2024-07-30T03:27:30.269+0000] {processor.py:157} INFO - Started process (PID=54448) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:27:30.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:27:30.280+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:27:30.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:27:30.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:27:30.343+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:27:30.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:27:30.360+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:27:30.360+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:27:30.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.118 seconds
[2024-07-30T03:28:00.766+0000] {processor.py:157} INFO - Started process (PID=54473) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:28:00.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:28:00.771+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:28:00.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:28:00.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:28:00.815+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:28:00.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:28:00.840+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:28:00.840+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:28:00.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.096 seconds
[2024-07-30T03:28:31.205+0000] {processor.py:157} INFO - Started process (PID=54498) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:28:31.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:28:31.212+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:28:31.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:28:31.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:28:31.242+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:28:31.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:28:31.254+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:28:31.254+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:28:31.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-30T03:29:01.660+0000] {processor.py:157} INFO - Started process (PID=54523) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:29:01.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:29:01.666+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:29:01.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:29:01.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:29:01.705+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:29:01.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:29:01.717+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:29:01.717+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:29:01.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-30T03:29:32.127+0000] {processor.py:157} INFO - Started process (PID=54548) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:29:32.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:29:32.133+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:29:32.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:29:32.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:29:32.164+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:29:32.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:29:32.173+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:29:32.173+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:29:32.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T03:30:02.543+0000] {processor.py:157} INFO - Started process (PID=54573) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:30:02.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:30:02.549+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:30:02.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:30:02.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:30:02.604+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:30:02.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:30:02.618+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:30:02.618+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:30:02.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.094 seconds
[2024-07-30T03:30:33.056+0000] {processor.py:157} INFO - Started process (PID=54598) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:30:33.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:30:33.081+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:30:33.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:30:33.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:30:33.150+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:30:33.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:30:33.173+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:30:33.172+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:30:33.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.155 seconds
[2024-07-30T03:31:03.640+0000] {processor.py:157} INFO - Started process (PID=54623) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:31:03.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:31:03.648+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:31:03.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:31:03.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:31:03.745+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:31:03.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:31:03.762+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:31:03.762+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:31:03.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.140 seconds
[2024-07-30T03:31:34.241+0000] {processor.py:157} INFO - Started process (PID=54648) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:31:34.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:31:34.252+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:31:34.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:31:34.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:31:34.316+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:31:34.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:31:34.329+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:31:34.329+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:31:34.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.112 seconds
[2024-07-30T03:32:04.912+0000] {processor.py:157} INFO - Started process (PID=54673) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:32:04.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:32:04.922+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:32:04.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:32:04.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:32:05.017+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:32:05.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:32:05.035+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:32:05.035+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:32:05.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.156 seconds
[2024-07-30T03:32:35.507+0000] {processor.py:157} INFO - Started process (PID=54698) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:32:35.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:32:35.514+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:32:35.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:32:35.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:32:35.558+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:32:35.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:32:35.571+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:32:35.571+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:32:35.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-30T03:33:06.061+0000] {processor.py:157} INFO - Started process (PID=54723) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:33:06.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:33:06.067+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:33:06.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:33:06.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:33:06.132+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:33:06.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:33:06.146+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:33:06.146+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:33:06.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-30T03:33:36.615+0000] {processor.py:157} INFO - Started process (PID=54748) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:33:36.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:33:36.625+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:33:36.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:33:36.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:33:36.688+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:33:36.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:33:36.704+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:33:36.704+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:33:36.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.111 seconds
[2024-07-30T03:34:07.216+0000] {processor.py:157} INFO - Started process (PID=54773) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:34:07.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:34:07.231+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:34:07.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:34:07.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:34:07.308+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:34:07.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:34:07.322+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:34:07.322+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:34:07.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.140 seconds
[2024-07-30T03:34:37.786+0000] {processor.py:157} INFO - Started process (PID=54798) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:34:37.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:34:37.794+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:34:37.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:34:37.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:34:37.852+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:34:37.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:34:37.865+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:34:37.865+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:34:37.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.095 seconds
[2024-07-30T03:35:08.327+0000] {processor.py:157} INFO - Started process (PID=54823) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:35:08.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:35:08.335+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:35:08.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:35:08.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:35:08.385+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:35:08.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:35:08.404+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:35:08.403+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:35:08.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-30T03:35:38.866+0000] {processor.py:157} INFO - Started process (PID=54848) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:35:38.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:35:38.873+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:35:38.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:35:38.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:35:38.933+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:35:38.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:35:38.947+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:35:38.947+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:35:38.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.100 seconds
[2024-07-30T03:36:09.421+0000] {processor.py:157} INFO - Started process (PID=54873) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:36:09.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:36:09.430+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:36:09.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:36:09.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:36:09.499+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:36:09.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:36:09.515+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:36:09.515+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:36:09.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.116 seconds
[2024-07-30T03:36:39.940+0000] {processor.py:157} INFO - Started process (PID=54898) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:36:39.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:36:39.947+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:36:39.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:36:39.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:36:39.990+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:36:39.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:36:40.005+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:36:40.005+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:36:40.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-30T03:37:10.555+0000] {processor.py:157} INFO - Started process (PID=54923) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:37:10.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:37:10.561+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:37:10.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:37:10.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:37:10.614+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:37:10.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:37:10.632+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:37:10.631+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:37:10.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.092 seconds
[2024-07-30T03:37:41.019+0000] {processor.py:157} INFO - Started process (PID=54948) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:37:41.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:37:41.022+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:37:41.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:37:41.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:37:41.052+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:37:41.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:37:41.064+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:37:41.064+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:37:41.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T03:38:11.496+0000] {processor.py:157} INFO - Started process (PID=54973) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:38:11.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:38:11.500+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:38:11.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:38:11.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:38:11.531+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:38:11.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:38:11.540+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:38:11.540+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:38:11.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T03:38:41.892+0000] {processor.py:157} INFO - Started process (PID=54998) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:38:41.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:38:41.902+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:38:41.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:38:41.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:38:41.944+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:38:41.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:38:41.958+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:38:41.957+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:38:41.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-30T03:39:12.432+0000] {processor.py:157} INFO - Started process (PID=55023) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:39:12.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:39:12.439+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:39:12.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:39:12.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:39:12.507+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:39:12.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:39:12.522+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:39:12.522+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:39:12.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.110 seconds
[2024-07-30T03:39:43.228+0000] {processor.py:157} INFO - Started process (PID=55048) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:39:43.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:39:43.246+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:39:43.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:39:43.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:39:43.303+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:39:43.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:39:43.318+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:39:43.318+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:39:43.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.111 seconds
[2024-07-30T03:40:13.776+0000] {processor.py:157} INFO - Started process (PID=55073) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:40:13.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:40:13.783+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:40:13.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:40:13.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:40:13.836+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:40:13.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:40:13.853+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:40:13.853+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:40:13.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.098 seconds
[2024-07-30T03:40:44.393+0000] {processor.py:157} INFO - Started process (PID=55098) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:40:44.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:40:44.400+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:40:44.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:40:44.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:40:44.482+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:40:44.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:40:44.503+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:40:44.503+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:40:44.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.142 seconds
[2024-07-30T03:41:14.932+0000] {processor.py:157} INFO - Started process (PID=55123) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:41:14.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:41:14.939+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:41:14.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:41:14.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:41:14.982+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:41:14.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:41:14.997+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:41:14.997+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:41:15.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-30T03:41:45.492+0000] {processor.py:157} INFO - Started process (PID=55148) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:41:45.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:41:45.500+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:41:45.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:41:45.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:41:45.563+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:41:45.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:41:45.578+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:41:45.578+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:41:45.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.116 seconds
[2024-07-30T03:42:16.030+0000] {processor.py:157} INFO - Started process (PID=55173) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:42:16.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:42:16.040+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:42:16.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:42:16.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:42:16.110+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:42:16.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:42:16.125+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:42:16.125+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:42:16.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.136 seconds
[2024-07-30T03:42:46.598+0000] {processor.py:157} INFO - Started process (PID=55198) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:42:46.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:42:46.607+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:42:46.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:42:46.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:42:46.667+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:42:46.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:42:46.679+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:42:46.679+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:42:46.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.098 seconds
[2024-07-30T03:43:17.118+0000] {processor.py:157} INFO - Started process (PID=55223) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:43:17.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:43:17.126+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:43:17.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:43:17.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:43:17.168+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:43:17.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:43:17.181+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:43:17.181+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:43:17.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-30T03:43:47.667+0000] {processor.py:157} INFO - Started process (PID=55248) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:43:47.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:43:47.678+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:43:47.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:43:47.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:43:47.780+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:43:47.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:43:47.800+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:43:47.800+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:43:47.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.156 seconds
[2024-07-30T03:44:18.221+0000] {processor.py:157} INFO - Started process (PID=55273) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:44:18.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:44:18.226+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:44:18.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:44:18.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:44:18.278+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:44:18.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:44:18.297+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:44:18.297+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:44:18.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-30T03:44:48.790+0000] {processor.py:157} INFO - Started process (PID=55298) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:44:48.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:44:48.798+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:44:48.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:44:48.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:44:48.859+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:44:48.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:44:48.875+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:44:48.875+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:44:48.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.107 seconds
[2024-07-30T03:45:19.396+0000] {processor.py:157} INFO - Started process (PID=55323) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:45:19.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:45:19.406+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:45:19.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:45:19.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:45:19.511+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:45:19.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:45:19.531+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:45:19.530+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:45:19.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.157 seconds
[2024-07-30T03:45:50.051+0000] {processor.py:157} INFO - Started process (PID=55348) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:45:50.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:45:50.060+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:45:50.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:45:50.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:45:50.151+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:45:50.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:45:50.172+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:45:50.172+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:45:50.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.157 seconds
[2024-07-30T03:46:20.680+0000] {processor.py:157} INFO - Started process (PID=55373) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:46:20.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:46:20.689+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:46:20.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:46:20.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:46:20.759+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:46:20.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:46:20.773+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:46:20.773+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:46:20.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.124 seconds
[2024-07-30T03:46:51.230+0000] {processor.py:157} INFO - Started process (PID=55398) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:46:51.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:46:51.242+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:46:51.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:46:51.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:46:51.312+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:46:51.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:46:51.336+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:46:51.336+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:46:51.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.137 seconds
[2024-07-30T03:47:21.788+0000] {processor.py:157} INFO - Started process (PID=55423) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:47:21.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:47:21.792+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:47:21.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:47:21.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:47:21.825+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:47:21.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:47:21.837+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:47:21.837+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:47:21.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-30T03:47:52.276+0000] {processor.py:157} INFO - Started process (PID=55448) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:47:52.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:47:52.281+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:47:52.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:47:52.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:47:52.349+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:47:52.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:47:52.368+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:47:52.368+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:47:52.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.109 seconds
[2024-07-30T03:48:22.852+0000] {processor.py:157} INFO - Started process (PID=55473) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:48:22.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:48:22.868+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:48:22.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:48:22.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:48:22.946+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:48:22.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:48:22.966+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:48:22.966+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:48:22.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.138 seconds
[2024-07-30T03:48:53.423+0000] {processor.py:157} INFO - Started process (PID=55498) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:48:53.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:48:53.429+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:48:53.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:48:53.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:48:53.480+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:48:53.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:48:53.493+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:48:53.493+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:48:53.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.088 seconds
[2024-07-30T03:49:23.974+0000] {processor.py:157} INFO - Started process (PID=55523) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:49:23.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:49:23.984+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:49:23.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:49:24.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:49:24.098+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:49:24.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:49:24.117+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:49:24.117+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:49:24.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.167 seconds
[2024-07-30T03:49:54.662+0000] {processor.py:157} INFO - Started process (PID=55548) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:49:54.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:49:54.670+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:49:54.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:49:54.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:49:54.727+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:49:54.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:49:54.742+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:49:54.742+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:49:54.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.100 seconds
[2024-07-30T03:50:25.133+0000] {processor.py:157} INFO - Started process (PID=55573) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:50:25.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:50:25.142+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:50:25.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:50:25.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:50:25.265+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:50:25.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:50:25.287+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:50:25.287+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:50:25.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.177 seconds
[2024-07-30T03:50:55.791+0000] {processor.py:157} INFO - Started process (PID=55598) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:50:55.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:50:55.802+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:50:55.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:50:55.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:50:55.905+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:50:55.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:50:55.923+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:50:55.923+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:50:55.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.170 seconds
[2024-07-30T03:51:26.419+0000] {processor.py:157} INFO - Started process (PID=55623) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:51:26.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:51:26.433+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:51:26.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:51:26.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:51:26.523+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:51:26.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:51:26.539+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:51:26.538+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:51:26.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.151 seconds
[2024-07-30T03:51:57.078+0000] {processor.py:157} INFO - Started process (PID=55648) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:51:57.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:51:57.084+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:51:57.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:51:57.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:51:57.134+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:51:57.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:51:57.162+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:51:57.162+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:51:57.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.124 seconds
[2024-07-30T03:52:27.602+0000] {processor.py:157} INFO - Started process (PID=55673) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:52:27.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:52:27.612+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:52:27.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:52:27.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:52:27.702+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:52:27.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:52:27.738+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:52:27.738+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:52:27.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.158 seconds
[2024-07-30T03:52:58.151+0000] {processor.py:157} INFO - Started process (PID=55698) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:52:58.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:52:58.158+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:52:58.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:52:58.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:52:58.211+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:52:58.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:52:58.228+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:52:58.228+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:52:58.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.095 seconds
[2024-07-30T03:53:28.688+0000] {processor.py:157} INFO - Started process (PID=55723) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:53:28.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:53:28.696+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:53:28.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:53:28.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:53:28.755+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:53:28.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:53:28.774+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:53:28.774+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:53:28.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.118 seconds
[2024-07-30T03:53:59.211+0000] {processor.py:157} INFO - Started process (PID=55748) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:53:59.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:53:59.231+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:53:59.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:53:59.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:53:59.341+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:53:59.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:53:59.362+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:53:59.362+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:53:59.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.179 seconds
[2024-07-30T03:54:29.823+0000] {processor.py:157} INFO - Started process (PID=55773) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:54:29.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:54:29.834+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:54:29.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:54:29.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:54:29.921+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:54:29.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:54:29.941+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:54:29.941+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:54:29.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.155 seconds
[2024-07-30T03:55:00.440+0000] {processor.py:157} INFO - Started process (PID=55798) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:55:00.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:55:00.450+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:55:00.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:55:00.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:55:00.530+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:55:00.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:55:00.555+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:55:00.555+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:55:00.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.175 seconds
[2024-07-30T03:55:31.026+0000] {processor.py:157} INFO - Started process (PID=55823) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:55:31.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:55:31.037+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:55:31.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:55:31.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:55:31.149+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:55:31.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:55:31.167+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:55:31.167+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:55:31.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.166 seconds
[2024-07-30T03:56:01.773+0000] {processor.py:157} INFO - Started process (PID=55848) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:56:01.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:56:01.784+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:56:01.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:56:01.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:56:01.859+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:56:01.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:56:01.875+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:56:01.875+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:56:01.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.134 seconds
[2024-07-30T03:56:32.330+0000] {processor.py:157} INFO - Started process (PID=55873) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:56:32.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:56:32.332+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:56:32.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:56:32.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:56:32.366+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:56:32.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:56:32.379+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:56:32.379+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:56:32.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-30T03:57:02.778+0000] {processor.py:157} INFO - Started process (PID=55898) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:57:02.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:57:02.784+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:57:02.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:57:02.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:57:02.826+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:57:02.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:57:02.839+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:57:02.839+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:57:02.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-30T03:57:33.296+0000] {processor.py:157} INFO - Started process (PID=55923) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:57:33.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:57:33.298+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:57:33.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:57:33.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:57:33.327+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:57:33.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:57:33.339+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:57:33.339+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:57:33.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T03:58:03.720+0000] {processor.py:157} INFO - Started process (PID=55948) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:58:03.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:58:03.724+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:58:03.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:58:03.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:58:03.755+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:58:03.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:58:03.765+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:58:03.765+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:58:03.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T03:58:34.155+0000] {processor.py:157} INFO - Started process (PID=55973) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:58:34.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:58:34.159+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:58:34.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:58:34.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:58:34.186+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:58:34.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:58:34.200+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:58:34.200+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:58:34.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T03:59:04.534+0000] {processor.py:157} INFO - Started process (PID=55998) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:59:04.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:59:04.540+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:59:04.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:59:04.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:59:04.580+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:59:04.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:59:04.593+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:59:04.593+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:59:04.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-30T03:59:35.098+0000] {processor.py:157} INFO - Started process (PID=56023) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:59:35.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T03:59:35.104+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:59:35.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:59:35.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T03:59:35.144+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:59:35.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:59:35.158+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:59:35.158+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T03:59:35.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-30T04:00:05.681+0000] {processor.py:157} INFO - Started process (PID=56048) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:00:05.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:00:05.687+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:00:05.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:00:05.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:00:05.755+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:00:05.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:00:05.768+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:00:05.768+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:00:05.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-30T04:00:36.191+0000] {processor.py:157} INFO - Started process (PID=56073) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:00:36.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:00:36.196+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:00:36.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:00:36.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:00:36.226+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:00:36.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:00:36.238+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:00:36.238+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:00:36.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-30T04:01:06.663+0000] {processor.py:157} INFO - Started process (PID=56098) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:01:06.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:01:06.667+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:01:06.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:01:06.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:01:06.739+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:01:06.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:01:06.752+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:01:06.752+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:01:06.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-30T04:01:37.240+0000] {processor.py:157} INFO - Started process (PID=56123) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:01:37.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:01:37.246+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:01:37.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:01:37.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:01:37.280+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:01:37.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:01:37.290+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:01:37.290+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:01:37.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-30T04:02:07.737+0000] {processor.py:157} INFO - Started process (PID=56148) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:02:07.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:02:07.740+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:02:07.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:02:07.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:02:07.778+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:02:07.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:02:07.791+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:02:07.791+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:02:07.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-30T04:02:38.265+0000] {processor.py:157} INFO - Started process (PID=56173) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:02:38.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:02:38.271+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:02:38.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:02:38.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:02:38.312+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:02:38.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:02:38.324+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:02:38.324+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:02:38.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-30T04:03:08.766+0000] {processor.py:157} INFO - Started process (PID=56198) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:03:08.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:03:08.771+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:03:08.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:03:08.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:03:08.834+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:03:08.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:03:08.847+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:03:08.847+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:03:08.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.097 seconds
[2024-07-30T04:03:39.395+0000] {processor.py:157} INFO - Started process (PID=56223) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:03:39.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:03:39.402+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:03:39.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:03:39.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:03:39.443+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:03:39.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:03:39.456+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:03:39.456+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:03:39.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-30T04:04:09.921+0000] {processor.py:157} INFO - Started process (PID=56248) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:04:09.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:04:09.924+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:04:09.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:04:09.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:04:09.957+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:04:09.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:04:09.967+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:04:09.967+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:04:09.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-30T04:04:40.388+0000] {processor.py:157} INFO - Started process (PID=56273) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:04:40.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:04:40.395+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:04:40.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:04:40.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:04:40.438+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:04:40.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:04:40.451+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:04:40.451+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:04:40.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-30T04:05:10.921+0000] {processor.py:157} INFO - Started process (PID=56298) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:05:10.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:05:10.928+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:05:10.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:05:10.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:05:10.972+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:05:10.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:05:10.985+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:05:10.985+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:05:10.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-30T04:05:41.461+0000] {processor.py:157} INFO - Started process (PID=56323) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:05:41.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:05:41.466+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:05:41.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:05:41.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:05:41.492+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:05:41.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:05:41.502+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:05:41.502+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:05:41.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-30T04:06:12.001+0000] {processor.py:157} INFO - Started process (PID=56348) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:06:12.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:06:12.007+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:06:12.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:06:12.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:06:12.064+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:06:12.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:06:12.077+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:06:12.077+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:06:12.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.095 seconds
[2024-07-30T04:06:42.483+0000] {processor.py:157} INFO - Started process (PID=56373) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:06:42.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:06:42.486+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:06:42.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:06:42.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:06:42.511+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:06:42.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:06:42.520+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:06:42.520+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:06:42.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-30T04:07:12.987+0000] {processor.py:157} INFO - Started process (PID=56398) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:07:12.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:07:12.993+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:07:12.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:07:13.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:07:13.047+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:07:13.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:07:13.062+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:07:13.062+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:07:13.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-30T04:07:43.557+0000] {processor.py:157} INFO - Started process (PID=56423) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:07:43.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:07:43.562+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:07:43.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:07:43.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:07:43.591+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:07:43.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:07:43.602+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:07:43.601+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:07:43.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T04:08:14.088+0000] {processor.py:157} INFO - Started process (PID=56448) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:08:14.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:08:14.094+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:08:14.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:08:14.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:08:14.140+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:08:14.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:08:14.154+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:08:14.154+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:08:14.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-30T04:08:44.610+0000] {processor.py:157} INFO - Started process (PID=56473) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:08:44.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:08:44.616+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:08:44.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:08:44.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:08:44.645+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:08:44.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:08:44.654+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:08:44.654+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:08:44.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T04:09:15.633+0000] {processor.py:157} INFO - Started process (PID=56498) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:09:15.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:09:15.639+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:09:15.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:09:15.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:09:15.696+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:09:15.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:09:15.711+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:09:15.711+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:09:15.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.102 seconds
[2024-07-30T04:10:06.546+0000] {processor.py:157} INFO - Started process (PID=56523) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:10:06.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:10:06.548+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:10:06.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:10:06.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:10:06.571+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:10:06.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:10:06.585+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:10:06.585+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:10:06.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-30T04:10:36.946+0000] {processor.py:157} INFO - Started process (PID=56550) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:10:36.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:10:36.956+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:10:36.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:10:36.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:10:36.995+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:10:36.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:10:37.008+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:10:37.008+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:10:37.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-30T04:26:28.246+0000] {processor.py:157} INFO - Started process (PID=56577) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:26:28.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:26:28.250+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:26:28.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:26:28.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:26:28.281+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:26:28.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:26:28.292+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:26:28.292+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:26:28.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T04:26:58.712+0000] {processor.py:157} INFO - Started process (PID=56602) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:26:58.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:26:58.719+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:26:58.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:26:58.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:26:58.758+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:26:58.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:26:58.771+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:26:58.771+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:26:58.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-30T04:27:29.176+0000] {processor.py:157} INFO - Started process (PID=56627) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:27:29.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:27:29.181+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:27:29.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:27:29.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:27:29.216+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:27:29.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:27:29.229+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:27:29.229+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:27:29.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-30T04:27:59.640+0000] {processor.py:157} INFO - Started process (PID=56652) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:27:59.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:27:59.644+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:27:59.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:27:59.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:27:59.674+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:27:59.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:27:59.689+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:27:59.689+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:27:59.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-30T04:28:57.136+0000] {processor.py:157} INFO - Started process (PID=56679) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:28:57.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:28:57.142+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:28:57.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:28:57.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:28:57.186+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:28:57.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:28:57.200+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:28:57.200+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:28:57.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-30T04:29:27.666+0000] {processor.py:157} INFO - Started process (PID=56704) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:29:27.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:29:27.672+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:29:27.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:29:27.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:29:27.700+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:29:27.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:29:27.710+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:29:27.710+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:29:27.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T04:31:10.356+0000] {processor.py:157} INFO - Started process (PID=56729) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:31:10.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:31:10.360+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:31:10.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:31:10.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:31:10.409+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:31:10.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:31:10.438+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:31:10.438+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:31:10.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.108 seconds
[2024-07-30T04:32:43.112+0000] {processor.py:157} INFO - Started process (PID=56754) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:32:43.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:32:43.119+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:32:43.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:32:43.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:32:43.177+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:32:43.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:32:43.200+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:32:43.200+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:32:43.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.111 seconds
[2024-07-30T04:33:13.504+0000] {processor.py:157} INFO - Started process (PID=56779) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:33:13.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:33:13.508+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:33:13.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:33:13.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:33:13.539+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:33:13.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:33:13.553+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:33:13.553+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:33:13.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-30T04:33:44.382+0000] {processor.py:157} INFO - Started process (PID=56804) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:33:44.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:33:44.387+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:33:44.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:33:44.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:33:44.431+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:33:44.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:33:44.443+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:33:44.443+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:33:44.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-30T04:34:30.550+0000] {processor.py:157} INFO - Started process (PID=56829) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:34:30.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:34:30.558+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:34:30.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:34:30.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:34:30.625+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:34:30.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:34:30.641+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:34:30.641+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:34:30.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.112 seconds
[2024-07-30T04:35:00.978+0000] {processor.py:157} INFO - Started process (PID=56856) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:35:00.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:35:00.983+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:35:00.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:35:00.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:35:01.009+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:35:01.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:35:01.021+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:35:01.021+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:35:01.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T04:35:31.453+0000] {processor.py:157} INFO - Started process (PID=56881) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:35:31.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:35:31.472+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:35:31.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:35:31.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:35:31.609+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:35:31.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:35:31.636+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:35:31.636+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:35:31.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.226 seconds
[2024-07-30T04:36:02.058+0000] {processor.py:157} INFO - Started process (PID=56906) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:36:02.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:36:02.062+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:36:02.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:36:02.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:36:02.088+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:36:02.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:36:02.097+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:36:02.097+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:36:02.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-30T04:36:32.573+0000] {processor.py:157} INFO - Started process (PID=56931) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:36:32.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:36:32.579+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:36:32.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:36:32.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:36:32.627+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:36:32.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:36:32.641+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:36:32.641+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:36:32.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.084 seconds
[2024-07-30T04:37:03.069+0000] {processor.py:157} INFO - Started process (PID=56956) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:37:03.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:37:03.073+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:37:03.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:37:03.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:37:03.107+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:37:03.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:37:03.119+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:37:03.119+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:37:03.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-30T04:37:33.499+0000] {processor.py:157} INFO - Started process (PID=56981) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:37:33.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:37:33.503+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:37:33.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:37:33.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:37:33.532+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:37:33.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:37:33.542+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:37:33.542+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:37:33.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T04:38:03.963+0000] {processor.py:157} INFO - Started process (PID=57006) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:38:03.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:38:03.968+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:38:03.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:38:03.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:38:03.999+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:38:03.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:38:04.010+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:38:04.010+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:38:04.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-30T04:38:34.388+0000] {processor.py:157} INFO - Started process (PID=57031) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:38:34.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:38:34.392+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:38:34.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:38:34.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:38:34.418+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:38:34.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:38:34.432+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:38:34.432+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:38:34.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T04:39:04.758+0000] {processor.py:157} INFO - Started process (PID=57056) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:39:04.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:39:04.762+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:39:04.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:39:04.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:39:04.795+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:39:04.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:39:04.806+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:39:04.806+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:39:04.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-30T04:39:35.203+0000] {processor.py:157} INFO - Started process (PID=57081) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:39:35.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:39:35.209+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:39:35.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:39:35.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:39:35.252+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:39:35.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:39:35.266+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:39:35.266+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:39:35.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-30T04:40:05.663+0000] {processor.py:157} INFO - Started process (PID=57106) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:40:05.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:40:05.668+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:40:05.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:40:05.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:40:05.697+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:40:05.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:40:05.708+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:40:05.708+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:40:05.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T04:40:36.069+0000] {processor.py:157} INFO - Started process (PID=57131) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:40:36.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:40:36.074+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:40:36.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:40:36.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:40:36.107+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:40:36.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:40:36.119+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:40:36.119+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:40:36.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-30T04:41:06.505+0000] {processor.py:157} INFO - Started process (PID=57156) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:41:06.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:41:06.507+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:41:06.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:41:06.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:41:06.533+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:41:06.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:41:06.544+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:41:06.544+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:41:06.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-30T04:41:36.986+0000] {processor.py:157} INFO - Started process (PID=57181) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:41:36.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:41:36.992+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:41:36.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:41:37.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:41:37.020+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:41:37.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:41:37.030+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:41:37.030+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:41:37.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T04:42:07.418+0000] {processor.py:157} INFO - Started process (PID=57206) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:42:07.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:42:07.427+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:42:07.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:42:07.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:42:07.466+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:42:07.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:42:07.477+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:42:07.477+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:42:07.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-30T04:42:37.823+0000] {processor.py:157} INFO - Started process (PID=57231) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:42:37.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:42:37.824+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:42:37.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:42:37.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:42:37.846+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:42:37.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:42:37.854+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:42:37.854+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:42:37.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.040 seconds
[2024-07-30T04:43:08.318+0000] {processor.py:157} INFO - Started process (PID=57256) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:43:08.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:43:08.325+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:43:08.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:43:08.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:43:08.379+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:43:08.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:43:08.397+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:43:08.396+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:43:08.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.095 seconds
[2024-07-30T04:43:59.394+0000] {processor.py:157} INFO - Started process (PID=57281) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:43:59.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:43:59.400+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:43:59.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:43:59.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:43:59.435+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:43:59.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:43:59.447+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:43:59.447+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:43:59.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-30T04:47:05.227+0000] {processor.py:157} INFO - Started process (PID=57308) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:47:05.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:47:05.232+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:47:05.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:47:05.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:47:05.300+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:47:05.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:47:05.324+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:47:05.323+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:47:05.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.119 seconds
[2024-07-30T04:47:35.941+0000] {processor.py:157} INFO - Started process (PID=57333) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:47:35.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:47:35.947+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:47:35.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:47:35.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:47:36.021+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:47:36.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:47:36.047+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:47:36.047+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:47:36.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.124 seconds
[2024-07-30T04:48:33.277+0000] {processor.py:157} INFO - Started process (PID=57358) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:48:33.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:48:33.282+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:48:33.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:48:33.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:48:33.323+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:48:33.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:48:33.334+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:48:33.334+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:48:33.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-30T04:49:03.720+0000] {processor.py:157} INFO - Started process (PID=57383) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:49:03.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T04:49:03.724+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:49:03.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:49:03.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T04:49:03.756+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:49:03.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:49:03.769+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:49:03.769+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T04:49:03.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-30T05:05:16.036+0000] {processor.py:157} INFO - Started process (PID=57408) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:05:16.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T05:05:16.044+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:05:16.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:05:16.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:05:16.101+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:05:16.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T05:05:16.126+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:05:16.126+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T05:05:16.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.117 seconds
[2024-07-30T05:05:46.589+0000] {processor.py:157} INFO - Started process (PID=57435) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:05:46.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T05:05:46.594+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:05:46.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:05:46.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:05:46.635+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:05:46.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T05:05:46.650+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:05:46.650+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T05:05:46.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-30T05:06:17.027+0000] {processor.py:157} INFO - Started process (PID=57460) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:06:17.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T05:06:17.033+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:06:17.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:06:17.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:06:17.063+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:06:17.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T05:06:17.075+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:06:17.075+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T05:06:17.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-30T05:06:47.450+0000] {processor.py:157} INFO - Started process (PID=57485) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:06:47.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T05:06:47.452+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:06:47.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:06:47.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:06:47.477+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:06:47.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T05:06:47.489+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:06:47.489+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T05:06:47.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-30T05:23:25.886+0000] {processor.py:157} INFO - Started process (PID=57512) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:23:25.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T05:23:25.893+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:23:25.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:23:25.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:23:25.959+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:23:25.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T05:23:25.983+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:23:25.983+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T05:23:26.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.124 seconds
[2024-07-30T05:23:56.447+0000] {processor.py:157} INFO - Started process (PID=57537) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:23:56.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T05:23:56.450+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:23:56.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:23:56.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:23:56.480+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:23:56.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T05:23:56.490+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:23:56.490+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T05:23:56.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T05:24:26.835+0000] {processor.py:157} INFO - Started process (PID=57562) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:24:26.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T05:24:26.839+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:24:26.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:24:26.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:24:26.874+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:24:26.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T05:24:26.887+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:24:26.887+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T05:24:26.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-30T05:24:57.359+0000] {processor.py:157} INFO - Started process (PID=57587) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:24:57.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T05:24:57.364+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:24:57.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:24:57.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:24:57.391+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:24:57.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T05:24:57.402+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:24:57.402+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T05:24:57.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T05:25:27.875+0000] {processor.py:157} INFO - Started process (PID=57612) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:25:27.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T05:25:27.880+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:25:27.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:25:27.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:25:27.913+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:25:27.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T05:25:27.929+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:25:27.929+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T05:25:27.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-30T05:42:15.008+0000] {processor.py:157} INFO - Started process (PID=57639) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:42:15.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T05:42:15.017+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:42:15.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:42:15.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:42:15.081+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:42:15.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T05:42:15.108+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:42:15.108+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T05:42:15.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.133 seconds
[2024-07-30T05:42:45.656+0000] {processor.py:157} INFO - Started process (PID=57664) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:42:45.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T05:42:45.662+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:42:45.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:42:45.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:42:45.702+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:42:45.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T05:42:45.714+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:42:45.714+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T05:42:45.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-30T05:43:16.080+0000] {processor.py:157} INFO - Started process (PID=57689) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:43:16.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T05:43:16.083+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:43:16.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:43:16.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:43:16.106+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:43:16.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T05:43:16.120+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:43:16.120+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T05:43:16.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-30T05:43:46.595+0000] {processor.py:157} INFO - Started process (PID=57714) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:43:46.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T05:43:46.597+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:43:46.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:43:46.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:43:46.625+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:43:46.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T05:43:46.637+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:43:46.637+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T05:43:46.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T05:44:17.071+0000] {processor.py:157} INFO - Started process (PID=57739) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:44:17.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T05:44:17.073+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:44:17.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:44:17.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:44:17.102+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:44:17.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T05:44:17.112+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:44:17.112+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T05:44:17.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-30T05:59:33.309+0000] {processor.py:157} INFO - Started process (PID=57765) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:59:33.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T05:59:33.316+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:59:33.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:59:33.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T05:59:33.376+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:59:33.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T05:59:33.401+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:59:33.401+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T05:59:33.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-30T06:00:03.881+0000] {processor.py:157} INFO - Started process (PID=57790) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:00:03.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T06:00:03.884+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:00:03.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:00:03.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:00:03.910+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:00:03.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:00:03.921+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:00:03.921+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T06:00:03.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-30T06:00:34.342+0000] {processor.py:157} INFO - Started process (PID=57815) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:00:34.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T06:00:34.349+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:00:34.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:00:34.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:00:34.409+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:00:34.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:00:34.421+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:00:34.421+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T06:00:34.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.095 seconds
[2024-07-30T06:01:04.903+0000] {processor.py:157} INFO - Started process (PID=57840) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:01:04.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T06:01:04.907+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:01:04.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:01:04.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:01:04.935+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:01:04.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:01:04.947+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:01:04.947+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T06:01:04.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T06:01:35.322+0000] {processor.py:157} INFO - Started process (PID=57865) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:01:35.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T06:01:35.327+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:01:35.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:01:35.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:01:35.357+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:01:35.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:01:35.370+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:01:35.370+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T06:01:35.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T06:17:12.368+0000] {processor.py:157} INFO - Started process (PID=57890) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:17:12.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T06:17:12.370+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:17:12.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:17:12.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:17:12.401+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:17:12.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:17:12.412+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:17:12.412+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T06:17:12.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T06:23:33.060+0000] {processor.py:157} INFO - Started process (PID=57917) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:23:33.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T06:23:33.065+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:23:33.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:23:33.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:23:33.170+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:23:33.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:23:33.186+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:23:33.186+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T06:23:33.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.151 seconds
[2024-07-30T06:24:03.777+0000] {processor.py:157} INFO - Started process (PID=57942) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:24:03.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T06:24:03.782+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:24:03.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:24:03.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:24:03.816+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:24:03.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:24:03.829+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:24:03.829+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T06:24:03.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-30T06:24:34.227+0000] {processor.py:157} INFO - Started process (PID=57967) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:24:34.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T06:24:34.231+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:24:34.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:24:34.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:24:34.254+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:24:34.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:24:34.266+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:24:34.266+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T06:24:34.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-30T06:25:04.744+0000] {processor.py:157} INFO - Started process (PID=57992) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:25:04.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T06:25:04.750+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:25:04.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:25:04.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:25:04.786+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:25:04.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:25:04.796+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:25:04.796+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T06:25:04.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-30T06:25:35.200+0000] {processor.py:157} INFO - Started process (PID=58017) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:25:35.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T06:25:35.204+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:25:35.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:25:35.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:25:35.236+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:25:35.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:25:35.251+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:25:35.251+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T06:25:35.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-30T06:31:37.789+0000] {processor.py:157} INFO - Started process (PID=58042) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:31:37.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T06:31:37.794+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:31:37.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:31:37.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:31:37.872+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:31:37.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:31:37.901+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:31:37.901+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T06:31:37.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.139 seconds
[2024-07-30T06:32:08.372+0000] {processor.py:157} INFO - Started process (PID=58069) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:32:08.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T06:32:08.380+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:32:08.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:32:08.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:32:08.419+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:32:08.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:32:08.434+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:32:08.434+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T06:32:08.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-30T06:33:25.248+0000] {processor.py:157} INFO - Started process (PID=58096) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:33:25.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T06:33:25.257+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:33:25.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:33:25.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:33:25.327+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:33:25.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:33:25.339+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:33:25.339+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T06:33:25.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.106 seconds
[2024-07-30T06:33:55.802+0000] {processor.py:157} INFO - Started process (PID=58121) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:33:55.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T06:33:55.806+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:33:55.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:33:55.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:33:55.836+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:33:55.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:33:55.848+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:33:55.848+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T06:33:55.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-30T06:34:26.252+0000] {processor.py:157} INFO - Started process (PID=58146) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:34:26.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T06:34:26.257+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:34:26.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:34:26.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:34:26.303+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:34:26.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:34:26.319+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:34:26.319+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T06:34:26.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.085 seconds
[2024-07-30T06:34:56.758+0000] {processor.py:157} INFO - Started process (PID=58171) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:34:56.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T06:34:56.763+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:34:56.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:34:56.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:34:56.792+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:34:56.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:34:56.802+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:34:56.802+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T06:34:56.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T06:35:27.215+0000] {processor.py:157} INFO - Started process (PID=58196) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:35:27.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T06:35:27.221+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:35:27.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:35:27.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:35:27.261+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:35:27.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:35:27.275+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:35:27.275+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T06:35:27.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-30T06:35:57.692+0000] {processor.py:157} INFO - Started process (PID=58221) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:35:57.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T06:35:57.697+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:35:57.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:35:57.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:35:57.726+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:35:57.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:35:57.735+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:35:57.735+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T06:35:57.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T06:36:28.176+0000] {processor.py:157} INFO - Started process (PID=58246) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:36:28.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T06:36:28.178+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:36:28.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:36:28.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:36:28.216+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:36:28.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:36:28.226+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:36:28.226+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T06:36:28.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-30T06:36:58.535+0000] {processor.py:157} INFO - Started process (PID=58271) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:36:58.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T06:36:58.538+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:36:58.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:36:58.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:36:58.565+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:36:58.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:36:58.578+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:36:58.578+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T06:36:58.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-30T06:38:47.747+0000] {processor.py:157} INFO - Started process (PID=58296) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:38:47.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T06:38:47.753+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:38:47.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:38:47.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:38:47.808+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:38:47.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:38:47.825+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:38:47.825+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T06:38:47.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.101 seconds
[2024-07-30T06:39:18.221+0000] {processor.py:157} INFO - Started process (PID=58321) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:39:18.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T06:39:18.225+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:39:18.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:39:18.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:39:18.256+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:39:18.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:39:18.271+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:39:18.271+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T06:39:18.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-30T06:55:15.279+0000] {processor.py:157} INFO - Started process (PID=58346) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:55:15.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T06:55:15.287+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:55:15.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:55:15.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T06:55:15.353+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:55:15.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:55:15.381+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:55:15.381+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T06:55:15.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-30T07:01:12.154+0000] {processor.py:157} INFO - Started process (PID=58373) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:01:12.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T07:01:12.161+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:01:12.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:01:12.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:01:12.251+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:01:12.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:01:12.272+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:01:12.272+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T07:01:12.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.138 seconds
[2024-07-30T07:01:42.616+0000] {processor.py:157} INFO - Started process (PID=58398) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:01:42.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T07:01:42.619+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:01:42.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:01:42.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:01:42.647+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:01:42.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:01:42.656+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:01:42.656+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T07:01:42.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T07:06:39.323+0000] {processor.py:157} INFO - Started process (PID=58423) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:06:39.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T07:06:39.329+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:06:39.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:06:39.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:06:39.372+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:06:39.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:06:39.404+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:06:39.404+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T07:06:39.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.116 seconds
[2024-07-30T07:23:06.531+0000] {processor.py:157} INFO - Started process (PID=58448) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:23:06.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T07:23:06.533+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:23:06.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:23:06.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:23:06.567+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:23:06.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:23:06.581+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:23:06.581+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T07:23:06.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-30T07:23:37.025+0000] {processor.py:157} INFO - Started process (PID=58473) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:23:37.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T07:23:37.055+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:23:37.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:23:37.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:23:37.096+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:23:37.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:23:37.106+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:23:37.106+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T07:23:37.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.096 seconds
[2024-07-30T07:24:07.483+0000] {processor.py:157} INFO - Started process (PID=58498) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:24:07.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T07:24:07.488+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:24:07.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:24:07.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:24:07.515+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:24:07.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:24:07.524+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:24:07.524+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T07:24:07.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-30T07:24:37.931+0000] {processor.py:157} INFO - Started process (PID=58523) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:24:37.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T07:24:37.935+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:24:37.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:24:37.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:24:37.965+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:24:37.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:24:37.974+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:24:37.974+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T07:24:37.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T07:25:08.387+0000] {processor.py:157} INFO - Started process (PID=58548) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:25:08.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T07:25:08.391+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:25:08.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:25:08.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:25:08.419+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:25:08.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:25:08.431+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:25:08.431+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T07:25:08.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T07:25:38.873+0000] {processor.py:157} INFO - Started process (PID=58573) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:25:38.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T07:25:38.879+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:25:38.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:25:38.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:25:38.920+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:25:38.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:25:38.936+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:25:38.936+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T07:25:38.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-30T07:29:57.523+0000] {processor.py:157} INFO - Started process (PID=58598) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:29:57.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T07:29:57.530+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:29:57.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:29:57.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:29:57.585+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:29:57.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:29:57.598+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:29:57.598+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T07:29:57.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.089 seconds
[2024-07-30T07:30:28.011+0000] {processor.py:157} INFO - Started process (PID=58623) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:30:28.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T07:30:28.015+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:30:28.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:30:28.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:30:28.059+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:30:28.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:30:28.074+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:30:28.074+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T07:30:28.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-30T07:32:24.957+0000] {processor.py:157} INFO - Started process (PID=58648) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:32:24.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T07:32:24.966+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:32:24.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:32:25.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:32:25.087+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:32:25.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:32:25.125+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:32:25.125+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T07:32:25.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.208 seconds
[2024-07-30T07:32:55.871+0000] {processor.py:157} INFO - Started process (PID=58673) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:32:55.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T07:32:55.877+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:32:55.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:32:55.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:32:55.945+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:32:55.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:32:55.960+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:32:55.960+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T07:32:55.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.123 seconds
[2024-07-30T07:34:18.795+0000] {processor.py:157} INFO - Started process (PID=58700) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:34:18.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T07:34:18.804+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:34:18.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:34:18.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:34:18.877+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:34:18.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:34:18.895+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:34:18.894+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T07:34:18.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.121 seconds
[2024-07-30T07:34:49.445+0000] {processor.py:157} INFO - Started process (PID=58725) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:34:49.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T07:34:49.452+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:34:49.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:34:49.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:34:49.500+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:34:49.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:34:49.526+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:34:49.526+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T07:34:49.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.120 seconds
[2024-07-30T07:50:55.150+0000] {processor.py:157} INFO - Started process (PID=58750) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:50:55.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T07:50:55.154+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:50:55.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:50:55.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:50:55.209+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:50:55.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:50:55.230+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:50:55.230+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T07:50:55.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.100 seconds
[2024-07-30T07:51:25.655+0000] {processor.py:157} INFO - Started process (PID=58775) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:51:25.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T07:51:25.660+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:51:25.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:51:25.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:51:25.699+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:51:25.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:51:25.711+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:51:25.711+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T07:51:25.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-30T07:57:15.728+0000] {processor.py:157} INFO - Started process (PID=58802) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:57:15.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T07:57:15.731+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:57:15.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:57:15.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:57:15.797+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:57:15.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:57:15.822+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:57:15.822+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T07:57:15.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.120 seconds
[2024-07-30T07:57:46.204+0000] {processor.py:157} INFO - Started process (PID=58827) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:57:46.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T07:57:46.211+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:57:46.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:57:46.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:57:46.248+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:57:46.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:57:46.259+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:57:46.259+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T07:57:46.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-30T07:58:16.719+0000] {processor.py:157} INFO - Started process (PID=58852) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:58:16.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T07:58:16.724+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:58:16.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:58:16.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:58:16.753+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:58:16.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:58:16.765+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:58:16.765+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T07:58:16.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T07:58:47.160+0000] {processor.py:157} INFO - Started process (PID=58877) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:58:47.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T07:58:47.164+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:58:47.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:58:47.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:58:47.193+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:58:47.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:58:47.204+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:58:47.204+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T07:58:47.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T07:59:17.637+0000] {processor.py:157} INFO - Started process (PID=58902) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:59:17.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T07:59:17.641+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:59:17.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:59:17.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T07:59:17.670+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:59:17.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:59:17.679+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:59:17.679+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T07:59:17.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T08:01:40.944+0000] {processor.py:157} INFO - Started process (PID=58929) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:01:40.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:01:40.948+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:01:40.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:01:40.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:01:40.984+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:01:40.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:01:40.996+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:01:40.995+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:01:41.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-30T08:06:02.266+0000] {processor.py:157} INFO - Started process (PID=58954) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:06:02.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:06:02.275+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:06:02.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:06:02.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:06:02.353+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:06:02.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:06:02.369+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:06:02.369+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:06:02.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.128 seconds
[2024-07-30T08:06:32.874+0000] {processor.py:157} INFO - Started process (PID=58979) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:06:32.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:06:32.884+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:06:32.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:06:32.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:06:32.990+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:06:32.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:06:33.020+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:06:33.020+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:06:33.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.174 seconds
[2024-07-30T08:07:03.477+0000] {processor.py:157} INFO - Started process (PID=59004) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:07:03.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:07:03.481+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:07:03.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:07:03.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:07:03.512+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:07:03.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:07:03.522+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:07:03.522+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:07:03.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-30T08:07:33.891+0000] {processor.py:157} INFO - Started process (PID=59029) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:07:33.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:07:33.895+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:07:33.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:07:33.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:07:33.923+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:07:33.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:07:33.936+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:07:33.936+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:07:33.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T08:08:04.332+0000] {processor.py:157} INFO - Started process (PID=59054) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:08:04.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:08:04.336+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:08:04.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:08:04.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:08:04.365+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:08:04.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:08:04.378+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:08:04.378+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:08:04.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T08:08:34.770+0000] {processor.py:157} INFO - Started process (PID=59079) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:08:34.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:08:34.774+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:08:34.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:08:34.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:08:34.808+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:08:34.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:08:34.820+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:08:34.820+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:08:34.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-30T08:09:05.284+0000] {processor.py:157} INFO - Started process (PID=59104) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:09:05.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:09:05.293+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:09:05.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:09:05.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:09:05.337+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:09:05.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:09:05.355+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:09:05.355+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:09:05.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.091 seconds
[2024-07-30T08:09:35.781+0000] {processor.py:157} INFO - Started process (PID=59129) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:09:35.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:09:35.786+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:09:35.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:09:35.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:09:35.817+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:09:35.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:09:35.829+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:09:35.829+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:09:35.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-30T08:10:06.279+0000] {processor.py:157} INFO - Started process (PID=59154) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:10:06.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:10:06.286+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:10:06.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:10:06.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:10:06.317+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:10:06.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:10:06.329+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:10:06.329+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:10:06.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T08:10:36.767+0000] {processor.py:157} INFO - Started process (PID=59179) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:10:36.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:10:36.771+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:10:36.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:10:36.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:10:36.802+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:10:36.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:10:36.811+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:10:36.811+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:10:36.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T08:11:07.176+0000] {processor.py:157} INFO - Started process (PID=59204) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:11:07.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:11:07.180+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:11:07.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:11:07.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:11:07.207+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:11:07.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:11:07.218+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:11:07.218+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:11:07.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T08:11:37.593+0000] {processor.py:157} INFO - Started process (PID=59229) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:11:37.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:11:37.598+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:11:37.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:11:37.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:11:37.625+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:11:37.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:11:37.633+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:11:37.633+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:11:37.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T08:12:08.031+0000] {processor.py:157} INFO - Started process (PID=59254) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:12:08.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:12:08.034+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:12:08.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:12:08.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:12:08.070+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:12:08.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:12:08.083+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:12:08.083+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:12:08.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-30T08:12:38.538+0000] {processor.py:157} INFO - Started process (PID=59279) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:12:38.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:12:38.542+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:12:38.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:12:38.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:12:38.567+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:12:38.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:12:38.577+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:12:38.577+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:12:38.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-30T08:13:08.933+0000] {processor.py:157} INFO - Started process (PID=59304) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:13:08.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:13:08.940+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:13:08.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:13:08.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:13:08.975+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:13:08.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:13:08.985+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:13:08.985+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:13:08.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-30T08:13:39.419+0000] {processor.py:157} INFO - Started process (PID=59329) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:13:39.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:13:39.423+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:13:39.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:13:39.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:13:39.450+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:13:39.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:13:39.464+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:13:39.464+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:13:39.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T08:14:09.835+0000] {processor.py:157} INFO - Started process (PID=59354) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:14:09.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:14:09.840+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:14:09.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:14:09.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:14:09.867+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:14:09.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:14:09.881+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:14:09.880+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:14:09.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T08:14:40.192+0000] {processor.py:157} INFO - Started process (PID=59379) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:14:40.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:14:40.195+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:14:40.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:14:40.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:14:40.221+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:14:40.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:14:40.234+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:14:40.234+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:14:40.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T08:15:10.607+0000] {processor.py:157} INFO - Started process (PID=59404) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:15:10.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:15:10.612+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:15:10.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:15:10.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:15:10.642+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:15:10.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:15:10.652+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:15:10.652+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:15:10.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T08:15:41.081+0000] {processor.py:157} INFO - Started process (PID=59429) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:15:41.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:15:41.082+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:15:41.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:15:41.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:15:41.104+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:15:41.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:15:41.114+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:15:41.114+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:15:41.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-30T08:16:11.641+0000] {processor.py:157} INFO - Started process (PID=59454) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:16:11.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:16:11.643+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:16:11.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:16:11.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:16:11.668+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:16:11.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:16:11.681+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:16:11.681+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:16:11.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T08:16:42.107+0000] {processor.py:157} INFO - Started process (PID=59479) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:16:42.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:16:42.110+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:16:42.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:16:42.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:16:42.138+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:16:42.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:16:42.149+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:16:42.149+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:16:42.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T08:17:12.538+0000] {processor.py:157} INFO - Started process (PID=59504) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:17:12.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:17:12.541+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:17:12.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:17:12.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:17:12.572+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:17:12.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:17:12.582+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:17:12.582+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:17:12.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T08:17:43.001+0000] {processor.py:157} INFO - Started process (PID=59529) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:17:43.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:17:43.006+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:17:43.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:17:43.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:17:43.033+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:17:43.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:17:43.043+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:17:43.043+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:17:43.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-30T08:18:13.481+0000] {processor.py:157} INFO - Started process (PID=59554) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:18:13.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:18:13.487+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:18:13.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:18:13.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:18:13.529+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:18:13.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:18:13.544+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:18:13.544+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:18:13.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-30T08:18:44.012+0000] {processor.py:157} INFO - Started process (PID=59579) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:18:44.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:18:44.017+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:18:44.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:18:44.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:18:44.044+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:18:44.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:18:44.053+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:18:44.053+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:18:44.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T08:19:14.400+0000] {processor.py:157} INFO - Started process (PID=59604) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:19:14.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:19:14.404+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:19:14.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:19:14.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:19:14.431+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:19:14.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:19:14.441+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:19:14.441+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:19:14.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-30T08:19:44.891+0000] {processor.py:157} INFO - Started process (PID=59629) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:19:44.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:19:44.896+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:19:44.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:19:44.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:19:44.923+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:19:44.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:19:44.933+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:19:44.933+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:19:44.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T08:20:15.321+0000] {processor.py:157} INFO - Started process (PID=59654) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:20:15.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:20:15.326+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:20:15.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:20:15.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:20:15.355+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:20:15.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:20:15.365+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:20:15.365+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:20:15.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T08:20:45.740+0000] {processor.py:157} INFO - Started process (PID=59679) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:20:45.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:20:45.744+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:20:45.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:20:45.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:20:45.773+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:20:45.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:20:45.784+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:20:45.784+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:20:45.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T08:21:16.195+0000] {processor.py:157} INFO - Started process (PID=59704) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:21:16.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:21:16.200+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:21:16.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:21:16.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:21:16.228+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:21:16.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:21:16.239+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:21:16.238+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:21:16.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T08:21:46.652+0000] {processor.py:157} INFO - Started process (PID=59729) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:21:46.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:21:46.656+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:21:46.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:21:46.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:21:46.681+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:21:46.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:21:46.692+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:21:46.692+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:21:46.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-30T08:22:17.036+0000] {processor.py:157} INFO - Started process (PID=59754) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:22:17.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:22:17.041+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:22:17.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:22:17.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:22:17.071+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:22:17.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:22:17.080+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:22:17.080+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:22:17.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T08:22:47.391+0000] {processor.py:157} INFO - Started process (PID=59779) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:22:47.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:22:47.393+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:22:47.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:22:47.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:22:47.416+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:22:47.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:22:47.424+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:22:47.424+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:22:47.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.041 seconds
[2024-07-30T08:23:17.849+0000] {processor.py:157} INFO - Started process (PID=59804) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:23:17.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:23:17.854+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:23:17.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:23:17.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:23:17.889+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:23:17.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:23:17.901+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:23:17.901+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:23:17.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-30T08:23:48.311+0000] {processor.py:157} INFO - Started process (PID=59829) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:23:48.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:23:48.313+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:23:48.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:23:48.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:23:48.344+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:23:48.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:23:48.356+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:23:48.356+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:23:48.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T08:24:18.697+0000] {processor.py:157} INFO - Started process (PID=59854) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:24:18.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:24:18.700+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:24:18.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:24:18.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:24:18.729+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:24:18.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:24:18.739+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:24:18.739+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:24:18.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T08:24:49.114+0000] {processor.py:157} INFO - Started process (PID=59879) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:24:49.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:24:49.119+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:24:49.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:24:49.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:24:49.156+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:24:49.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:24:49.166+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:24:49.166+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:24:49.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-30T08:25:19.546+0000] {processor.py:157} INFO - Started process (PID=59904) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:25:19.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:25:19.553+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:25:19.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:25:19.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:25:19.580+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:25:19.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:25:19.590+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:25:19.589+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:25:19.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T08:25:49.976+0000] {processor.py:157} INFO - Started process (PID=59929) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:25:49.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:25:49.981+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:25:49.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:25:49.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:25:50.007+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:25:50.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:25:50.017+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:25:50.017+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:25:50.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-30T08:26:20.382+0000] {processor.py:157} INFO - Started process (PID=59954) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:26:20.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:26:20.385+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:26:20.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:26:20.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:26:20.404+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:26:20.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:26:20.416+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:26:20.416+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:26:20.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.043 seconds
[2024-07-30T08:26:50.923+0000] {processor.py:157} INFO - Started process (PID=59979) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:26:50.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:26:50.927+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:26:50.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:26:50.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:26:50.954+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:26:50.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:26:50.965+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:26:50.965+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:26:50.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T08:27:21.370+0000] {processor.py:157} INFO - Started process (PID=60004) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:27:21.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:27:21.374+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:27:21.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:27:21.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:27:21.402+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:27:21.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:27:21.415+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:27:21.414+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:27:21.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T08:27:51.910+0000] {processor.py:157} INFO - Started process (PID=60029) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:27:51.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:27:51.914+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:27:51.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:27:51.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:27:51.944+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:27:51.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:27:51.954+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:27:51.954+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:27:51.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T08:28:22.366+0000] {processor.py:157} INFO - Started process (PID=60054) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:28:22.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:28:22.369+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:28:22.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:28:22.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:28:22.397+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:28:22.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:28:22.412+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:28:22.411+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:28:22.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T08:28:52.826+0000] {processor.py:157} INFO - Started process (PID=60079) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:28:52.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:28:52.829+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:28:52.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:28:52.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:28:52.859+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:28:52.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:28:52.868+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:28:52.868+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:28:52.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T08:29:23.319+0000] {processor.py:157} INFO - Started process (PID=60104) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:29:23.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:29:23.328+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:29:23.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:29:23.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:29:23.379+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:29:23.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:29:23.406+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:29:23.406+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:29:23.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-30T08:29:53.716+0000] {processor.py:157} INFO - Started process (PID=60129) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:29:53.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:29:53.720+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:29:53.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:29:53.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:29:53.752+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:29:53.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:29:53.770+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:29:53.770+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:29:53.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-30T08:30:24.572+0000] {processor.py:157} INFO - Started process (PID=60154) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:30:24.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:30:24.580+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:30:24.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:30:24.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:30:24.635+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:30:24.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:30:24.648+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:30:24.648+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:30:24.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.094 seconds
[2024-07-30T08:30:55.149+0000] {processor.py:157} INFO - Started process (PID=60179) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:30:55.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:30:55.158+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:30:55.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:30:55.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:30:55.220+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:30:55.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:30:55.235+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:30:55.234+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:30:55.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.106 seconds
[2024-07-30T08:31:25.655+0000] {processor.py:157} INFO - Started process (PID=60204) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:31:25.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:31:25.658+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:31:25.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:31:25.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:31:25.691+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:31:25.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:31:25.702+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:31:25.702+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:31:25.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T08:31:56.178+0000] {processor.py:157} INFO - Started process (PID=60229) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:31:56.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:31:56.181+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:31:56.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:31:56.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:31:56.211+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:31:56.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:31:56.221+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:31:56.221+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:31:56.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T08:32:26.806+0000] {processor.py:157} INFO - Started process (PID=60254) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:32:26.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:32:26.820+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:32:26.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:32:26.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:32:26.884+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:32:26.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:32:26.905+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:32:26.905+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:32:26.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.118 seconds
[2024-07-30T08:32:57.419+0000] {processor.py:157} INFO - Started process (PID=60279) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:32:57.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:32:57.430+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:32:57.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:32:57.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:32:57.510+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:32:57.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:32:57.526+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:32:57.526+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:32:57.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.127 seconds
[2024-07-30T08:33:27.983+0000] {processor.py:157} INFO - Started process (PID=60304) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:33:27.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:33:27.993+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:33:27.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:33:28.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:33:28.182+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:33:28.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:33:28.232+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:33:28.232+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:33:28.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.281 seconds
[2024-07-30T08:33:58.733+0000] {processor.py:157} INFO - Started process (PID=60329) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:33:58.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:33:58.740+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:33:58.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:33:58.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:33:58.829+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:33:58.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:33:58.858+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:33:58.858+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:33:58.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.160 seconds
[2024-07-30T08:34:29.362+0000] {processor.py:157} INFO - Started process (PID=60354) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:34:29.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:34:29.381+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:34:29.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:34:29.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:34:29.440+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:34:29.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:34:29.454+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:34:29.454+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:34:29.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.108 seconds
[2024-07-30T08:34:59.780+0000] {processor.py:157} INFO - Started process (PID=60379) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:34:59.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:34:59.782+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:34:59.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:34:59.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:34:59.803+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:34:59.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:34:59.814+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:34:59.814+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:34:59.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-30T08:35:30.237+0000] {processor.py:157} INFO - Started process (PID=60404) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:35:30.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:35:30.241+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:35:30.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:35:30.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:35:30.286+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:35:30.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:35:30.301+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:35:30.301+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:35:30.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-30T08:36:00.675+0000] {processor.py:157} INFO - Started process (PID=60429) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:36:00.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:36:00.678+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:36:00.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:36:00.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:36:00.707+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:36:00.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:36:00.716+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:36:00.716+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:36:00.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-30T08:36:31.152+0000] {processor.py:157} INFO - Started process (PID=60454) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:36:31.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:36:31.160+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:36:31.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:36:31.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:36:31.200+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:36:31.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:36:31.213+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:36:31.213+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:36:31.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-30T08:37:01.669+0000] {processor.py:157} INFO - Started process (PID=60479) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:37:01.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:37:01.675+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:37:01.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:37:01.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:37:01.719+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:37:01.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:37:01.733+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:37:01.732+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:37:01.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-30T08:37:32.205+0000] {processor.py:157} INFO - Started process (PID=60504) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:37:32.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:37:32.210+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:37:32.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:37:32.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:37:32.238+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:37:32.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:37:32.248+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:37:32.248+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:37:32.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T08:38:02.650+0000] {processor.py:157} INFO - Started process (PID=60529) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:38:02.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:38:02.654+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:38:02.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:38:02.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:38:02.682+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:38:02.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:38:02.694+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:38:02.694+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:38:02.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T08:38:33.019+0000] {processor.py:157} INFO - Started process (PID=60554) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:38:33.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:38:33.022+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:38:33.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:38:33.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:38:33.047+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:38:33.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:38:33.059+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:38:33.059+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:38:33.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-30T08:39:03.496+0000] {processor.py:157} INFO - Started process (PID=60579) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:39:03.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:39:03.501+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:39:03.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:39:03.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:39:03.543+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:39:03.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:39:03.555+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:39:03.555+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:39:03.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-30T08:39:33.975+0000] {processor.py:157} INFO - Started process (PID=60604) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:39:33.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:39:33.979+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:39:33.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:39:33.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:39:34.008+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:39:34.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:39:34.017+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:39:34.017+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:39:34.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T08:40:04.423+0000] {processor.py:157} INFO - Started process (PID=60629) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:40:04.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:40:04.429+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:40:04.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:40:04.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:40:04.457+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:40:04.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:40:04.467+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:40:04.467+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:40:04.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T08:40:34.907+0000] {processor.py:157} INFO - Started process (PID=60654) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:40:34.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:40:34.916+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:40:34.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:40:34.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:40:34.955+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:40:34.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:40:34.968+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:40:34.968+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:40:34.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-30T08:41:05.359+0000] {processor.py:157} INFO - Started process (PID=60679) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:41:05.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:41:05.361+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:41:05.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:41:05.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:41:05.389+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:41:05.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:41:05.398+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:41:05.398+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:41:05.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-30T08:41:35.837+0000] {processor.py:157} INFO - Started process (PID=60704) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:41:35.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:41:35.841+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:41:35.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:41:35.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:41:35.870+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:41:35.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:41:35.880+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:41:35.880+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:41:35.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T08:42:06.275+0000] {processor.py:157} INFO - Started process (PID=60729) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:42:06.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:42:06.280+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:42:06.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:42:06.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:42:06.319+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:42:06.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:42:06.333+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:42:06.333+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:42:06.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-30T08:42:36.746+0000] {processor.py:157} INFO - Started process (PID=60754) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:42:36.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:42:36.751+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:42:36.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:42:36.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:42:36.777+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:42:36.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:42:36.788+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:42:36.788+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:42:36.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-30T08:43:07.137+0000] {processor.py:157} INFO - Started process (PID=60779) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:43:07.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:43:07.140+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:43:07.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:43:07.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:43:07.177+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:43:07.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:43:07.190+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:43:07.190+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:43:07.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-30T08:43:37.577+0000] {processor.py:157} INFO - Started process (PID=60804) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:43:37.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:43:37.582+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:43:37.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:43:37.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:43:37.607+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:43:37.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:43:37.618+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:43:37.618+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:43:37.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T08:44:31.673+0000] {processor.py:157} INFO - Started process (PID=60830) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:44:31.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:44:31.679+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:44:31.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:44:31.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:44:31.732+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:44:31.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:44:31.745+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:44:31.745+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:44:31.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.088 seconds
[2024-07-30T08:45:02.187+0000] {processor.py:157} INFO - Started process (PID=60856) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:45:02.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:45:02.193+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:45:02.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:45:02.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:45:02.223+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:45:02.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:45:02.233+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:45:02.233+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:45:02.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-30T08:45:46.157+0000] {processor.py:157} INFO - Started process (PID=60881) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:45:46.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T08:45:46.160+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:45:46.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:45:46.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T08:45:46.189+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:45:46.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:45:46.199+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:45:46.199+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T08:45:46.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T09:02:23.985+0000] {processor.py:157} INFO - Started process (PID=60906) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:02:23.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T09:02:23.990+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:02:23.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:02:24.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:02:24.027+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:02:24.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T09:02:24.040+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:02:24.040+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T09:02:24.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-30T09:02:54.481+0000] {processor.py:157} INFO - Started process (PID=60933) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:02:54.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T09:02:54.488+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:02:54.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:02:54.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:02:54.529+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:02:54.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T09:02:54.543+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:02:54.543+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T09:02:54.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-30T09:03:24.994+0000] {processor.py:157} INFO - Started process (PID=60958) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:03:24.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T09:03:24.998+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:03:24.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:03:25.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:03:25.024+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:03:25.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T09:03:25.034+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:03:25.034+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T09:03:25.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-30T09:20:20.543+0000] {processor.py:157} INFO - Started process (PID=60983) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:20:20.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T09:20:20.549+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:20:20.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:20:20.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:20:20.604+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:20:20.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T09:20:20.637+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:20:20.637+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T09:20:20.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.129 seconds
[2024-07-30T09:20:51.208+0000] {processor.py:157} INFO - Started process (PID=61008) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:20:51.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T09:20:51.213+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:20:51.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:20:51.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:20:51.241+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:20:51.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T09:20:51.251+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:20:51.251+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T09:20:51.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T09:21:21.658+0000] {processor.py:157} INFO - Started process (PID=61033) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:21:21.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T09:21:21.661+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:21:21.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:21:21.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:21:21.692+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:21:21.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T09:21:21.703+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:21:21.703+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T09:21:21.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T09:21:52.150+0000] {processor.py:157} INFO - Started process (PID=61058) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:21:52.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T09:21:52.155+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:21:52.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:21:52.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:21:52.193+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:21:52.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T09:21:52.207+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:21:52.207+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T09:21:52.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-30T09:30:15.370+0000] {processor.py:157} INFO - Started process (PID=61083) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:30:15.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T09:30:15.385+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:30:15.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:30:15.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:30:15.509+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:30:15.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T09:30:15.562+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:30:15.562+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T09:30:15.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.245 seconds
[2024-07-30T09:30:46.116+0000] {processor.py:157} INFO - Started process (PID=61108) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:30:46.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T09:30:46.122+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:30:46.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:30:46.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:30:46.161+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:30:46.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T09:30:46.173+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:30:46.173+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T09:30:46.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-30T09:31:16.558+0000] {processor.py:157} INFO - Started process (PID=61133) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:31:16.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T09:31:16.563+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:31:16.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:31:16.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:31:16.600+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:31:16.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T09:31:16.611+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:31:16.611+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T09:31:16.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-30T09:31:47.050+0000] {processor.py:157} INFO - Started process (PID=61158) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:31:47.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T09:31:47.054+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:31:47.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:31:47.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:31:47.084+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:31:47.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T09:31:47.094+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:31:47.094+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T09:31:47.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T09:32:17.453+0000] {processor.py:157} INFO - Started process (PID=61183) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:32:17.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T09:32:17.456+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:32:17.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:32:17.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:32:17.487+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:32:17.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T09:32:17.497+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:32:17.497+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T09:32:17.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T09:37:18.386+0000] {processor.py:157} INFO - Started process (PID=61208) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:37:18.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T09:37:18.398+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:37:18.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:37:18.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:37:18.491+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:37:18.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T09:37:18.508+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:37:18.507+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T09:37:18.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.149 seconds
[2024-07-30T09:54:36.079+0000] {processor.py:157} INFO - Started process (PID=61235) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:54:36.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T09:54:36.090+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:54:36.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:54:36.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:54:36.281+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:54:36.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T09:54:36.319+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:54:36.319+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T09:54:36.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.385 seconds
[2024-07-30T09:55:06.959+0000] {processor.py:157} INFO - Started process (PID=61260) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:55:06.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T09:55:06.965+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:55:06.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:55:06.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T09:55:07.014+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:55:07.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T09:55:07.029+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:55:07.029+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T09:55:07.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.088 seconds
[2024-07-30T10:10:44.403+0000] {processor.py:157} INFO - Started process (PID=61287) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:10:44.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T10:10:44.414+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:10:44.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:10:44.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:10:44.514+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:10:44.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:10:44.542+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:10:44.541+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T10:10:44.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.169 seconds
[2024-07-30T10:11:15.136+0000] {processor.py:157} INFO - Started process (PID=61312) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:11:15.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T10:11:15.144+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:11:15.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:11:15.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:11:15.187+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:11:15.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:11:15.199+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:11:15.199+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T10:11:15.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-30T10:11:45.626+0000] {processor.py:157} INFO - Started process (PID=61337) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:11:45.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T10:11:45.631+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:11:45.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:11:45.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:11:45.661+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:11:45.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:11:45.674+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:11:45.674+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T10:11:45.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-30T10:12:16.043+0000] {processor.py:157} INFO - Started process (PID=61362) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:12:16.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T10:12:16.046+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:12:16.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:12:16.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:12:16.077+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:12:16.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:12:16.088+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:12:16.087+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T10:12:16.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T10:12:46.507+0000] {processor.py:157} INFO - Started process (PID=61387) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:12:46.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T10:12:46.513+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:12:46.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:12:46.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:12:46.540+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:12:46.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:12:46.553+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:12:46.553+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T10:12:46.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T10:13:16.930+0000] {processor.py:157} INFO - Started process (PID=61412) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:13:16.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T10:13:16.936+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:13:16.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:13:16.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:13:16.975+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:13:16.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:13:16.986+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:13:16.986+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T10:13:16.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-30T10:14:53.486+0000] {processor.py:157} INFO - Started process (PID=61437) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:14:53.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T10:14:53.491+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:14:53.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:14:53.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:14:53.589+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:14:53.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:14:53.620+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:14:53.619+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T10:14:53.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.168 seconds
[2024-07-30T10:15:24.228+0000] {processor.py:157} INFO - Started process (PID=61462) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:15:24.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T10:15:24.236+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:15:24.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:15:24.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:15:24.278+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:15:24.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:15:24.292+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:15:24.292+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T10:15:24.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-30T10:15:54.678+0000] {processor.py:157} INFO - Started process (PID=61487) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:15:54.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T10:15:54.685+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:15:54.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:15:54.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:15:54.716+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:15:54.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:15:54.727+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:15:54.727+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T10:15:54.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-30T10:16:25.144+0000] {processor.py:157} INFO - Started process (PID=61512) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:16:25.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T10:16:25.148+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:16:25.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:16:25.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:16:25.179+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:16:25.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:16:25.190+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:16:25.189+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T10:16:25.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T10:16:55.624+0000] {processor.py:157} INFO - Started process (PID=61537) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:16:55.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T10:16:55.632+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:16:55.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:16:55.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:16:55.669+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:16:55.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:16:55.682+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:16:55.682+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T10:16:55.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-30T10:17:26.092+0000] {processor.py:157} INFO - Started process (PID=61562) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:17:26.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T10:17:26.096+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:17:26.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:17:26.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:17:26.130+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:17:26.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:17:26.141+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:17:26.141+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T10:17:26.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-30T10:17:56.563+0000] {processor.py:157} INFO - Started process (PID=61587) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:17:56.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T10:17:56.566+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:17:56.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:17:56.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:17:56.597+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:17:56.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:17:56.606+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:17:56.606+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T10:17:56.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T10:18:26.937+0000] {processor.py:157} INFO - Started process (PID=61612) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:18:26.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T10:18:26.939+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:18:26.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:18:26.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:18:26.967+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:18:26.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:18:26.977+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:18:26.977+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T10:18:26.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-30T10:34:56.677+0000] {processor.py:157} INFO - Started process (PID=61639) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:34:56.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T10:34:56.684+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:34:56.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:34:56.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:34:56.749+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:34:56.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:34:56.767+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:34:56.766+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T10:34:56.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.111 seconds
[2024-07-30T10:35:27.195+0000] {processor.py:157} INFO - Started process (PID=61664) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:35:27.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T10:35:27.213+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:35:27.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:35:27.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:35:27.258+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:35:27.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:35:27.271+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:35:27.271+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T10:35:27.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.108 seconds
[2024-07-30T10:35:57.707+0000] {processor.py:157} INFO - Started process (PID=61689) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:35:57.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T10:35:57.713+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:35:57.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:35:57.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:35:57.742+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:35:57.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:35:57.751+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:35:57.751+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T10:35:57.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T10:36:28.194+0000] {processor.py:157} INFO - Started process (PID=61714) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:36:28.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T10:36:28.202+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:36:28.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:36:28.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:36:28.242+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:36:28.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:36:28.255+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:36:28.255+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T10:36:28.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-30T10:54:25.837+0000] {processor.py:157} INFO - Started process (PID=61739) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:54:25.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T10:54:25.841+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:54:25.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:54:25.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:54:25.869+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:54:25.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:54:25.878+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:54:25.878+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T10:54:25.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-30T10:54:56.272+0000] {processor.py:157} INFO - Started process (PID=61764) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:54:56.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T10:54:56.277+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:54:56.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:54:56.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:54:56.343+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:54:56.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:54:56.357+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:54:56.357+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T10:54:56.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.099 seconds
[2024-07-30T10:55:26.775+0000] {processor.py:157} INFO - Started process (PID=61789) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:55:26.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T10:55:26.779+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:55:26.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:55:26.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:55:26.815+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:55:26.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:55:26.827+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:55:26.827+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T10:55:26.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-30T10:55:57.279+0000] {processor.py:157} INFO - Started process (PID=61814) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:55:57.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T10:55:57.284+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:55:57.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:55:57.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:55:57.314+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:55:57.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:55:57.324+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:55:57.323+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T10:55:57.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-30T10:56:27.667+0000] {processor.py:157} INFO - Started process (PID=61839) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:56:27.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T10:56:27.673+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:56:27.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:56:27.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T10:56:27.705+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:56:27.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:56:27.716+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:56:27.716+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T10:56:27.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-30T11:12:27.308+0000] {processor.py:157} INFO - Started process (PID=61864) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:12:27.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T11:12:27.314+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:12:27.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:12:27.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:12:27.361+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:12:27.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T11:12:27.373+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:12:27.373+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T11:12:27.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-30T11:28:59.332+0000] {processor.py:157} INFO - Started process (PID=61891) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:28:59.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T11:28:59.341+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:28:59.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:28:59.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:28:59.417+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:28:59.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T11:28:59.454+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:28:59.454+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T11:28:59.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.154 seconds
[2024-07-30T11:29:30.039+0000] {processor.py:157} INFO - Started process (PID=61916) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:29:30.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T11:29:30.045+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:29:30.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:29:30.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:29:30.091+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:29:30.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T11:29:30.103+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:29:30.103+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T11:29:30.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-30T11:30:00.545+0000] {processor.py:157} INFO - Started process (PID=61941) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:30:00.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T11:30:00.549+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:30:00.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:30:00.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:30:00.579+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:30:00.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T11:30:00.589+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:30:00.589+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T11:30:00.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T11:30:31.019+0000] {processor.py:157} INFO - Started process (PID=61966) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:30:31.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T11:30:31.024+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:30:31.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:30:31.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:30:31.061+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:30:31.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T11:30:31.072+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:30:31.072+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T11:30:31.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-30T11:31:01.483+0000] {processor.py:157} INFO - Started process (PID=61991) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:31:01.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T11:31:01.573+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:31:01.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:31:01.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:31:01.615+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:31:01.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T11:31:01.630+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:31:01.630+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T11:31:01.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.164 seconds
[2024-07-30T11:47:11.441+0000] {processor.py:157} INFO - Started process (PID=62018) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:47:11.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T11:47:11.457+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:47:11.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:47:11.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:47:11.535+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:47:11.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T11:47:11.569+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:47:11.569+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T11:47:11.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.160 seconds
[2024-07-30T11:47:41.999+0000] {processor.py:157} INFO - Started process (PID=62043) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:47:42.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T11:47:42.005+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:47:42.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:47:42.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:47:42.035+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:47:42.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T11:47:42.046+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:47:42.046+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T11:47:42.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T11:48:12.509+0000] {processor.py:157} INFO - Started process (PID=62068) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:48:12.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T11:48:12.519+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:48:12.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:48:12.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:48:12.562+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:48:12.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T11:48:12.576+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:48:12.576+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T11:48:12.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.085 seconds
[2024-07-30T11:48:43.015+0000] {processor.py:157} INFO - Started process (PID=62093) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:48:43.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T11:48:43.021+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:48:43.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:48:43.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:48:43.053+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:48:43.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T11:48:43.062+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:48:43.062+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T11:48:43.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T11:49:13.450+0000] {processor.py:157} INFO - Started process (PID=62118) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:49:13.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T11:49:13.455+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:49:13.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:49:13.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T11:49:13.479+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:49:13.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T11:49:13.491+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:49:13.491+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T11:49:13.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T12:06:18.392+0000] {processor.py:157} INFO - Started process (PID=62145) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:06:18.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:06:18.398+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:06:18.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:06:18.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:06:18.456+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:06:18.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:06:18.476+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:06:18.476+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:06:18.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-30T12:06:48.933+0000] {processor.py:157} INFO - Started process (PID=62170) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:06:48.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:06:48.939+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:06:48.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:06:48.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:06:48.987+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:06:48.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:06:49.005+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:06:49.005+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:06:49.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-30T12:07:19.403+0000] {processor.py:157} INFO - Started process (PID=62195) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:07:19.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:07:19.405+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:07:19.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:07:19.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:07:19.427+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:07:19.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:07:19.436+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:07:19.436+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:07:19.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-30T12:07:49.863+0000] {processor.py:157} INFO - Started process (PID=62220) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:07:49.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:07:49.866+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:07:49.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:07:49.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:07:49.895+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:07:49.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:07:49.906+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:07:49.906+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:07:49.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T12:08:20.352+0000] {processor.py:157} INFO - Started process (PID=62245) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:08:20.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:08:20.355+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:08:20.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:08:20.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:08:20.381+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:08:20.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:08:20.398+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:08:20.398+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:08:20.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T12:17:17.476+0000] {processor.py:157} INFO - Started process (PID=62272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:17:17.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:17:17.488+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:17:17.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:17:17.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:17:17.557+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:17:17.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:17:17.577+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:17:17.577+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:17:17.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.129 seconds
[2024-07-30T12:17:48.141+0000] {processor.py:157} INFO - Started process (PID=62297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:17:48.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:17:48.153+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:17:48.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:17:48.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:17:48.211+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:17:48.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:17:48.231+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:17:48.231+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:17:48.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.127 seconds
[2024-07-30T12:18:18.641+0000] {processor.py:157} INFO - Started process (PID=62322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:18:18.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:18:18.658+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:18:18.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:18:18.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:18:18.724+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:18:18.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:18:18.740+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:18:18.740+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:18:18.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.118 seconds
[2024-07-30T12:18:49.231+0000] {processor.py:157} INFO - Started process (PID=62347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:18:49.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:18:49.243+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:18:49.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:18:49.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:18:49.307+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:18:49.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:18:49.321+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:18:49.321+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:18:49.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.120 seconds
[2024-07-30T12:19:19.785+0000] {processor.py:157} INFO - Started process (PID=62372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:19:19.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:19:19.791+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:19:19.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:19:19.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:19:19.847+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:19:19.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:19:19.862+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:19:19.862+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:19:19.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.110 seconds
[2024-07-30T12:19:50.361+0000] {processor.py:157} INFO - Started process (PID=62397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:19:50.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:19:50.375+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:19:50.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:19:50.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:19:50.438+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:19:50.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:19:50.492+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:19:50.491+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:19:50.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.174 seconds
[2024-07-30T12:20:20.927+0000] {processor.py:157} INFO - Started process (PID=62422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:20:20.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:20:20.930+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:20:20.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:20:20.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:20:20.961+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:20:20.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:20:20.972+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:20:20.972+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:20:20.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T12:20:51.371+0000] {processor.py:157} INFO - Started process (PID=62447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:20:51.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:20:51.380+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:20:51.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:20:51.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:20:51.423+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:20:51.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:20:51.449+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:20:51.449+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:20:51.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.106 seconds
[2024-07-30T12:21:21.848+0000] {processor.py:157} INFO - Started process (PID=62472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:21:21.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:21:21.855+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:21:21.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:21:21.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:21:21.882+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:21:21.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:21:21.891+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:21:21.891+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:21:21.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T12:21:52.302+0000] {processor.py:157} INFO - Started process (PID=62497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:21:52.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:21:52.313+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:21:52.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:21:52.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:21:52.361+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:21:52.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:21:52.379+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:21:52.378+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:21:52.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.092 seconds
[2024-07-30T12:22:22.764+0000] {processor.py:157} INFO - Started process (PID=62522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:22:22.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:22:22.770+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:22:22.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:22:22.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:22:22.797+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:22:22.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:22:22.808+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:22:22.808+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:22:22.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T12:22:53.188+0000] {processor.py:157} INFO - Started process (PID=62547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:22:53.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:22:53.193+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:22:53.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:22:53.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:22:53.239+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:22:53.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:22:53.251+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:22:53.251+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:22:53.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-30T12:23:23.732+0000] {processor.py:157} INFO - Started process (PID=62572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:23:23.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:23:23.737+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:23:23.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:23:23.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:23:23.767+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:23:23.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:23:23.777+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:23:23.777+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:23:23.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T12:23:54.213+0000] {processor.py:157} INFO - Started process (PID=62597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:23:54.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:23:54.219+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:23:54.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:23:54.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:23:54.267+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:23:54.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:23:54.280+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:23:54.279+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:23:54.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-30T12:24:24.655+0000] {processor.py:157} INFO - Started process (PID=62622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:24:24.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:24:24.659+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:24:24.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:24:24.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:24:24.687+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:24:24.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:24:24.698+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:24:24.698+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:24:24.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T12:24:55.097+0000] {processor.py:157} INFO - Started process (PID=62647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:24:55.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:24:55.102+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:24:55.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:24:55.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:24:55.142+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:24:55.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:24:55.155+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:24:55.155+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:24:55.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-30T12:25:25.590+0000] {processor.py:157} INFO - Started process (PID=62672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:25:25.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:25:25.595+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:25:25.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:25:25.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:25:25.629+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:25:25.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:25:25.640+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:25:25.640+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:25:25.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-30T12:25:56.084+0000] {processor.py:157} INFO - Started process (PID=62697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:25:56.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:25:56.088+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:25:56.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:25:56.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:25:56.126+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:25:56.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:25:56.139+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:25:56.139+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:25:56.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-30T12:26:26.642+0000] {processor.py:157} INFO - Started process (PID=62722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:26:26.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:26:26.648+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:26:26.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:26:26.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:26:26.677+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:26:26.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:26:26.688+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:26:26.688+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:26:26.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T12:26:57.041+0000] {processor.py:157} INFO - Started process (PID=62747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:26:57.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:26:57.046+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:26:57.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:26:57.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:26:57.085+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:26:57.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:26:57.099+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:26:57.099+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:26:57.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-30T12:27:27.571+0000] {processor.py:157} INFO - Started process (PID=62772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:27:27.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:27:27.574+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:27:27.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:27:27.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:27:27.618+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:27:27.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:27:27.628+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:27:27.627+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:27:27.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-30T12:27:58.058+0000] {processor.py:157} INFO - Started process (PID=62797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:27:58.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:27:58.063+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:27:58.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:27:58.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:27:58.107+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:27:58.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:27:58.136+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:27:58.136+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:27:58.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.091 seconds
[2024-07-30T12:28:28.628+0000] {processor.py:157} INFO - Started process (PID=62822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:28:28.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:28:28.633+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:28:28.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:28:28.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:28:28.662+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:28:28.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:28:28.672+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:28:28.672+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:28:28.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T12:28:59.035+0000] {processor.py:157} INFO - Started process (PID=62847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:28:59.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:28:59.042+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:28:59.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:28:59.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:28:59.081+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:28:59.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:28:59.093+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:28:59.093+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:28:59.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-30T12:29:29.539+0000] {processor.py:157} INFO - Started process (PID=62872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:29:29.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:29:29.544+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:29:29.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:29:29.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:29:29.585+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:29:29.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:29:29.598+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:29:29.597+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:29:29.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-30T12:30:00.018+0000] {processor.py:157} INFO - Started process (PID=62897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:30:00.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:30:00.023+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:30:00.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:30:00.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:30:00.058+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:30:00.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:30:00.075+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:30:00.075+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:30:00.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-30T12:30:30.527+0000] {processor.py:157} INFO - Started process (PID=62922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:30:30.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:30:30.532+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:30:30.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:30:30.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:30:30.575+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:30:30.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:30:30.588+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:30:30.588+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:30:30.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-30T12:31:01.038+0000] {processor.py:157} INFO - Started process (PID=62947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:31:01.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:31:01.041+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:31:01.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:31:01.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:31:01.071+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:31:01.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:31:01.081+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:31:01.081+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:31:01.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T12:31:31.496+0000] {processor.py:157} INFO - Started process (PID=62972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:31:31.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:31:31.500+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:31:31.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:31:31.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:31:31.530+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:31:31.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:31:31.540+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:31:31.539+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:31:31.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T12:32:01.954+0000] {processor.py:157} INFO - Started process (PID=62997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:32:01.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:32:01.960+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:32:01.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:32:01.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:32:02.002+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:32:02.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:32:02.015+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:32:02.015+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:32:02.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-30T12:32:32.402+0000] {processor.py:157} INFO - Started process (PID=63022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:32:32.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:32:32.409+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:32:32.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:32:32.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:32:32.439+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:32:32.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:32:32.451+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:32:32.451+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:32:32.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-30T12:33:02.943+0000] {processor.py:157} INFO - Started process (PID=63047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:33:02.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:33:02.950+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:33:02.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:33:02.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:33:02.989+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:33:02.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:33:03.001+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:33:03.001+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:33:03.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-30T12:33:33.487+0000] {processor.py:157} INFO - Started process (PID=63072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:33:33.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:33:33.517+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:33:33.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:33:33.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:33:33.583+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:33:33.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:33:33.625+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:33:33.625+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:33:33.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.163 seconds
[2024-07-30T12:34:04.192+0000] {processor.py:157} INFO - Started process (PID=63097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:34:04.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:34:04.201+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:34:04.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:34:04.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:34:04.257+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:34:04.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:34:04.269+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:34:04.269+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:34:04.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.095 seconds
[2024-07-30T12:34:34.769+0000] {processor.py:157} INFO - Started process (PID=63122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:34:34.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:34:34.772+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:34:34.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:34:34.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:34:34.807+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:34:34.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:34:34.817+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:34:34.817+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:34:34.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-30T12:35:05.233+0000] {processor.py:157} INFO - Started process (PID=63147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:35:05.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:35:05.238+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:35:05.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:35:05.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:35:05.293+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:35:05.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:35:05.306+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:35:05.306+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:35:05.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-30T12:35:35.806+0000] {processor.py:157} INFO - Started process (PID=63172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:35:35.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:35:35.810+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:35:35.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:35:35.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:35:35.843+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:35:35.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:35:35.855+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:35:35.855+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:35:35.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-30T12:36:06.237+0000] {processor.py:157} INFO - Started process (PID=63197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:36:06.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:36:06.243+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:36:06.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:36:06.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:36:06.307+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:36:06.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:36:06.321+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:36:06.321+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:36:06.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.100 seconds
[2024-07-30T12:36:36.807+0000] {processor.py:157} INFO - Started process (PID=63222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:36:36.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:36:36.813+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:36:36.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:36:36.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:36:36.843+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:36:36.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:36:36.855+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:36:36.855+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:36:36.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T12:37:07.222+0000] {processor.py:157} INFO - Started process (PID=63247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:37:07.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:37:07.226+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:37:07.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:37:07.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:37:07.261+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:37:07.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:37:07.274+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:37:07.274+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:37:07.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-30T12:37:37.682+0000] {processor.py:157} INFO - Started process (PID=63272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:37:37.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:37:37.686+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:37:37.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:37:37.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:37:37.732+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:37:37.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:37:37.742+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:37:37.742+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:37:37.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-30T12:38:08.493+0000] {processor.py:157} INFO - Started process (PID=63297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:38:08.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:38:08.498+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:38:08.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:38:08.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:38:08.540+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:38:08.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:38:08.552+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:38:08.552+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:38:08.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-30T12:38:39.016+0000] {processor.py:157} INFO - Started process (PID=63322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:38:39.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:38:39.021+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:38:39.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:38:39.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:38:39.053+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:38:39.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:38:39.065+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:38:39.065+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:38:39.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-30T12:39:09.563+0000] {processor.py:157} INFO - Started process (PID=63347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:39:09.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:39:09.569+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:39:09.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:39:09.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:39:09.618+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:39:09.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:39:09.632+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:39:09.632+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:39:09.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.107 seconds
[2024-07-30T12:39:40.066+0000] {processor.py:157} INFO - Started process (PID=63372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:39:40.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:39:40.077+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:39:40.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:39:40.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:39:40.137+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:39:40.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:39:40.155+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:39:40.155+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:39:40.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.106 seconds
[2024-07-30T12:40:10.630+0000] {processor.py:157} INFO - Started process (PID=63397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:40:10.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:40:10.636+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:40:10.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:40:10.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:40:10.679+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:40:10.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:40:10.689+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:40:10.689+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:40:10.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-30T12:40:41.158+0000] {processor.py:157} INFO - Started process (PID=63422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:40:41.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:40:41.164+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:40:41.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:40:41.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:40:41.232+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:40:41.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:40:41.246+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:40:41.246+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:40:41.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.106 seconds
[2024-07-30T12:41:11.691+0000] {processor.py:157} INFO - Started process (PID=63447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:41:11.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:41:11.695+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:41:11.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:41:11.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:41:11.725+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:41:11.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:41:11.736+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:41:11.736+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:41:11.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T12:41:42.075+0000] {processor.py:157} INFO - Started process (PID=63472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:41:42.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:41:42.082+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:41:42.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:41:42.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:41:42.122+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:41:42.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:41:42.135+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:41:42.135+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:41:42.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-30T12:42:12.530+0000] {processor.py:157} INFO - Started process (PID=63497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:42:12.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:42:12.534+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:42:12.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:42:12.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:42:12.569+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:42:12.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:42:12.579+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:42:12.579+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:42:12.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-30T12:42:42.970+0000] {processor.py:157} INFO - Started process (PID=63522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:42:42.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:42:42.976+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:42:42.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:42:42.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:42:43.013+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:42:43.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:42:43.025+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:42:43.025+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:42:43.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-30T12:43:13.479+0000] {processor.py:157} INFO - Started process (PID=63547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:43:13.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:43:13.485+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:43:13.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:43:13.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:43:13.514+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:43:13.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:43:13.525+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:43:13.525+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:43:13.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T12:43:43.953+0000] {processor.py:157} INFO - Started process (PID=63572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:43:43.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:43:43.967+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:43:43.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:43:43.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:43:44.010+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:43:44.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:43:44.024+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:43:44.024+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:43:44.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.088 seconds
[2024-07-30T12:44:14.496+0000] {processor.py:157} INFO - Started process (PID=63597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:44:14.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:44:14.501+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:44:14.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:44:14.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:44:14.529+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:44:14.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:44:14.539+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:44:14.539+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:44:14.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T12:44:44.934+0000] {processor.py:157} INFO - Started process (PID=63622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:44:44.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:44:44.938+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:44:44.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:44:44.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:44:44.965+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:44:44.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:44:44.977+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:44:44.977+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:44:44.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T12:45:15.385+0000] {processor.py:157} INFO - Started process (PID=63647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:45:15.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:45:15.390+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:45:15.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:45:15.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:45:15.430+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:45:15.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:45:15.443+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:45:15.443+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:45:15.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-30T12:45:45.878+0000] {processor.py:157} INFO - Started process (PID=63672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:45:45.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:45:45.881+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:45:45.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:45:45.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:45:45.915+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:45:45.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:45:45.925+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:45:45.925+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:45:45.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-30T12:46:16.279+0000] {processor.py:157} INFO - Started process (PID=63697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:46:16.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:46:16.282+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:46:16.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:46:16.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:46:16.309+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:46:16.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:46:16.319+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:46:16.319+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:46:16.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-30T12:46:46.729+0000] {processor.py:157} INFO - Started process (PID=63722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:46:46.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:46:46.734+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:46:46.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:46:46.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:46:46.763+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:46:46.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:46:46.774+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:46:46.774+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:46:46.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T12:47:17.059+0000] {processor.py:157} INFO - Started process (PID=63747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:47:17.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:47:17.062+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:47:17.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:47:17.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:47:17.085+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:47:17.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:47:17.094+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:47:17.094+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:47:17.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-30T12:47:47.486+0000] {processor.py:157} INFO - Started process (PID=63772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:47:47.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:47:47.492+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:47:47.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:47:47.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:47:47.531+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:47:47.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:47:47.544+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:47:47.544+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:47:47.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-30T12:48:17.885+0000] {processor.py:157} INFO - Started process (PID=63797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:48:17.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:48:17.888+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:48:17.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:48:17.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:48:17.915+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:48:17.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:48:17.924+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:48:17.924+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:48:17.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-30T12:48:48.303+0000] {processor.py:157} INFO - Started process (PID=63822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:48:48.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:48:48.307+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:48:48.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:48:48.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:48:48.337+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:48:48.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:48:48.348+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:48:48.348+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:48:48.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T12:49:18.751+0000] {processor.py:157} INFO - Started process (PID=63847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:49:18.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:49:18.754+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:49:18.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:49:18.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:49:18.786+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:49:18.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:49:18.796+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:49:18.796+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:49:18.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T12:49:49.203+0000] {processor.py:157} INFO - Started process (PID=63872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:49:49.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:49:49.210+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:49:49.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:49:49.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:49:49.274+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:49:49.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:49:49.286+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:49:49.286+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:49:49.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.100 seconds
[2024-07-30T12:50:19.707+0000] {processor.py:157} INFO - Started process (PID=63897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:50:19.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:50:19.712+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:50:19.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:50:19.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:50:19.743+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:50:19.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:50:19.755+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:50:19.755+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:50:19.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T12:50:50.077+0000] {processor.py:157} INFO - Started process (PID=63922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:50:50.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:50:50.081+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:50:50.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:50:50.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:50:50.115+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:50:50.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:50:50.132+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:50:50.132+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:50:50.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-30T12:51:20.473+0000] {processor.py:157} INFO - Started process (PID=63947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:51:20.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:51:20.476+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:51:20.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:51:20.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:51:20.502+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:51:20.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:51:20.512+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:51:20.512+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:51:20.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-30T12:51:50.924+0000] {processor.py:157} INFO - Started process (PID=63972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:51:50.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:51:50.928+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:51:50.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:51:50.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:51:50.962+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:51:50.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:51:50.975+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:51:50.975+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:51:50.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-30T12:52:21.357+0000] {processor.py:157} INFO - Started process (PID=63997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:52:21.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:52:21.361+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:52:21.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:52:21.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:52:21.394+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:52:21.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:52:21.407+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:52:21.406+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:52:21.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-30T12:52:51.765+0000] {processor.py:157} INFO - Started process (PID=64022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:52:51.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:52:51.769+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:52:51.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:52:51.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:52:51.795+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:52:51.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:52:51.806+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:52:51.806+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:52:51.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T12:53:22.264+0000] {processor.py:157} INFO - Started process (PID=64047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:53:22.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:53:22.267+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:53:22.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:53:22.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:53:22.299+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:53:22.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:53:22.309+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:53:22.309+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:53:22.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T12:53:52.739+0000] {processor.py:157} INFO - Started process (PID=64072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:53:52.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:53:52.746+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:53:52.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:53:52.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:53:52.782+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:53:52.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:53:52.792+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:53:52.792+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:53:52.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-30T12:54:23.151+0000] {processor.py:157} INFO - Started process (PID=64097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:54:23.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:54:23.156+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:54:23.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:54:23.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:54:23.186+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:54:23.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:54:23.198+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:54:23.197+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:54:23.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T12:54:53.598+0000] {processor.py:157} INFO - Started process (PID=64122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:54:53.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:54:53.601+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:54:53.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:54:53.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:54:53.631+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:54:53.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:54:53.641+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:54:53.641+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:54:53.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T12:55:24.035+0000] {processor.py:157} INFO - Started process (PID=64147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:55:24.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:55:24.038+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:55:24.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:55:24.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:55:24.065+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:55:24.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:55:24.078+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:55:24.078+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:55:24.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T12:55:54.425+0000] {processor.py:157} INFO - Started process (PID=64172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:55:54.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:55:54.429+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:55:54.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:55:54.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:55:54.459+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:55:54.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:55:54.470+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:55:54.470+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:55:54.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T12:56:25.027+0000] {processor.py:157} INFO - Started process (PID=64197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:56:25.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:56:25.032+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:56:25.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:56:25.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:56:25.072+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:56:25.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:56:25.084+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:56:25.084+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:56:25.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-30T12:56:55.472+0000] {processor.py:157} INFO - Started process (PID=64222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:56:55.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:56:55.476+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:56:55.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:56:55.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:56:55.509+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:56:55.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:56:55.523+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:56:55.523+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:56:55.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-30T12:57:26.016+0000] {processor.py:157} INFO - Started process (PID=64247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:57:26.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:57:26.020+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:57:26.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:57:26.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:57:26.048+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:57:26.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:57:26.058+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:57:26.058+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:57:26.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T12:57:56.458+0000] {processor.py:157} INFO - Started process (PID=64272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:57:56.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:57:56.462+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:57:56.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:57:56.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:57:56.499+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:57:56.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:57:56.511+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:57:56.511+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:57:56.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-30T12:58:27.022+0000] {processor.py:157} INFO - Started process (PID=64297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:58:27.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:58:27.026+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:58:27.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:58:27.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:58:27.055+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:58:27.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:58:27.067+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:58:27.067+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:58:27.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T12:58:57.524+0000] {processor.py:157} INFO - Started process (PID=64322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:58:57.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:58:57.526+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:58:57.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:58:57.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:58:57.556+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:58:57.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:58:57.568+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:58:57.568+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:58:57.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T12:59:28.012+0000] {processor.py:157} INFO - Started process (PID=64347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:59:28.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:59:28.016+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:59:28.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:59:28.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:59:28.047+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:59:28.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:59:28.058+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:59:28.058+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:59:28.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T12:59:58.523+0000] {processor.py:157} INFO - Started process (PID=64372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:59:58.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T12:59:58.528+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:59:58.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:59:58.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T12:59:58.571+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:59:58.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:59:58.581+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:59:58.581+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T12:59:58.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-30T13:00:29.056+0000] {processor.py:157} INFO - Started process (PID=64397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:00:29.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:00:29.062+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:00:29.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:00:29.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:00:29.092+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:00:29.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:00:29.105+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:00:29.105+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:00:29.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T13:00:59.532+0000] {processor.py:157} INFO - Started process (PID=64422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:00:59.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:00:59.536+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:00:59.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:00:59.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:00:59.557+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:00:59.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:00:59.567+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:00:59.567+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:00:59.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-30T13:01:30.056+0000] {processor.py:157} INFO - Started process (PID=64447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:01:30.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:01:30.060+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:01:30.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:01:30.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:01:30.091+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:01:30.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:01:30.101+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:01:30.100+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:01:30.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T13:02:00.518+0000] {processor.py:157} INFO - Started process (PID=64472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:02:00.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:02:00.523+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:02:00.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:02:00.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:02:00.563+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:02:00.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:02:00.574+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:02:00.574+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:02:00.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-30T13:02:30.910+0000] {processor.py:157} INFO - Started process (PID=64497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:02:30.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:02:30.913+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:02:30.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:02:30.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:02:30.941+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:02:30.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:02:30.953+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:02:30.953+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:02:30.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T13:03:01.411+0000] {processor.py:157} INFO - Started process (PID=64522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:03:01.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:03:01.415+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:03:01.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:03:01.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:03:01.463+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:03:01.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:03:01.474+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:03:01.474+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:03:01.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-30T13:03:31.857+0000] {processor.py:157} INFO - Started process (PID=64547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:03:31.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:03:31.861+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:03:31.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:03:31.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:03:31.890+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:03:31.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:03:31.899+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:03:31.899+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:03:31.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-30T13:04:02.353+0000] {processor.py:157} INFO - Started process (PID=64572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:04:02.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:04:02.355+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:04:02.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:04:02.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:04:02.384+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:04:02.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:04:02.397+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:04:02.396+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:04:02.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T13:04:32.806+0000] {processor.py:157} INFO - Started process (PID=64597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:04:32.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:04:32.808+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:04:32.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:04:32.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:04:32.830+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:04:32.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:04:32.841+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:04:32.841+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:04:32.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-30T13:05:03.208+0000] {processor.py:157} INFO - Started process (PID=64622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:05:03.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:05:03.213+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:05:03.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:05:03.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:05:03.246+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:05:03.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:05:03.257+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:05:03.256+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:05:03.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-30T13:05:33.656+0000] {processor.py:157} INFO - Started process (PID=64647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:05:33.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:05:33.662+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:05:33.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:05:33.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:05:33.702+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:05:33.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:05:33.714+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:05:33.714+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:05:33.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-30T13:06:04.074+0000] {processor.py:157} INFO - Started process (PID=64672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:06:04.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:06:04.078+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:06:04.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:06:04.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:06:04.110+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:06:04.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:06:04.120+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:06:04.120+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:06:04.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T13:06:34.574+0000] {processor.py:157} INFO - Started process (PID=64697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:06:34.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:06:34.578+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:06:34.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:06:34.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:06:34.608+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:06:34.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:06:34.618+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:06:34.618+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:06:34.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T13:07:05.022+0000] {processor.py:157} INFO - Started process (PID=64722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:07:05.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:07:05.028+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:07:05.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:07:05.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:07:05.059+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:07:05.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:07:05.069+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:07:05.069+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:07:05.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-30T13:07:35.524+0000] {processor.py:157} INFO - Started process (PID=64747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:07:35.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:07:35.529+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:07:35.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:07:35.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:07:35.571+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:07:35.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:07:35.583+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:07:35.583+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:07:35.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-30T13:08:05.956+0000] {processor.py:157} INFO - Started process (PID=64772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:08:05.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:08:05.957+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:08:05.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:08:05.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:08:05.979+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:08:05.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:08:05.991+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:08:05.991+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:08:06.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-30T13:08:36.341+0000] {processor.py:157} INFO - Started process (PID=64797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:08:36.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:08:36.346+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:08:36.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:08:36.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:08:36.374+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:08:36.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:08:36.384+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:08:36.384+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:08:36.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T13:09:06.861+0000] {processor.py:157} INFO - Started process (PID=64822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:09:06.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:09:06.868+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:09:06.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:09:06.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:09:06.906+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:09:06.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:09:06.919+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:09:06.919+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:09:06.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-30T13:09:37.340+0000] {processor.py:157} INFO - Started process (PID=64847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:09:37.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:09:37.345+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:09:37.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:09:37.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:09:37.376+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:09:37.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:09:37.386+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:09:37.386+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:09:37.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T13:10:07.838+0000] {processor.py:157} INFO - Started process (PID=64872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:10:07.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:10:07.842+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:10:07.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:10:07.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:10:07.868+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:10:07.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:10:07.878+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:10:07.878+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:10:07.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-30T13:10:38.290+0000] {processor.py:157} INFO - Started process (PID=64897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:10:38.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:10:38.298+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:10:38.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:10:38.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:10:38.352+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:10:38.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:10:38.367+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:10:38.367+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:10:38.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-30T13:11:08.810+0000] {processor.py:157} INFO - Started process (PID=64922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:11:08.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:11:08.814+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:11:08.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:11:08.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:11:08.844+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:11:08.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:11:08.857+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:11:08.857+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:11:08.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T13:11:39.292+0000] {processor.py:157} INFO - Started process (PID=64947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:11:39.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:11:39.296+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:11:39.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:11:39.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:11:39.322+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:11:39.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:11:39.332+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:11:39.332+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:11:39.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-30T13:12:09.777+0000] {processor.py:157} INFO - Started process (PID=64972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:12:09.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:12:09.781+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:12:09.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:12:09.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:12:09.815+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:12:09.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:12:09.826+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:12:09.826+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:12:09.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-30T13:12:40.267+0000] {processor.py:157} INFO - Started process (PID=64997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:12:40.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:12:40.275+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:12:40.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:12:40.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:12:40.313+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:12:40.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:12:40.325+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:12:40.325+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:12:40.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-30T13:13:10.783+0000] {processor.py:157} INFO - Started process (PID=65022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:13:10.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:13:10.787+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:13:10.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:13:10.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:13:10.817+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:13:10.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:13:10.828+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:13:10.828+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:13:10.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T13:13:41.192+0000] {processor.py:157} INFO - Started process (PID=65047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:13:41.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:13:41.195+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:13:41.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:13:41.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:13:41.225+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:13:41.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:13:41.235+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:13:41.235+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:13:41.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T13:14:11.663+0000] {processor.py:157} INFO - Started process (PID=65072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:14:11.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:14:11.667+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:14:11.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:14:11.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:14:11.694+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:14:11.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:14:11.704+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:14:11.704+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:14:11.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T13:14:42.126+0000] {processor.py:157} INFO - Started process (PID=65097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:14:42.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:14:42.130+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:14:42.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:14:42.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:14:42.159+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:14:42.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:14:42.170+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:14:42.170+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:14:42.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T13:15:12.509+0000] {processor.py:157} INFO - Started process (PID=65122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:15:12.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:15:12.512+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:15:12.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:15:12.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:15:12.541+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:15:12.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:15:12.553+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:15:12.553+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:15:12.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T13:15:43.076+0000] {processor.py:157} INFO - Started process (PID=65147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:15:43.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:15:43.080+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:15:43.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:15:43.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:15:43.116+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:15:43.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:15:43.129+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:15:43.129+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:15:43.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-30T13:16:13.492+0000] {processor.py:157} INFO - Started process (PID=65172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:16:13.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:16:13.496+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:16:13.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:16:13.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:16:13.524+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:16:13.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:16:13.534+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:16:13.534+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:16:13.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T13:16:43.975+0000] {processor.py:157} INFO - Started process (PID=65197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:16:43.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:16:43.979+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:16:43.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:16:43.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:16:44.007+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:16:44.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:16:44.018+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:16:44.018+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:16:44.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T13:17:14.443+0000] {processor.py:157} INFO - Started process (PID=65222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:17:14.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:17:14.449+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:17:14.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:17:14.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:17:14.479+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:17:14.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:17:14.489+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:17:14.489+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:17:14.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T13:17:44.893+0000] {processor.py:157} INFO - Started process (PID=65247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:17:44.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:17:44.897+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:17:44.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:17:44.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:17:44.923+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:17:44.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:17:44.933+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:17:44.933+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:17:44.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-30T13:18:15.358+0000] {processor.py:157} INFO - Started process (PID=65272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:18:15.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:18:15.361+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:18:15.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:18:15.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:18:15.382+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:18:15.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:18:15.390+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:18:15.390+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:18:15.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.042 seconds
[2024-07-30T13:18:45.787+0000] {processor.py:157} INFO - Started process (PID=65297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:18:45.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:18:45.790+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:18:45.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:18:45.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:18:45.819+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:18:45.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:18:45.831+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:18:45.831+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:18:45.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T13:19:16.294+0000] {processor.py:157} INFO - Started process (PID=65322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:19:16.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:19:16.300+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:19:16.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:19:16.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:19:16.330+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:19:16.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:19:16.341+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:19:16.340+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:19:16.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-30T13:19:46.677+0000] {processor.py:157} INFO - Started process (PID=65347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:19:46.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:19:46.683+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:19:46.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:19:46.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:19:46.714+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:19:46.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:19:46.725+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:19:46.725+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:19:46.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T13:20:17.168+0000] {processor.py:157} INFO - Started process (PID=65372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:20:17.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:20:17.173+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:20:17.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:20:17.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:20:17.212+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:20:17.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:20:17.226+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:20:17.226+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:20:17.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-30T13:20:47.582+0000] {processor.py:157} INFO - Started process (PID=65397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:20:47.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:20:47.586+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:20:47.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:20:47.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:20:47.613+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:20:47.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:20:47.624+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:20:47.624+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:20:47.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-30T13:21:18.061+0000] {processor.py:157} INFO - Started process (PID=65422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:21:18.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:21:18.064+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:21:18.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:21:18.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:21:18.092+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:21:18.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:21:18.102+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:21:18.102+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:21:18.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T13:21:48.540+0000] {processor.py:157} INFO - Started process (PID=65447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:21:48.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:21:48.542+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:21:48.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:21:48.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:21:48.562+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:21:48.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:21:48.572+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:21:48.572+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:21:48.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.041 seconds
[2024-07-30T13:22:18.930+0000] {processor.py:157} INFO - Started process (PID=65472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:22:18.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:22:18.933+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:22:18.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:22:18.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:22:18.959+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:22:18.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:22:18.969+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:22:18.969+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:22:18.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-30T13:22:49.420+0000] {processor.py:157} INFO - Started process (PID=65497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:22:49.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:22:49.425+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:22:49.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:22:49.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:22:49.467+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:22:49.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:22:49.479+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:22:49.479+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:22:49.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-30T13:23:19.944+0000] {processor.py:157} INFO - Started process (PID=65522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:23:19.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:23:19.949+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:23:19.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:23:19.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:23:19.978+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:23:19.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:23:19.991+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:23:19.991+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:23:20.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-30T13:23:50.480+0000] {processor.py:157} INFO - Started process (PID=65547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:23:50.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:23:50.486+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:23:50.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:23:50.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:23:50.515+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:23:50.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:23:50.524+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:23:50.524+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:23:50.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T13:24:20.984+0000] {processor.py:157} INFO - Started process (PID=65572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:24:20.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:24:20.990+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:24:20.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:24:21.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:24:21.028+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:24:21.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:24:21.040+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:24:21.040+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:24:21.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-30T13:24:51.476+0000] {processor.py:157} INFO - Started process (PID=65597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:24:51.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:24:51.480+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:24:51.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:24:51.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:24:51.506+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:24:51.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:24:51.519+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:24:51.519+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:24:51.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T13:25:21.878+0000] {processor.py:157} INFO - Started process (PID=65622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:25:21.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:25:21.881+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:25:21.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:25:21.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:25:21.906+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:25:21.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:25:21.915+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:25:21.915+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:25:21.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-30T13:25:52.323+0000] {processor.py:157} INFO - Started process (PID=65647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:25:52.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:25:52.327+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:25:52.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:25:52.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:25:52.356+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:25:52.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:25:52.366+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:25:52.366+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:25:52.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T13:26:22.815+0000] {processor.py:157} INFO - Started process (PID=65672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:26:22.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:26:22.819+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:26:22.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:26:22.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:26:22.849+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:26:22.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:26:22.859+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:26:22.859+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:26:22.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T13:26:53.355+0000] {processor.py:157} INFO - Started process (PID=65697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:26:53.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:26:53.360+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:26:53.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:26:53.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:26:53.389+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:26:53.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:26:53.399+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:26:53.399+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:26:53.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T13:27:23.796+0000] {processor.py:157} INFO - Started process (PID=65722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:27:23.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:27:23.799+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:27:23.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:27:23.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:27:23.828+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:27:23.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:27:23.838+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:27:23.838+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:27:23.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T13:27:54.240+0000] {processor.py:157} INFO - Started process (PID=65747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:27:54.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:27:54.244+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:27:54.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:27:54.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:27:54.276+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:27:54.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:27:54.288+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:27:54.288+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:27:54.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-30T13:28:24.666+0000] {processor.py:157} INFO - Started process (PID=65772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:28:24.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:28:24.670+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:28:24.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:28:24.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:28:24.700+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:28:24.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:28:24.711+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:28:24.711+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:28:24.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-30T13:28:55.070+0000] {processor.py:157} INFO - Started process (PID=65797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:28:55.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:28:55.074+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:28:55.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:28:55.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:28:55.106+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:28:55.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:28:55.117+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:28:55.117+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:28:55.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T13:29:25.513+0000] {processor.py:157} INFO - Started process (PID=65822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:29:25.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:29:25.517+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:29:25.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:29:25.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:29:25.546+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:29:25.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:29:25.556+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:29:25.556+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:29:25.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T13:29:55.980+0000] {processor.py:157} INFO - Started process (PID=65847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:29:55.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:29:55.983+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:29:55.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:29:55.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:29:56.010+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:29:56.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:29:56.021+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:29:56.021+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:29:56.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T13:30:26.371+0000] {processor.py:157} INFO - Started process (PID=65872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:30:26.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:30:26.374+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:30:26.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:30:26.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:30:26.399+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:30:26.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:30:26.413+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:30:26.413+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:30:26.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T13:30:56.863+0000] {processor.py:157} INFO - Started process (PID=65897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:30:56.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:30:56.867+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:30:56.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:30:56.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:30:56.896+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:30:56.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:30:56.908+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:30:56.907+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:30:56.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T13:31:27.300+0000] {processor.py:157} INFO - Started process (PID=65922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:31:27.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:31:27.304+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:31:27.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:31:27.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:31:27.333+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:31:27.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:31:27.343+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:31:27.343+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:31:27.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T13:31:57.802+0000] {processor.py:157} INFO - Started process (PID=65947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:31:57.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:31:57.804+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:31:57.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:31:57.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:31:57.830+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:31:57.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:31:57.840+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:31:57.840+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:31:57.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-30T13:32:28.229+0000] {processor.py:157} INFO - Started process (PID=65972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:32:28.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:32:28.232+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:32:28.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:32:28.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:32:28.261+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:32:28.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:32:28.272+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:32:28.272+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:32:28.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T13:32:58.691+0000] {processor.py:157} INFO - Started process (PID=65997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:32:58.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:32:58.698+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:32:58.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:32:58.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:32:58.735+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:32:58.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:32:58.748+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:32:58.748+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:32:58.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-30T13:33:29.171+0000] {processor.py:157} INFO - Started process (PID=66022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:33:29.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:33:29.175+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:33:29.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:33:29.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:33:29.201+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:33:29.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:33:29.211+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:33:29.211+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:33:29.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-30T13:33:59.637+0000] {processor.py:157} INFO - Started process (PID=66047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:33:59.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:33:59.644+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:33:59.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:33:59.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:33:59.702+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:33:59.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:33:59.718+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:33:59.718+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:33:59.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.097 seconds
[2024-07-30T13:34:30.108+0000] {processor.py:157} INFO - Started process (PID=66072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:34:30.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:34:30.116+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:34:30.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:34:30.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:34:30.157+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:34:30.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:34:30.169+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:34:30.169+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:34:30.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-30T13:35:00.651+0000] {processor.py:157} INFO - Started process (PID=66097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:35:00.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:35:00.655+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:35:00.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:35:00.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:35:00.681+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:35:00.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:35:00.691+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:35:00.691+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:35:00.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-30T13:35:31.081+0000] {processor.py:157} INFO - Started process (PID=66122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:35:31.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:35:31.085+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:35:31.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:35:31.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:35:31.115+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:35:31.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:35:31.126+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:35:31.126+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:35:31.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T13:36:01.458+0000] {processor.py:157} INFO - Started process (PID=66147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:36:01.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:36:01.464+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:36:01.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:36:01.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:36:01.501+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:36:01.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:36:01.516+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:36:01.516+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:36:01.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-30T13:36:31.925+0000] {processor.py:157} INFO - Started process (PID=66172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:36:31.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:36:31.929+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:36:31.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:36:31.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:36:31.956+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:36:31.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:36:31.966+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:36:31.966+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:36:31.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-30T13:37:02.356+0000] {processor.py:157} INFO - Started process (PID=66197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:37:02.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:37:02.360+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:37:02.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:37:02.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:37:02.390+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:37:02.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:37:02.400+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:37:02.400+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:37:02.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T13:37:32.835+0000] {processor.py:157} INFO - Started process (PID=66222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:37:32.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:37:32.841+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:37:32.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:37:32.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:37:32.877+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:37:32.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:37:32.887+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:37:32.887+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:37:32.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-30T13:38:03.373+0000] {processor.py:157} INFO - Started process (PID=66247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:38:03.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:38:03.376+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:38:03.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:38:03.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:38:03.416+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:38:03.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:38:03.426+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:38:03.426+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:38:03.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-30T13:38:33.908+0000] {processor.py:157} INFO - Started process (PID=66272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:38:33.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:38:33.917+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:38:33.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:38:33.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:38:33.955+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:38:33.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:38:33.967+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:38:33.967+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:38:33.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-30T13:39:04.382+0000] {processor.py:157} INFO - Started process (PID=66297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:39:04.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:39:04.385+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:39:04.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:39:04.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:39:04.423+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:39:04.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:39:04.434+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:39:04.434+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:39:04.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-30T13:39:34.817+0000] {processor.py:157} INFO - Started process (PID=66322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:39:34.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:39:34.823+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:39:34.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:39:34.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:39:34.864+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:39:34.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:39:34.885+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:39:34.885+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:39:34.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.084 seconds
[2024-07-30T13:40:05.386+0000] {processor.py:157} INFO - Started process (PID=66347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:40:05.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:40:05.392+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:40:05.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:40:05.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:40:05.449+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:40:05.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:40:05.463+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:40:05.463+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:40:05.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.094 seconds
[2024-07-30T13:40:35.927+0000] {processor.py:157} INFO - Started process (PID=66372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:40:35.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:40:35.933+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:40:35.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:40:35.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:40:35.966+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:40:35.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:40:35.975+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:40:35.975+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:40:35.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-30T13:41:06.431+0000] {processor.py:157} INFO - Started process (PID=66397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:41:06.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:41:06.436+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:41:06.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:41:06.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:41:06.473+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:41:06.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:41:06.488+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:41:06.487+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:41:06.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-30T13:41:36.946+0000] {processor.py:157} INFO - Started process (PID=66422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:41:36.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:41:36.952+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:41:36.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:41:36.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:41:36.984+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:41:36.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:41:36.995+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:41:36.995+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:41:37.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-30T13:42:07.425+0000] {processor.py:157} INFO - Started process (PID=66447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:42:07.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:42:07.430+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:42:07.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:42:07.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:42:07.463+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:42:07.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:42:07.474+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:42:07.474+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:42:07.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-30T13:42:37.898+0000] {processor.py:157} INFO - Started process (PID=66472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:42:37.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:42:37.904+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:42:37.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:42:37.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:42:37.939+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:42:37.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:42:37.954+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:42:37.953+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:42:37.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-30T13:43:08.461+0000] {processor.py:157} INFO - Started process (PID=66497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:43:08.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:43:08.466+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:43:08.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:43:08.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:43:08.498+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:43:08.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:43:08.509+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:43:08.509+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:43:08.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-30T13:43:38.858+0000] {processor.py:157} INFO - Started process (PID=66522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:43:38.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:43:38.861+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:43:38.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:43:38.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:43:38.894+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:43:38.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:43:38.905+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:43:38.905+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:43:38.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-30T13:44:09.312+0000] {processor.py:157} INFO - Started process (PID=66547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:44:09.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:44:09.316+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:44:09.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:44:09.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:44:09.344+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:44:09.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:44:09.354+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:44:09.354+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:44:09.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T13:44:39.785+0000] {processor.py:157} INFO - Started process (PID=66572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:44:39.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:44:39.791+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:44:39.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:44:39.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:44:39.849+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:44:39.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:44:39.865+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:44:39.865+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:44:39.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.096 seconds
[2024-07-30T13:45:10.305+0000] {processor.py:157} INFO - Started process (PID=66597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:45:10.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:45:10.311+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:45:10.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:45:10.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:45:10.342+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:45:10.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:45:10.352+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:45:10.352+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:45:10.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-30T13:45:40.753+0000] {processor.py:157} INFO - Started process (PID=66622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:45:40.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:45:40.758+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:45:40.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:45:40.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:45:40.791+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:45:40.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:45:40.803+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:45:40.803+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:45:40.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-30T13:46:11.211+0000] {processor.py:157} INFO - Started process (PID=66647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:46:11.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:46:11.214+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:46:11.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:46:11.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:46:11.239+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:46:11.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:46:11.251+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:46:11.251+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:46:11.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-30T13:46:41.627+0000] {processor.py:157} INFO - Started process (PID=66672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:46:41.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:46:41.634+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:46:41.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:46:41.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:46:41.666+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:46:41.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:46:41.678+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:46:41.678+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:46:41.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-30T13:47:11.977+0000] {processor.py:157} INFO - Started process (PID=66697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:47:11.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:47:11.980+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:47:11.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:47:11.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:47:12.003+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:47:12.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:47:12.012+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:47:12.012+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:47:12.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-30T13:47:42.364+0000] {processor.py:157} INFO - Started process (PID=66722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:47:42.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:47:42.369+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:47:42.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:47:42.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:47:42.401+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:47:42.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:47:42.412+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:47:42.412+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:47:42.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T13:48:12.889+0000] {processor.py:157} INFO - Started process (PID=66747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:48:12.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:48:12.895+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:48:12.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:48:12.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:48:12.935+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:48:12.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:48:12.948+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:48:12.948+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:48:12.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-30T13:48:43.331+0000] {processor.py:157} INFO - Started process (PID=66772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:48:43.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:48:43.335+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:48:43.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:48:43.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:48:43.365+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:48:43.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:48:43.376+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:48:43.375+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:48:43.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T13:49:13.844+0000] {processor.py:157} INFO - Started process (PID=66797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:49:13.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:49:13.850+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:49:13.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:49:13.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:49:13.883+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:49:13.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:49:13.895+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:49:13.895+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:49:13.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-30T13:49:44.320+0000] {processor.py:157} INFO - Started process (PID=66822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:49:44.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:49:44.325+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:49:44.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:49:44.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:49:44.362+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:49:44.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:49:44.373+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:49:44.373+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:49:44.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-30T13:50:14.771+0000] {processor.py:157} INFO - Started process (PID=66847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:50:14.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:50:14.777+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:50:14.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:50:14.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:50:14.811+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:50:14.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:50:14.823+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:50:14.823+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:50:14.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-30T13:50:45.250+0000] {processor.py:157} INFO - Started process (PID=66872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:50:45.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:50:45.256+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:50:45.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:50:45.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:50:45.283+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:50:45.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:50:45.295+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:50:45.294+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:50:45.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T13:51:15.699+0000] {processor.py:157} INFO - Started process (PID=66897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:51:15.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:51:15.704+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:51:15.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:51:15.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:51:15.739+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:51:15.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:51:15.751+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:51:15.751+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:51:15.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-30T13:51:46.153+0000] {processor.py:157} INFO - Started process (PID=66922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:51:46.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:51:46.159+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:51:46.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:51:46.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:51:46.210+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:51:46.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:51:46.234+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:51:46.234+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:51:46.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.098 seconds
[2024-07-30T13:52:16.730+0000] {processor.py:157} INFO - Started process (PID=66947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:52:16.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:52:16.734+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:52:16.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:52:16.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:52:16.764+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:52:16.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:52:16.774+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:52:16.774+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:52:16.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T13:52:47.220+0000] {processor.py:157} INFO - Started process (PID=66972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:52:47.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:52:47.224+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:52:47.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:52:47.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:52:47.251+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:52:47.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:52:47.261+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:52:47.261+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:52:47.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T13:53:17.653+0000] {processor.py:157} INFO - Started process (PID=66997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:53:17.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:53:17.659+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:53:17.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:53:17.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:53:17.697+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:53:17.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:53:17.710+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:53:17.710+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:53:17.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-30T13:53:48.204+0000] {processor.py:157} INFO - Started process (PID=67022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:53:48.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:53:48.210+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:53:48.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:53:48.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:53:48.236+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:53:48.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:53:48.247+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:53:48.247+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:53:48.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T13:54:18.745+0000] {processor.py:157} INFO - Started process (PID=67047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:54:18.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:54:18.750+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:54:18.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:54:18.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:54:18.796+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:54:18.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:54:18.813+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:54:18.813+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:54:18.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-30T13:54:49.295+0000] {processor.py:157} INFO - Started process (PID=67072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:54:49.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:54:49.303+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:54:49.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:54:49.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:54:49.337+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:54:49.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:54:49.349+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:54:49.349+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:54:49.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-30T13:55:19.797+0000] {processor.py:157} INFO - Started process (PID=67097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:55:19.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:55:19.799+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:55:19.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:55:19.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:55:19.828+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:55:19.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:55:19.837+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:55:19.837+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:55:19.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-30T13:55:50.344+0000] {processor.py:157} INFO - Started process (PID=67122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:55:50.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:55:50.348+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:55:50.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:55:50.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:55:50.385+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:55:50.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:55:50.398+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:55:50.398+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:55:50.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-30T13:56:20.777+0000] {processor.py:157} INFO - Started process (PID=67147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:56:20.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:56:20.783+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:56:20.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:56:20.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:56:20.816+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:56:20.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:56:20.828+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:56:20.828+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:56:20.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-30T13:56:51.340+0000] {processor.py:157} INFO - Started process (PID=67172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:56:51.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:56:51.344+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:56:51.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:56:51.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:56:51.373+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:56:51.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:56:51.385+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:56:51.385+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:56:51.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T13:57:21.760+0000] {processor.py:157} INFO - Started process (PID=67197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:57:21.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:57:21.766+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:57:21.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:57:21.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:57:21.805+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:57:21.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:57:21.816+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:57:21.816+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:57:21.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-30T13:57:52.294+0000] {processor.py:157} INFO - Started process (PID=67222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:57:52.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:57:52.299+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:57:52.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:57:52.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:57:52.329+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:57:52.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:57:52.342+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:57:52.342+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:57:52.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-30T13:58:22.695+0000] {processor.py:157} INFO - Started process (PID=67247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:58:22.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:58:22.698+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:58:22.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:58:22.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:58:22.730+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:58:22.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:58:22.740+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:58:22.740+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:58:22.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T13:58:53.132+0000] {processor.py:157} INFO - Started process (PID=67272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:58:53.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:58:53.136+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:58:53.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:58:53.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:58:53.168+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:58:53.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:58:53.179+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:58:53.179+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:58:53.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T13:59:23.591+0000] {processor.py:157} INFO - Started process (PID=67297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:59:23.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:59:23.595+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:59:23.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:59:23.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:59:23.628+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:59:23.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:59:23.639+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:59:23.639+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:59:23.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T13:59:54.114+0000] {processor.py:157} INFO - Started process (PID=67322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:59:54.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T13:59:54.121+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:59:54.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:59:54.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T13:59:54.158+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:59:54.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:59:54.172+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:59:54.172+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T13:59:54.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-30T14:00:24.620+0000] {processor.py:157} INFO - Started process (PID=67347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:00:24.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:00:24.626+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:00:24.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:00:24.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:00:24.653+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:00:24.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:00:24.664+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:00:24.664+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:00:24.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T14:00:55.008+0000] {processor.py:157} INFO - Started process (PID=67372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:00:55.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:00:55.013+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:00:55.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:00:55.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:00:55.040+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:00:55.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:00:55.051+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:00:55.051+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:00:55.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T14:01:25.614+0000] {processor.py:157} INFO - Started process (PID=67397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:01:25.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:01:25.619+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:01:25.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:01:25.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:01:25.664+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:01:25.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:01:25.677+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:01:25.677+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:01:26.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.441 seconds
[2024-07-30T14:01:56.552+0000] {processor.py:157} INFO - Started process (PID=67422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:01:56.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:01:56.559+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:01:56.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:01:56.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:01:56.637+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:01:56.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:01:56.653+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:01:56.652+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:01:56.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.119 seconds
[2024-07-30T14:02:27.037+0000] {processor.py:157} INFO - Started process (PID=67447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:02:27.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:02:27.040+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:02:27.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:02:27.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:02:27.070+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:02:27.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:02:27.081+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:02:27.081+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:02:27.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T14:02:57.580+0000] {processor.py:157} INFO - Started process (PID=67472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:02:57.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:02:57.586+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:02:57.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:02:57.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:02:57.632+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:02:57.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:02:57.646+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:02:57.646+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:02:57.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.091 seconds
[2024-07-30T14:03:28.078+0000] {processor.py:157} INFO - Started process (PID=67497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:03:28.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:03:28.083+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:03:28.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:03:28.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:03:28.111+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:03:28.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:03:28.120+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:03:28.120+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:03:28.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T14:03:58.544+0000] {processor.py:157} INFO - Started process (PID=67522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:03:58.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:03:58.550+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:03:58.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:03:58.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:03:58.609+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:03:58.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:03:58.624+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:03:58.624+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:03:58.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.118 seconds
[2024-07-30T14:04:29.052+0000] {processor.py:157} INFO - Started process (PID=67547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:04:29.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:04:29.061+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:04:29.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:04:29.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:04:29.089+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:04:29.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:04:29.101+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:04:29.101+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:04:29.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-30T14:04:59.481+0000] {processor.py:157} INFO - Started process (PID=67572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:04:59.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:04:59.486+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:04:59.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:04:59.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:04:59.544+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:04:59.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:04:59.557+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:04:59.557+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:04:59.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-30T14:05:29.932+0000] {processor.py:157} INFO - Started process (PID=67597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:05:29.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:05:29.935+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:05:29.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:05:29.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:05:29.961+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:05:29.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:05:29.971+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:05:29.971+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:05:29.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-30T14:06:00.413+0000] {processor.py:157} INFO - Started process (PID=67622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:06:00.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:06:00.418+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:06:00.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:06:00.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:06:00.466+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:06:00.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:06:00.484+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:06:00.484+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:06:00.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-30T14:06:30.837+0000] {processor.py:157} INFO - Started process (PID=67647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:06:30.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:06:30.841+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:06:30.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:06:30.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:06:30.869+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:06:30.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:06:30.878+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:06:30.878+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:06:30.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-30T14:07:01.311+0000] {processor.py:157} INFO - Started process (PID=67672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:07:01.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:07:01.315+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:07:01.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:07:01.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:07:01.347+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:07:01.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:07:01.359+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:07:01.359+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:07:01.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T14:07:31.766+0000] {processor.py:157} INFO - Started process (PID=67697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:07:31.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:07:31.771+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:07:31.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:07:31.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:07:31.800+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:07:31.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:07:31.811+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:07:31.811+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:07:31.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T14:08:02.137+0000] {processor.py:157} INFO - Started process (PID=67722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:08:02.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:08:02.143+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:08:02.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:08:02.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:08:02.183+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:08:02.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:08:02.197+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:08:02.197+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:08:02.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-30T14:08:32.680+0000] {processor.py:157} INFO - Started process (PID=67747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:08:32.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:08:32.683+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:08:32.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:08:32.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:08:32.713+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:08:32.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:08:32.723+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:08:32.723+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:08:32.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T14:09:03.093+0000] {processor.py:157} INFO - Started process (PID=67772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:09:03.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:09:03.099+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:09:03.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:09:03.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:09:03.143+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:09:03.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:09:03.155+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:09:03.155+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:09:03.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-30T14:09:33.517+0000] {processor.py:157} INFO - Started process (PID=67797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:09:33.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:09:33.526+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:09:33.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:09:33.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:09:33.575+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:09:33.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:09:33.588+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:09:33.588+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:09:33.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.096 seconds
[2024-07-30T14:10:04.096+0000] {processor.py:157} INFO - Started process (PID=67822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:10:04.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:10:04.102+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:10:04.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:10:04.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:10:04.179+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:10:04.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:10:04.195+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:10:04.195+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:10:04.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.277 seconds
[2024-07-30T14:10:35.036+0000] {processor.py:157} INFO - Started process (PID=67847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:10:35.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:10:35.047+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:10:35.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:10:35.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:10:35.135+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:10:35.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:10:35.151+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:10:35.151+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:10:35.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.172 seconds
[2024-07-30T14:11:05.649+0000] {processor.py:157} INFO - Started process (PID=67872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:11:05.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:11:05.656+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:11:05.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:11:05.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:11:05.695+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:11:05.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:11:05.707+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:11:05.706+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:11:05.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-30T14:11:36.076+0000] {processor.py:157} INFO - Started process (PID=67897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:11:36.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:11:36.079+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:11:36.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:11:36.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:11:36.101+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:11:36.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:11:36.112+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:11:36.112+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:11:36.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-30T14:12:06.537+0000] {processor.py:157} INFO - Started process (PID=67922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:12:06.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:12:06.542+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:12:06.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:12:06.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:12:06.571+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:12:06.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:12:06.581+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:12:06.581+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:12:06.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T14:12:37.001+0000] {processor.py:157} INFO - Started process (PID=67947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:12:37.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:12:37.008+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:12:37.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:12:37.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:12:37.046+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:12:37.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:12:37.058+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:12:37.058+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:12:37.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-30T14:13:07.498+0000] {processor.py:157} INFO - Started process (PID=67972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:13:07.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:13:07.502+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:13:07.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:13:07.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:13:07.530+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:13:07.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:13:07.543+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:13:07.543+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:13:07.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.189 seconds
[2024-07-30T14:13:38.191+0000] {processor.py:157} INFO - Started process (PID=67997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:13:38.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:13:38.194+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:13:38.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:13:38.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:13:38.224+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:13:38.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:13:38.234+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:13:38.234+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:13:38.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T14:14:08.645+0000] {processor.py:157} INFO - Started process (PID=68022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:14:08.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:14:08.648+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:14:08.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:14:08.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:14:08.678+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:14:08.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:14:08.690+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:14:08.690+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:14:08.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T14:14:39.090+0000] {processor.py:157} INFO - Started process (PID=68047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:14:39.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:14:39.095+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:14:39.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:14:39.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:14:39.125+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:14:39.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:14:39.138+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:14:39.137+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:14:39.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-30T14:15:09.596+0000] {processor.py:157} INFO - Started process (PID=68072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:15:09.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:15:09.603+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:15:09.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:15:09.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:15:09.637+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:15:09.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:15:09.651+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:15:09.650+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:15:09.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-30T14:15:40.095+0000] {processor.py:157} INFO - Started process (PID=68097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:15:40.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:15:40.100+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:15:40.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:15:40.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:15:40.127+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:15:40.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:15:40.139+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:15:40.139+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:15:40.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T14:16:10.500+0000] {processor.py:157} INFO - Started process (PID=68122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:16:10.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:16:10.503+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:16:10.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:16:10.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:16:10.530+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:16:10.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:16:10.540+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:16:10.540+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:16:10.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-30T14:16:40.919+0000] {processor.py:157} INFO - Started process (PID=68147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:16:40.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:16:40.922+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:16:40.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:16:40.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:16:40.950+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:16:40.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:16:40.960+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:16:40.960+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:16:40.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-30T14:17:11.366+0000] {processor.py:157} INFO - Started process (PID=68172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:17:11.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:17:11.370+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:17:11.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:17:11.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:17:11.398+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:17:11.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:17:11.408+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:17:11.408+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:17:11.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T14:17:41.898+0000] {processor.py:157} INFO - Started process (PID=68197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:17:41.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:17:41.906+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:17:41.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:17:41.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:17:41.951+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:17:41.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:17:41.965+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:17:41.965+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:17:41.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-30T14:18:12.353+0000] {processor.py:157} INFO - Started process (PID=68222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:18:12.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:18:12.355+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:18:12.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:18:12.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:18:12.374+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:18:12.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:18:12.386+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:18:12.386+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:18:12.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.042 seconds
[2024-07-30T14:18:42.790+0000] {processor.py:157} INFO - Started process (PID=68247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:18:42.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:18:42.793+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:18:42.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:18:42.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:18:42.821+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:18:42.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:18:42.832+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:18:42.832+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:18:42.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.200 seconds
[2024-07-30T14:19:13.532+0000] {processor.py:157} INFO - Started process (PID=68272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:19:13.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:19:13.537+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:19:13.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:19:13.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:19:13.579+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:19:13.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:19:13.594+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:19:13.594+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:19:13.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-30T14:19:44.039+0000] {processor.py:157} INFO - Started process (PID=68297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:19:44.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:19:44.043+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:19:44.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:19:44.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:19:44.076+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:19:44.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:19:44.086+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:19:44.086+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:19:44.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T14:20:14.492+0000] {processor.py:157} INFO - Started process (PID=68322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:20:14.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:20:14.496+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:20:14.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:20:14.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:20:14.526+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:20:14.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:20:14.536+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:20:14.536+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:20:14.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T14:20:44.917+0000] {processor.py:157} INFO - Started process (PID=68347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:20:44.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:20:44.919+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:20:44.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:20:44.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:20:44.950+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:20:44.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:20:44.961+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:20:44.961+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:20:44.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T14:21:15.353+0000] {processor.py:157} INFO - Started process (PID=68372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:21:15.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:21:15.357+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:21:15.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:21:15.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:21:15.399+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:21:15.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:21:15.413+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:21:15.413+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:21:15.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-30T14:21:45.913+0000] {processor.py:157} INFO - Started process (PID=68397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:21:45.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:21:45.920+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:21:45.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:21:45.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:21:45.987+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:21:45.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:21:46.131+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:21:46.131+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:21:46.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.234 seconds
[2024-07-30T14:22:16.685+0000] {processor.py:157} INFO - Started process (PID=68422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:22:16.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:22:16.691+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:22:16.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:22:16.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:22:16.742+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:22:16.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:22:16.754+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:22:16.754+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:22:16.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.084 seconds
[2024-07-30T14:22:47.273+0000] {processor.py:157} INFO - Started process (PID=68447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:22:47.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:22:47.286+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:22:47.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:22:47.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:22:47.353+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:22:47.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:22:47.370+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:22:47.370+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:22:47.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.130 seconds
[2024-07-30T14:23:17.868+0000] {processor.py:157} INFO - Started process (PID=68472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:23:17.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:23:17.878+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:23:17.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:23:17.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:23:17.927+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:23:17.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:23:17.939+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:23:17.939+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:23:17.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.099 seconds
[2024-07-30T14:23:48.369+0000] {processor.py:157} INFO - Started process (PID=68497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:23:48.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:23:48.373+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:23:48.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:23:48.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:23:48.404+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:23:48.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:23:48.414+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:23:48.414+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:23:48.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T14:24:18.856+0000] {processor.py:157} INFO - Started process (PID=68522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:24:18.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:24:18.867+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:24:18.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:24:18.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:24:18.979+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:24:18.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:24:19.068+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:24:19.067+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:24:19.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.511 seconds
[2024-07-30T14:24:49.980+0000] {processor.py:157} INFO - Started process (PID=68547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:24:49.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:24:49.987+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:24:49.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:24:50.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:24:50.046+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:24:50.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:24:50.249+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:24:50.248+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:24:50.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.307 seconds
[2024-07-30T14:25:20.763+0000] {processor.py:157} INFO - Started process (PID=68572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:25:20.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:25:20.771+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:25:20.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:25:20.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:25:20.842+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:25:20.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:25:20.861+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:25:20.860+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:25:20.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.127 seconds
[2024-07-30T14:25:51.311+0000] {processor.py:157} INFO - Started process (PID=68597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:25:51.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:25:51.325+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:25:51.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:25:51.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:25:51.392+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:25:51.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:25:51.407+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:25:51.407+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:25:51.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.121 seconds
[2024-07-30T14:26:21.915+0000] {processor.py:157} INFO - Started process (PID=68622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:26:21.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:26:21.926+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:26:21.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:26:21.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:26:21.982+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:26:21.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:26:22.006+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:26:22.006+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:26:22.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.108 seconds
[2024-07-30T14:26:52.336+0000] {processor.py:157} INFO - Started process (PID=68647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:26:52.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:26:52.339+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:26:52.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:26:52.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:26:52.367+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:26:52.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:26:52.379+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:26:52.379+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:26:52.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T14:27:22.756+0000] {processor.py:157} INFO - Started process (PID=68672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:27:22.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:27:22.762+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:27:22.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:27:22.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:27:22.812+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:27:22.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:27:22.826+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:27:22.825+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:27:22.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.222 seconds
[2024-07-30T14:27:53.423+0000] {processor.py:157} INFO - Started process (PID=68697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:27:53.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:27:53.428+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:27:53.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:27:53.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:27:53.469+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:27:53.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:27:53.482+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:27:53.482+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:27:53.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-30T14:28:24.246+0000] {processor.py:157} INFO - Started process (PID=68722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:28:24.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:28:24.256+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:28:24.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:28:24.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:28:24.334+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:28:24.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:28:24.351+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:28:24.350+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:28:24.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.130 seconds
[2024-07-30T14:28:54.720+0000] {processor.py:157} INFO - Started process (PID=68747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:28:54.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:28:54.724+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:28:54.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:28:54.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:28:54.759+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:28:54.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:28:54.771+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:28:54.771+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:28:54.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-30T14:29:25.260+0000] {processor.py:157} INFO - Started process (PID=68772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:29:25.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:29:25.276+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:29:25.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:29:25.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:29:25.344+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:29:25.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:29:25.360+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:29:25.360+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:29:25.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.125 seconds
[2024-07-30T14:29:55.859+0000] {processor.py:157} INFO - Started process (PID=68797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:29:55.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:29:55.877+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:29:55.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:29:55.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:29:55.934+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:29:55.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:29:55.959+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:29:55.959+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:29:55.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-30T14:30:26.424+0000] {processor.py:157} INFO - Started process (PID=68822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:30:26.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:30:26.431+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:30:26.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:30:26.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:30:26.480+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:30:26.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:30:26.649+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:30:26.649+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:30:26.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.241 seconds
[2024-07-30T14:30:57.044+0000] {processor.py:157} INFO - Started process (PID=68847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:30:57.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:30:57.047+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:30:57.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:30:57.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:30:57.077+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:30:57.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:30:57.088+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:30:57.088+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:30:57.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T14:31:27.509+0000] {processor.py:157} INFO - Started process (PID=68872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:31:27.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:31:27.519+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:31:27.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:31:27.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:31:27.659+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:31:27.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:31:27.677+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:31:27.677+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:31:27.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.193 seconds
[2024-07-30T14:31:58.070+0000] {processor.py:157} INFO - Started process (PID=68897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:31:58.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:31:58.078+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:31:58.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:31:58.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:31:58.156+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:31:58.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:31:58.175+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:31:58.175+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:31:58.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.127 seconds
[2024-07-30T14:32:28.641+0000] {processor.py:157} INFO - Started process (PID=68922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:32:28.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:32:28.648+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:32:28.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:32:28.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:32:28.701+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:32:28.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:32:28.717+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:32:28.717+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:32:28.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.094 seconds
[2024-07-30T14:32:59.148+0000] {processor.py:157} INFO - Started process (PID=68947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:32:59.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:32:59.158+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:32:59.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:32:59.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:32:59.236+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:32:59.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:32:59.254+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:32:59.254+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:32:59.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.282 seconds
[2024-07-30T14:33:29.976+0000] {processor.py:157} INFO - Started process (PID=68972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:33:29.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:33:29.984+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:33:29.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:33:30.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:33:30.026+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:33:30.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:33:30.150+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:33:30.150+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:33:30.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.191 seconds
[2024-07-30T14:34:00.555+0000] {processor.py:157} INFO - Started process (PID=68997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:34:00.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:34:00.559+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:34:00.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:34:00.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:34:00.589+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:34:00.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:34:00.600+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:34:00.599+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:34:00.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T14:34:30.952+0000] {processor.py:157} INFO - Started process (PID=69022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:34:30.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:34:30.958+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:34:30.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:34:30.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:34:31.043+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:34:31.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:34:31.069+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:34:31.069+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:34:31.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.138 seconds
[2024-07-30T14:35:01.504+0000] {processor.py:157} INFO - Started process (PID=69047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:35:01.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:35:01.520+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:35:01.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:35:01.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:35:01.624+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:35:01.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:35:01.655+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:35:01.655+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:35:01.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.189 seconds
[2024-07-30T14:35:32.089+0000] {processor.py:157} INFO - Started process (PID=69072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:35:32.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:35:32.094+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:35:32.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:35:32.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:35:32.137+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:35:32.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:35:32.152+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:35:32.152+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:35:32.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-30T14:36:02.597+0000] {processor.py:157} INFO - Started process (PID=69097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:36:02.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:36:02.632+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:36:02.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:36:02.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:36:02.699+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:36:02.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:36:02.731+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:36:02.731+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:36:02.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.327 seconds
[2024-07-30T14:36:33.513+0000] {processor.py:157} INFO - Started process (PID=69122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:36:33.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:36:33.534+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:36:33.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:36:33.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:36:33.599+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:36:33.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:36:33.838+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:36:33.838+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:36:33.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.347 seconds
[2024-07-30T14:37:04.187+0000] {processor.py:157} INFO - Started process (PID=69147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:37:04.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:37:04.198+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:37:04.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:37:04.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:37:04.250+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:37:04.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:37:04.265+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:37:04.264+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:37:04.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-30T14:37:34.785+0000] {processor.py:157} INFO - Started process (PID=69172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:37:34.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:37:34.809+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:37:34.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:37:34.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:37:34.854+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:37:34.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:37:34.866+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:37:34.866+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:37:34.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.099 seconds
[2024-07-30T14:38:05.349+0000] {processor.py:157} INFO - Started process (PID=69197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:38:05.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:38:05.356+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:38:05.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:38:05.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:38:05.428+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:38:05.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:38:05.460+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:38:05.460+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:38:05.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.142 seconds
[2024-07-30T14:38:36.014+0000] {processor.py:157} INFO - Started process (PID=69222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:38:36.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:38:36.030+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:38:36.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:38:36.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:38:36.091+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:38:36.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:38:36.112+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:38:36.111+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:38:36.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.259 seconds
[2024-07-30T14:39:07.198+0000] {processor.py:157} INFO - Started process (PID=69247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:39:07.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:39:07.217+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:39:07.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:39:07.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:39:07.266+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:39:07.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:39:07.414+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:39:07.414+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:39:07.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.233 seconds
[2024-07-30T14:39:37.818+0000] {processor.py:157} INFO - Started process (PID=69272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:39:37.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:39:37.821+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:39:37.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:39:37.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:39:37.854+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:39:37.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:39:37.863+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:39:37.863+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:39:37.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T14:40:08.287+0000] {processor.py:157} INFO - Started process (PID=69297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:40:08.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:40:08.293+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:40:08.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:40:08.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:40:08.333+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:40:08.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:40:08.346+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:40:08.346+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:40:08.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-30T14:40:38.802+0000] {processor.py:157} INFO - Started process (PID=69322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:40:38.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:40:38.808+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:40:38.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:40:38.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:40:38.843+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:40:38.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:40:38.854+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:40:38.854+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:40:38.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-30T14:41:09.201+0000] {processor.py:157} INFO - Started process (PID=69347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:41:09.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:41:09.206+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:41:09.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:41:09.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:41:09.234+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:41:09.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:41:09.246+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:41:09.246+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:41:09.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T14:41:39.620+0000] {processor.py:157} INFO - Started process (PID=69372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:41:39.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:41:39.625+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:41:39.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:41:39.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:41:39.657+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:41:39.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:41:39.668+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:41:39.668+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:41:39.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.226 seconds
[2024-07-30T14:42:10.395+0000] {processor.py:157} INFO - Started process (PID=69397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:42:10.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:42:10.401+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:42:10.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:42:10.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:42:10.434+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:42:10.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:42:10.514+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:42:10.514+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:42:10.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.133 seconds
[2024-07-30T14:42:40.973+0000] {processor.py:157} INFO - Started process (PID=69422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:42:40.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:42:40.979+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:42:40.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:42:40.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:42:41.017+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:42:41.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:42:41.033+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:42:41.033+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:42:41.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-30T14:43:11.441+0000] {processor.py:157} INFO - Started process (PID=69447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:43:11.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:43:11.446+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:43:11.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:43:11.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:43:11.480+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:43:11.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:43:11.491+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:43:11.491+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:43:11.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-30T14:43:41.927+0000] {processor.py:157} INFO - Started process (PID=69472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:43:41.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:43:41.932+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:43:41.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:43:41.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:43:41.966+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:43:41.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:43:41.978+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:43:41.978+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:43:41.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-30T14:44:12.359+0000] {processor.py:157} INFO - Started process (PID=69497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:44:12.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:44:12.361+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:44:12.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:44:12.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:44:12.391+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:44:12.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:44:12.400+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:44:12.400+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:44:12.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-30T14:44:42.791+0000] {processor.py:157} INFO - Started process (PID=69522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:44:42.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:44:42.798+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:44:42.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:44:42.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:44:42.837+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:44:42.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:44:43.007+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:44:43.007+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:44:43.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.230 seconds
[2024-07-30T14:45:13.499+0000] {processor.py:157} INFO - Started process (PID=69547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:45:13.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:45:13.502+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:45:13.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:45:13.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:45:13.528+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:45:13.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:45:13.607+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:45:13.607+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:45:13.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.121 seconds
[2024-07-30T14:45:44.167+0000] {processor.py:157} INFO - Started process (PID=69572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:45:44.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:45:44.172+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:45:44.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:45:44.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:45:44.198+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:45:44.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:45:44.208+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:45:44.208+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:45:44.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T14:46:14.635+0000] {processor.py:157} INFO - Started process (PID=69597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:46:14.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:46:14.638+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:46:14.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:46:14.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:46:14.668+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:46:14.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:46:14.677+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:46:14.677+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:46:14.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T14:46:45.027+0000] {processor.py:157} INFO - Started process (PID=69622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:46:45.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:46:45.032+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:46:45.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:46:45.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:46:45.058+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:46:45.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:46:45.068+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:46:45.068+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:46:45.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-30T14:47:15.396+0000] {processor.py:157} INFO - Started process (PID=69647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:47:15.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:47:15.400+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:47:15.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:47:15.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:47:15.432+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:47:15.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:47:15.442+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:47:15.442+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:47:15.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.164 seconds
[2024-07-30T14:47:46.090+0000] {processor.py:157} INFO - Started process (PID=69672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:47:46.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:47:46.098+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:47:46.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:47:46.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:47:46.162+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:47:46.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:47:46.269+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:47:46.269+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:47:46.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.192 seconds
[2024-07-30T14:48:16.722+0000] {processor.py:157} INFO - Started process (PID=69697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:48:16.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:48:16.727+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:48:16.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:48:16.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:48:16.758+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:48:16.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:48:16.769+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:48:16.769+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:48:16.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-30T14:48:47.146+0000] {processor.py:157} INFO - Started process (PID=69722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:48:47.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:48:47.150+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:48:47.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:48:47.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:48:47.176+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:48:47.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:48:47.189+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:48:47.189+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:48:47.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T14:49:17.556+0000] {processor.py:157} INFO - Started process (PID=69747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:49:17.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:49:17.563+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:49:17.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:49:17.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:49:17.600+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:49:17.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:49:17.612+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:49:17.612+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:49:17.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-30T14:49:48.079+0000] {processor.py:157} INFO - Started process (PID=69772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:49:48.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:49:48.083+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:49:48.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:49:48.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:49:48.111+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:49:48.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:49:48.123+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:49:48.123+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:49:48.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T14:50:18.482+0000] {processor.py:157} INFO - Started process (PID=69797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:50:18.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:50:18.486+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:50:18.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:50:18.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:50:18.518+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:50:18.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:50:18.530+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:50:18.530+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:50:18.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.205 seconds
[2024-07-30T14:50:49.237+0000] {processor.py:157} INFO - Started process (PID=69822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:50:49.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:50:49.240+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:50:49.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:50:49.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:50:49.269+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:50:49.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:50:49.353+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:50:49.353+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:50:49.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.127 seconds
[2024-07-30T14:51:19.757+0000] {processor.py:157} INFO - Started process (PID=69847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:51:19.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:51:19.761+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:51:19.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:51:19.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:51:19.795+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:51:19.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:51:19.805+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:51:19.805+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:51:19.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T14:51:50.301+0000] {processor.py:157} INFO - Started process (PID=69872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:51:50.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:51:50.307+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:51:50.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:51:50.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:51:50.339+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:51:50.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:51:50.349+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:51:50.348+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:51:50.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-30T14:52:20.726+0000] {processor.py:157} INFO - Started process (PID=69897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:52:20.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:52:20.732+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:52:20.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:52:20.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:52:20.774+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:52:20.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:52:20.787+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:52:20.787+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:52:20.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-30T14:52:51.180+0000] {processor.py:157} INFO - Started process (PID=69922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:52:51.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:52:51.185+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:52:51.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:52:51.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:52:51.215+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:52:51.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:52:51.225+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:52:51.225+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:52:51.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T14:53:21.610+0000] {processor.py:157} INFO - Started process (PID=69947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:53:21.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:53:21.618+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:53:21.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:53:21.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:53:21.657+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:53:21.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:53:21.810+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:53:21.810+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:53:21.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.220 seconds
[2024-07-30T14:53:52.244+0000] {processor.py:157} INFO - Started process (PID=69972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:53:52.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:53:52.248+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:53:52.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:53:52.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:53:52.280+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:53:52.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:53:52.362+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:53:52.362+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:53:52.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.127 seconds
[2024-07-30T14:54:22.737+0000] {processor.py:157} INFO - Started process (PID=69997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:54:22.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:54:22.740+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:54:22.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:54:22.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:54:22.764+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:54:22.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:54:22.779+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:54:22.779+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:54:22.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-30T14:54:53.146+0000] {processor.py:157} INFO - Started process (PID=70022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:54:53.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:54:53.153+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:54:53.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:54:53.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:54:53.198+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:54:53.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:54:53.212+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:54:53.212+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:54:53.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-30T14:55:23.600+0000] {processor.py:157} INFO - Started process (PID=70047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:55:23.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:55:23.605+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:55:23.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:55:23.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:55:23.634+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:55:23.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:55:23.645+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:55:23.645+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:55:23.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T14:55:54.044+0000] {processor.py:157} INFO - Started process (PID=70072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:55:54.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:55:54.051+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:55:54.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:55:54.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:55:54.080+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:55:54.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:55:54.091+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:55:54.091+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:55:54.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.182 seconds
[2024-07-30T14:56:24.649+0000] {processor.py:157} INFO - Started process (PID=70097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:56:24.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:56:24.656+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:56:24.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:56:24.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:56:24.711+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:56:24.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:56:24.799+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:56:24.799+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:56:24.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.164 seconds
[2024-07-30T14:56:55.228+0000] {processor.py:157} INFO - Started process (PID=70122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:56:55.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:56:55.233+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:56:55.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:56:55.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:56:55.263+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:56:55.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:56:55.401+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:56:55.401+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:56:55.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.185 seconds
[2024-07-30T14:57:25.778+0000] {processor.py:157} INFO - Started process (PID=70147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:57:25.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:57:25.783+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:57:25.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:57:25.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:57:25.815+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:57:25.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:57:25.826+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:57:25.826+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:57:25.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-30T14:57:56.249+0000] {processor.py:157} INFO - Started process (PID=70172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:57:56.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:57:56.252+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:57:56.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:57:56.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:57:56.282+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:57:56.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:57:56.294+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:57:56.294+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:57:56.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T14:58:26.652+0000] {processor.py:157} INFO - Started process (PID=70197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:58:26.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:58:26.654+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:58:26.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:58:26.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:58:26.681+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:58:26.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:58:26.692+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:58:26.692+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:58:26.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T14:58:57.068+0000] {processor.py:157} INFO - Started process (PID=70222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:58:57.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:58:57.071+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:58:57.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:58:57.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:58:57.100+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:58:57.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:58:57.182+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:58:57.181+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:58:57.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.126 seconds
[2024-07-30T14:59:27.721+0000] {processor.py:157} INFO - Started process (PID=70247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:59:27.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:59:27.726+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:59:27.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:59:27.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:59:27.755+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:59:27.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:59:27.834+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:59:27.833+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:59:27.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.125 seconds
[2024-07-30T14:59:58.403+0000] {processor.py:157} INFO - Started process (PID=70272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:59:58.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T14:59:58.408+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:59:58.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:59:58.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T14:59:58.433+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:59:58.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:59:58.446+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:59:58.446+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T14:59:58.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T15:00:28.743+0000] {processor.py:157} INFO - Started process (PID=70297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:00:28.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:00:28.745+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:00:28.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:00:28.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:00:28.768+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:00:28.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:00:28.778+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:00:28.778+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:00:28.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-30T15:00:59.187+0000] {processor.py:157} INFO - Started process (PID=70322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:00:59.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:00:59.190+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:00:59.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:00:59.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:00:59.217+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:00:59.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:00:59.226+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:00:59.226+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:00:59.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-30T15:01:29.601+0000] {processor.py:157} INFO - Started process (PID=70347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:01:29.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:01:29.606+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:01:29.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:01:29.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:01:29.638+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:01:29.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:01:29.648+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:01:29.648+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:01:29.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.207 seconds
[2024-07-30T15:02:00.206+0000] {processor.py:157} INFO - Started process (PID=70372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:02:00.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:02:00.210+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:02:00.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:02:00.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:02:00.238+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:02:00.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:02:00.317+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:02:00.317+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:02:00.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.123 seconds
[2024-07-30T15:02:30.732+0000] {processor.py:157} INFO - Started process (PID=70397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:02:30.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:02:30.736+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:02:30.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:02:30.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:02:30.765+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:02:30.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:02:30.842+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:02:30.841+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:02:30.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.121 seconds
[2024-07-30T15:03:01.264+0000] {processor.py:157} INFO - Started process (PID=70422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:03:01.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:03:01.269+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:03:01.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:03:01.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:03:01.300+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:03:01.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:03:01.310+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:03:01.310+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:03:01.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T15:03:31.734+0000] {processor.py:157} INFO - Started process (PID=70447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:03:31.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:03:31.739+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:03:31.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:03:31.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:03:31.772+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:03:31.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:03:31.782+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:03:31.782+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:03:31.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-30T15:04:02.229+0000] {processor.py:157} INFO - Started process (PID=70472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:04:02.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:04:02.237+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:04:02.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:04:02.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:04:02.274+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:04:02.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:04:02.287+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:04:02.287+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:04:02.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-30T15:04:32.625+0000] {processor.py:157} INFO - Started process (PID=70497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:04:32.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:04:32.631+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:04:32.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:04:32.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:04:32.658+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:04:32.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:04:32.668+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:04:32.668+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:04:32.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.214 seconds
[2024-07-30T15:05:03.391+0000] {processor.py:157} INFO - Started process (PID=70522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:05:03.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:05:03.396+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:05:03.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:05:03.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:05:03.436+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:05:03.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:05:03.545+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:05:03.545+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:05:03.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.170 seconds
[2024-07-30T15:05:33.999+0000] {processor.py:157} INFO - Started process (PID=70547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:05:34.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:05:34.003+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:05:34.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:05:34.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:05:34.034+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:05:34.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:05:34.117+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:05:34.117+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:05:34.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.130 seconds
[2024-07-30T15:06:04.669+0000] {processor.py:157} INFO - Started process (PID=70572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:06:04.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:06:04.673+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:06:04.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:06:04.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:06:04.705+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:06:04.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:06:04.714+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:06:04.714+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:06:04.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T15:06:35.135+0000] {processor.py:157} INFO - Started process (PID=70597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:06:35.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:06:35.140+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:06:35.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:06:35.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:06:35.175+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:06:35.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:06:35.186+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:06:35.186+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:06:35.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-30T15:07:05.579+0000] {processor.py:157} INFO - Started process (PID=70622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:07:05.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:07:05.583+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:07:05.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:07:05.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:07:05.613+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:07:05.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:07:05.627+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:07:05.627+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:07:05.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-30T15:07:36.045+0000] {processor.py:157} INFO - Started process (PID=70647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:07:36.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:07:36.050+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:07:36.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:07:36.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:07:36.078+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:07:36.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:07:36.224+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:07:36.224+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:07:36.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.191 seconds
[2024-07-30T15:08:06.701+0000] {processor.py:157} INFO - Started process (PID=70672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:08:06.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:08:06.707+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:08:06.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:08:06.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:08:06.750+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:08:06.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:08:06.835+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:08:06.835+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:08:06.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.152 seconds
[2024-07-30T15:08:37.353+0000] {processor.py:157} INFO - Started process (PID=70697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:08:37.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:08:37.358+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:08:37.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:08:37.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:08:37.460+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:08:37.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:08:37.467+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:08:37.467+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:08:37.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.130 seconds
[2024-07-30T15:09:07.937+0000] {processor.py:157} INFO - Started process (PID=70722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:09:07.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:09:07.941+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:09:07.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:09:07.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:09:07.971+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:09:07.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:09:07.982+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:09:07.982+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:09:07.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T15:09:38.370+0000] {processor.py:157} INFO - Started process (PID=70747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:09:38.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:09:38.374+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:09:38.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:09:38.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:09:38.411+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:09:38.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:09:38.422+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:09:38.422+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:09:38.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-30T15:10:08.820+0000] {processor.py:157} INFO - Started process (PID=70772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:10:08.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:10:08.822+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:10:08.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:10:08.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:10:08.854+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:10:08.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:10:08.867+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:10:08.867+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:10:09.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.188 seconds
[2024-07-30T15:10:39.893+0000] {processor.py:157} INFO - Started process (PID=70797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:10:39.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:10:39.899+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:10:39.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:10:39.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:10:39.952+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:10:39.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:10:40.129+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:10:40.129+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:10:40.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.261 seconds
[2024-07-30T15:11:10.667+0000] {processor.py:157} INFO - Started process (PID=70822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:11:10.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:11:10.671+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:11:10.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:11:10.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:11:10.700+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:11:10.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:11:10.788+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:11:10.788+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:11:10.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.133 seconds
[2024-07-30T15:11:41.420+0000] {processor.py:157} INFO - Started process (PID=70847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:11:41.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:11:41.429+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:11:41.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:11:41.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:11:41.476+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:11:41.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:11:41.488+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:11:41.488+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:11:41.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.084 seconds
[2024-07-30T15:12:11.922+0000] {processor.py:157} INFO - Started process (PID=70872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:12:11.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:12:11.927+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:12:11.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:12:11.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:12:11.953+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:12:11.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:12:11.962+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:12:11.962+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:12:11.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-30T15:12:42.410+0000] {processor.py:157} INFO - Started process (PID=70897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:12:42.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:12:42.415+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:12:42.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:12:42.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:12:42.448+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:12:42.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:12:42.457+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:12:42.457+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:12:42.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T15:13:12.840+0000] {processor.py:157} INFO - Started process (PID=70922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:13:12.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:13:12.844+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:13:12.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:13:12.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:13:12.877+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:13:12.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:13:12.891+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:13:12.891+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:13:13.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.225 seconds
[2024-07-30T15:13:43.485+0000] {processor.py:157} INFO - Started process (PID=70947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:13:43.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:13:43.487+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:13:43.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:13:43.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:13:43.512+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:13:43.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:13:43.594+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:13:43.594+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:13:43.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.120 seconds
[2024-07-30T15:14:14.176+0000] {processor.py:157} INFO - Started process (PID=70972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:14:14.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:14:14.181+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:14:14.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:14:14.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:14:14.276+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:14:14.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:14:14.287+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:14:14.287+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:14:14.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-30T15:14:44.842+0000] {processor.py:157} INFO - Started process (PID=70997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:14:44.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:14:44.861+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:14:44.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:14:44.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:14:44.915+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:14:44.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:14:44.929+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:14:44.929+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:14:44.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.109 seconds
[2024-07-30T15:15:15.405+0000] {processor.py:157} INFO - Started process (PID=71022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:15:15.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:15:15.418+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:15:15.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:15:15.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:15:15.493+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:15:15.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:15:15.516+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:15:15.516+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:15:15.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.134 seconds
[2024-07-30T15:15:46.008+0000] {processor.py:157} INFO - Started process (PID=71047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:15:46.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:15:46.036+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:15:46.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:15:46.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:15:46.086+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:15:46.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:15:46.099+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:15:46.099+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:15:46.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.110 seconds
[2024-07-30T15:16:16.517+0000] {processor.py:157} INFO - Started process (PID=71072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:16:16.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:16:16.522+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:16:16.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:16:16.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:16:16.552+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:16:16.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:16:16.708+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:16:16.708+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:16:16.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.204 seconds
[2024-07-30T15:16:47.133+0000] {processor.py:157} INFO - Started process (PID=71097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:16:47.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:16:47.139+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:16:47.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:16:47.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:16:47.182+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:16:47.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:16:47.263+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:16:47.263+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:16:47.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.145 seconds
[2024-07-30T15:17:17.660+0000] {processor.py:157} INFO - Started process (PID=71122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:17:17.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:17:17.663+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:17:17.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:17:17.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:17:17.803+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:17:17.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:17:17.814+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:17:17.813+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:17:17.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.167 seconds
[2024-07-30T15:17:48.371+0000] {processor.py:157} INFO - Started process (PID=71147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:17:48.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:17:48.375+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:17:48.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:17:48.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:17:48.406+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:17:48.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:17:48.416+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:17:48.416+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:17:48.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T15:18:18.746+0000] {processor.py:157} INFO - Started process (PID=71172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:18:18.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:18:18.754+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:18:18.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:18:18.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:18:18.794+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:18:18.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:18:18.807+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:18:18.806+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:18:18.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-30T15:18:49.196+0000] {processor.py:157} INFO - Started process (PID=71197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:18:49.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:18:49.200+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:18:49.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:18:49.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:18:49.228+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:18:49.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:18:49.239+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:18:49.239+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:18:49.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.130 seconds
[2024-07-30T15:19:19.762+0000] {processor.py:157} INFO - Started process (PID=71222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:19:19.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:19:19.767+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:19:19.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:19:19.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:19:19.796+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:19:19.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:19:19.908+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:19:19.908+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:19:19.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.157 seconds
[2024-07-30T15:19:50.360+0000] {processor.py:157} INFO - Started process (PID=71247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:19:50.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:19:50.365+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:19:50.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:19:50.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:19:50.394+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:19:50.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:19:50.472+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:19:50.472+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:19:50.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.124 seconds
[2024-07-30T15:20:20.835+0000] {processor.py:157} INFO - Started process (PID=71272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:20:20.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:20:20.839+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:20:20.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:20:20.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:20:20.943+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:20:20.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:20:20.954+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:20:20.954+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:20:20.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.131 seconds
[2024-07-30T15:20:51.327+0000] {processor.py:157} INFO - Started process (PID=71297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:20:51.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:20:51.330+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:20:51.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:20:51.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:20:51.358+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:20:51.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:20:51.367+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:20:51.367+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:20:51.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-30T15:21:21.802+0000] {processor.py:157} INFO - Started process (PID=71322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:21:21.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:21:21.808+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:21:21.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:21:21.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:21:21.840+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:21:21.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:21:21.851+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:21:21.851+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:21:21.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-30T15:21:52.304+0000] {processor.py:157} INFO - Started process (PID=71347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:21:52.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:21:52.308+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:21:52.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:21:52.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:21:52.346+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:21:52.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:21:52.361+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:21:52.361+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:21:52.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.140 seconds
[2024-07-30T15:22:22.807+0000] {processor.py:157} INFO - Started process (PID=71372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:22:22.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:22:22.809+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:22:22.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:22:22.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:22:22.833+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:22:22.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:22:22.919+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:22:22.919+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:22:22.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.123 seconds
[2024-07-30T15:22:53.355+0000] {processor.py:157} INFO - Started process (PID=71397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:22:53.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:22:53.362+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:22:53.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:22:53.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:22:53.512+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:22:53.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:22:53.521+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:22:53.521+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:22:53.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.179 seconds
[2024-07-30T15:23:23.890+0000] {processor.py:157} INFO - Started process (PID=71422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:23:23.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:23:23.892+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:23:23.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:23:23.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:23:23.918+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:23:23.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:23:23.927+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:23:23.927+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:23:23.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-30T15:23:54.400+0000] {processor.py:157} INFO - Started process (PID=71447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:23:54.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:23:54.408+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:23:54.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:23:54.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:23:54.449+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:23:54.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:23:54.463+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:23:54.463+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:23:54.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-30T15:24:24.868+0000] {processor.py:157} INFO - Started process (PID=71472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:24:24.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:24:24.873+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:24:24.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:24:24.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:24:24.901+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:24:24.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:24:24.915+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:24:24.915+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:24:24.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-30T15:24:55.345+0000] {processor.py:157} INFO - Started process (PID=71497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:24:55.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:24:55.363+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:24:55.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:24:55.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:24:55.444+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:24:55.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:24:55.637+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:24:55.637+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:24:55.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.318 seconds
[2024-07-30T15:25:26.185+0000] {processor.py:157} INFO - Started process (PID=71522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:25:26.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:25:26.192+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:25:26.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:25:26.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:25:26.236+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:25:26.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:25:26.344+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:25:26.344+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:25:26.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.172 seconds
[2024-07-30T15:25:56.876+0000] {processor.py:157} INFO - Started process (PID=71547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:25:56.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:25:56.879+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:25:56.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:25:56.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:25:57.018+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:25:57.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:25:57.027+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:25:57.027+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:25:57.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.161 seconds
[2024-07-30T15:26:27.579+0000] {processor.py:157} INFO - Started process (PID=71572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:26:27.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:26:27.585+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:26:27.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:26:27.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:26:27.627+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:26:27.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:26:27.641+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:26:27.641+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:26:27.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-30T15:26:58.015+0000] {processor.py:157} INFO - Started process (PID=71597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:26:58.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:26:58.019+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:26:58.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:26:58.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:26:58.056+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:26:58.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:26:58.069+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:26:58.069+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:26:58.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-30T15:27:28.556+0000] {processor.py:157} INFO - Started process (PID=71622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:27:28.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:27:28.567+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:27:28.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:27:28.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:27:28.608+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:27:28.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:27:28.619+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:27:28.618+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:27:28.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.287 seconds
[2024-07-30T15:27:59.268+0000] {processor.py:157} INFO - Started process (PID=71647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:27:59.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:27:59.271+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:27:59.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:27:59.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:27:59.303+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:27:59.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:27:59.396+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:27:59.396+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:27:59.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.140 seconds
[2024-07-30T15:28:29.850+0000] {processor.py:157} INFO - Started process (PID=71672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:28:29.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:28:29.858+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:28:29.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:28:29.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:28:29.900+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:28:29.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:28:30.010+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:28:30.010+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:28:30.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.173 seconds
[2024-07-30T15:29:00.415+0000] {processor.py:157} INFO - Started process (PID=71697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:29:00.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:29:00.420+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:29:00.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:29:00.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:29:00.519+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:29:00.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:29:00.526+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:29:00.526+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:29:00.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.123 seconds
[2024-07-30T15:29:31.034+0000] {processor.py:157} INFO - Started process (PID=71722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:29:31.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:29:31.038+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:29:31.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:29:31.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:29:31.067+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:29:31.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:29:31.080+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:29:31.080+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:29:31.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T15:30:01.516+0000] {processor.py:157} INFO - Started process (PID=71747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:30:01.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:30:01.521+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:30:01.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:30:01.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:30:01.568+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:30:01.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:30:01.582+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:30:01.582+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:30:01.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-30T15:30:32.026+0000] {processor.py:157} INFO - Started process (PID=71772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:30:32.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:30:32.030+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:30:32.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:30:32.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:30:32.057+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:30:32.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:30:32.201+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:30:32.201+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:30:32.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.188 seconds
[2024-07-30T15:31:02.769+0000] {processor.py:157} INFO - Started process (PID=71797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:31:02.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:31:02.773+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:31:02.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:31:02.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:31:02.803+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:31:02.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:31:02.887+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:31:02.887+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:31:02.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.132 seconds
[2024-07-30T15:31:33.328+0000] {processor.py:157} INFO - Started process (PID=71822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:31:33.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:31:33.334+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:31:33.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:31:33.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:31:33.445+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:31:33.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:31:33.453+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:31:33.453+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:31:33.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.139 seconds
[2024-07-30T15:32:04.028+0000] {processor.py:157} INFO - Started process (PID=71847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:32:04.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:32:04.040+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:32:04.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:32:04.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:32:04.234+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:32:04.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:32:04.242+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:32:04.242+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:32:04.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.230 seconds
[2024-07-30T15:32:34.754+0000] {processor.py:157} INFO - Started process (PID=71872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:32:34.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:32:34.759+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:32:34.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:32:34.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:32:34.794+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:32:34.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:32:34.806+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:32:34.806+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:32:34.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-30T15:33:05.218+0000] {processor.py:157} INFO - Started process (PID=71897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:33:05.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:33:05.223+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:33:05.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:33:05.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:33:05.278+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:33:05.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:33:05.288+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:33:05.288+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:33:05.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.208 seconds
[2024-07-30T15:33:35.819+0000] {processor.py:157} INFO - Started process (PID=71922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:33:35.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:33:35.825+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:33:35.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:33:35.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:33:35.853+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:33:35.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:33:35.938+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:33:35.938+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:33:35.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.132 seconds
[2024-07-30T15:34:06.354+0000] {processor.py:157} INFO - Started process (PID=71947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:34:06.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:34:06.361+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:34:06.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:34:06.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:34:06.401+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:34:06.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:34:06.579+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:34:06.579+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:34:06.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.241 seconds
[2024-07-30T15:34:37.030+0000] {processor.py:157} INFO - Started process (PID=71972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:34:37.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:34:37.040+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:34:37.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:34:37.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:34:37.236+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:34:37.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:34:37.248+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:34:37.248+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:34:37.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.235 seconds
[2024-07-30T15:35:07.700+0000] {processor.py:157} INFO - Started process (PID=71997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:35:07.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:35:07.706+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:35:07.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:35:07.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:35:07.745+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:35:07.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:35:07.757+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:35:07.757+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:35:07.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-30T15:35:38.199+0000] {processor.py:157} INFO - Started process (PID=72022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:35:38.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:35:38.204+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:35:38.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:35:38.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:35:38.231+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:35:38.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:35:38.244+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:35:38.244+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:35:38.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T15:36:08.680+0000] {processor.py:157} INFO - Started process (PID=72047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:36:08.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:36:08.685+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:36:08.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:36:08.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:36:08.710+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:36:08.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:36:08.723+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:36:08.723+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:36:08.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.201 seconds
[2024-07-30T15:36:39.244+0000] {processor.py:157} INFO - Started process (PID=72072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:36:39.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:36:39.248+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:36:39.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:36:39.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:36:39.285+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:36:39.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:36:39.371+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:36:39.371+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:36:39.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.139 seconds
[2024-07-30T15:37:09.815+0000] {processor.py:157} INFO - Started process (PID=72097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:37:09.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:37:09.817+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:37:09.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:37:09.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:37:09.847+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:37:09.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:37:09.957+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:37:09.956+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:37:09.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.154 seconds
[2024-07-30T15:37:40.466+0000] {processor.py:157} INFO - Started process (PID=72122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:37:40.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:37:40.469+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:37:40.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:37:40.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:37:40.579+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:37:40.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:37:40.590+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:37:40.590+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:37:40.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.136 seconds
[2024-07-30T15:38:11.064+0000] {processor.py:157} INFO - Started process (PID=72147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:38:11.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:38:11.071+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:38:11.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:38:11.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:38:11.129+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:38:11.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:38:11.143+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:38:11.143+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:38:11.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.096 seconds
[2024-07-30T15:38:41.542+0000] {processor.py:157} INFO - Started process (PID=72172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:38:41.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:38:41.545+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:38:41.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:38:41.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:38:41.571+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:38:41.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:38:41.584+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:38:41.584+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:38:41.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T15:39:11.962+0000] {processor.py:157} INFO - Started process (PID=72197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:39:11.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:39:11.967+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:39:11.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:39:11.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:39:11.994+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:39:11.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:39:12.132+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:39:12.132+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:39:12.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.186 seconds
[2024-07-30T15:39:42.522+0000] {processor.py:157} INFO - Started process (PID=72222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:39:42.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:39:42.528+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:39:42.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:39:42.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:39:42.566+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:39:42.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:39:42.653+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:39:42.653+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:39:42.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.144 seconds
[2024-07-30T15:40:13.115+0000] {processor.py:157} INFO - Started process (PID=72247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:40:13.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:40:13.121+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:40:13.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:40:13.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:40:13.218+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:40:13.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:40:13.226+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:40:13.225+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:40:13.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.123 seconds
[2024-07-30T15:40:43.744+0000] {processor.py:157} INFO - Started process (PID=72272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:40:43.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:40:43.748+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:40:43.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:40:43.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:40:43.883+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:40:43.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:40:43.890+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:40:43.890+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:40:43.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.159 seconds
[2024-07-30T15:41:14.361+0000] {processor.py:157} INFO - Started process (PID=72297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:41:14.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:41:14.366+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:41:14.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:41:14.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:41:14.437+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:41:14.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:41:14.457+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:41:14.457+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:41:14.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.112 seconds
[2024-07-30T15:41:44.888+0000] {processor.py:157} INFO - Started process (PID=72322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:41:44.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:41:44.892+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:41:44.891+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:41:44.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:41:44.922+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:41:44.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:41:44.931+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:41:44.931+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:41:45.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.177 seconds
[2024-07-30T15:42:15.570+0000] {processor.py:157} INFO - Started process (PID=72347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:42:15.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:42:15.572+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:42:15.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:42:15.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:42:15.597+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:42:15.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:42:15.678+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:42:15.678+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:42:15.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.116 seconds
[2024-07-30T15:42:46.105+0000] {processor.py:157} INFO - Started process (PID=72372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:42:46.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:42:46.111+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:42:46.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:42:46.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:42:46.149+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:42:46.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:42:46.230+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:42:46.230+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:42:46.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.139 seconds
[2024-07-30T15:43:16.765+0000] {processor.py:157} INFO - Started process (PID=72397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:43:16.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:43:16.770+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:43:16.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:43:16.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:43:16.909+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:43:16.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:43:16.918+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:43:16.917+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:43:16.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.163 seconds
[2024-07-30T15:43:47.466+0000] {processor.py:157} INFO - Started process (PID=72422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:43:47.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:43:47.471+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:43:47.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:43:47.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:43:47.502+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:43:47.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:43:47.512+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:43:47.512+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:43:47.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T15:44:17.853+0000] {processor.py:157} INFO - Started process (PID=72447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:44:17.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:44:17.858+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:44:17.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:44:17.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:44:17.919+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:44:17.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:44:17.934+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:44:17.933+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:44:17.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.099 seconds
[2024-07-30T15:44:48.431+0000] {processor.py:157} INFO - Started process (PID=72472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:44:48.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:44:48.435+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:44:48.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:44:48.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:44:48.465+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:44:48.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:44:48.477+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:44:48.477+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:44:48.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.186 seconds
[2024-07-30T15:45:19.247+0000] {processor.py:157} INFO - Started process (PID=72497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:45:19.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:45:19.261+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:45:19.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:45:19.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:45:19.325+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:45:19.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:45:19.495+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:45:19.495+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:45:19.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.278 seconds
[2024-07-30T15:45:50.109+0000] {processor.py:157} INFO - Started process (PID=72522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:45:50.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:45:50.115+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:45:50.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:45:50.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:45:50.245+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:45:50.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:45:50.257+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:45:50.257+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:45:50.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.164 seconds
[2024-07-30T15:46:20.717+0000] {processor.py:157} INFO - Started process (PID=72547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:46:20.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:46:20.723+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:46:20.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:46:20.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:46:20.949+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:46:20.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:46:20.958+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:46:20.958+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:46:20.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.254 seconds
[2024-07-30T15:46:51.417+0000] {processor.py:157} INFO - Started process (PID=72572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:46:51.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:46:51.421+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:46:51.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:46:51.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:46:51.454+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:46:51.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:46:51.467+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:46:51.467+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:46:51.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-30T15:47:21.992+0000] {processor.py:157} INFO - Started process (PID=72597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:47:21.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:47:21.998+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:47:21.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:47:22.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:47:22.064+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:47:22.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:47:22.077+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:47:22.077+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:47:22.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.106 seconds
[2024-07-30T15:47:52.510+0000] {processor.py:157} INFO - Started process (PID=72622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:47:52.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:47:52.514+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:47:52.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:47:52.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:47:52.549+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:47:52.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:47:52.707+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:47:52.707+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:47:52.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.211 seconds
[2024-07-30T15:48:23.122+0000] {processor.py:157} INFO - Started process (PID=72647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:48:23.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:48:23.131+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:48:23.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:48:23.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:48:23.171+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:48:23.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:48:23.252+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:48:23.252+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:48:23.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.143 seconds
[2024-07-30T15:48:53.662+0000] {processor.py:157} INFO - Started process (PID=72672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:48:53.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:48:53.664+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:48:53.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:48:53.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:48:53.764+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:48:53.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:48:53.771+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:48:53.771+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:48:53.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.119 seconds
[2024-07-30T15:49:24.285+0000] {processor.py:157} INFO - Started process (PID=72697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:49:24.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:49:24.291+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:49:24.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:49:24.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:49:24.423+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:49:24.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:49:24.431+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:49:24.431+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:49:24.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.158 seconds
[2024-07-30T15:49:55.031+0000] {processor.py:157} INFO - Started process (PID=72722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:49:55.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:49:55.034+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:49:55.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:49:55.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:49:55.062+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:49:55.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:49:55.074+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:49:55.074+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:49:55.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T15:50:25.478+0000] {processor.py:157} INFO - Started process (PID=72747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:50:25.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:50:25.485+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:50:25.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:50:25.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:50:25.517+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:50:25.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:50:25.531+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:50:25.531+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:50:25.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-30T15:50:55.848+0000] {processor.py:157} INFO - Started process (PID=72772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:50:55.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:50:55.851+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:50:55.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:50:55.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:50:55.882+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:50:55.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:50:55.895+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:50:55.895+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:50:55.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T15:51:26.331+0000] {processor.py:157} INFO - Started process (PID=72797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:51:26.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:51:26.337+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:51:26.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:51:26.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:51:26.373+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:51:26.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:51:26.385+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:51:26.385+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:51:26.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-30T15:51:56.733+0000] {processor.py:157} INFO - Started process (PID=72822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:51:56.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:51:56.742+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:51:56.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:51:56.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:51:56.777+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:51:56.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:51:56.791+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:51:56.791+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:51:56.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-30T15:52:27.254+0000] {processor.py:157} INFO - Started process (PID=72847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:52:27.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:52:27.259+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:52:27.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:52:27.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:52:27.295+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:52:27.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:52:27.307+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:52:27.307+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:52:27.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-30T15:52:57.741+0000] {processor.py:157} INFO - Started process (PID=72872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:52:57.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:52:57.745+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:52:57.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:52:57.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:52:57.818+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:52:57.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:52:57.843+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:52:57.843+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:52:57.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.123 seconds
[2024-07-30T15:53:28.178+0000] {processor.py:157} INFO - Started process (PID=72897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:53:28.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:53:28.182+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:53:28.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:53:28.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:53:28.210+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:53:28.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:53:28.222+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:53:28.222+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:53:28.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T15:53:58.594+0000] {processor.py:157} INFO - Started process (PID=72922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:53:58.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:53:58.599+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:53:58.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:53:58.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:53:58.639+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:53:58.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:53:58.684+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:53:58.684+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:53:58.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.114 seconds
[2024-07-30T15:54:29.087+0000] {processor.py:157} INFO - Started process (PID=72947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:54:29.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:54:29.093+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:54:29.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:54:29.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:54:29.123+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:54:29.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:54:29.134+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:54:29.134+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:54:29.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T15:54:59.593+0000] {processor.py:157} INFO - Started process (PID=72972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:54:59.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:54:59.600+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:54:59.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:54:59.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:54:59.645+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:54:59.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:54:59.659+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:54:59.659+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:54:59.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-30T15:55:30.049+0000] {processor.py:157} INFO - Started process (PID=72997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:55:30.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:55:30.054+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:55:30.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:55:30.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:55:30.084+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:55:30.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:55:30.096+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:55:30.096+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:55:30.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T15:56:00.464+0000] {processor.py:157} INFO - Started process (PID=73022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:56:00.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:56:00.469+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:56:00.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:56:00.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:56:00.532+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:56:00.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:56:00.546+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:56:00.546+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:56:00.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.099 seconds
[2024-07-30T15:56:30.936+0000] {processor.py:157} INFO - Started process (PID=73047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:56:30.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:56:30.940+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:56:30.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:56:30.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:56:30.967+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:56:30.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:56:30.979+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:56:30.979+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:56:30.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T15:57:01.389+0000] {processor.py:157} INFO - Started process (PID=73072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:57:01.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:57:01.393+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:57:01.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:57:01.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:57:01.419+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:57:01.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:57:01.430+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:57:01.430+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:57:01.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-30T15:57:31.849+0000] {processor.py:157} INFO - Started process (PID=73097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:57:31.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:57:31.854+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:57:31.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:57:31.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:57:31.917+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:57:31.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:57:31.931+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:57:31.931+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:57:31.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.100 seconds
[2024-07-30T15:58:02.338+0000] {processor.py:157} INFO - Started process (PID=73122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:58:02.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:58:02.345+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:58:02.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:58:02.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:58:02.372+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:58:02.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:58:02.383+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:58:02.383+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:58:02.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T15:58:32.816+0000] {processor.py:157} INFO - Started process (PID=73147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:58:32.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:58:32.821+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:58:32.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:58:32.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:58:32.867+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:58:32.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:58:32.882+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:58:32.882+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:58:32.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-30T15:59:03.209+0000] {processor.py:157} INFO - Started process (PID=73172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:59:03.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:59:03.212+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:59:03.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:59:03.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:59:03.240+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:59:03.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:59:03.253+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:59:03.253+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:59:03.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T15:59:33.677+0000] {processor.py:157} INFO - Started process (PID=73197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:59:33.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T15:59:33.682+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:59:33.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:59:33.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T15:59:33.711+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:59:33.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:59:33.723+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:59:33.723+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T15:59:33.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T16:00:04.077+0000] {processor.py:157} INFO - Started process (PID=73222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:00:04.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:00:04.090+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:00:04.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:00:04.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:00:04.135+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:00:04.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:00:04.160+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:00:04.159+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:00:04.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-30T16:00:34.602+0000] {processor.py:157} INFO - Started process (PID=73247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:00:34.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:00:34.606+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:00:34.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:00:34.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:00:34.634+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:00:34.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:00:34.644+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:00:34.644+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:00:34.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T16:01:05.053+0000] {processor.py:157} INFO - Started process (PID=73272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:01:05.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:01:05.059+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:01:05.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:01:05.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:01:05.091+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:01:05.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:01:05.104+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:01:05.104+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:01:05.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-30T16:01:35.507+0000] {processor.py:157} INFO - Started process (PID=73297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:01:35.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:01:35.512+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:01:35.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:01:35.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:01:35.547+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:01:35.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:01:35.561+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:01:35.561+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:01:35.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-30T16:02:05.936+0000] {processor.py:157} INFO - Started process (PID=73322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:02:05.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:02:05.941+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:02:05.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:02:05.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:02:05.968+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:02:05.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:02:05.981+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:02:05.981+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:02:05.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T16:02:36.377+0000] {processor.py:157} INFO - Started process (PID=73347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:02:36.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:02:36.381+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:02:36.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:02:36.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:02:36.408+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:02:36.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:02:36.421+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:02:36.421+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:02:36.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T16:03:06.862+0000] {processor.py:157} INFO - Started process (PID=73372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:03:06.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:03:06.867+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:03:06.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:03:06.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:03:06.934+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:03:06.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:03:06.950+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:03:06.950+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:03:06.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-30T16:03:37.350+0000] {processor.py:157} INFO - Started process (PID=73397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:03:37.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:03:37.355+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:03:37.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:03:37.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:03:37.379+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:03:37.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:03:37.389+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:03:37.389+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:03:37.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-30T16:04:07.863+0000] {processor.py:157} INFO - Started process (PID=73422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:04:07.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:04:07.869+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:04:07.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:04:07.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:04:07.948+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:04:07.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:04:07.973+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:04:07.973+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:04:07.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.128 seconds
[2024-07-30T16:04:38.347+0000] {processor.py:157} INFO - Started process (PID=73447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:04:38.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:04:38.350+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:04:38.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:04:38.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:04:38.378+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:04:38.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:04:38.389+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:04:38.389+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:04:38.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T16:05:08.752+0000] {processor.py:157} INFO - Started process (PID=73472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:05:08.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:05:08.757+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:05:08.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:05:08.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:05:08.829+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:05:08.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:05:08.843+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:05:08.843+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:05:08.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.112 seconds
[2024-07-30T16:05:39.243+0000] {processor.py:157} INFO - Started process (PID=73497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:05:39.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:05:39.246+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:05:39.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:05:39.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:05:39.274+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:05:39.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:05:39.291+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:05:39.291+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:05:39.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-30T16:06:09.693+0000] {processor.py:157} INFO - Started process (PID=73522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:06:09.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:06:09.697+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:06:09.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:06:09.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:06:09.725+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:06:09.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:06:09.735+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:06:09.735+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:06:09.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T16:06:40.158+0000] {processor.py:157} INFO - Started process (PID=73547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:06:40.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:06:40.164+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:06:40.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:06:40.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:06:40.193+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:06:40.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:06:40.203+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:06:40.203+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:06:40.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T16:07:10.575+0000] {processor.py:157} INFO - Started process (PID=73572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:07:10.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:07:10.579+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:07:10.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:07:10.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:07:10.616+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:07:10.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:07:10.629+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:07:10.629+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:07:10.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-30T16:07:41.098+0000] {processor.py:157} INFO - Started process (PID=73597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:07:41.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:07:41.101+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:07:41.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:07:41.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:07:41.127+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:07:41.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:07:41.137+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:07:41.137+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:07:41.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-30T16:08:11.522+0000] {processor.py:157} INFO - Started process (PID=73622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:08:11.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:08:11.527+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:08:11.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:08:11.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:08:11.559+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:08:11.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:08:11.569+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:08:11.569+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:08:11.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-30T16:08:41.927+0000] {processor.py:157} INFO - Started process (PID=73647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:08:41.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:08:41.933+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:08:41.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:08:41.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:08:41.961+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:08:41.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:08:41.971+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:08:41.971+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:08:41.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T16:09:12.356+0000] {processor.py:157} INFO - Started process (PID=73672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:09:12.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:09:12.359+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:09:12.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:09:12.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:09:12.394+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:09:12.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:09:12.407+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:09:12.407+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:09:12.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-30T16:09:42.820+0000] {processor.py:157} INFO - Started process (PID=73697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:09:42.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:09:42.823+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:09:42.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:09:42.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:09:42.855+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:09:42.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:09:42.868+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:09:42.868+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:09:42.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-30T16:10:13.202+0000] {processor.py:157} INFO - Started process (PID=73722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:10:13.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:10:13.206+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:10:13.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:10:13.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:10:13.233+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:10:13.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:10:13.243+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:10:13.243+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:10:13.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T16:10:43.651+0000] {processor.py:157} INFO - Started process (PID=73747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:10:43.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:10:43.657+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:10:43.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:10:43.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:10:43.695+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:10:43.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:10:43.708+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:10:43.707+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:10:43.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-30T16:11:14.084+0000] {processor.py:157} INFO - Started process (PID=73772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:11:14.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:11:14.086+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:11:14.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:11:14.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:11:14.121+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:11:14.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:11:14.135+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:11:14.135+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:11:14.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-30T16:11:44.525+0000] {processor.py:157} INFO - Started process (PID=73797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:11:44.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:11:44.530+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:11:44.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:11:44.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:11:44.554+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:11:44.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:11:44.565+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:11:44.565+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:11:44.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-30T16:12:14.928+0000] {processor.py:157} INFO - Started process (PID=73822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:12:14.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:12:14.934+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:12:14.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:12:14.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:12:14.973+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:12:14.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:12:14.984+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:12:14.984+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:12:14.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-30T16:12:45.374+0000] {processor.py:157} INFO - Started process (PID=73847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:12:45.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:12:45.379+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:12:45.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:12:45.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:12:45.407+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:12:45.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:12:45.421+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:12:45.421+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:12:45.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T16:13:15.783+0000] {processor.py:157} INFO - Started process (PID=73872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:13:15.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:13:15.788+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:13:15.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:13:15.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:13:15.816+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:13:15.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:13:15.827+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:13:15.827+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:13:15.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T16:13:46.270+0000] {processor.py:157} INFO - Started process (PID=73897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:13:46.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:13:46.275+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:13:46.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:13:46.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:13:46.318+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:13:46.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:13:46.332+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:13:46.332+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:13:46.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-30T16:14:16.735+0000] {processor.py:157} INFO - Started process (PID=73922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:14:16.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:14:16.738+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:14:16.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:14:16.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:14:16.766+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:14:16.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:14:16.776+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:14:16.776+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:14:16.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T16:14:47.209+0000] {processor.py:157} INFO - Started process (PID=73947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:14:47.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:14:47.214+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:14:47.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:14:47.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:14:47.252+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:14:47.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:14:47.264+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:14:47.264+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:14:47.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-30T16:15:17.649+0000] {processor.py:157} INFO - Started process (PID=73972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:15:17.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:15:17.653+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:15:17.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:15:17.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:15:17.681+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:15:17.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:15:17.699+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:15:17.699+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:15:17.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-30T16:15:48.129+0000] {processor.py:157} INFO - Started process (PID=73997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:15:48.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:15:48.135+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:15:48.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:15:48.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:15:48.175+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:15:48.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:15:48.188+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:15:48.187+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:15:48.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-30T16:16:18.540+0000] {processor.py:157} INFO - Started process (PID=74022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:16:18.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:16:18.543+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:16:18.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:16:18.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:16:18.574+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:16:18.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:16:18.588+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:16:18.588+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:16:18.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-30T16:16:48.998+0000] {processor.py:157} INFO - Started process (PID=74047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:16:49.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:16:49.004+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:16:49.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:16:49.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:16:49.035+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:16:49.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:16:49.046+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:16:49.046+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:16:49.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T16:17:19.481+0000] {processor.py:157} INFO - Started process (PID=74072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:17:19.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:17:19.487+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:17:19.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:17:19.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:17:19.526+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:17:19.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:17:19.538+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:17:19.537+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:17:19.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-30T16:17:49.880+0000] {processor.py:157} INFO - Started process (PID=74097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:17:49.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:17:49.884+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:17:49.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:17:49.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:17:49.909+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:17:49.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:17:49.918+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:17:49.918+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:17:49.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-30T16:18:20.300+0000] {processor.py:157} INFO - Started process (PID=74122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:18:20.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:18:20.302+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:18:20.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:18:20.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:18:20.334+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:18:20.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:18:20.346+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:18:20.346+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:18:20.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T16:18:50.752+0000] {processor.py:157} INFO - Started process (PID=74147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:18:50.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:18:50.754+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:18:50.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:18:50.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:18:50.782+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:18:50.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:18:50.792+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:18:50.792+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:18:50.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-30T16:19:21.192+0000] {processor.py:157} INFO - Started process (PID=74172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:19:21.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:19:21.195+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:19:21.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:19:21.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:19:21.225+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:19:21.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:19:21.235+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:19:21.235+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:19:21.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T16:19:51.651+0000] {processor.py:157} INFO - Started process (PID=74197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:19:51.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:19:51.655+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:19:51.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:19:51.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:19:51.689+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:19:51.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:19:51.702+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:19:51.702+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:19:51.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-30T16:20:22.038+0000] {processor.py:157} INFO - Started process (PID=74222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:20:22.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:20:22.045+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:20:22.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:20:22.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:20:22.081+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:20:22.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:20:22.091+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:20:22.091+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:20:22.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-30T16:20:52.476+0000] {processor.py:157} INFO - Started process (PID=74247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:20:52.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:20:52.480+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:20:52.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:20:52.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:20:52.509+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:20:52.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:20:52.519+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:20:52.519+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:20:52.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T16:21:22.815+0000] {processor.py:157} INFO - Started process (PID=74272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:21:22.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:21:22.817+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:21:22.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:21:22.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:21:22.839+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:21:22.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:21:22.850+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:21:22.849+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:21:22.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-30T16:21:53.262+0000] {processor.py:157} INFO - Started process (PID=74297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:21:53.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:21:53.267+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:21:53.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:21:53.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:21:53.294+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:21:53.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:21:53.304+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:21:53.304+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:21:53.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-30T16:22:23.734+0000] {processor.py:157} INFO - Started process (PID=74322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:22:23.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:22:23.739+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:22:23.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:22:23.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:22:23.772+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:22:23.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:22:23.785+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:22:23.785+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:22:23.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-30T16:22:54.199+0000] {processor.py:157} INFO - Started process (PID=74347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:22:54.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:22:54.203+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:22:54.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:22:54.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:22:54.255+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:22:54.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:22:54.266+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:22:54.266+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:22:54.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-30T16:23:24.738+0000] {processor.py:157} INFO - Started process (PID=74372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:23:24.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:23:24.742+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:23:24.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:23:24.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:23:24.773+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:23:24.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:23:24.787+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:23:24.787+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:23:24.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-30T16:23:55.184+0000] {processor.py:157} INFO - Started process (PID=74397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:23:55.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:23:55.189+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:23:55.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:23:55.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:23:55.254+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:23:55.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:23:55.269+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:23:55.269+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:23:55.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.100 seconds
[2024-07-30T16:24:25.692+0000] {processor.py:157} INFO - Started process (PID=74422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:24:25.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:24:25.695+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:24:25.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:24:25.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:24:25.727+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:24:25.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:24:25.740+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:24:25.740+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:24:25.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-30T16:24:56.160+0000] {processor.py:157} INFO - Started process (PID=74447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:24:56.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:24:56.165+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:24:56.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:24:56.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:24:56.201+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:24:56.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:24:56.213+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:24:56.213+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:24:56.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-30T16:25:26.624+0000] {processor.py:157} INFO - Started process (PID=74472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:25:26.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:25:26.630+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:25:26.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:25:26.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:25:26.660+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:25:26.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:25:26.674+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:25:26.674+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:25:26.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-30T16:25:57.031+0000] {processor.py:157} INFO - Started process (PID=74497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:25:57.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:25:57.033+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:25:57.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:25:57.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:25:57.058+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:25:57.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:25:57.069+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:25:57.069+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:25:57.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-30T16:26:27.495+0000] {processor.py:157} INFO - Started process (PID=74522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:26:27.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:26:27.499+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:26:27.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:26:27.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:26:27.529+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:26:27.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:26:27.539+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:26:27.539+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:26:27.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T16:26:57.921+0000] {processor.py:157} INFO - Started process (PID=74547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:26:57.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:26:57.926+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:26:57.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:26:57.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:26:57.963+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:26:57.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:26:57.975+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:26:57.975+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:26:57.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-30T16:27:28.351+0000] {processor.py:157} INFO - Started process (PID=74572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:27:28.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:27:28.364+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:27:28.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:27:28.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:27:28.399+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:27:28.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:27:28.413+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:27:28.413+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:27:28.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-30T16:27:58.858+0000] {processor.py:157} INFO - Started process (PID=74597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:27:58.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:27:58.862+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:27:58.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:27:58.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:27:58.889+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:27:58.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:27:58.904+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:27:58.904+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:27:58.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T16:28:29.213+0000] {processor.py:157} INFO - Started process (PID=74622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:28:29.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:28:29.216+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:28:29.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:28:29.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:28:29.240+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:28:29.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:28:29.250+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:28:29.250+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:28:29.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-30T16:28:59.671+0000] {processor.py:157} INFO - Started process (PID=74647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:28:59.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:28:59.674+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:28:59.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:28:59.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:28:59.702+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:28:59.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:28:59.713+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:28:59.713+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:28:59.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T16:29:30.136+0000] {processor.py:157} INFO - Started process (PID=74672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:29:30.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:29:30.140+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:29:30.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:29:30.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:29:30.173+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:29:30.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:29:30.183+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:29:30.183+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:29:30.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-30T16:30:00.569+0000] {processor.py:157} INFO - Started process (PID=74697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:30:00.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:30:00.572+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:30:00.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:30:00.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:30:00.599+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:30:00.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:30:00.609+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:30:00.608+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:30:00.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-30T16:30:31.041+0000] {processor.py:157} INFO - Started process (PID=74722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:30:31.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:30:31.045+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:30:31.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:30:31.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:30:31.075+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:30:31.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:30:31.089+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:30:31.089+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:30:31.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-30T16:31:01.528+0000] {processor.py:157} INFO - Started process (PID=74747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:31:01.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:31:01.532+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:31:01.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:31:01.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:31:01.558+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:31:01.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:31:01.571+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:31:01.571+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:31:01.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T16:31:31.987+0000] {processor.py:157} INFO - Started process (PID=74772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:31:31.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:31:31.991+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:31:31.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:31:32.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:31:32.020+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:31:32.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:31:32.032+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:31:32.032+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:31:32.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T16:32:02.482+0000] {processor.py:157} INFO - Started process (PID=74797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:32:02.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:32:02.487+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:32:02.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:32:02.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:32:02.513+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:32:02.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:32:02.525+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:32:02.525+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:32:02.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T16:32:32.973+0000] {processor.py:157} INFO - Started process (PID=74822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:32:32.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:32:32.978+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:32:32.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:32:32.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:32:33.012+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:32:33.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:32:33.024+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:32:33.024+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:32:33.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-30T16:33:03.393+0000] {processor.py:157} INFO - Started process (PID=74847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:33:03.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:33:03.397+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:33:03.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:33:03.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:33:03.426+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:33:03.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:33:03.437+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:33:03.437+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:33:03.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T16:33:33.844+0000] {processor.py:157} INFO - Started process (PID=74872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:33:33.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:33:33.849+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:33:33.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:33:33.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:33:33.880+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:33:33.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:33:33.894+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:33:33.894+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:33:33.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-30T16:34:04.343+0000] {processor.py:157} INFO - Started process (PID=74897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:34:04.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:34:04.350+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:34:04.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:34:04.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:34:04.432+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:34:04.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:34:04.450+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:34:04.450+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:34:04.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.126 seconds
[2024-07-30T16:34:34.861+0000] {processor.py:157} INFO - Started process (PID=74922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:34:34.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:34:34.867+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:34:34.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:34:34.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:34:34.902+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:34:34.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:34:34.913+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:34:34.912+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:34:34.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-30T16:35:05.330+0000] {processor.py:157} INFO - Started process (PID=74947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:35:05.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:35:05.336+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:35:05.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:35:05.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:35:05.397+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:35:05.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:35:05.416+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:35:05.416+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:35:05.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-30T16:35:35.835+0000] {processor.py:157} INFO - Started process (PID=74972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:35:35.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:35:35.839+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:35:35.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:35:35.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:35:35.872+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:35:35.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:35:35.883+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:35:35.883+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:35:35.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-30T16:36:06.312+0000] {processor.py:157} INFO - Started process (PID=74997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:36:06.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:36:06.333+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:36:06.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:36:06.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:36:06.379+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:36:06.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:36:06.409+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:36:06.409+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:36:06.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.114 seconds
[2024-07-30T16:36:36.853+0000] {processor.py:157} INFO - Started process (PID=75022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:36:36.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:36:36.857+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:36:36.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:36:36.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:36:36.889+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:36:36.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:36:36.902+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:36:36.902+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:36:36.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-30T16:37:07.354+0000] {processor.py:157} INFO - Started process (PID=75047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:37:07.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:37:07.359+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:37:07.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:37:07.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:37:07.409+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:37:07.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:37:07.445+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:37:07.445+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:37:07.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.124 seconds
[2024-07-30T16:37:37.874+0000] {processor.py:157} INFO - Started process (PID=75072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:37:37.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:37:37.876+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:37:37.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:37:37.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:37:37.909+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:37:37.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:37:37.920+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:37:37.920+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:37:37.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-30T16:38:08.347+0000] {processor.py:157} INFO - Started process (PID=75097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:38:08.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:38:08.352+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:38:08.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:38:08.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:38:08.419+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:38:08.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:38:08.434+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:38:08.434+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:38:08.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.103 seconds
[2024-07-30T16:38:38.858+0000] {processor.py:157} INFO - Started process (PID=75122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:38:38.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:38:38.862+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:38:38.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:38:38.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:38:38.896+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:38:38.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:38:38.908+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:38:38.908+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:38:38.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-30T16:39:09.291+0000] {processor.py:157} INFO - Started process (PID=75147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:39:09.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:39:09.295+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:39:09.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:39:09.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:39:09.354+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:39:09.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:39:09.369+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:39:09.369+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:39:09.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.092 seconds
[2024-07-30T16:39:39.807+0000] {processor.py:157} INFO - Started process (PID=75172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:39:39.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:39:39.810+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:39:39.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:39:39.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:39:39.845+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:39:39.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:39:39.859+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:39:39.859+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:39:39.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-30T16:40:10.250+0000] {processor.py:157} INFO - Started process (PID=75197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:40:10.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:40:10.254+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:40:10.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:40:10.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:40:10.316+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:40:10.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:40:10.330+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:40:10.330+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:40:10.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.097 seconds
[2024-07-30T16:40:40.682+0000] {processor.py:157} INFO - Started process (PID=75222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:40:40.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:40:40.688+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:40:40.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:40:40.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:40:40.731+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:40:40.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:40:40.746+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:40:40.745+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:40:40.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-30T16:41:11.226+0000] {processor.py:157} INFO - Started process (PID=75247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:41:11.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:41:11.234+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:41:11.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:41:11.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:41:11.277+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:41:11.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:41:11.290+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:41:11.290+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:41:11.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-30T16:41:41.716+0000] {processor.py:157} INFO - Started process (PID=75272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:41:41.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:41:41.724+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:41:41.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:41:41.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:41:41.781+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:41:41.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:41:41.808+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:41:41.808+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:41:41.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.115 seconds
[2024-07-30T16:42:12.220+0000] {processor.py:157} INFO - Started process (PID=75297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:42:12.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:42:12.224+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:42:12.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:42:12.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:42:12.252+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:42:12.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:42:12.266+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:42:12.266+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:42:12.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T16:42:42.601+0000] {processor.py:157} INFO - Started process (PID=75322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:42:42.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:42:42.605+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:42:42.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:42:42.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:42:42.640+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:42:42.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:42:42.653+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:42:42.653+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:42:42.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-30T16:43:13.061+0000] {processor.py:157} INFO - Started process (PID=75347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:43:13.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:43:13.064+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:43:13.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:43:13.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:43:13.090+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:43:13.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:43:13.100+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:43:13.100+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:43:13.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-30T16:43:43.520+0000] {processor.py:157} INFO - Started process (PID=75372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:43:43.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:43:43.525+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:43:43.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:43:43.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:43:43.551+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:43:43.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:43:43.561+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:43:43.561+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:43:43.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-30T16:44:13.897+0000] {processor.py:157} INFO - Started process (PID=75397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:44:13.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:44:13.901+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:44:13.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:44:13.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:44:13.929+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:44:13.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:44:13.940+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:44:13.939+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:44:13.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T16:44:44.344+0000] {processor.py:157} INFO - Started process (PID=75422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:44:44.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:44:44.350+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:44:44.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:44:44.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:44:44.391+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:44:44.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:44:44.404+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:44:44.404+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:44:44.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-30T16:45:14.816+0000] {processor.py:157} INFO - Started process (PID=75447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:45:14.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:45:14.823+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:45:14.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:45:14.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:45:14.860+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:45:14.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:45:14.872+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:45:14.872+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:45:14.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-30T16:45:45.348+0000] {processor.py:157} INFO - Started process (PID=75472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:45:45.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:45:45.353+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:45:45.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:45:45.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:45:45.389+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:45:45.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:45:45.401+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:45:45.401+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:45:45.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-30T16:46:15.788+0000] {processor.py:157} INFO - Started process (PID=75497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:46:15.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:46:15.796+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:46:15.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:46:15.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:46:15.839+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:46:15.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:46:15.854+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:46:15.854+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:46:15.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.084 seconds
[2024-07-30T16:46:46.261+0000] {processor.py:157} INFO - Started process (PID=75522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:46:46.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:46:46.265+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:46:46.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:46:46.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:46:46.294+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:46:46.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:46:46.303+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:46:46.303+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:46:46.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T16:47:16.752+0000] {processor.py:157} INFO - Started process (PID=75547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:47:16.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:47:16.757+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:47:16.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:47:16.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:47:16.791+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:47:16.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:47:16.802+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:47:16.802+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:47:16.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-30T16:47:47.195+0000] {processor.py:157} INFO - Started process (PID=75572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:47:47.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:47:47.203+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:47:47.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:47:47.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:47:47.236+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:47:47.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:47:47.248+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:47:47.248+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:47:47.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-30T16:48:17.640+0000] {processor.py:157} INFO - Started process (PID=75597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:48:17.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:48:17.644+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:48:17.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:48:17.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:48:17.678+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:48:17.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:48:17.692+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:48:17.692+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:48:17.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-30T16:48:48.135+0000] {processor.py:157} INFO - Started process (PID=75622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:48:48.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:48:48.140+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:48:48.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:48:48.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:48:48.173+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:48:48.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:48:48.186+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:48:48.185+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:48:48.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-30T16:49:18.657+0000] {processor.py:157} INFO - Started process (PID=75647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:49:18.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:49:18.665+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:49:18.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:49:18.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:49:18.701+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:49:18.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:49:18.716+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:49:18.716+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:49:18.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-30T16:49:49.103+0000] {processor.py:157} INFO - Started process (PID=75672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:49:49.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:49:49.108+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:49:49.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:49:49.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:49:49.150+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:49:49.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:49:49.169+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:49:49.169+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:49:49.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-30T16:50:19.623+0000] {processor.py:157} INFO - Started process (PID=75697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:50:19.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:50:19.634+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:50:19.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:50:19.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:50:19.697+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:50:19.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:50:19.710+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:50:19.710+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:50:19.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-30T16:50:50.092+0000] {processor.py:157} INFO - Started process (PID=75722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:50:50.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:50:50.098+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:50:50.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:50:50.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:50:50.137+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:50:50.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:50:50.153+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:50:50.153+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:50:50.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-30T16:51:20.538+0000] {processor.py:157} INFO - Started process (PID=75747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:51:20.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:51:20.546+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:51:20.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:51:20.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:51:20.591+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:51:20.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:51:20.604+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:51:20.604+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:51:20.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-30T16:51:50.989+0000] {processor.py:157} INFO - Started process (PID=75772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:51:50.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:51:50.992+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:51:50.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:51:51.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:51:51.014+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:51:51.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:51:51.024+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:51:51.024+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:51:51.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-30T16:52:21.434+0000] {processor.py:157} INFO - Started process (PID=75797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:52:21.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:52:21.442+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:52:21.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:52:21.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:52:21.506+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:52:21.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:52:21.523+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:52:21.523+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:52:21.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.110 seconds
[2024-07-30T16:52:52.003+0000] {processor.py:157} INFO - Started process (PID=75822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:52:52.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:52:52.011+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:52:52.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:52:52.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:52:52.050+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:52:52.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:52:52.063+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:52:52.063+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:52:52.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-30T16:53:22.460+0000] {processor.py:157} INFO - Started process (PID=75847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:53:22.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:53:22.465+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:53:22.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:53:22.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:53:22.500+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:53:22.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:53:22.510+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:53:22.510+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:53:22.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-30T16:53:52.927+0000] {processor.py:157} INFO - Started process (PID=75872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:53:52.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:53:52.932+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:53:52.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:53:52.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:53:52.972+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:53:52.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:53:52.986+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:53:52.986+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:53:52.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-30T16:54:23.409+0000] {processor.py:157} INFO - Started process (PID=75897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:54:23.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:54:23.413+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:54:23.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:54:23.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:54:23.442+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:54:23.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:54:23.453+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:54:23.452+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:54:23.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T16:54:53.850+0000] {processor.py:157} INFO - Started process (PID=75922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:54:53.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:54:53.856+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:54:53.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:54:53.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:54:53.896+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:54:53.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:54:53.911+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:54:53.911+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:54:53.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-30T16:55:24.359+0000] {processor.py:157} INFO - Started process (PID=75947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:55:24.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:55:24.364+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:55:24.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:55:24.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:55:24.407+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:55:24.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:55:24.423+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:55:24.423+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:55:24.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-30T16:55:54.797+0000] {processor.py:157} INFO - Started process (PID=75972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:55:54.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:55:54.801+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:55:54.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:55:54.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:55:54.830+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:55:54.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:55:54.847+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:55:54.847+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:55:54.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-30T16:56:25.198+0000] {processor.py:157} INFO - Started process (PID=75997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:56:25.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:56:25.205+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:56:25.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:56:25.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:56:25.245+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:56:25.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:56:25.258+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:56:25.258+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:56:25.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-30T16:56:55.630+0000] {processor.py:157} INFO - Started process (PID=76022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:56:55.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:56:55.635+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:56:55.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:56:55.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:56:55.678+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:56:55.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:56:55.693+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:56:55.693+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:56:55.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-30T16:57:26.130+0000] {processor.py:157} INFO - Started process (PID=76047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:57:26.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:57:26.138+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:57:26.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:57:26.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:57:26.178+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:57:26.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:57:26.188+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:57:26.188+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:57:26.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-30T16:57:56.661+0000] {processor.py:157} INFO - Started process (PID=76072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:57:56.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:57:56.665+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:57:56.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:57:56.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:57:56.695+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:57:56.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:57:56.708+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:57:56.708+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:57:56.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-30T16:58:27.434+0000] {processor.py:157} INFO - Started process (PID=76097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:58:27.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:58:27.440+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:58:27.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:58:27.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:58:27.485+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:58:27.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:58:27.503+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:58:27.502+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:58:27.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.089 seconds
[2024-07-30T16:59:18.227+0000] {processor.py:157} INFO - Started process (PID=76122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:59:18.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T16:59:18.231+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:59:18.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:59:18.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T16:59:18.261+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:59:18.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:59:18.272+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:59:18.272+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T16:59:18.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T17:15:02.449+0000] {processor.py:157} INFO - Started process (PID=76150) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:15:02.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T17:15:02.454+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:15:02.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:15:02.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:15:02.516+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:15:02.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:15:02.535+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:15:02.535+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T17:15:02.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.120 seconds
[2024-07-30T17:15:33.107+0000] {processor.py:157} INFO - Started process (PID=76175) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:15:33.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T17:15:33.115+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:15:33.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:15:33.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:15:33.158+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:15:33.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:15:33.171+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:15:33.171+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T17:15:33.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-30T17:16:03.525+0000] {processor.py:157} INFO - Started process (PID=76200) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:16:03.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T17:16:03.527+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:16:03.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:16:03.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:16:03.547+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:16:03.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:16:03.558+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:16:03.558+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T17:16:03.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.043 seconds
[2024-07-30T17:16:34.020+0000] {processor.py:157} INFO - Started process (PID=76225) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:16:34.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T17:16:34.026+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:16:34.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:16:34.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:16:34.053+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:16:34.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:16:34.063+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:16:34.063+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T17:16:34.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T17:17:04.894+0000] {processor.py:157} INFO - Started process (PID=76250) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:17:04.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T17:17:04.902+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:17:04.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:17:04.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:17:04.938+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:17:04.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:17:04.952+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:17:04.952+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T17:17:04.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-30T17:17:35.369+0000] {processor.py:157} INFO - Started process (PID=76275) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:17:35.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T17:17:35.373+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:17:35.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:17:35.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:17:35.401+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:17:35.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:17:35.411+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:17:35.411+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T17:17:35.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T17:18:08.197+0000] {processor.py:157} INFO - Started process (PID=76300) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:18:08.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T17:18:08.202+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:18:08.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:18:08.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:18:08.229+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:18:08.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:18:08.239+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:18:08.239+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T17:18:08.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T17:18:38.668+0000] {processor.py:157} INFO - Started process (PID=76325) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:18:38.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T17:18:38.676+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:18:38.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:18:38.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:18:38.721+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:18:38.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:18:38.734+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:18:38.734+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T17:18:38.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.085 seconds
[2024-07-30T17:19:09.153+0000] {processor.py:157} INFO - Started process (PID=76350) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:19:09.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T17:19:09.159+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:19:09.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:19:09.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:19:09.191+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:19:09.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:19:09.203+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:19:09.203+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T17:19:09.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-30T17:19:39.544+0000] {processor.py:157} INFO - Started process (PID=76375) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:19:39.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T17:19:39.546+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:19:39.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:19:39.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:19:39.569+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:19:39.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:19:39.578+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:19:39.578+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T17:19:39.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-30T17:35:22.588+0000] {processor.py:157} INFO - Started process (PID=76400) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:35:22.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T17:35:22.597+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:35:22.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:35:22.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:35:22.662+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:35:22.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:35:22.689+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:35:22.689+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T17:35:22.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-30T17:35:53.182+0000] {processor.py:157} INFO - Started process (PID=76425) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:35:53.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T17:35:53.189+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:35:53.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:35:53.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:35:53.254+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:35:53.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:35:53.270+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:35:53.270+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T17:35:53.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-30T17:51:31.646+0000] {processor.py:157} INFO - Started process (PID=76452) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:51:31.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T17:51:31.655+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:51:31.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:51:31.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:51:31.701+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:51:31.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:51:31.725+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:51:31.725+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T17:51:31.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.099 seconds
[2024-07-30T17:52:02.122+0000] {processor.py:157} INFO - Started process (PID=76477) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:52:02.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T17:52:02.127+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:52:02.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:52:02.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:52:02.159+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:52:02.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:52:02.170+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:52:02.170+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T17:52:02.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-30T17:52:32.565+0000] {processor.py:157} INFO - Started process (PID=76502) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:52:32.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T17:52:32.571+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:52:32.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:52:32.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:52:32.606+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:52:32.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:52:32.622+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:52:32.622+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T17:52:32.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-30T17:53:03.021+0000] {processor.py:157} INFO - Started process (PID=76527) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:53:03.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T17:53:03.024+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:53:03.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:53:03.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:53:03.057+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:53:03.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:53:03.068+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:53:03.068+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T17:53:03.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T17:53:36.820+0000] {processor.py:157} INFO - Started process (PID=76552) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:53:36.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T17:53:36.823+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:53:36.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:53:36.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:53:36.854+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:53:36.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:53:36.868+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:53:36.868+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T17:53:36.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T17:54:07.331+0000] {processor.py:157} INFO - Started process (PID=76577) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:54:07.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T17:54:07.336+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:54:07.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:54:07.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:54:07.373+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:54:07.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:54:07.387+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:54:07.387+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T17:54:07.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-30T17:54:37.726+0000] {processor.py:157} INFO - Started process (PID=76602) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:54:37.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T17:54:37.730+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:54:37.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:54:37.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:54:37.765+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:54:37.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:54:37.776+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:54:37.776+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T17:54:37.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-30T17:55:08.204+0000] {processor.py:157} INFO - Started process (PID=76627) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:55:08.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T17:55:08.207+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:55:08.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:55:08.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:55:08.234+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:55:08.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:55:08.244+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:55:08.244+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T17:55:08.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T17:55:38.642+0000] {processor.py:157} INFO - Started process (PID=76652) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:55:38.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T17:55:38.646+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:55:38.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:55:38.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:55:38.672+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:55:38.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:55:38.682+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:55:38.682+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T17:55:38.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-30T17:56:11.340+0000] {processor.py:157} INFO - Started process (PID=76677) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:56:11.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T17:56:11.345+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:56:11.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:56:11.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:56:11.376+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:56:11.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:56:11.388+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:56:11.388+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T17:56:11.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T17:56:41.779+0000] {processor.py:157} INFO - Started process (PID=76702) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:56:41.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T17:56:41.785+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:56:41.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:56:41.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:56:41.821+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:56:41.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:56:41.834+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:56:41.834+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T17:56:41.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-30T17:57:12.295+0000] {processor.py:157} INFO - Started process (PID=76727) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:57:12.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T17:57:12.299+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:57:12.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:57:12.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:57:12.329+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:57:12.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:57:12.341+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:57:12.341+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T17:57:12.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T17:57:42.800+0000] {processor.py:157} INFO - Started process (PID=76752) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:57:42.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T17:57:42.804+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:57:42.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:57:42.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:57:42.837+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:57:42.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:57:42.849+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:57:42.849+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T17:57:42.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-30T17:58:13.270+0000] {processor.py:157} INFO - Started process (PID=76777) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:58:13.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T17:58:13.274+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:58:13.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:58:13.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:58:13.308+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:58:13.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:58:13.322+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:58:13.322+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T17:58:13.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-30T17:58:43.675+0000] {processor.py:157} INFO - Started process (PID=76802) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:58:43.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T17:58:43.681+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:58:43.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:58:43.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:58:43.716+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:58:43.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:58:43.728+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:58:43.728+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T17:58:43.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-30T17:59:14.128+0000] {processor.py:157} INFO - Started process (PID=76827) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:59:14.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T17:59:14.130+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:59:14.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:59:14.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:59:14.158+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:59:14.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:59:14.171+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:59:14.171+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T17:59:14.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T17:59:44.582+0000] {processor.py:157} INFO - Started process (PID=76852) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:59:44.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T17:59:44.586+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:59:44.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:59:44.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T17:59:44.615+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:59:44.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:59:44.625+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:59:44.625+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T17:59:44.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T18:00:14.999+0000] {processor.py:157} INFO - Started process (PID=76877) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:00:15.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T18:00:15.002+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:00:15.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:00:15.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:00:15.035+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:00:15.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:00:15.046+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:00:15.046+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T18:00:15.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T18:00:45.430+0000] {processor.py:157} INFO - Started process (PID=76902) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:00:45.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T18:00:45.435+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:00:45.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:00:45.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:00:45.475+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:00:45.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:00:45.492+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:00:45.491+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T18:00:45.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.083 seconds
[2024-07-30T18:17:24.881+0000] {processor.py:157} INFO - Started process (PID=76927) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:17:24.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T18:17:24.888+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:17:24.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:17:24.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:17:24.960+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:17:24.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:17:24.981+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:17:24.981+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T18:17:25.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.123 seconds
[2024-07-30T18:17:55.446+0000] {processor.py:157} INFO - Started process (PID=76954) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:17:55.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T18:17:55.451+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:17:55.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:17:55.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:17:55.496+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:17:55.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:17:55.509+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:17:55.509+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T18:17:55.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-30T18:18:25.902+0000] {processor.py:157} INFO - Started process (PID=76979) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:18:25.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T18:18:25.904+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:18:25.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:18:25.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:18:25.934+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:18:25.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:18:25.944+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:18:25.944+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T18:18:25.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T18:18:56.287+0000] {processor.py:157} INFO - Started process (PID=77004) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:18:56.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T18:18:56.290+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:18:56.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:18:56.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:18:56.320+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:18:56.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:18:56.330+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:18:56.330+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T18:18:56.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T18:19:26.892+0000] {processor.py:157} INFO - Started process (PID=77029) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:19:26.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T18:19:26.999+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:19:26.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:19:27.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:19:27.043+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:19:27.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:19:27.057+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:19:27.057+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T18:19:27.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.184 seconds
[2024-07-30T18:35:43.556+0000] {processor.py:157} INFO - Started process (PID=77054) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:35:43.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T18:35:43.565+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:35:43.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:35:43.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:35:43.621+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:35:43.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:35:43.638+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:35:43.638+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T18:35:43.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.103 seconds
[2024-07-30T18:53:43.701+0000] {processor.py:157} INFO - Started process (PID=77081) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:53:43.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T18:53:43.708+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:53:43.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:53:43.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:53:43.793+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:53:43.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:53:43.814+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:53:43.814+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T18:53:43.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.138 seconds
[2024-07-30T18:54:14.347+0000] {processor.py:157} INFO - Started process (PID=77106) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:54:14.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T18:54:14.353+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:54:14.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:54:14.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:54:14.403+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:54:14.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:54:14.432+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:54:14.432+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T18:54:14.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.110 seconds
[2024-07-30T18:54:44.810+0000] {processor.py:157} INFO - Started process (PID=77131) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:54:44.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T18:54:44.814+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:54:44.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:54:44.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:54:44.842+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:54:44.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:54:44.852+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:54:44.852+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T18:54:44.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T18:55:15.313+0000] {processor.py:157} INFO - Started process (PID=77156) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:55:15.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T18:55:15.319+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:55:15.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:55:15.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:55:15.376+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:55:15.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:55:15.397+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:55:15.397+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T18:55:15.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.110 seconds
[2024-07-30T18:55:45.870+0000] {processor.py:157} INFO - Started process (PID=77181) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:55:45.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T18:55:45.875+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:55:45.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:55:45.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:55:45.921+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:55:45.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:55:45.936+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:55:45.936+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T18:55:45.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-30T18:56:16.334+0000] {processor.py:157} INFO - Started process (PID=77206) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:56:16.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T18:56:16.338+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:56:16.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:56:16.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:56:16.366+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:56:16.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:56:16.376+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:56:16.376+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T18:56:16.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T18:56:46.807+0000] {processor.py:157} INFO - Started process (PID=77231) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:56:46.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T18:56:46.814+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:56:46.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:56:46.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:56:46.851+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:56:46.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:56:46.864+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:56:46.864+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T18:56:46.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-30T18:57:17.296+0000] {processor.py:157} INFO - Started process (PID=77256) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:57:17.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T18:57:17.300+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:57:17.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:57:17.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:57:17.330+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:57:17.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:57:17.343+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:57:17.343+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T18:57:17.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T18:57:47.779+0000] {processor.py:157} INFO - Started process (PID=77281) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:57:47.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T18:57:47.784+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:57:47.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:57:47.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:57:47.815+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:57:47.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:57:47.828+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:57:47.828+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T18:57:47.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-30T18:58:18.140+0000] {processor.py:157} INFO - Started process (PID=77306) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:58:18.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T18:58:18.144+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:58:18.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:58:18.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:58:18.171+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:58:18.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:58:18.180+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:58:18.180+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T18:58:18.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T18:58:48.617+0000] {processor.py:157} INFO - Started process (PID=77331) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:58:48.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T18:58:48.620+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:58:48.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:58:48.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:58:48.653+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:58:48.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:58:48.662+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:58:48.662+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T18:58:48.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T18:59:19.092+0000] {processor.py:157} INFO - Started process (PID=77356) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:59:19.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T18:59:19.095+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:59:19.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:59:19.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:59:19.118+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:59:19.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:59:19.128+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:59:19.128+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T18:59:19.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-30T18:59:49.490+0000] {processor.py:157} INFO - Started process (PID=77381) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:59:49.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T18:59:49.493+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:59:49.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:59:49.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T18:59:49.521+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:59:49.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:59:49.532+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:59:49.532+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T18:59:49.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T19:00:19.976+0000] {processor.py:157} INFO - Started process (PID=77406) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:00:19.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:00:19.982+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:00:19.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:00:19.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:00:20.023+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:00:20.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:00:20.035+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:00:20.035+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:00:20.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-30T19:00:50.450+0000] {processor.py:157} INFO - Started process (PID=77431) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:00:50.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:00:50.453+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:00:50.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:00:50.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:00:50.482+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:00:50.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:00:50.492+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:00:50.492+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:00:50.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-30T19:01:20.907+0000] {processor.py:157} INFO - Started process (PID=77456) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:01:20.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:01:20.911+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:01:20.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:01:20.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:01:20.943+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:01:20.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:01:20.952+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:01:20.952+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:01:20.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T19:01:51.314+0000] {processor.py:157} INFO - Started process (PID=77481) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:01:51.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:01:51.316+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:01:51.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:01:51.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:01:51.343+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:01:51.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:01:51.353+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:01:51.353+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:01:51.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-30T19:02:21.789+0000] {processor.py:157} INFO - Started process (PID=77506) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:02:21.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:02:21.792+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:02:21.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:02:21.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:02:21.821+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:02:21.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:02:21.832+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:02:21.832+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:02:21.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T19:02:52.246+0000] {processor.py:157} INFO - Started process (PID=77531) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:02:52.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:02:52.248+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:02:52.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:02:52.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:02:52.270+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:02:52.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:02:52.277+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:02:52.277+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:02:52.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.043 seconds
[2024-07-30T19:03:22.721+0000] {processor.py:157} INFO - Started process (PID=77556) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:03:22.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:03:22.725+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:03:22.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:03:22.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:03:22.752+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:03:22.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:03:22.763+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:03:22.763+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:03:22.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T19:03:53.201+0000] {processor.py:157} INFO - Started process (PID=77581) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:03:53.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:03:53.208+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:03:53.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:03:53.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:03:53.248+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:03:53.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:03:53.261+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:03:53.261+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:03:53.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-30T19:04:23.727+0000] {processor.py:157} INFO - Started process (PID=77606) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:04:23.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:04:23.730+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:04:23.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:04:23.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:04:23.758+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:04:23.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:04:23.768+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:04:23.768+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:04:23.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-30T19:04:54.240+0000] {processor.py:157} INFO - Started process (PID=77631) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:04:54.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:04:54.243+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:04:54.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:04:54.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:04:54.272+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:04:54.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:04:54.282+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:04:54.282+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:04:54.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T19:05:24.657+0000] {processor.py:157} INFO - Started process (PID=77656) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:05:24.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:05:24.661+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:05:24.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:05:24.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:05:24.689+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:05:24.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:05:24.702+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:05:24.702+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:05:24.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-30T19:05:55.103+0000] {processor.py:157} INFO - Started process (PID=77681) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:05:55.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:05:55.108+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:05:55.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:05:55.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:05:55.138+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:05:55.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:05:55.148+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:05:55.148+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:05:55.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T19:06:25.574+0000] {processor.py:157} INFO - Started process (PID=77706) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:06:25.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:06:25.579+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:06:25.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:06:25.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:06:25.619+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:06:25.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:06:25.635+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:06:25.635+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:06:25.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-30T19:06:56.050+0000] {processor.py:157} INFO - Started process (PID=77731) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:06:56.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:06:56.052+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:06:56.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:06:56.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:06:56.080+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:06:56.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:06:56.090+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:06:56.090+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:06:56.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-30T19:07:26.469+0000] {processor.py:157} INFO - Started process (PID=77756) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:07:26.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:07:26.473+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:07:26.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:07:26.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:07:26.505+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:07:26.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:07:26.516+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:07:26.516+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:07:26.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-30T19:07:56.892+0000] {processor.py:157} INFO - Started process (PID=77781) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:07:56.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:07:56.896+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:07:56.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:07:56.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:07:56.922+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:07:56.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:07:56.932+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:07:56.931+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:07:56.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T19:08:27.340+0000] {processor.py:157} INFO - Started process (PID=77806) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:08:27.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:08:27.345+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:08:27.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:08:27.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:08:27.374+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:08:27.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:08:27.386+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:08:27.386+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:08:27.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T19:08:57.862+0000] {processor.py:157} INFO - Started process (PID=77831) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:08:57.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:08:57.868+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:08:57.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:08:57.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:08:57.907+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:08:57.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:08:57.920+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:08:57.920+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:08:57.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-30T19:09:28.432+0000] {processor.py:157} INFO - Started process (PID=77856) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:09:28.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:09:28.436+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:09:28.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:09:28.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:09:28.463+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:09:28.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:09:28.473+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:09:28.473+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:09:28.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-30T19:09:58.937+0000] {processor.py:157} INFO - Started process (PID=77881) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:09:58.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:09:58.941+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:09:58.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:09:58.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:09:58.973+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:09:58.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:09:58.983+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:09:58.983+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:09:58.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T19:10:29.385+0000] {processor.py:157} INFO - Started process (PID=77906) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:10:29.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:10:29.390+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:10:29.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:10:29.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:10:29.416+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:10:29.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:10:29.426+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:10:29.426+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:10:29.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T19:10:59.881+0000] {processor.py:157} INFO - Started process (PID=77931) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:10:59.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:10:59.886+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:10:59.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:10:59.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:10:59.953+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:10:59.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:10:59.965+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:10:59.965+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:10:59.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.100 seconds
[2024-07-30T19:11:30.423+0000] {processor.py:157} INFO - Started process (PID=77956) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:11:30.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:11:30.427+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:11:30.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:11:30.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:11:30.455+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:11:30.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:11:30.465+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:11:30.465+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:11:30.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T19:12:00.884+0000] {processor.py:157} INFO - Started process (PID=77981) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:12:00.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:12:00.888+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:12:00.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:12:00.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:12:00.918+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:12:00.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:12:00.930+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:12:00.930+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:12:00.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T19:12:31.339+0000] {processor.py:157} INFO - Started process (PID=78006) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:12:31.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:12:31.344+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:12:31.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:12:31.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:12:31.372+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:12:31.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:12:31.385+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:12:31.385+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:12:31.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-30T19:13:01.820+0000] {processor.py:157} INFO - Started process (PID=78031) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:13:01.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:13:01.824+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:13:01.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:13:01.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:13:01.860+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:13:01.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:13:01.873+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:13:01.872+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:13:01.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-30T19:13:32.296+0000] {processor.py:157} INFO - Started process (PID=78056) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:13:32.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:13:32.299+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:13:32.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:13:32.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:13:32.327+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:13:32.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:13:32.339+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:13:32.339+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:13:32.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T19:14:02.798+0000] {processor.py:157} INFO - Started process (PID=78081) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:14:02.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:14:02.802+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:14:02.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:14:02.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:14:02.831+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:14:02.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:14:02.842+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:14:02.842+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:14:02.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T19:14:33.221+0000] {processor.py:157} INFO - Started process (PID=78106) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:14:33.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:14:33.224+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:14:33.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:14:33.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:14:33.255+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:14:33.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:14:33.269+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:14:33.269+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:14:33.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T19:15:03.676+0000] {processor.py:157} INFO - Started process (PID=78131) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:15:03.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:15:03.681+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:15:03.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:15:03.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:15:03.712+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:15:03.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:15:03.723+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:15:03.723+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:15:03.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-30T19:15:34.104+0000] {processor.py:157} INFO - Started process (PID=78156) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:15:34.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:15:34.110+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:15:34.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:15:34.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:15:34.138+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:15:34.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:15:34.148+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:15:34.148+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:15:34.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T19:16:04.593+0000] {processor.py:157} INFO - Started process (PID=78181) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:16:04.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:16:04.597+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:16:04.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:16:04.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:16:04.636+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:16:04.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:16:04.649+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:16:04.649+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:16:04.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-30T19:16:35.006+0000] {processor.py:157} INFO - Started process (PID=78206) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:16:35.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:16:35.009+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:16:35.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:16:35.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:16:35.032+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:16:35.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:16:35.041+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:16:35.041+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:16:35.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-30T19:17:05.487+0000] {processor.py:157} INFO - Started process (PID=78231) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:17:05.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:17:05.491+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:17:05.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:17:05.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:17:05.520+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:17:05.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:17:05.530+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:17:05.530+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:17:05.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T19:17:35.956+0000] {processor.py:157} INFO - Started process (PID=78256) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:17:35.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:17:35.959+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:17:35.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:17:35.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:17:35.986+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:17:35.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:17:35.997+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:17:35.997+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:17:36.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T19:18:06.360+0000] {processor.py:157} INFO - Started process (PID=78281) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:18:06.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:18:06.364+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:18:06.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:18:06.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:18:06.390+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:18:06.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:18:06.400+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:18:06.400+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:18:06.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-30T19:18:36.829+0000] {processor.py:157} INFO - Started process (PID=78306) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:18:36.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:18:36.833+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:18:36.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:18:36.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:18:36.862+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:18:36.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:18:36.870+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:18:36.870+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:18:36.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-30T19:19:07.206+0000] {processor.py:157} INFO - Started process (PID=78331) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:19:07.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:19:07.210+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:19:07.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:19:07.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:19:07.240+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:19:07.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:19:07.251+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:19:07.251+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:19:07.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T19:19:37.674+0000] {processor.py:157} INFO - Started process (PID=78356) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:19:37.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:19:37.679+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:19:37.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:19:37.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:19:37.708+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:19:37.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:19:37.717+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:19:37.717+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:19:37.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T19:20:08.079+0000] {processor.py:157} INFO - Started process (PID=78381) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:20:08.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:20:08.081+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:20:08.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:20:08.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:20:08.108+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:20:08.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:20:08.119+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:20:08.119+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:20:08.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-30T19:20:38.528+0000] {processor.py:157} INFO - Started process (PID=78406) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:20:38.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:20:38.533+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:20:38.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:20:38.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:20:38.561+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:20:38.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:20:38.571+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:20:38.571+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:20:38.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T19:21:09.061+0000] {processor.py:157} INFO - Started process (PID=78431) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:21:09.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:21:09.066+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:21:09.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:21:09.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:21:09.098+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:21:09.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:21:09.109+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:21:09.109+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:21:09.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-30T19:21:39.454+0000] {processor.py:157} INFO - Started process (PID=78456) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:21:39.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:21:39.460+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:21:39.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:21:39.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:21:39.490+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:21:39.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:21:39.501+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:21:39.501+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:21:39.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T19:22:09.943+0000] {processor.py:157} INFO - Started process (PID=78481) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:22:09.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:22:09.946+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:22:09.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:22:09.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:22:09.977+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:22:09.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:22:09.987+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:22:09.987+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:22:09.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T19:22:40.399+0000] {processor.py:157} INFO - Started process (PID=78506) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:22:40.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:22:40.404+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:22:40.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:22:40.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:22:40.442+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:22:40.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:22:40.455+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:22:40.455+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:22:40.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-30T19:23:10.858+0000] {processor.py:157} INFO - Started process (PID=78531) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:23:10.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:23:10.862+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:23:10.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:23:10.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:23:10.892+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:23:10.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:23:10.902+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:23:10.902+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:23:10.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-30T19:23:41.326+0000] {processor.py:157} INFO - Started process (PID=78556) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:23:41.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:23:41.328+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:23:41.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:23:41.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:23:41.347+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:23:41.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:23:41.355+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:23:41.355+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:23:41.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.040 seconds
[2024-07-30T19:24:11.771+0000] {processor.py:157} INFO - Started process (PID=78581) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:24:11.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:24:11.776+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:24:11.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:24:11.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:24:11.807+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:24:11.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:24:11.816+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:24:11.815+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:24:11.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T19:24:42.234+0000] {processor.py:157} INFO - Started process (PID=78606) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:24:42.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:24:42.239+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:24:42.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:24:42.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:24:42.265+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:24:42.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:24:42.276+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:24:42.276+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:24:42.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-30T19:25:12.634+0000] {processor.py:157} INFO - Started process (PID=78631) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:25:12.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:25:12.640+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:25:12.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:25:12.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:25:12.676+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:25:12.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:25:12.687+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:25:12.687+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:25:12.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-30T19:25:43.187+0000] {processor.py:157} INFO - Started process (PID=78656) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:25:43.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:25:43.192+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:25:43.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:25:43.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:25:43.224+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:25:43.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:25:43.238+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:25:43.238+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:25:43.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-30T19:26:13.607+0000] {processor.py:157} INFO - Started process (PID=78681) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:26:13.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:26:13.614+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:26:13.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:26:13.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:26:13.646+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:26:13.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:26:13.657+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:26:13.657+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:26:13.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T19:26:44.084+0000] {processor.py:157} INFO - Started process (PID=78706) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:26:44.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:26:44.087+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:26:44.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:26:44.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:26:44.116+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:26:44.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:26:44.126+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:26:44.126+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:26:44.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T19:27:14.483+0000] {processor.py:157} INFO - Started process (PID=78731) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:27:14.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:27:14.485+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:27:14.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:27:14.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:27:14.508+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:27:14.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:27:14.518+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:27:14.518+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:27:14.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-30T19:27:44.931+0000] {processor.py:157} INFO - Started process (PID=78756) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:27:44.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:27:44.935+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:27:44.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:27:44.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:27:44.961+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:27:44.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:27:44.971+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:27:44.971+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:27:44.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T19:28:15.418+0000] {processor.py:157} INFO - Started process (PID=78781) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:28:15.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:28:15.422+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:28:15.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:28:15.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:28:15.453+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:28:15.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:28:15.465+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:28:15.465+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:28:15.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T19:28:45.829+0000] {processor.py:157} INFO - Started process (PID=78806) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:28:45.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:28:45.834+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:28:45.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:28:45.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:28:45.862+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:28:45.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:28:45.873+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:28:45.872+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:28:45.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T19:29:16.327+0000] {processor.py:157} INFO - Started process (PID=78831) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:29:16.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:29:16.331+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:29:16.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:29:16.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:29:16.362+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:29:16.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:29:16.375+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:29:16.375+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:29:16.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-30T19:29:46.700+0000] {processor.py:157} INFO - Started process (PID=78856) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:29:46.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:29:46.703+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:29:46.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:29:46.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:29:46.737+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:29:46.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:29:46.749+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:29:46.749+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:29:46.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-30T19:30:17.195+0000] {processor.py:157} INFO - Started process (PID=78881) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:30:17.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:30:17.199+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:30:17.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:30:17.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:30:17.229+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:30:17.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:30:17.240+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:30:17.240+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:30:17.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T19:30:47.633+0000] {processor.py:157} INFO - Started process (PID=78906) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:30:47.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:30:47.636+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:30:47.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:30:47.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:30:47.660+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:30:47.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:30:47.669+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:30:47.669+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:30:47.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-30T19:47:19.341+0000] {processor.py:157} INFO - Started process (PID=78933) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:47:19.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:47:19.357+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:47:19.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:47:19.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:47:19.452+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:47:19.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:47:19.489+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:47:19.489+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:47:19.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.174 seconds
[2024-07-30T19:47:50.121+0000] {processor.py:157} INFO - Started process (PID=78958) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:47:50.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T19:47:50.126+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:47:50.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:47:50.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T19:47:50.194+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:47:50.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:47:50.209+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:47:50.209+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T19:47:50.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.103 seconds
[2024-07-30T20:03:37.650+0000] {processor.py:157} INFO - Started process (PID=78983) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:03:37.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T20:03:37.654+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:03:37.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:03:37.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:03:37.690+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:03:37.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:03:37.727+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:03:37.727+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T20:03:37.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.099 seconds
[2024-07-30T20:04:08.345+0000] {processor.py:157} INFO - Started process (PID=79008) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:04:08.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T20:04:08.349+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:04:08.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:04:08.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:04:08.387+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:04:08.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:04:08.398+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:04:08.398+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T20:04:08.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-30T20:04:38.770+0000] {processor.py:157} INFO - Started process (PID=79033) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:04:38.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T20:04:38.776+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:04:38.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:04:38.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:04:38.801+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:04:38.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:04:38.816+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:04:38.816+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T20:04:38.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T20:05:09.287+0000] {processor.py:157} INFO - Started process (PID=79058) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:05:09.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T20:05:09.291+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:05:09.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:05:09.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:05:09.321+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:05:09.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:05:09.331+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:05:09.331+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T20:05:09.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T20:05:39.814+0000] {processor.py:157} INFO - Started process (PID=79083) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:05:39.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T20:05:39.817+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:05:39.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:05:39.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:05:39.847+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:05:39.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:05:39.860+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:05:39.860+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T20:05:39.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T20:23:29.202+0000] {processor.py:157} INFO - Started process (PID=79110) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:23:29.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T20:23:29.222+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:23:29.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:23:29.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:23:29.307+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:23:29.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:23:29.331+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:23:29.331+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T20:23:29.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.147 seconds
[2024-07-30T20:23:59.956+0000] {processor.py:157} INFO - Started process (PID=79135) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:23:59.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T20:23:59.962+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:23:59.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:23:59.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:24:00.002+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:24:00.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:24:00.017+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:24:00.016+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T20:24:00.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-30T20:24:30.400+0000] {processor.py:157} INFO - Started process (PID=79160) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:24:30.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T20:24:30.405+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:24:30.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:24:30.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:24:30.438+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:24:30.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:24:30.450+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:24:30.450+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T20:24:30.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-30T20:25:00.921+0000] {processor.py:157} INFO - Started process (PID=79185) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:25:00.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T20:25:00.925+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:25:00.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:25:00.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:25:00.953+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:25:00.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:25:00.963+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:25:00.963+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T20:25:00.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T20:25:31.363+0000] {processor.py:157} INFO - Started process (PID=79210) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:25:31.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T20:25:31.368+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:25:31.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:25:31.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:25:31.400+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:25:31.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:25:31.410+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:25:31.410+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T20:25:31.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-30T20:26:01.768+0000] {processor.py:157} INFO - Started process (PID=79235) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:26:01.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T20:26:01.774+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:26:01.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:26:01.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:26:01.807+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:26:01.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:26:01.821+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:26:01.820+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T20:26:01.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-30T20:26:32.191+0000] {processor.py:157} INFO - Started process (PID=79260) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:26:32.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T20:26:32.196+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:26:32.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:26:32.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:26:32.226+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:26:32.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:26:32.237+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:26:32.236+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T20:26:32.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-30T20:27:02.649+0000] {processor.py:157} INFO - Started process (PID=79285) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:27:02.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T20:27:02.656+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:27:02.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:27:02.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:27:02.689+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:27:02.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:27:02.700+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:27:02.700+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T20:27:02.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-30T20:27:33.102+0000] {processor.py:157} INFO - Started process (PID=79310) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:27:33.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T20:27:33.107+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:27:33.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:27:33.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:27:33.139+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:27:33.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:27:33.151+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:27:33.151+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T20:27:33.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-30T20:43:04.267+0000] {processor.py:157} INFO - Started process (PID=79337) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:43:04.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T20:43:04.272+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:43:04.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:43:04.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:43:04.337+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:43:04.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:43:04.359+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:43:04.359+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T20:43:04.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.118 seconds
[2024-07-30T20:43:34.781+0000] {processor.py:157} INFO - Started process (PID=79362) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:43:34.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T20:43:34.786+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:43:34.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:43:34.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:43:34.827+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:43:34.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:43:34.840+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:43:34.840+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T20:43:34.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-30T20:44:05.333+0000] {processor.py:157} INFO - Started process (PID=79387) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:44:05.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T20:44:05.336+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:44:05.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:44:05.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:44:05.368+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:44:05.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:44:05.378+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:44:05.378+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T20:44:05.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T20:44:35.854+0000] {processor.py:157} INFO - Started process (PID=79412) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:44:35.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T20:44:35.859+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:44:35.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:44:35.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:44:35.897+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:44:35.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:44:35.909+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:44:35.909+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T20:44:35.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-30T20:45:06.373+0000] {processor.py:157} INFO - Started process (PID=79437) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:45:06.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T20:45:06.377+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:45:06.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:45:06.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T20:45:06.403+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:45:06.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:45:06.414+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:45:06.414+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T20:45:06.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-30T21:01:41.292+0000] {processor.py:157} INFO - Started process (PID=79462) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:01:41.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T21:01:41.301+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:01:41.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:01:41.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:01:41.387+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:01:41.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:01:41.409+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:01:41.409+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T21:01:41.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.149 seconds
[2024-07-30T21:02:12.054+0000] {processor.py:157} INFO - Started process (PID=79489) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:02:12.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T21:02:12.062+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:02:12.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:02:12.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:02:12.120+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:02:12.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:02:12.134+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:02:12.134+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T21:02:12.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.097 seconds
[2024-07-30T21:02:42.541+0000] {processor.py:157} INFO - Started process (PID=79514) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:02:42.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T21:02:42.545+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:02:42.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:02:42.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:02:42.573+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:02:42.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:02:42.586+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:02:42.586+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T21:02:42.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-30T21:03:13.001+0000] {processor.py:157} INFO - Started process (PID=79539) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:03:13.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T21:03:13.004+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:03:13.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:03:13.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:03:13.030+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:03:13.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:03:13.040+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:03:13.040+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T21:03:13.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-30T21:03:43.466+0000] {processor.py:157} INFO - Started process (PID=79564) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:03:43.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T21:03:43.471+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:03:43.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:03:43.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:03:43.511+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:03:43.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:03:43.524+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:03:43.524+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T21:03:43.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-30T21:04:13.950+0000] {processor.py:157} INFO - Started process (PID=79589) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:04:13.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T21:04:13.955+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:04:13.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:04:13.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:04:13.987+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:04:13.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:04:13.998+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:04:13.998+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T21:04:14.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T21:19:58.467+0000] {processor.py:157} INFO - Started process (PID=79614) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:19:58.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T21:19:58.476+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:19:58.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:19:58.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:19:58.518+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:19:58.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:19:58.530+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:19:58.530+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T21:19:58.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-30T21:35:59.056+0000] {processor.py:157} INFO - Started process (PID=79641) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:35:59.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T21:35:59.067+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:35:59.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:35:59.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:35:59.139+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:35:59.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:35:59.188+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:35:59.188+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T21:35:59.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.169 seconds
[2024-07-30T21:36:29.837+0000] {processor.py:157} INFO - Started process (PID=79666) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:36:29.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T21:36:29.853+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:36:29.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:36:29.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:36:29.920+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:36:29.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:36:29.934+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:36:29.934+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T21:36:29.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.123 seconds
[2024-07-30T21:37:00.327+0000] {processor.py:157} INFO - Started process (PID=79691) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:37:00.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T21:37:00.336+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:37:00.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:37:00.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:37:00.388+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:37:00.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:37:00.420+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:37:00.419+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T21:37:00.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.109 seconds
[2024-07-30T21:37:30.867+0000] {processor.py:157} INFO - Started process (PID=79716) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:37:30.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T21:37:30.871+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:37:30.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:37:30.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:37:30.907+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:37:30.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:37:30.917+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:37:30.917+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T21:37:30.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-30T21:38:01.353+0000] {processor.py:157} INFO - Started process (PID=79741) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:38:01.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T21:38:01.358+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:38:01.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:38:01.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:38:01.386+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:38:01.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:38:01.396+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:38:01.396+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T21:38:01.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T21:38:31.810+0000] {processor.py:157} INFO - Started process (PID=79766) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:38:31.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T21:38:31.815+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:38:31.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:38:31.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:38:31.851+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:38:31.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:38:31.865+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:38:31.865+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T21:38:31.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-30T21:39:02.193+0000] {processor.py:157} INFO - Started process (PID=79791) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:39:02.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T21:39:02.198+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:39:02.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:39:02.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:39:02.227+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:39:02.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:39:02.238+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:39:02.238+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T21:39:02.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T21:39:32.569+0000] {processor.py:157} INFO - Started process (PID=79816) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:39:32.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T21:39:32.574+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:39:32.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:39:32.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:39:32.605+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:39:32.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:39:32.616+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:39:32.616+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T21:39:32.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-30T21:40:03.057+0000] {processor.py:157} INFO - Started process (PID=79841) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:40:03.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T21:40:03.063+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:40:03.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:40:03.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:40:03.101+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:40:03.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:40:03.114+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:40:03.114+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T21:40:03.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-30T21:56:03.000+0000] {processor.py:157} INFO - Started process (PID=79868) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:56:03.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T21:56:03.008+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:56:03.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:56:03.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:56:03.092+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:56:03.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:56:03.117+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:56:03.116+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T21:56:03.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.149 seconds
[2024-07-30T21:56:33.893+0000] {processor.py:157} INFO - Started process (PID=79893) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:56:33.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T21:56:33.905+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:56:33.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:56:33.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:56:33.965+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:56:33.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:56:33.978+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:56:33.978+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T21:56:33.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.110 seconds
[2024-07-30T21:57:04.413+0000] {processor.py:157} INFO - Started process (PID=79918) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:57:04.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T21:57:04.417+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:57:04.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:57:04.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T21:57:04.447+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:57:04.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:57:04.457+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:57:04.457+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T21:57:04.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-30T22:12:52.167+0000] {processor.py:157} INFO - Started process (PID=79943) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:12:52.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T22:12:52.173+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:12:52.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:12:52.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:12:52.254+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:12:52.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T22:12:52.284+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:12:52.284+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T22:12:52.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.142 seconds
[2024-07-30T22:13:22.796+0000] {processor.py:157} INFO - Started process (PID=79968) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:13:22.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T22:13:22.801+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:13:22.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:13:22.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:13:22.866+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:13:22.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T22:13:22.879+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:13:22.879+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T22:13:22.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-30T22:13:53.298+0000] {processor.py:157} INFO - Started process (PID=79993) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:13:53.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T22:13:53.303+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:13:53.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:13:53.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:13:53.333+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:13:53.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T22:13:53.346+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:13:53.346+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T22:13:53.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-30T22:14:23.802+0000] {processor.py:157} INFO - Started process (PID=80018) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:14:23.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T22:14:23.809+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:14:23.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:14:23.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:14:23.848+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:14:23.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T22:14:23.862+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:14:23.862+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T22:14:23.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-30T22:14:54.241+0000] {processor.py:157} INFO - Started process (PID=80043) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:14:54.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T22:14:54.244+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:14:54.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:14:54.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:14:54.265+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:14:54.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T22:14:54.273+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:14:54.273+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T22:14:54.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-30T22:31:10.266+0000] {processor.py:157} INFO - Started process (PID=80068) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:31:10.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T22:31:10.274+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:31:10.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:31:10.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:31:10.327+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:31:10.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T22:31:10.360+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:31:10.360+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T22:31:10.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.123 seconds
[2024-07-30T22:31:40.892+0000] {processor.py:157} INFO - Started process (PID=80093) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:31:40.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T22:31:40.899+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:31:40.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:31:40.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:31:40.955+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:31:40.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T22:31:40.969+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:31:40.969+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T22:31:40.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.094 seconds
[2024-07-30T22:47:29.381+0000] {processor.py:157} INFO - Started process (PID=80118) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:47:29.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T22:47:29.401+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:47:29.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:47:29.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:47:29.516+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:47:29.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T22:47:29.555+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:47:29.555+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T22:47:29.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.226 seconds
[2024-07-30T22:48:00.217+0000] {processor.py:157} INFO - Started process (PID=80143) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:48:00.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T22:48:00.223+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:48:00.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:48:00.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:48:00.294+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:48:00.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T22:48:00.311+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:48:00.311+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T22:48:00.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.118 seconds
[2024-07-30T22:48:30.715+0000] {processor.py:157} INFO - Started process (PID=80168) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:48:30.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T22:48:30.717+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:48:30.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:48:30.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:48:30.740+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:48:30.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T22:48:30.752+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:48:30.752+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T22:48:30.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-30T22:49:01.199+0000] {processor.py:157} INFO - Started process (PID=80193) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:49:01.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T22:49:01.207+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:49:01.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:49:01.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:49:01.245+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:49:01.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T22:49:01.257+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:49:01.257+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T22:49:01.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-30T22:49:31.622+0000] {processor.py:157} INFO - Started process (PID=80218) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:49:31.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T22:49:31.627+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:49:31.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:49:31.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:49:31.654+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:49:31.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T22:49:31.666+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:49:31.666+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T22:49:31.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T22:50:02.015+0000] {processor.py:157} INFO - Started process (PID=80243) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:50:02.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T22:50:02.021+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:50:02.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:50:02.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:50:02.046+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:50:02.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T22:50:02.058+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:50:02.058+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T22:50:02.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T22:50:32.477+0000] {processor.py:157} INFO - Started process (PID=80268) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:50:32.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T22:50:32.481+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:50:32.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:50:32.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:50:32.509+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:50:32.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T22:50:32.520+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:50:32.520+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T22:50:32.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T22:51:02.892+0000] {processor.py:157} INFO - Started process (PID=80293) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:51:02.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T22:51:02.896+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:51:02.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:51:02.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T22:51:02.926+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:51:02.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T22:51:02.936+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:51:02.936+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T22:51:02.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-30T23:09:00.589+0000] {processor.py:157} INFO - Started process (PID=80320) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:09:00.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T23:09:00.594+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:09:00.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:09:00.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:09:00.644+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:09:00.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T23:09:00.673+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:09:00.673+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T23:09:00.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.112 seconds
[2024-07-30T23:09:31.124+0000] {processor.py:157} INFO - Started process (PID=80345) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:09:31.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T23:09:31.144+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:09:31.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:09:31.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:09:31.196+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:09:31.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T23:09:31.209+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:09:31.209+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T23:09:31.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.101 seconds
[2024-07-30T23:10:01.734+0000] {processor.py:157} INFO - Started process (PID=80370) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:10:01.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T23:10:01.739+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:10:01.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:10:01.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:10:01.766+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:10:01.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T23:10:01.782+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:10:01.782+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T23:10:01.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-30T23:10:32.174+0000] {processor.py:157} INFO - Started process (PID=80395) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:10:32.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T23:10:32.176+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:10:32.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:10:32.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:10:32.201+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:10:32.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T23:10:32.212+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:10:32.212+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T23:10:32.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-30T23:11:02.655+0000] {processor.py:157} INFO - Started process (PID=80420) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:11:02.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T23:11:02.662+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:11:02.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:11:02.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:11:02.701+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:11:02.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T23:11:02.715+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:11:02.715+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T23:11:02.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-30T23:27:44.233+0000] {processor.py:157} INFO - Started process (PID=80445) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:27:44.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T23:27:44.241+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:27:44.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:27:44.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:27:44.297+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:27:44.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T23:27:44.329+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:27:44.328+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T23:27:44.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.121 seconds
[2024-07-30T23:28:14.959+0000] {processor.py:157} INFO - Started process (PID=80470) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:28:14.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T23:28:14.964+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:28:14.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:28:14.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:28:15.012+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:28:15.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T23:28:15.026+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:28:15.026+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T23:28:15.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.083 seconds
[2024-07-30T23:28:45.499+0000] {processor.py:157} INFO - Started process (PID=80495) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:28:45.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T23:28:45.504+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:28:45.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:28:45.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:28:45.531+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:28:45.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T23:28:45.541+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:28:45.541+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T23:28:45.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-30T23:29:15.894+0000] {processor.py:157} INFO - Started process (PID=80520) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:29:15.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T23:29:15.898+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:29:15.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:29:15.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:29:15.926+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:29:15.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T23:29:15.937+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:29:15.937+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T23:29:15.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-30T23:44:46.080+0000] {processor.py:157} INFO - Started process (PID=80545) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:44:46.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T23:44:46.090+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:44:46.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:44:46.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:44:46.176+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:44:46.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T23:44:46.200+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:44:46.200+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T23:44:46.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.141 seconds
[2024-07-30T23:45:16.718+0000] {processor.py:157} INFO - Started process (PID=80570) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:45:16.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-30T23:45:16.723+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:45:16.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:45:16.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-30T23:45:16.768+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:45:16.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T23:45:16.781+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:45:16.781+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-30T00:30:00+00:00, run_after=2024-07-31T00:30:00+00:00
[2024-07-30T23:45:16.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
