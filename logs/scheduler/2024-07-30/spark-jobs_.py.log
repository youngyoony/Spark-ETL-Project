[2024-07-30T00:05:59.360+0000] {processor.py:157} INFO - Started process (PID=51062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:05:59.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T00:05:59.367+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:05:59.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:05:59.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:05:59.418+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:05:59.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T00:05:59.434+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:05:59.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-30T00:05:59.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-30T00:06:30.121+0000] {processor.py:157} INFO - Started process (PID=51089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:06:30.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T00:06:30.127+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:06:30.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:06:30.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:06:30.208+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:06:30.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T00:06:30.225+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:06:30.225+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-30T00:06:30.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-30T00:07:00.629+0000] {processor.py:157} INFO - Started process (PID=51114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:07:00.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T00:07:00.632+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:07:00.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:07:00.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:07:00.662+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:07:00.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T00:07:00.672+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:07:00.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-30T00:07:00.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T00:07:31.121+0000] {processor.py:157} INFO - Started process (PID=51139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:07:31.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T00:07:31.125+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:07:31.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:07:31.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:07:31.152+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:07:31.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T00:07:31.162+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:07:31.162+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-30T00:07:31.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T00:23:37.483+0000] {processor.py:157} INFO - Started process (PID=51165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:23:37.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T00:23:37.499+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:23:37.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:23:37.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:23:37.591+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:23:37.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T00:23:37.621+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:23:37.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-30T00:23:37.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-07-30T00:24:08.249+0000] {processor.py:157} INFO - Started process (PID=51191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:24:08.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T00:24:08.252+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:24:08.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:24:08.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:24:08.292+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:24:08.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T00:24:08.304+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:24:08.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-30T00:24:08.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-30T00:24:38.693+0000] {processor.py:157} INFO - Started process (PID=51216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:24:38.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T00:24:38.695+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:24:38.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:24:38.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:24:38.734+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:24:38.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T00:24:38.745+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:24:38.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-30T00:24:38.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-30T00:25:09.104+0000] {processor.py:157} INFO - Started process (PID=51241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:25:09.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T00:25:09.108+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:25:09.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:25:09.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:25:09.141+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:25:09.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T00:25:09.153+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:25:09.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-30T00:25:09.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-30T00:25:39.606+0000] {processor.py:157} INFO - Started process (PID=51266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:25:39.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T00:25:39.610+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:25:39.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:25:39.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:25:39.651+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:25:39.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T00:25:39.663+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:25:39.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-30T00:25:39.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-30T00:42:51.602+0000] {processor.py:157} INFO - Started process (PID=51291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:42:51.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T00:42:51.607+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:42:51.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:42:51.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:42:51.678+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:42:51.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T00:42:51.742+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:42:51.741+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-30T00:42:51.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-07-30T00:43:22.245+0000] {processor.py:157} INFO - Started process (PID=51718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:43:22.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T00:43:22.256+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:43:22.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:43:22.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:43:22.297+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:43:22.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T00:43:22.309+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:43:22.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-30T00:43:22.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-30T00:43:52.774+0000] {processor.py:157} INFO - Started process (PID=51743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:43:52.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T00:43:52.789+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:43:52.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:43:52.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:43:52.844+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:43:52.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T00:43:52.857+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:43:52.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-30T00:43:52.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-30T00:44:23.212+0000] {processor.py:157} INFO - Started process (PID=51768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:44:23.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T00:44:23.216+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:44:23.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:44:23.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:44:23.247+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:44:23.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T00:44:23.259+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:44:23.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-30T00:44:23.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-30T00:44:53.680+0000] {processor.py:157} INFO - Started process (PID=51793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:44:53.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T00:44:53.685+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:44:53.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:44:53.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T00:44:53.754+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:44:53.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T00:44:53.768+0000] {logging_mixin.py:151} INFO - [2024-07-30T00:44:53.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-30T00:44:53.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-30T01:02:35.296+0000] {processor.py:157} INFO - Started process (PID=51823) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:02:35.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T01:02:35.313+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:02:35.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:02:35.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:02:35.386+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:02:35.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:02:35.398+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:02:35.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T01:02:35.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-30T01:03:05.916+0000] {processor.py:157} INFO - Started process (PID=52238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:03:05.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T01:03:05.936+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:03:05.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:03:05.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:03:05.981+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:03:05.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:03:06.001+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:03:06.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T01:03:06.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-30T01:03:36.392+0000] {processor.py:157} INFO - Started process (PID=52264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:03:36.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T01:03:36.395+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:03:36.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:03:36.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:03:36.422+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:03:36.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:03:36.434+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:03:36.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T01:03:36.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T01:04:06.809+0000] {processor.py:157} INFO - Started process (PID=52289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:04:06.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T01:04:06.814+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:04:06.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:04:06.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:04:06.844+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:04:06.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:04:06.857+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:04:06.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T01:04:06.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-30T01:04:37.292+0000] {processor.py:157} INFO - Started process (PID=52314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:04:37.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T01:04:37.298+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:04:37.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:04:37.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:04:37.332+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:04:37.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:04:37.343+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:04:37.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T01:04:37.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-30T01:06:35.288+0000] {processor.py:157} INFO - Started process (PID=52340) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:06:35.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T01:06:35.294+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:06:35.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:06:35.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:06:35.339+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:06:35.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:06:35.354+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:06:35.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T01:06:35.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-30T01:07:05.810+0000] {processor.py:157} INFO - Started process (PID=52366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:07:05.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T01:07:05.815+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:07:05.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:07:05.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:07:05.854+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:07:05.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:07:05.867+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:07:05.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T01:07:05.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-30T01:07:36.247+0000] {processor.py:157} INFO - Started process (PID=52391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:07:36.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T01:07:36.249+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:07:36.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:07:36.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:07:36.279+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:07:36.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:07:36.290+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:07:36.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T01:07:36.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T01:08:06.680+0000] {processor.py:157} INFO - Started process (PID=52416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:08:06.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T01:08:06.683+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:08:06.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:08:06.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:08:06.714+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:08:06.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:08:06.726+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:08:06.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T01:08:06.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T01:08:37.117+0000] {processor.py:157} INFO - Started process (PID=52441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:08:37.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T01:08:37.122+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:08:37.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:08:37.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:08:37.161+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:08:37.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:08:37.172+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:08:37.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T01:08:37.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-30T01:25:57.726+0000] {processor.py:157} INFO - Started process (PID=52468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:25:57.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T01:25:57.729+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:25:57.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:25:57.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:25:57.783+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:25:57.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:25:57.803+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:25:57.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T01:25:57.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-30T01:26:28.236+0000] {processor.py:157} INFO - Started process (PID=52492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:26:28.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T01:26:28.248+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:26:28.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:26:28.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:26:28.294+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:26:28.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:26:28.312+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:26:28.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T01:26:28.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-30T01:26:58.753+0000] {processor.py:157} INFO - Started process (PID=52518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:26:58.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T01:26:58.756+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:26:58.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:26:58.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:26:58.786+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:26:58.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:26:58.799+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:26:58.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T01:26:58.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T01:27:29.214+0000] {processor.py:157} INFO - Started process (PID=52543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:27:29.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T01:27:29.219+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:27:29.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:27:29.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:27:29.248+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:27:29.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:27:29.258+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:27:29.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T01:27:29.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T01:27:59.612+0000] {processor.py:157} INFO - Started process (PID=52568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:27:59.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T01:27:59.615+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:27:59.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:27:59.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:27:59.643+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:27:59.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:27:59.655+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:27:59.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T01:27:59.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T01:43:46.874+0000] {processor.py:157} INFO - Started process (PID=52593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:43:46.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T01:43:46.879+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:43:46.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:43:46.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:43:46.947+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:43:46.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:43:46.967+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:43:46.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T01:43:46.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-30T01:44:17.668+0000] {processor.py:157} INFO - Started process (PID=52620) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:44:17.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T01:44:17.673+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:44:17.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:44:17.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:44:17.730+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:44:17.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:44:17.747+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:44:17.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T01:44:17.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-30T01:44:48.108+0000] {processor.py:157} INFO - Started process (PID=52645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:44:48.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T01:44:48.111+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:44:48.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:44:48.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:44:48.141+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:44:48.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:44:48.152+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:44:48.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T01:44:48.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T01:45:18.492+0000] {processor.py:157} INFO - Started process (PID=52670) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:45:18.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T01:45:18.495+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:45:18.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:45:18.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:45:18.522+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:45:18.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:45:18.532+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:45:18.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T01:45:18.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-30T01:45:48.991+0000] {processor.py:157} INFO - Started process (PID=52695) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:45:48.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T01:45:48.994+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:45:48.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:45:49.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:45:49.022+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:45:49.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:45:49.031+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:45:49.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T01:45:49.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-30T01:46:19.406+0000] {processor.py:157} INFO - Started process (PID=52720) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:46:19.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T01:46:19.411+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:46:19.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:46:19.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:46:19.437+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:46:19.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:46:19.446+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:46:19.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T01:46:19.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-30T01:46:49.859+0000] {processor.py:157} INFO - Started process (PID=52745) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:46:49.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T01:46:49.865+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:46:49.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:46:49.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:46:49.899+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:46:49.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:46:49.911+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:46:49.911+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T01:46:49.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-30T01:47:20.239+0000] {processor.py:157} INFO - Started process (PID=52770) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:47:20.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T01:47:20.242+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:47:20.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:47:20.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:47:20.275+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:47:20.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:47:20.286+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:47:20.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T01:47:20.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-30T01:47:50.667+0000] {processor.py:157} INFO - Started process (PID=52795) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:47:50.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T01:47:50.672+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:47:50.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:47:50.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T01:47:50.713+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:47:50.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T01:47:50.725+0000] {logging_mixin.py:151} INFO - [2024-07-30T01:47:50.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T01:47:50.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-30T02:03:45.929+0000] {processor.py:157} INFO - Started process (PID=52822) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:03:45.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T02:03:45.946+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:03:45.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:03:45.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:03:46.006+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:03:46.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:03:46.042+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:03:46.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T02:03:46.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-07-30T02:04:16.675+0000] {processor.py:157} INFO - Started process (PID=52847) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:04:16.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T02:04:16.687+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:04:16.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:04:16.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:04:16.737+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:04:16.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:04:16.750+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:04:16.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T02:04:16.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-30T02:04:47.164+0000] {processor.py:157} INFO - Started process (PID=52872) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:04:47.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T02:04:47.167+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:04:47.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:04:47.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:04:47.191+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:04:47.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:04:47.201+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:04:47.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T02:04:47.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-30T02:05:17.610+0000] {processor.py:157} INFO - Started process (PID=52897) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:05:17.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T02:05:17.613+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:05:17.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:05:17.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:05:17.641+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:05:17.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:05:17.652+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:05:17.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T02:05:17.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T02:07:44.434+0000] {processor.py:157} INFO - Started process (PID=52922) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:07:44.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T02:07:44.443+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:07:44.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:07:44.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:07:44.501+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:07:44.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:07:44.530+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:07:44.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T02:07:44.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-30T02:08:14.978+0000] {processor.py:157} INFO - Started process (PID=52947) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:08:14.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T02:08:14.985+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:08:14.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:08:15.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:08:15.022+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:08:15.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:08:15.033+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:08:15.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T02:08:15.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-30T02:08:45.407+0000] {processor.py:157} INFO - Started process (PID=52972) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:08:45.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T02:08:45.410+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:08:45.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:08:45.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:08:45.441+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:08:45.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:08:45.453+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:08:45.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T02:08:45.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T02:09:15.826+0000] {processor.py:157} INFO - Started process (PID=52997) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:09:15.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T02:09:15.829+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:09:15.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:09:15.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:09:15.860+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:09:15.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:09:15.869+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:09:15.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T02:09:15.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T02:09:46.209+0000] {processor.py:157} INFO - Started process (PID=53022) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:09:46.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T02:09:46.212+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:09:46.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:09:46.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:09:46.244+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:09:46.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:09:46.254+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:09:46.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T02:09:46.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T02:27:05.364+0000] {processor.py:157} INFO - Started process (PID=53047) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:27:05.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T02:27:05.371+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:27:05.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:27:05.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:27:05.452+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:27:05.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:27:05.482+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:27:05.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T02:27:05.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-07-30T02:27:35.996+0000] {processor.py:157} INFO - Started process (PID=53072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:27:35.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T02:27:35.999+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:27:35.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:27:36.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:27:36.029+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:27:36.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:27:36.039+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:27:36.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T02:27:36.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T02:28:06.457+0000] {processor.py:157} INFO - Started process (PID=53097) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:28:06.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T02:28:06.461+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:28:06.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:28:06.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:28:06.495+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:28:06.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:28:06.508+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:28:06.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T02:28:06.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-30T02:28:36.923+0000] {processor.py:157} INFO - Started process (PID=53122) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:28:36.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T02:28:36.927+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:28:36.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:28:36.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:28:36.958+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:28:36.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:28:36.968+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:28:36.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T02:28:36.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T02:29:07.411+0000] {processor.py:157} INFO - Started process (PID=53147) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:29:07.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T02:29:07.416+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:29:07.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:29:07.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:29:07.444+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:29:07.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:29:07.453+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:29:07.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T02:29:07.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T02:29:37.860+0000] {processor.py:157} INFO - Started process (PID=53172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:29:37.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T02:29:37.865+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:29:37.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:29:37.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:29:37.893+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:29:37.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:29:37.903+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:29:37.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T02:29:37.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T02:45:35.556+0000] {processor.py:157} INFO - Started process (PID=53197) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:45:35.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T02:45:35.562+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:45:35.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:45:35.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:45:35.608+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:45:35.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:45:35.634+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:45:35.633+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T02:45:35.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-30T02:46:06.202+0000] {processor.py:157} INFO - Started process (PID=53222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:46:06.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T02:46:06.207+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:46:06.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:46:06.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:46:06.243+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:46:06.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:46:06.256+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:46:06.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T02:46:06.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-30T02:46:36.723+0000] {processor.py:157} INFO - Started process (PID=53247) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:46:36.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T02:46:36.726+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:46:36.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:46:36.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:46:36.753+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:46:36.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:46:36.766+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:46:36.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T02:46:36.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T02:47:07.208+0000] {processor.py:157} INFO - Started process (PID=53272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:47:07.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T02:47:07.213+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:47:07.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:47:07.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:47:07.241+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:47:07.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:47:07.253+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:47:07.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T02:47:07.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T02:56:32.032+0000] {processor.py:157} INFO - Started process (PID=53299) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:56:32.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T02:56:32.039+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:56:32.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:56:32.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:56:32.093+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:56:32.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:56:32.113+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:56:32.113+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T02:56:32.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-30T02:57:02.685+0000] {processor.py:157} INFO - Started process (PID=53324) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:57:02.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T02:57:02.690+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:57:02.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:57:02.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:57:02.720+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:57:02.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:57:02.730+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:57:02.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T02:57:02.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-30T02:57:33.174+0000] {processor.py:157} INFO - Started process (PID=53349) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:57:33.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T02:57:33.178+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:57:33.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:57:33.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:57:33.217+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:57:33.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:57:33.230+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:57:33.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T02:57:33.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-30T02:58:03.699+0000] {processor.py:157} INFO - Started process (PID=53374) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:58:03.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T02:58:03.704+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:58:03.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:58:03.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:58:03.737+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:58:03.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:58:03.747+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:58:03.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T02:58:03.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-30T02:58:34.152+0000] {processor.py:157} INFO - Started process (PID=53399) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:58:34.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T02:58:34.155+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:58:34.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:58:34.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T02:58:34.180+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:58:34.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T02:58:34.189+0000] {logging_mixin.py:151} INFO - [2024-07-30T02:58:34.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T02:58:34.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-30T03:06:37.390+0000] {processor.py:157} INFO - Started process (PID=53426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:06:37.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:06:37.407+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:06:37.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:06:37.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:06:37.486+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:06:37.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:06:37.525+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:06:37.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:06:37.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-07-30T03:07:07.977+0000] {processor.py:157} INFO - Started process (PID=53451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:07:07.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:07:07.985+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:07:07.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:07:08.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:07:08.029+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:07:08.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:07:08.041+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:07:08.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:07:08.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-30T03:07:38.560+0000] {processor.py:157} INFO - Started process (PID=53476) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:07:38.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:07:38.569+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:07:38.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:07:38.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:07:38.645+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:07:38.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:07:38.666+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:07:38.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:07:38.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-30T03:08:09.070+0000] {processor.py:157} INFO - Started process (PID=53501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:08:09.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:08:09.077+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:08:09.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:08:09.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:08:09.128+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:08:09.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:08:09.140+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:08:09.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:08:09.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-30T03:08:39.501+0000] {processor.py:157} INFO - Started process (PID=53526) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:08:39.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:08:39.503+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:08:39.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:08:39.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:08:39.530+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:08:39.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:08:39.539+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:08:39.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:08:39.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-30T03:09:09.874+0000] {processor.py:157} INFO - Started process (PID=53551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:09:09.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:09:09.879+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:09:09.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:09:09.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:09:09.905+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:09:09.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:09:09.914+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:09:09.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:09:09.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T03:09:40.306+0000] {processor.py:157} INFO - Started process (PID=53576) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:09:40.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:09:40.315+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:09:40.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:09:40.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:09:40.377+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:09:40.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:09:40.391+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:09:40.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:09:40.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-30T03:10:10.919+0000] {processor.py:157} INFO - Started process (PID=53601) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:10:10.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:10:10.925+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:10:10.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:10:10.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:10:11.002+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:10:11.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:10:11.019+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:10:11.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:10:11.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-07-30T03:10:41.596+0000] {processor.py:157} INFO - Started process (PID=53626) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:10:41.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:10:41.609+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:10:41.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:10:41.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:10:41.714+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:10:41.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:10:41.734+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:10:41.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:10:41.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-07-30T03:11:12.152+0000] {processor.py:157} INFO - Started process (PID=53651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:11:12.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:11:12.177+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:11:12.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:11:12.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:11:12.226+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:11:12.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:11:12.242+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:11:12.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:11:12.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-30T03:11:42.758+0000] {processor.py:157} INFO - Started process (PID=53676) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:11:42.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:11:42.773+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:11:42.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:11:42.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:11:42.863+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:11:42.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:11:42.885+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:11:42.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:11:42.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-07-30T03:12:13.347+0000] {processor.py:157} INFO - Started process (PID=53700) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:12:13.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:12:13.354+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:12:13.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:12:13.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:12:13.407+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:12:13.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:12:13.420+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:12:13.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:12:13.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-30T03:12:43.890+0000] {processor.py:157} INFO - Started process (PID=53726) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:12:43.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:12:43.896+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:12:43.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:12:43.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:12:43.978+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:12:43.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:12:43.992+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:12:43.992+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:12:44.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-30T03:13:14.390+0000] {processor.py:157} INFO - Started process (PID=53751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:13:14.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:13:14.405+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:13:14.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:13:14.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:13:14.467+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:13:14.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:13:14.484+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:13:14.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:13:14.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-30T03:13:45.031+0000] {processor.py:157} INFO - Started process (PID=53776) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:13:45.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:13:45.047+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:13:45.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:13:45.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:13:45.096+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:13:45.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:13:45.116+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:13:45.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:13:45.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-30T03:14:15.534+0000] {processor.py:157} INFO - Started process (PID=53801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:14:15.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:14:15.547+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:14:15.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:14:15.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:14:15.609+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:14:15.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:14:15.624+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:14:15.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:14:15.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-30T03:14:46.148+0000] {processor.py:157} INFO - Started process (PID=53826) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:14:46.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:14:46.154+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:14:46.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:14:46.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:14:46.209+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:14:46.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:14:46.222+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:14:46.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:14:46.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-30T03:15:16.738+0000] {processor.py:157} INFO - Started process (PID=53851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:15:16.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:15:16.766+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:15:16.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:15:16.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:15:16.827+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:15:16.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:15:16.839+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:15:16.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:15:16.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-07-30T03:15:47.316+0000] {processor.py:157} INFO - Started process (PID=53876) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:15:47.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:15:47.324+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:15:47.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:15:47.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:15:47.378+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:15:47.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:15:47.391+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:15:47.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:15:47.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-30T03:16:17.911+0000] {processor.py:157} INFO - Started process (PID=53901) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:16:17.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:16:17.923+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:16:17.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:16:17.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:16:18.028+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:16:18.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:16:18.050+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:16:18.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:16:18.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-07-30T03:16:48.604+0000] {processor.py:157} INFO - Started process (PID=53926) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:16:48.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:16:48.611+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:16:48.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:16:48.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:16:48.671+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:16:48.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:16:48.683+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:16:48.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:16:48.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-30T03:17:19.103+0000] {processor.py:157} INFO - Started process (PID=53951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:17:19.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:17:19.105+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:17:19.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:17:19.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:17:19.136+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:17:19.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:17:19.147+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:17:19.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:17:19.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-30T03:17:49.614+0000] {processor.py:157} INFO - Started process (PID=53976) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:17:49.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:17:49.621+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:17:49.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:17:49.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:17:49.683+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:17:49.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:17:49.696+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:17:49.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:17:49.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-30T03:18:20.119+0000] {processor.py:157} INFO - Started process (PID=54001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:18:20.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:18:20.125+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:18:20.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:18:20.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:18:20.166+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:18:20.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:18:20.179+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:18:20.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:18:20.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-30T03:18:50.630+0000] {processor.py:157} INFO - Started process (PID=54026) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:18:50.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:18:50.634+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:18:50.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:18:50.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:18:50.693+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:18:50.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:18:50.706+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:18:50.706+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:18:50.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-30T03:19:21.205+0000] {processor.py:157} INFO - Started process (PID=54050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:19:21.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:19:21.210+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:19:21.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:19:21.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:19:21.288+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:19:21.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:19:21.304+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:19:21.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:19:21.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-30T03:19:51.820+0000] {processor.py:157} INFO - Started process (PID=54076) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:19:51.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:19:51.846+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:19:51.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:19:51.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:19:51.894+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:19:51.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:19:51.907+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:19:51.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:19:51.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-30T03:20:22.345+0000] {processor.py:157} INFO - Started process (PID=54101) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:20:22.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:20:22.352+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:20:22.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:20:22.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:20:22.404+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:20:22.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:20:22.428+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:20:22.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:20:22.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-30T03:20:52.931+0000] {processor.py:157} INFO - Started process (PID=54126) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:20:52.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:20:52.938+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:20:52.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:20:52.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:20:53.004+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:20:53.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:20:53.020+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:20:53.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:20:53.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-07-30T03:21:23.489+0000] {processor.py:157} INFO - Started process (PID=54151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:21:23.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:21:23.499+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:21:23.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:21:23.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:21:23.575+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:21:23.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:21:23.591+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:21:23.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:21:23.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-30T03:21:54.145+0000] {processor.py:157} INFO - Started process (PID=54176) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:21:54.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:21:54.154+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:21:54.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:21:54.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:21:54.241+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:21:54.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:21:54.260+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:21:54.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:21:54.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-07-30T03:22:24.799+0000] {processor.py:157} INFO - Started process (PID=54200) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:22:24.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:22:24.806+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:22:24.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:22:24.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:22:24.869+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:22:24.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:22:24.882+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:22:24.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:22:24.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-30T03:22:55.363+0000] {processor.py:157} INFO - Started process (PID=54226) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:22:55.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:22:55.366+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:22:55.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:22:55.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:22:55.423+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:22:55.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:22:55.438+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:22:55.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:22:55.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-30T03:23:25.872+0000] {processor.py:157} INFO - Started process (PID=54251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:23:25.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:23:25.879+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:23:25.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:23:25.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:23:25.937+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:23:25.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:23:25.952+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:23:25.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:23:25.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-30T03:23:56.421+0000] {processor.py:157} INFO - Started process (PID=54276) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:23:56.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:23:56.437+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:23:56.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:23:56.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:23:56.490+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:23:56.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:23:56.504+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:23:56.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:23:56.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-30T03:24:26.910+0000] {processor.py:157} INFO - Started process (PID=54301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:24:26.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:24:26.918+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:24:26.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:24:26.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:24:26.979+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:24:26.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:24:26.993+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:24:26.992+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:24:27.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-30T03:24:57.473+0000] {processor.py:157} INFO - Started process (PID=54324) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:24:57.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:24:57.480+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:24:57.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:24:57.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:24:57.540+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:24:57.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:24:57.552+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:24:57.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:24:57.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-30T03:25:28.050+0000] {processor.py:157} INFO - Started process (PID=54351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:25:28.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:25:28.058+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:25:28.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:25:28.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:25:28.105+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:25:28.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:25:28.118+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:25:28.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:25:28.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-30T03:25:58.568+0000] {processor.py:157} INFO - Started process (PID=54376) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:25:58.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:25:58.574+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:25:58.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:25:58.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:25:58.625+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:25:58.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:25:58.643+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:25:58.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:25:58.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-30T03:26:29.135+0000] {processor.py:157} INFO - Started process (PID=54401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:26:29.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:26:29.142+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:26:29.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:26:29.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:26:29.219+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:26:29.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:26:29.238+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:26:29.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:26:29.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-30T03:26:59.707+0000] {processor.py:157} INFO - Started process (PID=54426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:26:59.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:26:59.712+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:26:59.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:26:59.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:26:59.775+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:26:59.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:26:59.789+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:26:59.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:26:59.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-30T03:27:30.269+0000] {processor.py:157} INFO - Started process (PID=54451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:27:30.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:27:30.281+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:27:30.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:27:30.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:27:30.343+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:27:30.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:27:30.360+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:27:30.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:27:30.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-30T03:28:00.766+0000] {processor.py:157} INFO - Started process (PID=54476) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:28:00.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:28:00.771+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:28:00.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:28:00.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:28:00.815+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:28:00.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:28:00.839+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:28:00.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:28:00.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-30T03:28:31.206+0000] {processor.py:157} INFO - Started process (PID=54501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:28:31.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:28:31.212+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:28:31.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:28:31.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:28:31.241+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:28:31.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:28:31.252+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:28:31.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:28:31.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T03:29:01.661+0000] {processor.py:157} INFO - Started process (PID=54526) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:29:01.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:29:01.666+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:29:01.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:29:01.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:29:01.705+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:29:01.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:29:01.717+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:29:01.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:29:01.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-30T03:29:32.129+0000] {processor.py:157} INFO - Started process (PID=54551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:29:32.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:29:32.134+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:29:32.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:29:32.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:29:32.165+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:29:32.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:29:32.176+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:29:32.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:29:32.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T03:30:02.543+0000] {processor.py:157} INFO - Started process (PID=54576) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:30:02.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:30:02.550+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:30:02.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:30:02.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:30:02.605+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:30:02.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:30:02.618+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:30:02.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:30:02.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-30T03:30:33.056+0000] {processor.py:157} INFO - Started process (PID=54601) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:30:33.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:30:33.080+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:30:33.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:30:33.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:30:33.150+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:30:33.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:30:33.173+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:30:33.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:30:33.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-07-30T03:31:03.643+0000] {processor.py:157} INFO - Started process (PID=54626) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:31:03.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:31:03.648+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:31:03.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:31:03.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:31:03.745+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:31:03.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:31:03.763+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:31:03.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:31:03.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-07-30T03:31:34.242+0000] {processor.py:157} INFO - Started process (PID=54651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:31:34.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:31:34.252+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:31:34.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:31:34.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:31:34.316+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:31:34.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:31:34.329+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:31:34.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:31:34.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-30T03:32:04.914+0000] {processor.py:157} INFO - Started process (PID=54676) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:32:04.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:32:04.923+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:32:04.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:32:04.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:32:05.017+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:32:05.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:32:05.035+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:32:05.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:32:05.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-07-30T03:32:35.509+0000] {processor.py:157} INFO - Started process (PID=54701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:32:35.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:32:35.515+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:32:35.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:32:35.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:32:35.558+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:32:35.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:32:35.571+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:32:35.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:32:35.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-30T03:33:06.065+0000] {processor.py:157} INFO - Started process (PID=54726) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:33:06.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:33:06.070+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:33:06.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:33:06.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:33:06.132+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:33:06.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:33:06.146+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:33:06.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:33:06.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-30T03:33:36.615+0000] {processor.py:157} INFO - Started process (PID=54751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:33:36.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:33:36.629+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:33:36.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:33:36.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:33:36.688+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:33:36.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:33:36.705+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:33:36.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:33:36.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-30T03:34:07.220+0000] {processor.py:157} INFO - Started process (PID=54776) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:34:07.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:34:07.231+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:34:07.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:34:07.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:34:07.308+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:34:07.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:34:07.322+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:34:07.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:34:07.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-30T03:34:37.786+0000] {processor.py:157} INFO - Started process (PID=54801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:34:37.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:34:37.794+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:34:37.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:34:37.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:34:37.852+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:34:37.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:34:37.865+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:34:37.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:34:37.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-30T03:35:08.327+0000] {processor.py:157} INFO - Started process (PID=54826) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:35:08.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:35:08.335+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:35:08.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:35:08.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:35:08.385+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:35:08.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:35:08.404+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:35:08.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:35:08.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-30T03:35:38.866+0000] {processor.py:157} INFO - Started process (PID=54851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:35:38.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:35:38.874+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:35:38.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:35:38.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:35:38.934+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:35:38.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:35:38.947+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:35:38.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:35:38.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-30T03:36:09.421+0000] {processor.py:157} INFO - Started process (PID=54876) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:36:09.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:36:09.430+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:36:09.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:36:09.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:36:09.498+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:36:09.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:36:09.515+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:36:09.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:36:09.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-07-30T03:36:39.943+0000] {processor.py:157} INFO - Started process (PID=54900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:36:39.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:36:39.950+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:36:39.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:36:39.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:36:39.989+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:36:39.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:36:40.004+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:36:40.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:36:40.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-30T03:37:10.555+0000] {processor.py:157} INFO - Started process (PID=54925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:37:10.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:37:10.561+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:37:10.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:37:10.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:37:10.615+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:37:10.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:37:10.633+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:37:10.633+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:37:10.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-30T03:37:41.021+0000] {processor.py:157} INFO - Started process (PID=54951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:37:41.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:37:41.024+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:37:41.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:37:41.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:37:41.056+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:37:41.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:37:41.067+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:37:41.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:37:41.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T03:38:11.497+0000] {processor.py:157} INFO - Started process (PID=54976) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:38:11.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:38:11.501+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:38:11.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:38:11.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:38:11.533+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:38:11.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:38:11.543+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:38:11.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:38:11.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T03:38:41.895+0000] {processor.py:157} INFO - Started process (PID=55001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:38:41.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:38:41.905+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:38:41.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:38:41.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:38:41.944+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:38:41.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:38:41.957+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:38:41.957+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:38:41.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-30T03:39:12.432+0000] {processor.py:157} INFO - Started process (PID=55026) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:39:12.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:39:12.440+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:39:12.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:39:12.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:39:12.507+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:39:12.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:39:12.523+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:39:12.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:39:12.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-07-30T03:39:43.228+0000] {processor.py:157} INFO - Started process (PID=55051) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:39:43.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:39:43.249+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:39:43.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:39:43.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:39:43.302+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:39:43.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:39:43.318+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:39:43.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:39:43.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-07-30T03:40:13.777+0000] {processor.py:157} INFO - Started process (PID=55076) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:40:13.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:40:13.784+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:40:13.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:40:13.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:40:13.836+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:40:13.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:40:13.853+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:40:13.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:40:13.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-30T03:40:44.393+0000] {processor.py:157} INFO - Started process (PID=55101) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:40:44.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:40:44.401+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:40:44.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:40:44.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:40:44.483+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:40:44.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:40:44.503+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:40:44.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:40:44.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-07-30T03:41:14.936+0000] {processor.py:157} INFO - Started process (PID=55126) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:41:14.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:41:14.941+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:41:14.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:41:14.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:41:14.982+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:41:14.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:41:14.994+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:41:14.994+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:41:15.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-30T03:41:45.492+0000] {processor.py:157} INFO - Started process (PID=55151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:41:45.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:41:45.500+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:41:45.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:41:45.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:41:45.562+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:41:45.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:41:45.577+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:41:45.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:41:45.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-30T03:42:16.030+0000] {processor.py:157} INFO - Started process (PID=55176) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:42:16.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:42:16.040+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:42:16.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:42:16.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:42:16.111+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:42:16.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:42:16.126+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:42:16.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:42:16.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-30T03:42:46.599+0000] {processor.py:157} INFO - Started process (PID=55201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:42:46.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:42:46.619+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:42:46.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:42:46.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:42:46.667+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:42:46.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:42:46.681+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:42:46.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:42:46.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-30T03:43:17.119+0000] {processor.py:157} INFO - Started process (PID=55226) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:43:17.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:43:17.127+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:43:17.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:43:17.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:43:17.168+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:43:17.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:43:17.181+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:43:17.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:43:17.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-30T03:43:47.667+0000] {processor.py:157} INFO - Started process (PID=55251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:43:47.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:43:47.678+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:43:47.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:43:47.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:43:47.780+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:43:47.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:43:47.800+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:43:47.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:43:47.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-07-30T03:44:18.221+0000] {processor.py:157} INFO - Started process (PID=55275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:44:18.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:44:18.226+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:44:18.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:44:18.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:44:18.278+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:44:18.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:44:18.297+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:44:18.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:44:18.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-30T03:44:48.791+0000] {processor.py:157} INFO - Started process (PID=55301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:44:48.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:44:48.799+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:44:48.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:44:48.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:44:48.859+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:44:48.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:44:48.875+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:44:48.875+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:44:48.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-30T03:45:19.398+0000] {processor.py:157} INFO - Started process (PID=55326) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:45:19.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:45:19.407+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:45:19.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:45:19.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:45:19.512+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:45:19.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:45:19.531+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:45:19.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:45:19.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-07-30T03:45:50.051+0000] {processor.py:157} INFO - Started process (PID=55351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:45:50.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:45:50.061+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:45:50.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:45:50.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:45:50.151+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:45:50.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:45:50.173+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:45:50.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:45:50.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-07-30T03:46:20.680+0000] {processor.py:157} INFO - Started process (PID=55376) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:46:20.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:46:20.690+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:46:20.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:46:20.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:46:20.760+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:46:20.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:46:20.773+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:46:20.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:46:20.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-30T03:46:51.230+0000] {processor.py:157} INFO - Started process (PID=55401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:46:51.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:46:51.242+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:46:51.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:46:51.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:46:51.311+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:46:51.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:46:51.337+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:46:51.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:46:51.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-07-30T03:47:21.790+0000] {processor.py:157} INFO - Started process (PID=55426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:47:21.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:47:21.793+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:47:21.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:47:21.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:47:21.825+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:47:21.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:47:21.837+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:47:21.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:47:21.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-30T03:47:52.276+0000] {processor.py:157} INFO - Started process (PID=55450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:47:52.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:47:52.280+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:47:52.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:47:52.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:47:52.349+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:47:52.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:47:52.370+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:47:52.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:47:52.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-30T03:48:22.852+0000] {processor.py:157} INFO - Started process (PID=55475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:48:22.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:48:22.867+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:48:22.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:48:22.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:48:22.946+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:48:22.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:48:22.967+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:48:22.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:48:22.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-07-30T03:48:53.424+0000] {processor.py:157} INFO - Started process (PID=55501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:48:53.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:48:53.430+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:48:53.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:48:53.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:48:53.481+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:48:53.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:48:53.493+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:48:53.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:48:53.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-30T03:49:23.974+0000] {processor.py:157} INFO - Started process (PID=55526) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:49:23.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:49:23.986+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:49:23.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:49:24.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:49:24.098+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:49:24.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:49:24.119+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:49:24.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:49:24.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-07-30T03:49:54.662+0000] {processor.py:157} INFO - Started process (PID=55551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:49:54.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:49:54.671+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:49:54.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:49:54.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:49:54.728+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:49:54.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:49:54.745+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:49:54.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:49:54.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-30T03:50:25.133+0000] {processor.py:157} INFO - Started process (PID=55576) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:50:25.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:50:25.141+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:50:25.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:50:25.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:50:25.265+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:50:25.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:50:25.287+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:50:25.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:50:25.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-07-30T03:50:55.791+0000] {processor.py:157} INFO - Started process (PID=55601) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:50:55.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:50:55.801+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:50:55.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:50:55.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:50:55.906+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:50:55.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:50:55.926+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:50:55.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:50:55.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-07-30T03:51:26.423+0000] {processor.py:157} INFO - Started process (PID=55626) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:51:26.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:51:26.437+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:51:26.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:51:26.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:51:26.522+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:51:26.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:51:26.540+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:51:26.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:51:26.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-07-30T03:51:57.078+0000] {processor.py:157} INFO - Started process (PID=55651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:51:57.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:51:57.084+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:51:57.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:51:57.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:51:57.134+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:51:57.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:51:57.162+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:51:57.162+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:51:57.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-30T03:52:27.602+0000] {processor.py:157} INFO - Started process (PID=55676) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:52:27.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:52:27.612+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:52:27.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:52:27.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:52:27.704+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:52:27.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:52:27.737+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:52:27.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:52:27.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-07-30T03:52:58.151+0000] {processor.py:157} INFO - Started process (PID=55700) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:52:58.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:52:58.158+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:52:58.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:52:58.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:52:58.210+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:52:58.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:52:58.225+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:52:58.225+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:52:58.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-30T03:53:28.688+0000] {processor.py:157} INFO - Started process (PID=55726) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:53:28.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:53:28.697+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:53:28.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:53:28.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:53:28.756+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:53:28.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:53:28.781+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:53:28.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:53:28.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-30T03:53:59.214+0000] {processor.py:157} INFO - Started process (PID=55751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:53:59.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:53:59.231+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:53:59.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:53:59.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:53:59.341+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:53:59.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:53:59.362+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:53:59.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:53:59.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-07-30T03:54:29.823+0000] {processor.py:157} INFO - Started process (PID=55775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:54:29.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:54:29.835+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:54:29.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:54:29.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:54:29.922+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:54:29.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:54:29.941+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:54:29.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:54:29.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-07-30T03:55:00.441+0000] {processor.py:157} INFO - Started process (PID=55801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:55:00.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:55:00.458+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:55:00.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:55:00.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:55:00.530+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:55:00.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:55:00.560+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:55:00.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:55:00.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-07-30T03:55:31.029+0000] {processor.py:157} INFO - Started process (PID=55826) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:55:31.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:55:31.037+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:55:31.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:55:31.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:55:31.149+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:55:31.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:55:31.167+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:55:31.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:55:31.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-07-30T03:56:01.778+0000] {processor.py:157} INFO - Started process (PID=55851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:56:01.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:56:01.786+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:56:01.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:56:01.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:56:01.860+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:56:01.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:56:01.875+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:56:01.875+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:56:01.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-30T03:56:32.335+0000] {processor.py:157} INFO - Started process (PID=55876) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:56:32.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:56:32.343+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:56:32.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:56:32.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:56:32.376+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:56:32.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:56:32.386+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:56:32.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:56:32.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-30T03:57:02.780+0000] {processor.py:157} INFO - Started process (PID=55901) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:57:02.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:57:02.787+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:57:02.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:57:02.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:57:02.827+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:57:02.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:57:02.839+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:57:02.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:57:02.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-30T03:57:33.296+0000] {processor.py:157} INFO - Started process (PID=55926) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:57:33.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:57:33.299+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:57:33.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:57:33.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:57:33.327+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:57:33.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:57:33.339+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:57:33.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:57:33.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T03:58:03.725+0000] {processor.py:157} INFO - Started process (PID=55951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:58:03.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:58:03.728+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:58:03.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:58:03.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:58:03.757+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:58:03.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:58:03.768+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:58:03.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:58:03.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T03:58:34.156+0000] {processor.py:157} INFO - Started process (PID=55976) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:58:34.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:58:34.160+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:58:34.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:58:34.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:58:34.186+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:58:34.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:58:34.196+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:58:34.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:58:34.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T03:59:04.534+0000] {processor.py:157} INFO - Started process (PID=56001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:59:04.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:59:04.542+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:59:04.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:59:04.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:59:04.580+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:59:04.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:59:04.595+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:59:04.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:59:04.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-30T03:59:35.098+0000] {processor.py:157} INFO - Started process (PID=56026) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:59:35.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T03:59:35.104+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:59:35.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:59:35.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T03:59:35.143+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:59:35.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T03:59:35.158+0000] {logging_mixin.py:151} INFO - [2024-07-30T03:59:35.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T03:59:35.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-30T04:00:05.682+0000] {processor.py:157} INFO - Started process (PID=56051) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:00:05.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:00:05.688+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:00:05.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:00:05.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:00:05.755+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:00:05.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:00:05.768+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:00:05.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:00:05.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-30T04:00:36.191+0000] {processor.py:157} INFO - Started process (PID=56076) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:00:36.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:00:36.196+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:00:36.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:00:36.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:00:36.224+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:00:36.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:00:36.234+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:00:36.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:00:36.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T04:01:06.665+0000] {processor.py:157} INFO - Started process (PID=56101) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:01:06.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:01:06.670+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:01:06.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:01:06.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:01:06.740+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:01:06.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:01:06.756+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:01:06.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:01:06.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-30T04:01:37.241+0000] {processor.py:157} INFO - Started process (PID=56126) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:01:37.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:01:37.247+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:01:37.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:01:37.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:01:37.280+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:01:37.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:01:37.294+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:01:37.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:01:37.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-30T04:02:07.737+0000] {processor.py:157} INFO - Started process (PID=56151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:02:07.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:02:07.740+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:02:07.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:02:07.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:02:07.778+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:02:07.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:02:07.791+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:02:07.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:02:07.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-30T04:02:38.268+0000] {processor.py:157} INFO - Started process (PID=56176) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:02:38.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:02:38.271+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:02:38.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:02:38.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:02:38.309+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:02:38.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:02:38.322+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:02:38.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:02:38.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-30T04:03:08.766+0000] {processor.py:157} INFO - Started process (PID=56201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:03:08.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:03:08.771+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:03:08.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:03:08.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:03:08.834+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:03:08.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:03:08.850+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:03:08.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:03:08.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-30T04:03:39.395+0000] {processor.py:157} INFO - Started process (PID=56226) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:03:39.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:03:39.403+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:03:39.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:03:39.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:03:39.443+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:03:39.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:03:39.456+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:03:39.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:03:39.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-30T04:04:09.925+0000] {processor.py:157} INFO - Started process (PID=56251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:04:09.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:04:09.927+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:04:09.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:04:09.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:04:09.957+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:04:09.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:04:09.968+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:04:09.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:04:09.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T04:04:40.390+0000] {processor.py:157} INFO - Started process (PID=56276) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:04:40.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:04:40.397+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:04:40.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:04:40.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:04:40.438+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:04:40.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:04:40.456+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:04:40.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:04:40.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-30T04:05:10.921+0000] {processor.py:157} INFO - Started process (PID=56301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:05:10.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:05:10.929+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:05:10.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:05:10.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:05:10.972+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:05:10.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:05:10.985+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:05:10.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:05:10.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-30T04:05:41.462+0000] {processor.py:157} INFO - Started process (PID=56326) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:05:41.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:05:41.467+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:05:41.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:05:41.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:05:41.496+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:05:41.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:05:41.505+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:05:41.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:05:41.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T04:06:12.001+0000] {processor.py:157} INFO - Started process (PID=56350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:06:12.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:06:12.007+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:06:12.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:06:12.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:06:12.065+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:06:12.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:06:12.079+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:06:12.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:06:12.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-30T04:06:42.485+0000] {processor.py:157} INFO - Started process (PID=56376) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:06:42.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:06:42.488+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:06:42.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:06:42.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:06:42.512+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:06:42.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:06:42.524+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:06:42.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:06:42.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-30T04:07:12.987+0000] {processor.py:157} INFO - Started process (PID=56400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:07:12.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:07:12.993+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:07:12.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:07:13.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:07:13.047+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:07:13.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:07:13.061+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:07:13.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:07:13.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-30T04:07:43.559+0000] {processor.py:157} INFO - Started process (PID=56426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:07:43.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:07:43.563+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:07:43.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:07:43.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:07:43.590+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:07:43.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:07:43.600+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:07:43.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:07:43.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T04:08:14.088+0000] {processor.py:157} INFO - Started process (PID=56451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:08:14.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:08:14.093+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:08:14.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:08:14.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:08:14.140+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:08:14.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:08:14.154+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:08:14.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:08:14.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-30T04:08:44.611+0000] {processor.py:157} INFO - Started process (PID=56476) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:08:44.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:08:44.616+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:08:44.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:08:44.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:08:44.645+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:08:44.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:08:44.654+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:08:44.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:08:44.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T04:09:15.633+0000] {processor.py:157} INFO - Started process (PID=56501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:09:15.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:09:15.639+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:09:15.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:09:15.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:09:15.696+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:09:15.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:09:15.711+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:09:15.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:09:15.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-30T04:10:06.546+0000] {processor.py:157} INFO - Started process (PID=56526) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:10:06.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:10:06.548+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:10:06.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:10:06.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:10:06.569+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:10:06.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:10:06.581+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:10:06.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:10:06.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-30T04:10:36.950+0000] {processor.py:157} INFO - Started process (PID=56553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:10:36.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:10:36.955+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:10:36.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:10:36.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:10:36.995+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:10:36.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:10:37.007+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:10:37.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:10:37.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-30T04:26:28.246+0000] {processor.py:157} INFO - Started process (PID=56580) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:26:28.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:26:28.248+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:26:28.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:26:28.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:26:28.273+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:26:28.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:26:28.288+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:26:28.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:26:28.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T04:26:58.712+0000] {processor.py:157} INFO - Started process (PID=56605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:26:58.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:26:58.717+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:26:58.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:26:58.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:26:58.759+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:26:58.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:26:58.771+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:26:58.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:26:58.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-30T04:27:29.177+0000] {processor.py:157} INFO - Started process (PID=56630) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:27:29.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:27:29.182+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:27:29.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:27:29.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:27:29.218+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:27:29.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:27:29.230+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:27:29.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:27:29.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-30T04:27:59.642+0000] {processor.py:157} INFO - Started process (PID=56655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:27:59.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:27:59.644+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:27:59.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:27:59.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:27:59.676+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:27:59.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:27:59.690+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:27:59.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:27:59.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-30T04:28:57.136+0000] {processor.py:157} INFO - Started process (PID=56682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:28:57.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:28:57.142+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:28:57.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:28:57.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:28:57.186+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:28:57.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:28:57.200+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:28:57.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:28:57.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-30T04:29:27.668+0000] {processor.py:157} INFO - Started process (PID=56707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:29:27.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:29:27.673+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:29:27.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:29:27.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:29:27.701+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:29:27.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:29:27.713+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:29:27.713+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:29:27.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T04:31:10.356+0000] {processor.py:157} INFO - Started process (PID=56732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:31:10.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:31:10.360+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:31:10.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:31:10.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:31:10.408+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:31:10.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:31:10.438+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:31:10.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:31:10.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-07-30T04:32:43.112+0000] {processor.py:157} INFO - Started process (PID=56757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:32:43.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:32:43.119+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:32:43.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:32:43.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:32:43.177+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:32:43.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:32:43.200+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:32:43.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:32:43.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-30T04:33:13.504+0000] {processor.py:157} INFO - Started process (PID=56781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:33:13.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:33:13.507+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:33:13.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:33:13.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:33:13.540+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:33:13.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:33:13.553+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:33:13.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:33:13.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-30T04:33:44.384+0000] {processor.py:157} INFO - Started process (PID=56807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:33:44.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:33:44.390+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:33:44.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:33:44.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:33:44.431+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:33:44.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:33:44.443+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:33:44.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:33:44.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-30T04:34:30.550+0000] {processor.py:157} INFO - Started process (PID=56832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:34:30.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:34:30.557+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:34:30.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:34:30.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:34:30.625+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:34:30.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:34:30.641+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:34:30.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:34:30.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-30T04:35:00.979+0000] {processor.py:157} INFO - Started process (PID=56859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:35:00.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:35:00.983+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:35:00.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:35:00.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:35:01.012+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:35:01.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:35:01.022+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:35:01.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:35:01.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T04:35:31.453+0000] {processor.py:157} INFO - Started process (PID=56883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:35:31.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:35:31.472+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:35:31.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:35:31.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:35:31.610+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:35:31.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:35:31.636+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:35:31.636+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:35:31.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.222 seconds
[2024-07-30T04:36:02.058+0000] {processor.py:157} INFO - Started process (PID=56909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:36:02.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:36:02.062+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:36:02.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:36:02.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:36:02.090+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:36:02.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:36:02.100+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:36:02.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:36:02.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T04:36:32.573+0000] {processor.py:157} INFO - Started process (PID=56934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:36:32.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:36:32.579+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:36:32.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:36:32.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:36:32.626+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:36:32.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:36:32.642+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:36:32.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:36:32.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-30T04:37:03.072+0000] {processor.py:157} INFO - Started process (PID=56959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:37:03.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:37:03.075+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:37:03.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:37:03.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:37:03.107+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:37:03.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:37:03.116+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:37:03.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:37:03.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T04:37:33.503+0000] {processor.py:157} INFO - Started process (PID=56984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:37:33.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:37:33.505+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:37:33.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:37:33.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:37:33.534+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:37:33.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:37:33.545+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:37:33.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:37:33.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T04:38:03.965+0000] {processor.py:157} INFO - Started process (PID=57009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:38:03.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:38:03.969+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:38:03.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:38:03.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:38:03.999+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:38:03.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:38:04.011+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:38:04.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:38:04.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T04:38:34.394+0000] {processor.py:157} INFO - Started process (PID=57034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:38:34.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:38:34.403+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:38:34.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:38:34.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:38:34.426+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:38:34.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:38:34.435+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:38:34.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:38:34.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T04:39:04.766+0000] {processor.py:157} INFO - Started process (PID=57059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:39:04.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:39:04.768+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:39:04.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:39:04.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:39:04.794+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:39:04.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:39:04.803+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:39:04.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:39:04.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-30T04:39:35.204+0000] {processor.py:157} INFO - Started process (PID=57084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:39:35.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:39:35.209+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:39:35.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:39:35.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:39:35.251+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:39:35.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:39:35.263+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:39:35.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:39:35.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-30T04:40:05.665+0000] {processor.py:157} INFO - Started process (PID=57109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:40:05.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:40:05.668+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:40:05.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:40:05.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:40:05.701+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:40:05.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:40:05.711+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:40:05.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:40:05.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-30T04:40:36.071+0000] {processor.py:157} INFO - Started process (PID=57134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:40:36.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:40:36.074+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:40:36.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:40:36.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:40:36.106+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:40:36.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:40:36.116+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:40:36.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:40:36.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T04:41:06.506+0000] {processor.py:157} INFO - Started process (PID=57159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:41:06.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:41:06.509+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:41:06.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:41:06.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:41:06.536+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:41:06.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:41:06.548+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:41:06.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:41:06.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T04:41:36.988+0000] {processor.py:157} INFO - Started process (PID=57184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:41:36.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:41:36.993+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:41:36.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:41:37.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:41:37.024+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:41:37.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:41:37.033+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:41:37.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:41:37.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T04:42:07.422+0000] {processor.py:157} INFO - Started process (PID=57209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:42:07.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:42:07.427+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:42:07.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:42:07.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:42:07.466+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:42:07.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:42:07.478+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:42:07.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:42:07.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-30T04:42:37.823+0000] {processor.py:157} INFO - Started process (PID=57234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:42:37.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:42:37.825+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:42:37.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:42:37.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:42:37.847+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:42:37.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:42:37.857+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:42:37.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:42:37.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-30T04:43:08.321+0000] {processor.py:157} INFO - Started process (PID=57259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:43:08.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:43:08.325+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:43:08.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:43:08.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:43:08.379+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:43:08.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:43:08.396+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:43:08.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:43:08.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-30T04:43:59.395+0000] {processor.py:157} INFO - Started process (PID=57284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:43:59.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:43:59.401+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:43:59.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:43:59.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:43:59.436+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:43:59.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:43:59.447+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:43:59.447+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:43:59.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-30T04:47:05.234+0000] {processor.py:157} INFO - Started process (PID=57311) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:47:05.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:47:05.239+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:47:05.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:47:05.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:47:05.306+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:47:05.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:47:05.329+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:47:05.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:47:05.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-30T04:47:35.941+0000] {processor.py:157} INFO - Started process (PID=57336) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:47:35.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:47:35.947+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:47:35.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:47:35.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:47:36.022+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:47:36.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:47:36.047+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:47:36.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:47:36.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-30T04:48:33.277+0000] {processor.py:157} INFO - Started process (PID=57361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:48:33.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:48:33.281+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:48:33.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:48:33.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:48:33.324+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:48:33.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:48:33.338+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:48:33.338+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:48:33.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-30T04:49:03.722+0000] {processor.py:157} INFO - Started process (PID=57386) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:49:03.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T04:49:03.725+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:49:03.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:49:03.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T04:49:03.757+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:49:03.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T04:49:03.773+0000] {logging_mixin.py:151} INFO - [2024-07-30T04:49:03.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T04:49:03.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-30T05:05:16.039+0000] {processor.py:157} INFO - Started process (PID=57411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:05:16.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T05:05:16.045+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:05:16.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:05:16.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:05:16.099+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:05:16.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T05:05:16.120+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:05:16.120+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T05:05:16.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-30T05:05:46.589+0000] {processor.py:157} INFO - Started process (PID=57438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:05:46.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T05:05:46.595+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:05:46.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:05:46.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:05:46.635+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:05:46.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T05:05:46.646+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:05:46.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T05:05:46.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-30T05:06:17.027+0000] {processor.py:157} INFO - Started process (PID=57463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:06:17.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T05:06:17.033+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:06:17.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:06:17.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:06:17.062+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:06:17.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T05:06:17.076+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:06:17.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T05:06:17.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-30T05:06:47.450+0000] {processor.py:157} INFO - Started process (PID=57488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:06:47.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T05:06:47.453+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:06:47.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:06:47.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:06:47.476+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:06:47.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T05:06:47.486+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:06:47.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T05:06:47.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-30T05:23:25.888+0000] {processor.py:157} INFO - Started process (PID=57515) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:23:25.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T05:23:25.893+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:23:25.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:23:25.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:23:25.958+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:23:25.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T05:23:25.979+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:23:25.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T05:23:25.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-30T05:23:56.447+0000] {processor.py:157} INFO - Started process (PID=57540) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:23:56.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T05:23:56.450+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:23:56.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:23:56.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:23:56.480+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:23:56.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T05:23:56.490+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:23:56.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T05:23:56.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T05:24:26.835+0000] {processor.py:157} INFO - Started process (PID=57565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:24:26.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T05:24:26.839+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:24:26.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:24:26.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:24:26.873+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:24:26.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T05:24:26.885+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:24:26.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T05:24:26.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-30T05:24:57.359+0000] {processor.py:157} INFO - Started process (PID=57590) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:24:57.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T05:24:57.364+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:24:57.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:24:57.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:24:57.394+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:24:57.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T05:24:57.406+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:24:57.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T05:24:57.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T05:25:27.884+0000] {processor.py:157} INFO - Started process (PID=57615) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:25:27.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T05:25:27.891+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:25:27.891+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:25:27.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:25:27.920+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:25:27.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T05:25:27.931+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:25:27.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T05:25:27.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-30T05:42:15.008+0000] {processor.py:157} INFO - Started process (PID=57642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:42:15.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T05:42:15.017+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:42:15.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:42:15.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:42:15.080+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:42:15.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T05:42:15.106+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:42:15.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T05:42:15.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-07-30T05:42:45.657+0000] {processor.py:157} INFO - Started process (PID=57667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:42:45.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T05:42:45.665+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:42:45.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:42:45.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:42:45.702+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:42:45.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T05:42:45.714+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:42:45.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T05:42:45.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-30T05:43:16.081+0000] {processor.py:157} INFO - Started process (PID=57692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:43:16.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T05:43:16.084+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:43:16.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:43:16.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:43:16.109+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:43:16.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T05:43:16.122+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:43:16.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T05:43:16.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T05:43:46.597+0000] {processor.py:157} INFO - Started process (PID=57717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:43:46.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T05:43:46.599+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:43:46.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:43:46.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:43:46.631+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:43:46.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T05:43:46.641+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:43:46.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T05:43:46.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T05:44:17.073+0000] {processor.py:157} INFO - Started process (PID=57742) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:44:17.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T05:44:17.075+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:44:17.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:44:17.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:44:17.104+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:44:17.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T05:44:17.113+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:44:17.113+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T05:44:17.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-30T05:59:33.309+0000] {processor.py:157} INFO - Started process (PID=57768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:59:33.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T05:59:33.315+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:59:33.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:59:33.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T05:59:33.375+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:59:33.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T05:59:33.392+0000] {logging_mixin.py:151} INFO - [2024-07-30T05:59:33.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T05:59:33.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-30T06:00:03.883+0000] {processor.py:157} INFO - Started process (PID=57793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:00:03.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T06:00:03.886+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:00:03.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:00:03.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:00:03.915+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:00:03.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:00:03.924+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:00:03.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T06:00:03.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T06:00:34.343+0000] {processor.py:157} INFO - Started process (PID=57818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:00:34.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T06:00:34.350+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:00:34.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:00:34.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:00:34.408+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:00:34.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:00:34.419+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:00:34.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T06:00:34.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-30T06:01:04.904+0000] {processor.py:157} INFO - Started process (PID=57843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:01:04.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T06:01:04.908+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:01:04.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:01:04.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:01:04.937+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:01:04.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:01:04.952+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:01:04.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T06:01:04.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T06:01:35.324+0000] {processor.py:157} INFO - Started process (PID=57868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:01:35.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T06:01:35.327+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:01:35.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:01:35.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:01:35.357+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:01:35.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:01:35.367+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:01:35.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T06:01:35.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T06:17:12.370+0000] {processor.py:157} INFO - Started process (PID=57893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:17:12.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T06:17:12.372+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:17:12.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:17:12.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:17:12.406+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:17:12.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:17:12.415+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:17:12.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T06:17:12.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-30T06:23:33.065+0000] {processor.py:157} INFO - Started process (PID=57920) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:23:33.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T06:23:33.071+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:23:33.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:23:33.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:23:33.169+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:23:33.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:23:33.190+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:23:33.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T06:23:33.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-07-30T06:24:03.779+0000] {processor.py:157} INFO - Started process (PID=57945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:24:03.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T06:24:03.784+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:24:03.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:24:03.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:24:03.821+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:24:03.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:24:03.832+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:24:03.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T06:24:03.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-30T06:24:34.228+0000] {processor.py:157} INFO - Started process (PID=57970) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:24:34.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T06:24:34.232+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:24:34.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:24:34.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:24:34.258+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:24:34.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:24:34.266+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:24:34.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T06:24:34.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T06:25:04.744+0000] {processor.py:157} INFO - Started process (PID=57995) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:25:04.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T06:25:04.750+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:25:04.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:25:04.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:25:04.784+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:25:04.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:25:04.795+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:25:04.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T06:25:04.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-30T06:25:35.200+0000] {processor.py:157} INFO - Started process (PID=58020) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:25:35.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T06:25:35.205+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:25:35.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:25:35.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:25:35.235+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:25:35.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:25:35.247+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:25:35.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T06:25:35.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-30T06:31:37.789+0000] {processor.py:157} INFO - Started process (PID=58045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:31:37.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T06:31:37.794+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:31:37.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:31:37.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:31:37.865+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:31:37.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:31:37.902+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:31:37.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T06:31:37.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-07-30T06:32:08.375+0000] {processor.py:157} INFO - Started process (PID=58072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:32:08.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T06:32:08.381+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:32:08.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:32:08.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:32:08.419+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:32:08.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:32:08.432+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:32:08.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T06:32:08.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-30T06:33:25.248+0000] {processor.py:157} INFO - Started process (PID=58099) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:33:25.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T06:33:25.257+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:33:25.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:33:25.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:33:25.327+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:33:25.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:33:25.339+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:33:25.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T06:33:25.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-30T06:33:55.803+0000] {processor.py:157} INFO - Started process (PID=58124) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:33:55.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T06:33:55.806+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:33:55.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:33:55.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:33:55.836+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:33:55.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:33:55.846+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:33:55.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T06:33:55.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T06:34:26.252+0000] {processor.py:157} INFO - Started process (PID=58149) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:34:26.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T06:34:26.257+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:34:26.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:34:26.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:34:26.303+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:34:26.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:34:26.320+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:34:26.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T06:34:26.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-30T06:34:56.760+0000] {processor.py:157} INFO - Started process (PID=58174) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:34:56.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T06:34:56.764+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:34:56.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:34:56.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:34:56.792+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:34:56.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:34:56.805+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:34:56.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T06:34:56.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T06:35:27.216+0000] {processor.py:157} INFO - Started process (PID=58199) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:35:27.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T06:35:27.224+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:35:27.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:35:27.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:35:27.261+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:35:27.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:35:27.272+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:35:27.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T06:35:27.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-30T06:35:57.693+0000] {processor.py:157} INFO - Started process (PID=58224) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:35:57.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T06:35:57.697+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:35:57.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:35:57.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:35:57.726+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:35:57.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:35:57.738+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:35:57.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T06:35:57.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T06:36:28.178+0000] {processor.py:157} INFO - Started process (PID=58249) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:36:28.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T06:36:28.181+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:36:28.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:36:28.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:36:28.216+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:36:28.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:36:28.226+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:36:28.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T06:36:28.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-30T06:36:58.535+0000] {processor.py:157} INFO - Started process (PID=58274) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:36:58.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T06:36:58.537+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:36:58.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:36:58.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:36:58.565+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:36:58.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:36:58.574+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:36:58.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T06:36:58.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-30T06:38:47.749+0000] {processor.py:157} INFO - Started process (PID=58299) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:38:47.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T06:38:47.754+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:38:47.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:38:47.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:38:47.808+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:38:47.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:38:47.833+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:38:47.833+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T06:38:47.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-07-30T06:39:18.223+0000] {processor.py:157} INFO - Started process (PID=58324) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:39:18.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T06:39:18.225+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:39:18.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:39:18.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:39:18.259+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:39:18.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:39:18.274+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:39:18.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T06:39:18.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-30T06:55:15.280+0000] {processor.py:157} INFO - Started process (PID=58348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:55:15.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T06:55:15.291+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:55:15.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:55:15.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T06:55:15.346+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:55:15.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T06:55:15.379+0000] {logging_mixin.py:151} INFO - [2024-07-30T06:55:15.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T06:55:15.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-30T07:01:12.155+0000] {processor.py:157} INFO - Started process (PID=58376) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:01:12.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T07:01:12.161+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:01:12.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:01:12.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:01:12.251+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:01:12.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:01:12.269+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:01:12.269+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T07:01:12.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-07-30T07:01:42.619+0000] {processor.py:157} INFO - Started process (PID=58401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:01:42.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T07:01:42.621+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:01:42.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:01:42.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:01:42.652+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:01:42.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:01:42.664+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:01:42.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T07:01:42.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T07:06:39.324+0000] {processor.py:157} INFO - Started process (PID=58426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:06:39.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T07:06:39.330+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:06:39.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:06:39.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:06:39.372+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:06:39.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:06:39.403+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:06:39.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T07:06:39.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-30T07:23:06.534+0000] {processor.py:157} INFO - Started process (PID=58451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:23:06.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T07:23:06.537+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:23:06.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:23:06.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:23:06.570+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:23:06.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:23:06.589+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:23:06.589+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T07:23:06.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-30T07:23:37.025+0000] {processor.py:157} INFO - Started process (PID=58475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:23:37.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T07:23:37.056+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:23:37.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:23:37.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:23:37.095+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:23:37.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:23:37.107+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:23:37.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T07:23:37.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-30T07:24:07.483+0000] {processor.py:157} INFO - Started process (PID=58501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:24:07.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T07:24:07.489+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:24:07.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:24:07.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:24:07.516+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:24:07.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:24:07.527+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:24:07.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T07:24:07.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T07:24:37.937+0000] {processor.py:157} INFO - Started process (PID=58526) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:24:37.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T07:24:37.943+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:24:37.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:24:37.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:24:37.966+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:24:37.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:24:37.978+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:24:37.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T07:24:37.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-30T07:25:08.387+0000] {processor.py:157} INFO - Started process (PID=58551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:25:08.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T07:25:08.391+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:25:08.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:25:08.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:25:08.418+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:25:08.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:25:08.428+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:25:08.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T07:25:08.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T07:25:38.875+0000] {processor.py:157} INFO - Started process (PID=58576) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:25:38.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T07:25:38.880+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:25:38.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:25:38.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:25:38.919+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:25:38.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:25:38.932+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:25:38.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T07:25:38.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-30T07:29:57.523+0000] {processor.py:157} INFO - Started process (PID=58601) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:29:57.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T07:29:57.528+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:29:57.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:29:57.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:29:57.585+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:29:57.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:29:57.598+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:29:57.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T07:29:57.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-30T07:30:28.018+0000] {processor.py:157} INFO - Started process (PID=58626) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:30:28.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T07:30:28.028+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:30:28.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:30:28.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:30:28.063+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:30:28.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:30:28.078+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:30:28.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T07:30:28.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-30T07:32:24.958+0000] {processor.py:157} INFO - Started process (PID=58651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:32:24.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T07:32:24.966+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:32:24.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:32:25.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:32:25.086+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:32:25.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:32:25.125+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:32:25.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T07:32:25.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.192 seconds
[2024-07-30T07:32:55.871+0000] {processor.py:157} INFO - Started process (PID=58676) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:32:55.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T07:32:55.877+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:32:55.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:32:55.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:32:55.945+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:32:55.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:32:55.961+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:32:55.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T07:32:55.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-07-30T07:34:18.796+0000] {processor.py:157} INFO - Started process (PID=58703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:34:18.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T07:34:18.805+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:34:18.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:34:18.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:34:18.877+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:34:18.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:34:18.896+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:34:18.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T07:34:18.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-30T07:34:49.445+0000] {processor.py:157} INFO - Started process (PID=58727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:34:49.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T07:34:49.452+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:34:49.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:34:49.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:34:49.501+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:34:49.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:34:49.526+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:34:49.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T07:34:49.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-30T07:50:55.153+0000] {processor.py:157} INFO - Started process (PID=58753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:50:55.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T07:50:55.157+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:50:55.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:50:55.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:50:55.207+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:50:55.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:50:55.224+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:50:55.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T07:50:55.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-30T07:51:25.660+0000] {processor.py:157} INFO - Started process (PID=58778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:51:25.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T07:51:25.662+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:51:25.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:51:25.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:51:25.700+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:51:25.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:51:25.714+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:51:25.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T07:51:25.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-30T07:57:15.726+0000] {processor.py:157} INFO - Started process (PID=58804) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:57:15.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T07:57:15.731+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:57:15.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:57:15.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:57:15.788+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:57:15.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:57:15.811+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:57:15.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T07:57:15.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-07-30T07:57:46.207+0000] {processor.py:157} INFO - Started process (PID=58830) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:57:46.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T07:57:46.212+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:57:46.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:57:46.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:57:46.249+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:57:46.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:57:46.262+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:57:46.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T07:57:46.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-30T07:58:16.719+0000] {processor.py:157} INFO - Started process (PID=58855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:58:16.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T07:58:16.725+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:58:16.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:58:16.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:58:16.756+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:58:16.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:58:16.765+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:58:16.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T07:58:16.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-30T07:58:47.160+0000] {processor.py:157} INFO - Started process (PID=58880) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:58:47.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T07:58:47.164+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:58:47.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:58:47.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:58:47.193+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:58:47.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:58:47.205+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:58:47.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T07:58:47.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T07:59:17.638+0000] {processor.py:157} INFO - Started process (PID=58905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:59:17.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T07:59:17.641+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:59:17.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:59:17.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T07:59:17.672+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:59:17.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T07:59:17.683+0000] {logging_mixin.py:151} INFO - [2024-07-30T07:59:17.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T07:59:17.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T08:01:40.945+0000] {processor.py:157} INFO - Started process (PID=58932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:01:40.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:01:40.949+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:01:40.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:01:40.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:01:40.987+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:01:40.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:01:40.999+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:01:40.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:01:41.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-30T08:06:02.266+0000] {processor.py:157} INFO - Started process (PID=58955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:06:02.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:06:02.274+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:06:02.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:06:02.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:06:02.353+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:06:02.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:06:02.372+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:06:02.372+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:06:02.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-30T08:06:32.874+0000] {processor.py:157} INFO - Started process (PID=58982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:06:32.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:06:32.885+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:06:32.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:06:32.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:06:32.989+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:06:32.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:06:33.019+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:06:33.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:06:33.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.169 seconds
[2024-07-30T08:07:03.478+0000] {processor.py:157} INFO - Started process (PID=59007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:07:03.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:07:03.481+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:07:03.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:07:03.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:07:03.516+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:07:03.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:07:03.528+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:07:03.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:07:03.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-30T08:07:33.891+0000] {processor.py:157} INFO - Started process (PID=59032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:07:33.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:07:33.896+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:07:33.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:07:33.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:07:33.926+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:07:33.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:07:33.939+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:07:33.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:07:33.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-30T08:08:04.332+0000] {processor.py:157} INFO - Started process (PID=59057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:08:04.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:08:04.337+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:08:04.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:08:04.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:08:04.368+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:08:04.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:08:04.381+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:08:04.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:08:04.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-30T08:08:34.770+0000] {processor.py:157} INFO - Started process (PID=59082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:08:34.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:08:34.774+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:08:34.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:08:34.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:08:34.808+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:08:34.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:08:34.821+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:08:34.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:08:34.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-30T08:09:05.290+0000] {processor.py:157} INFO - Started process (PID=59107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:09:05.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:09:05.293+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:09:05.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:09:05.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:09:05.333+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:09:05.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:09:05.350+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:09:05.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:09:05.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-30T08:09:35.783+0000] {processor.py:157} INFO - Started process (PID=59132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:09:35.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:09:35.786+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:09:35.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:09:35.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:09:35.816+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:09:35.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:09:35.827+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:09:35.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:09:35.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T08:10:06.282+0000] {processor.py:157} INFO - Started process (PID=59157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:10:06.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:10:06.286+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:10:06.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:10:06.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:10:06.316+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:10:06.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:10:06.328+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:10:06.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:10:06.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T08:10:36.768+0000] {processor.py:157} INFO - Started process (PID=59182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:10:36.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:10:36.772+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:10:36.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:10:36.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:10:36.804+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:10:36.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:10:36.815+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:10:36.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:10:36.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-30T08:11:07.178+0000] {processor.py:157} INFO - Started process (PID=59207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:11:07.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:11:07.182+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:11:07.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:11:07.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:11:07.210+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:11:07.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:11:07.221+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:11:07.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:11:07.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T08:11:37.595+0000] {processor.py:157} INFO - Started process (PID=59232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:11:37.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:11:37.600+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:11:37.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:11:37.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:11:37.629+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:11:37.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:11:37.637+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:11:37.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:11:37.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T08:12:08.033+0000] {processor.py:157} INFO - Started process (PID=59257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:12:08.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:12:08.036+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:12:08.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:12:08.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:12:08.070+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:12:08.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:12:08.084+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:12:08.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:12:08.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-30T08:12:38.538+0000] {processor.py:157} INFO - Started process (PID=59282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:12:38.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:12:38.542+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:12:38.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:12:38.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:12:38.568+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:12:38.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:12:38.582+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:12:38.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:12:38.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T08:13:08.935+0000] {processor.py:157} INFO - Started process (PID=59307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:13:08.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:13:08.940+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:13:08.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:13:08.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:13:08.976+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:13:08.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:13:08.986+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:13:08.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:13:08.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-30T08:13:39.420+0000] {processor.py:157} INFO - Started process (PID=59332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:13:39.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:13:39.423+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:13:39.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:13:39.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:13:39.450+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:13:39.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:13:39.459+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:13:39.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:13:39.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-30T08:14:09.839+0000] {processor.py:157} INFO - Started process (PID=59357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:14:09.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:14:09.843+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:14:09.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:14:09.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:14:09.873+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:14:09.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:14:09.883+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:14:09.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:14:09.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T08:14:40.193+0000] {processor.py:157} INFO - Started process (PID=59382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:14:40.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:14:40.196+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:14:40.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:14:40.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:14:40.221+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:14:40.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:14:40.230+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:14:40.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:14:40.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-30T08:15:10.609+0000] {processor.py:157} INFO - Started process (PID=59407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:15:10.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:15:10.613+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:15:10.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:15:10.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:15:10.642+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:15:10.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:15:10.653+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:15:10.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:15:10.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T08:15:41.081+0000] {processor.py:157} INFO - Started process (PID=59432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:15:41.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:15:41.083+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:15:41.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:15:41.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:15:41.106+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:15:41.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:15:41.116+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:15:41.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:15:41.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-30T08:16:11.646+0000] {processor.py:157} INFO - Started process (PID=59457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:16:11.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:16:11.653+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:16:11.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:16:11.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:16:11.673+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:16:11.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:16:11.682+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:16:11.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:16:11.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-30T08:16:42.110+0000] {processor.py:157} INFO - Started process (PID=59482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:16:42.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:16:42.112+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:16:42.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:16:42.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:16:42.143+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:16:42.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:16:42.152+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:16:42.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:16:42.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T08:17:12.540+0000] {processor.py:157} INFO - Started process (PID=59507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:17:12.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:17:12.543+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:17:12.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:17:12.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:17:12.573+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:17:12.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:17:12.585+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:17:12.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:17:12.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T08:17:43.002+0000] {processor.py:157} INFO - Started process (PID=59532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:17:43.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:17:43.007+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:17:43.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:17:43.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:17:43.033+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:17:43.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:17:43.044+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:17:43.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:17:43.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-30T08:18:13.484+0000] {processor.py:157} INFO - Started process (PID=59557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:18:13.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:18:13.490+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:18:13.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:18:13.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:18:13.528+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:18:13.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:18:13.540+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:18:13.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:18:13.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-30T08:18:44.012+0000] {processor.py:157} INFO - Started process (PID=59582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:18:44.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:18:44.015+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:18:44.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:18:44.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:18:44.044+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:18:44.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:18:44.057+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:18:44.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:18:44.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T08:19:14.403+0000] {processor.py:157} INFO - Started process (PID=59607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:19:14.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:19:14.406+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:19:14.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:19:14.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:19:14.434+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:19:14.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:19:14.444+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:19:14.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:19:14.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-30T08:19:44.894+0000] {processor.py:157} INFO - Started process (PID=59632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:19:44.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:19:44.896+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:19:44.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:19:44.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:19:44.925+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:19:44.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:19:44.937+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:19:44.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:19:44.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T08:20:15.323+0000] {processor.py:157} INFO - Started process (PID=59657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:20:15.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:20:15.326+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:20:15.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:20:15.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:20:15.359+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:20:15.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:20:15.368+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:20:15.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:20:15.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-30T08:20:45.743+0000] {processor.py:157} INFO - Started process (PID=59682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:20:45.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:20:45.746+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:20:45.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:20:45.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:20:45.772+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:20:45.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:20:45.783+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:20:45.783+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:20:45.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T08:21:16.196+0000] {processor.py:157} INFO - Started process (PID=59707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:21:16.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:21:16.200+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:21:16.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:21:16.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:21:16.228+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:21:16.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:21:16.239+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:21:16.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:21:16.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T08:21:46.652+0000] {processor.py:157} INFO - Started process (PID=59732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:21:46.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:21:46.656+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:21:46.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:21:46.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:21:46.681+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:21:46.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:21:46.689+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:21:46.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:21:46.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-30T08:22:17.037+0000] {processor.py:157} INFO - Started process (PID=59757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:22:17.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:22:17.042+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:22:17.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:22:17.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:22:17.074+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:22:17.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:22:17.085+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:22:17.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:22:17.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T08:22:47.391+0000] {processor.py:157} INFO - Started process (PID=59782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:22:47.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:22:47.394+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:22:47.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:22:47.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:22:47.418+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:22:47.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:22:47.427+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:22:47.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:22:47.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-30T08:23:17.850+0000] {processor.py:157} INFO - Started process (PID=59807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:23:17.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:23:17.854+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:23:17.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:23:17.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:23:17.889+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:23:17.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:23:17.901+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:23:17.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:23:17.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-30T08:23:48.314+0000] {processor.py:157} INFO - Started process (PID=59832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:23:48.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:23:48.316+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:23:48.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:23:48.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:23:48.343+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:23:48.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:23:48.353+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:23:48.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:23:48.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-30T08:24:18.698+0000] {processor.py:157} INFO - Started process (PID=59857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:24:18.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:24:18.701+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:24:18.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:24:18.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:24:18.727+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:24:18.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:24:18.737+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:24:18.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:24:18.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-30T08:24:49.117+0000] {processor.py:157} INFO - Started process (PID=59882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:24:49.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:24:49.122+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:24:49.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:24:49.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:24:49.156+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:24:49.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:24:49.165+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:24:49.165+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:24:49.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-30T08:25:19.548+0000] {processor.py:157} INFO - Started process (PID=59907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:25:19.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:25:19.554+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:25:19.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:25:19.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:25:19.583+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:25:19.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:25:19.593+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:25:19.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:25:19.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T08:25:49.977+0000] {processor.py:157} INFO - Started process (PID=59932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:25:49.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:25:49.982+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:25:49.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:25:49.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:25:50.007+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:25:50.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:25:50.017+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:25:50.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:25:50.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T08:26:20.382+0000] {processor.py:157} INFO - Started process (PID=59957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:26:20.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:26:20.385+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:26:20.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:26:20.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:26:20.404+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:26:20.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:26:20.412+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:26:20.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:26:20.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.040 seconds
[2024-07-30T08:26:50.924+0000] {processor.py:157} INFO - Started process (PID=59982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:26:50.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:26:50.927+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:26:50.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:26:50.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:26:50.958+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:26:50.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:26:50.970+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:26:50.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:26:50.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T08:27:21.371+0000] {processor.py:157} INFO - Started process (PID=60007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:27:21.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:27:21.375+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:27:21.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:27:21.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:27:21.402+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:27:21.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:27:21.411+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:27:21.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:27:21.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-30T08:27:51.911+0000] {processor.py:157} INFO - Started process (PID=60032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:27:51.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:27:51.914+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:27:51.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:27:51.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:27:51.944+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:27:51.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:27:51.954+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:27:51.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:27:51.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T08:28:22.370+0000] {processor.py:157} INFO - Started process (PID=60057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:28:22.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:28:22.373+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:28:22.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:28:22.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:28:22.403+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:28:22.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:28:22.414+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:28:22.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:28:22.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T08:28:52.826+0000] {processor.py:157} INFO - Started process (PID=60082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:28:52.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:28:52.830+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:28:52.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:28:52.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:28:52.860+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:28:52.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:28:52.872+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:28:52.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:28:52.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T08:29:23.322+0000] {processor.py:157} INFO - Started process (PID=60107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:29:23.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:29:23.329+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:29:23.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:29:23.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:29:23.379+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:29:23.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:29:23.406+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:29:23.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:29:23.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-30T08:29:53.716+0000] {processor.py:157} INFO - Started process (PID=60132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:29:53.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:29:53.720+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:29:53.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:29:53.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:29:53.752+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:29:53.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:29:53.769+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:29:53.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:29:53.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-30T08:30:24.572+0000] {processor.py:157} INFO - Started process (PID=60157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:30:24.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:30:24.582+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:30:24.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:30:24.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:30:24.635+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:30:24.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:30:24.648+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:30:24.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:30:24.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-30T08:30:55.149+0000] {processor.py:157} INFO - Started process (PID=60182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:30:55.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:30:55.158+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:30:55.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:30:55.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:30:55.220+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:30:55.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:30:55.235+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:30:55.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:30:55.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-30T08:31:25.660+0000] {processor.py:157} INFO - Started process (PID=60207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:31:25.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:31:25.662+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:31:25.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:31:25.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:31:25.690+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:31:25.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:31:25.701+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:31:25.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:31:25.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T08:31:56.181+0000] {processor.py:157} INFO - Started process (PID=60232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:31:56.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:31:56.184+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:31:56.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:31:56.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:31:56.212+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:31:56.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:31:56.224+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:31:56.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:31:56.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T08:32:26.806+0000] {processor.py:157} INFO - Started process (PID=60257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:32:26.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:32:26.819+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:32:26.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:32:26.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:32:26.884+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:32:26.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:32:26.905+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:32:26.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:32:26.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-30T08:32:57.421+0000] {processor.py:157} INFO - Started process (PID=60281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:32:57.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:32:57.433+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:32:57.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:32:57.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:32:57.510+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:32:57.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:32:57.526+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:32:57.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:32:57.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-30T08:33:27.983+0000] {processor.py:157} INFO - Started process (PID=60307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:33:27.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:33:27.994+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:33:27.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:33:28.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:33:28.182+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:33:28.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:33:28.232+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:33:28.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:33:28.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.270 seconds
[2024-07-30T08:33:58.733+0000] {processor.py:157} INFO - Started process (PID=60332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:33:58.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:33:58.741+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:33:58.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:33:58.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:33:58.829+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:33:58.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:33:58.858+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:33:58.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:33:58.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-07-30T08:34:29.377+0000] {processor.py:157} INFO - Started process (PID=60357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:34:29.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:34:29.382+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:34:29.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:34:29.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:34:29.440+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:34:29.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:34:29.455+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:34:29.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:34:29.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-30T08:34:59.780+0000] {processor.py:157} INFO - Started process (PID=60381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:34:59.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:34:59.783+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:34:59.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:34:59.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:34:59.803+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:34:59.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:34:59.811+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:34:59.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:34:59.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-30T08:35:30.241+0000] {processor.py:157} INFO - Started process (PID=60407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:35:30.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:35:30.245+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:35:30.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:35:30.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:35:30.285+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:35:30.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:35:30.298+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:35:30.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:35:30.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-30T08:36:00.678+0000] {processor.py:157} INFO - Started process (PID=60432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:36:00.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:36:00.681+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:36:00.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:36:00.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:36:00.707+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:36:00.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:36:00.720+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:36:00.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:36:00.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T08:36:31.154+0000] {processor.py:157} INFO - Started process (PID=60457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:36:31.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:36:31.161+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:36:31.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:36:31.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:36:31.200+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:36:31.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:36:31.213+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:36:31.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:36:31.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-30T08:37:01.669+0000] {processor.py:157} INFO - Started process (PID=60482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:37:01.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:37:01.674+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:37:01.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:37:01.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:37:01.720+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:37:01.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:37:01.733+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:37:01.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:37:01.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-30T08:37:32.206+0000] {processor.py:157} INFO - Started process (PID=60507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:37:32.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:37:32.210+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:37:32.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:37:32.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:37:32.238+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:37:32.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:37:32.248+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:37:32.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:37:32.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T08:38:02.650+0000] {processor.py:157} INFO - Started process (PID=60532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:38:02.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:38:02.654+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:38:02.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:38:02.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:38:02.682+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:38:02.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:38:02.692+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:38:02.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:38:02.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T08:38:33.019+0000] {processor.py:157} INFO - Started process (PID=60557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:38:33.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:38:33.022+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:38:33.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:38:33.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:38:33.051+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:38:33.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:38:33.061+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:38:33.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:38:33.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T08:39:03.498+0000] {processor.py:157} INFO - Started process (PID=60582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:39:03.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:39:03.502+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:39:03.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:39:03.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:39:03.543+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:39:03.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:39:03.556+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:39:03.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:39:03.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-30T08:39:33.977+0000] {processor.py:157} INFO - Started process (PID=60607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:39:33.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:39:33.980+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:39:33.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:39:33.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:39:34.011+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:39:34.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:39:34.020+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:39:34.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:39:34.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T08:40:04.425+0000] {processor.py:157} INFO - Started process (PID=60632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:40:04.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:40:04.430+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:40:04.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:40:04.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:40:04.460+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:40:04.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:40:04.470+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:40:04.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:40:04.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T08:40:34.910+0000] {processor.py:157} INFO - Started process (PID=60657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:40:34.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:40:34.917+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:40:34.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:40:34.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:40:34.955+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:40:34.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:40:34.968+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:40:34.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:40:34.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-30T08:41:05.361+0000] {processor.py:157} INFO - Started process (PID=60682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:41:05.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:41:05.363+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:41:05.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:41:05.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:41:05.388+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:41:05.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:41:05.398+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:41:05.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:41:05.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-30T08:41:35.840+0000] {processor.py:157} INFO - Started process (PID=60707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:41:35.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:41:35.844+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:41:35.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:41:35.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:41:35.872+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:41:35.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:41:35.883+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:41:35.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:41:35.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T08:42:06.275+0000] {processor.py:157} INFO - Started process (PID=60732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:42:06.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:42:06.279+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:42:06.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:42:06.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:42:06.319+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:42:06.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:42:06.330+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:42:06.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:42:06.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-30T08:42:36.747+0000] {processor.py:157} INFO - Started process (PID=60757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:42:36.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:42:36.752+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:42:36.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:42:36.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:42:36.781+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:42:36.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:42:36.792+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:42:36.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:42:36.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T08:43:07.141+0000] {processor.py:157} INFO - Started process (PID=60782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:43:07.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:43:07.144+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:43:07.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:43:07.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:43:07.177+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:43:07.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:43:07.190+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:43:07.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:43:07.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-30T08:43:37.578+0000] {processor.py:157} INFO - Started process (PID=60807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:43:37.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:43:37.582+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:43:37.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:43:37.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:43:37.607+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:43:37.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:43:37.617+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:43:37.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:43:37.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-30T08:44:31.673+0000] {processor.py:157} INFO - Started process (PID=60832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:44:31.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:44:31.680+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:44:31.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:44:31.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:44:31.731+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:44:31.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:44:31.746+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:44:31.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:44:31.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-30T08:45:02.189+0000] {processor.py:157} INFO - Started process (PID=60859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:45:02.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:45:02.194+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:45:02.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:45:02.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:45:02.224+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:45:02.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:45:02.235+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:45:02.235+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:45:02.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T08:45:46.159+0000] {processor.py:157} INFO - Started process (PID=60884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:45:46.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T08:45:46.162+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:45:46.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:45:46.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T08:45:46.191+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:45:46.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T08:45:46.202+0000] {logging_mixin.py:151} INFO - [2024-07-30T08:45:46.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T08:45:46.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T09:02:23.985+0000] {processor.py:157} INFO - Started process (PID=60909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:02:23.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T09:02:23.990+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:02:23.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:02:24.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:02:24.026+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:02:24.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T09:02:24.037+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:02:24.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T09:02:24.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-30T09:02:54.484+0000] {processor.py:157} INFO - Started process (PID=60936) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:02:54.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T09:02:54.489+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:02:54.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:02:54.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:02:54.529+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:02:54.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T09:02:54.543+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:02:54.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T09:02:54.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-30T09:03:24.995+0000] {processor.py:157} INFO - Started process (PID=60961) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:03:24.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T09:03:24.999+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:03:24.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:03:25.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:03:25.024+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:03:25.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T09:03:25.033+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:03:25.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T09:03:25.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-30T09:20:20.547+0000] {processor.py:157} INFO - Started process (PID=60985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:20:20.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T09:20:20.554+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:20:20.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:20:20.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:20:20.611+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:20:20.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T09:20:20.637+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:20:20.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T09:20:20.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-30T09:20:51.210+0000] {processor.py:157} INFO - Started process (PID=61011) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:20:51.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T09:20:51.212+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:20:51.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:20:51.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:20:51.241+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:20:51.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T09:20:51.251+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:20:51.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T09:20:51.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-30T09:21:21.661+0000] {processor.py:157} INFO - Started process (PID=61036) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:21:21.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T09:21:21.664+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:21:21.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:21:21.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:21:21.695+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:21:21.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T09:21:21.706+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:21:21.706+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T09:21:21.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T09:21:52.154+0000] {processor.py:157} INFO - Started process (PID=61061) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:21:52.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T09:21:52.158+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:21:52.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:21:52.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:21:52.193+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:21:52.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T09:21:52.206+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:21:52.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T09:21:52.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-30T09:30:15.370+0000] {processor.py:157} INFO - Started process (PID=61086) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:30:15.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T09:30:15.384+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:30:15.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:30:15.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:30:15.498+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:30:15.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T09:30:15.568+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:30:15.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T09:30:15.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.246 seconds
[2024-07-30T09:30:46.116+0000] {processor.py:157} INFO - Started process (PID=61111) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:30:46.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T09:30:46.122+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:30:46.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:30:46.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:30:46.161+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:30:46.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T09:30:46.173+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:30:46.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T09:30:46.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-30T09:31:16.559+0000] {processor.py:157} INFO - Started process (PID=61136) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:31:16.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T09:31:16.565+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:31:16.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:31:16.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:31:16.600+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:31:16.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T09:31:16.616+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:31:16.616+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T09:31:16.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-30T09:31:47.051+0000] {processor.py:157} INFO - Started process (PID=61161) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:31:47.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T09:31:47.055+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:31:47.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:31:47.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:31:47.084+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:31:47.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T09:31:47.093+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:31:47.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T09:31:47.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T09:32:17.456+0000] {processor.py:157} INFO - Started process (PID=61186) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:32:17.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T09:32:17.459+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:32:17.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:32:17.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:32:17.488+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:32:17.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T09:32:17.500+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:32:17.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T09:32:17.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T09:37:18.386+0000] {processor.py:157} INFO - Started process (PID=61211) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:37:18.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T09:37:18.399+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:37:18.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:37:18.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:37:18.479+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:37:18.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T09:37:18.509+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:37:18.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T09:37:18.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-07-30T09:54:36.079+0000] {processor.py:157} INFO - Started process (PID=61238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:54:36.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T09:54:36.089+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:54:36.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:54:36.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:54:36.281+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:54:36.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T09:54:36.318+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:54:36.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T09:54:36.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.375 seconds
[2024-07-30T09:55:06.960+0000] {processor.py:157} INFO - Started process (PID=61263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:55:06.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T09:55:06.966+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:55:06.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:55:06.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T09:55:07.012+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:55:07.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T09:55:07.029+0000] {logging_mixin.py:151} INFO - [2024-07-30T09:55:07.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T09:55:07.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-30T10:10:44.407+0000] {processor.py:157} INFO - Started process (PID=61290) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:10:44.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T10:10:44.414+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:10:44.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:10:44.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:10:44.506+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:10:44.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:10:44.533+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:10:44.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T10:10:44.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-07-30T10:11:15.138+0000] {processor.py:157} INFO - Started process (PID=61315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:11:15.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T10:11:15.146+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:11:15.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:11:15.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:11:15.188+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:11:15.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:11:15.202+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:11:15.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T10:11:15.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-30T10:11:45.627+0000] {processor.py:157} INFO - Started process (PID=61340) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:11:45.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T10:11:45.632+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:11:45.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:11:45.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:11:45.661+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:11:45.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:11:45.671+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:11:45.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T10:11:45.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T10:12:16.046+0000] {processor.py:157} INFO - Started process (PID=61365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:12:16.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T10:12:16.049+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:12:16.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:12:16.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:12:16.079+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:12:16.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:12:16.091+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:12:16.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T10:12:16.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T10:12:46.509+0000] {processor.py:157} INFO - Started process (PID=61390) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:12:46.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T10:12:46.514+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:12:46.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:12:46.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:12:46.540+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:12:46.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:12:46.549+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:12:46.549+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T10:12:46.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T10:13:16.930+0000] {processor.py:157} INFO - Started process (PID=61415) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:13:16.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T10:13:16.936+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:13:16.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:13:16.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:13:16.976+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:13:16.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:13:16.989+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:13:16.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T10:13:16.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-30T10:14:53.491+0000] {processor.py:157} INFO - Started process (PID=61440) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:14:53.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T10:14:53.499+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:14:53.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:14:53.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:14:53.588+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:14:53.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:14:53.621+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:14:53.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T10:14:53.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-07-30T10:15:24.233+0000] {processor.py:157} INFO - Started process (PID=61465) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:15:24.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T10:15:24.237+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:15:24.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:15:24.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:15:24.278+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:15:24.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:15:24.289+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:15:24.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T10:15:24.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-30T10:15:54.680+0000] {processor.py:157} INFO - Started process (PID=61490) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:15:54.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T10:15:54.686+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:15:54.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:15:54.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:15:54.716+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:15:54.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:15:54.727+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:15:54.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T10:15:54.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-30T10:16:25.146+0000] {processor.py:157} INFO - Started process (PID=61515) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:16:25.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T10:16:25.150+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:16:25.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:16:25.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:16:25.180+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:16:25.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:16:25.194+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:16:25.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T10:16:25.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T10:16:55.627+0000] {processor.py:157} INFO - Started process (PID=61540) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:16:55.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T10:16:55.632+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:16:55.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:16:55.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:16:55.669+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:16:55.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:16:55.681+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:16:55.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T10:16:55.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-30T10:17:26.094+0000] {processor.py:157} INFO - Started process (PID=61565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:17:26.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T10:17:26.096+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:17:26.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:17:26.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:17:26.130+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:17:26.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:17:26.144+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:17:26.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T10:17:26.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-30T10:17:56.564+0000] {processor.py:157} INFO - Started process (PID=61590) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:17:56.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T10:17:56.567+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:17:56.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:17:56.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:17:56.597+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:17:56.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:17:56.606+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:17:56.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T10:17:56.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T10:18:26.939+0000] {processor.py:157} INFO - Started process (PID=61615) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:18:26.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T10:18:26.941+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:18:26.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:18:26.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:18:26.966+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:18:26.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:18:26.976+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:18:26.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T10:18:26.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-30T10:34:56.679+0000] {processor.py:157} INFO - Started process (PID=61642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:34:56.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T10:34:56.684+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:34:56.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:34:56.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:34:56.750+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:34:56.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:34:56.776+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:34:56.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T10:34:56.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-30T10:35:27.195+0000] {processor.py:157} INFO - Started process (PID=61665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:35:27.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T10:35:27.214+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:35:27.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:35:27.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:35:27.259+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:35:27.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:35:27.271+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:35:27.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T10:35:27.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-30T10:35:57.709+0000] {processor.py:157} INFO - Started process (PID=61692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:35:57.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T10:35:57.714+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:35:57.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:35:57.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:35:57.745+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:35:57.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:35:57.756+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:35:57.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T10:35:57.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T10:36:28.196+0000] {processor.py:157} INFO - Started process (PID=61717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:36:28.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T10:36:28.202+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:36:28.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:36:28.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:36:28.241+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:36:28.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:36:28.252+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:36:28.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T10:36:28.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-30T10:54:25.838+0000] {processor.py:157} INFO - Started process (PID=61742) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:54:25.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T10:54:25.842+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:54:25.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:54:25.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:54:25.870+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:54:25.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:54:25.882+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:54:25.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T10:54:25.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T10:54:56.272+0000] {processor.py:157} INFO - Started process (PID=61767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:54:56.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T10:54:56.276+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:54:56.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:54:56.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:54:56.343+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:54:56.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:54:56.356+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:54:56.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T10:54:56.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-30T10:55:26.780+0000] {processor.py:157} INFO - Started process (PID=61792) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:55:26.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T10:55:26.783+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:55:26.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:55:26.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:55:26.815+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:55:26.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:55:26.827+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:55:26.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T10:55:26.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-30T10:55:57.280+0000] {processor.py:157} INFO - Started process (PID=61817) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:55:57.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T10:55:57.284+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:55:57.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:55:57.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:55:57.315+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:55:57.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:55:57.328+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:55:57.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T10:55:57.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-30T10:56:27.668+0000] {processor.py:157} INFO - Started process (PID=61842) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:56:27.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T10:56:27.673+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:56:27.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:56:27.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T10:56:27.706+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:56:27.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T10:56:27.716+0000] {logging_mixin.py:151} INFO - [2024-07-30T10:56:27.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T10:56:27.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-30T11:12:27.310+0000] {processor.py:157} INFO - Started process (PID=61867) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:12:27.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T11:12:27.320+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:12:27.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:12:27.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:12:27.361+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:12:27.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T11:12:27.375+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:12:27.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T11:12:27.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-30T11:28:59.332+0000] {processor.py:157} INFO - Started process (PID=61894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:28:59.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T11:28:59.341+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:28:59.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:28:59.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:28:59.416+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:28:59.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T11:28:59.454+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:28:59.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T11:28:59.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-07-30T11:29:30.041+0000] {processor.py:157} INFO - Started process (PID=61919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:29:30.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T11:29:30.047+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:29:30.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:29:30.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:29:30.090+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:29:30.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T11:29:30.103+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:29:30.103+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T11:29:30.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-30T11:30:00.548+0000] {processor.py:157} INFO - Started process (PID=61944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:30:00.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T11:30:00.551+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:30:00.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:30:00.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:30:00.580+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:30:00.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T11:30:00.592+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:30:00.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T11:30:00.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T11:30:31.019+0000] {processor.py:157} INFO - Started process (PID=61969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:30:31.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T11:30:31.024+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:30:31.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:30:31.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:30:31.063+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:30:31.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T11:30:31.076+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:30:31.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T11:30:31.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-30T11:31:01.484+0000] {processor.py:157} INFO - Started process (PID=61994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:31:01.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T11:31:01.573+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:31:01.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:31:01.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:31:01.615+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:31:01.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T11:31:01.627+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:31:01.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T11:31:01.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-07-30T11:47:11.441+0000] {processor.py:157} INFO - Started process (PID=62020) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:47:11.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T11:47:11.457+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:47:11.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:47:11.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:47:11.536+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:47:11.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T11:47:11.570+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:47:11.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T11:47:11.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-07-30T11:47:41.999+0000] {processor.py:157} INFO - Started process (PID=62046) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:47:42.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T11:47:42.004+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:47:42.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:47:42.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:47:42.033+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:47:42.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T11:47:42.043+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:47:42.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T11:47:42.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T11:48:12.519+0000] {processor.py:157} INFO - Started process (PID=62071) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:48:12.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T11:48:12.523+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:48:12.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:48:12.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:48:12.562+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:48:12.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T11:48:12.576+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:48:12.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T11:48:12.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-30T11:48:43.018+0000] {processor.py:157} INFO - Started process (PID=62096) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:48:43.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T11:48:43.023+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:48:43.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:48:43.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:48:43.054+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:48:43.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T11:48:43.067+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:48:43.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T11:48:43.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-30T11:49:13.451+0000] {processor.py:157} INFO - Started process (PID=62121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:49:13.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T11:49:13.455+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:49:13.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:49:13.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T11:49:13.483+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:49:13.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T11:49:13.493+0000] {logging_mixin.py:151} INFO - [2024-07-30T11:49:13.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T11:49:13.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T12:06:18.392+0000] {processor.py:157} INFO - Started process (PID=62148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:06:18.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:06:18.398+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:06:18.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:06:18.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:06:18.457+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:06:18.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:06:18.475+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:06:18.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:06:18.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-30T12:06:48.935+0000] {processor.py:157} INFO - Started process (PID=62173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:06:48.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:06:48.940+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:06:48.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:06:48.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:06:48.987+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:06:48.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:06:49.001+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:06:49.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:06:49.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-30T12:07:19.403+0000] {processor.py:157} INFO - Started process (PID=62198) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:07:19.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:07:19.405+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:07:19.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:07:19.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:07:19.429+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:07:19.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:07:19.440+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:07:19.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:07:19.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-30T12:07:49.866+0000] {processor.py:157} INFO - Started process (PID=62223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:07:49.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:07:49.868+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:07:49.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:07:49.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:07:49.898+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:07:49.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:07:49.909+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:07:49.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:07:49.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T12:08:20.354+0000] {processor.py:157} INFO - Started process (PID=62248) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:08:20.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:08:20.358+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:08:20.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:08:20.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:08:20.388+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:08:20.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:08:20.398+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:08:20.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:08:20.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T12:17:17.478+0000] {processor.py:157} INFO - Started process (PID=62275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:17:17.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:17:17.489+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:17:17.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:17:17.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:17:17.557+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:17:17.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:17:17.575+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:17:17.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:17:17.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-30T12:17:48.145+0000] {processor.py:157} INFO - Started process (PID=62300) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:17:48.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:17:48.154+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:17:48.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:17:48.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:17:48.211+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:17:48.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:17:48.231+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:17:48.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:17:48.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-30T12:18:18.641+0000] {processor.py:157} INFO - Started process (PID=62325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:18:18.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:18:18.658+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:18:18.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:18:18.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:18:18.724+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:18:18.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:18:18.739+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:18:18.739+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:18:18.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-30T12:18:49.234+0000] {processor.py:157} INFO - Started process (PID=62350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:18:49.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:18:49.243+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:18:49.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:18:49.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:18:49.308+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:18:49.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:18:49.322+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:18:49.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:18:49.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-07-30T12:19:19.785+0000] {processor.py:157} INFO - Started process (PID=62374) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:19:19.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:19:19.791+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:19:19.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:19:19.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:19:19.847+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:19:19.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:19:19.862+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:19:19.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:19:19.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-30T12:19:50.360+0000] {processor.py:157} INFO - Started process (PID=62399) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:19:50.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:19:50.376+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:19:50.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:19:50.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:19:50.437+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:19:50.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:19:50.492+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:19:50.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:19:50.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.177 seconds
[2024-07-30T12:20:20.929+0000] {processor.py:157} INFO - Started process (PID=62425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:20:20.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:20:20.932+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:20:20.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:20:20.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:20:20.964+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:20:20.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:20:20.975+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:20:20.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:20:20.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T12:20:51.371+0000] {processor.py:157} INFO - Started process (PID=62450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:20:51.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:20:51.380+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:20:51.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:20:51.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:20:51.424+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:20:51.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:20:51.449+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:20:51.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:20:51.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-30T12:21:21.849+0000] {processor.py:157} INFO - Started process (PID=62474) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:21:21.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:21:21.855+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:21:21.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:21:21.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:21:21.883+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:21:21.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:21:21.894+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:21:21.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:21:21.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T12:21:52.303+0000] {processor.py:157} INFO - Started process (PID=62500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:21:52.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:21:52.313+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:21:52.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:21:52.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:21:52.361+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:21:52.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:21:52.376+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:21:52.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:21:52.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-30T12:22:22.767+0000] {processor.py:157} INFO - Started process (PID=62525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:22:22.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:22:22.770+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:22:22.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:22:22.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:22:22.801+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:22:22.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:22:22.811+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:22:22.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:22:22.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T12:22:53.190+0000] {processor.py:157} INFO - Started process (PID=62550) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:22:53.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:22:53.193+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:22:53.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:22:53.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:22:53.239+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:22:53.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:22:53.251+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:22:53.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:22:53.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-30T12:23:23.734+0000] {processor.py:157} INFO - Started process (PID=62575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:23:23.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:23:23.739+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:23:23.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:23:23.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:23:23.769+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:23:23.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:23:23.780+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:23:23.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:23:23.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T12:23:54.215+0000] {processor.py:157} INFO - Started process (PID=62600) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:23:54.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:23:54.219+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:23:54.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:23:54.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:23:54.267+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:23:54.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:23:54.281+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:23:54.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:23:54.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-30T12:24:24.656+0000] {processor.py:157} INFO - Started process (PID=62625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:24:24.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:24:24.660+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:24:24.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:24:24.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:24:24.690+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:24:24.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:24:24.703+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:24:24.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:24:24.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-30T12:24:55.097+0000] {processor.py:157} INFO - Started process (PID=62650) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:24:55.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:24:55.102+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:24:55.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:24:55.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:24:55.139+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:24:55.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:24:55.153+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:24:55.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:24:55.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-30T12:25:25.590+0000] {processor.py:157} INFO - Started process (PID=62675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:25:25.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:25:25.594+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:25:25.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:25:25.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:25:25.630+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:25:25.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:25:25.647+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:25:25.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:25:25.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-30T12:25:56.084+0000] {processor.py:157} INFO - Started process (PID=62700) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:25:56.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:25:56.089+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:25:56.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:25:56.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:25:56.127+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:25:56.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:25:56.139+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:25:56.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:25:56.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-30T12:26:26.644+0000] {processor.py:157} INFO - Started process (PID=62724) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:26:26.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:26:26.649+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:26:26.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:26:26.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:26:26.680+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:26:26.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:26:26.691+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:26:26.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:26:26.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-30T12:26:57.042+0000] {processor.py:157} INFO - Started process (PID=62750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:26:57.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:26:57.046+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:26:57.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:26:57.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:26:57.085+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:26:57.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:26:57.097+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:26:57.097+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:26:57.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-30T12:27:27.571+0000] {processor.py:157} INFO - Started process (PID=62775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:27:27.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:27:27.575+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:27:27.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:27:27.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:27:27.620+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:27:27.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:27:27.631+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:27:27.631+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:27:27.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-30T12:27:58.058+0000] {processor.py:157} INFO - Started process (PID=62800) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:27:58.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:27:58.064+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:27:58.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:27:58.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:27:58.108+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:27:58.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:27:58.136+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:27:58.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:27:58.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-30T12:28:28.629+0000] {processor.py:157} INFO - Started process (PID=62825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:28:28.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:28:28.635+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:28:28.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:28:28.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:28:28.663+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:28:28.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:28:28.673+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:28:28.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:28:28.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T12:28:59.036+0000] {processor.py:157} INFO - Started process (PID=62850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:28:59.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:28:59.042+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:28:59.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:28:59.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:28:59.081+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:28:59.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:28:59.093+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:28:59.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:28:59.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-30T12:29:29.542+0000] {processor.py:157} INFO - Started process (PID=62875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:29:29.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:29:29.547+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:29:29.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:29:29.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:29:29.586+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:29:29.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:29:29.598+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:29:29.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:29:29.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-30T12:30:00.019+0000] {processor.py:157} INFO - Started process (PID=62900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:30:00.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:30:00.025+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:30:00.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:30:00.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:30:00.058+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:30:00.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:30:00.072+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:30:00.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:30:00.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-30T12:30:30.531+0000] {processor.py:157} INFO - Started process (PID=62925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:30:30.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:30:30.535+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:30:30.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:30:30.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:30:30.575+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:30:30.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:30:30.588+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:30:30.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:30:30.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-30T12:31:01.038+0000] {processor.py:157} INFO - Started process (PID=62950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:31:01.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:31:01.042+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:31:01.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:31:01.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:31:01.075+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:31:01.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:31:01.085+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:31:01.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:31:01.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-30T12:31:31.496+0000] {processor.py:157} INFO - Started process (PID=62975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:31:31.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:31:31.501+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:31:31.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:31:31.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:31:31.532+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:31:31.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:31:31.543+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:31:31.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:31:31.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T12:32:01.955+0000] {processor.py:157} INFO - Started process (PID=63000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:32:01.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:32:01.961+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:32:01.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:32:01.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:32:02.003+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:32:02.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:32:02.014+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:32:02.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:32:02.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-30T12:32:32.404+0000] {processor.py:157} INFO - Started process (PID=63025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:32:32.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:32:32.409+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:32:32.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:32:32.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:32:32.438+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:32:32.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:32:32.448+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:32:32.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:32:32.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T12:33:02.945+0000] {processor.py:157} INFO - Started process (PID=63050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:33:02.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:33:02.950+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:33:02.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:33:02.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:33:02.989+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:33:02.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:33:03.002+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:33:03.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:33:03.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-30T12:33:33.488+0000] {processor.py:157} INFO - Started process (PID=63075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:33:33.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:33:33.517+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:33:33.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:33:33.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:33:33.582+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:33:33.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:33:33.626+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:33:33.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:33:33.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-07-30T12:34:04.196+0000] {processor.py:157} INFO - Started process (PID=63099) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:34:04.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:34:04.200+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:34:04.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:34:04.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:34:04.257+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:34:04.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:34:04.269+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:34:04.269+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:34:04.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-30T12:34:34.771+0000] {processor.py:157} INFO - Started process (PID=63125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:34:34.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:34:34.775+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:34:34.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:34:34.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:34:34.807+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:34:34.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:34:34.818+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:34:34.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:34:34.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T12:35:05.233+0000] {processor.py:157} INFO - Started process (PID=63150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:35:05.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:35:05.238+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:35:05.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:35:05.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:35:05.293+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:35:05.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:35:05.305+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:35:05.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:35:05.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-30T12:35:35.810+0000] {processor.py:157} INFO - Started process (PID=63175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:35:35.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:35:35.813+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:35:35.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:35:35.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:35:35.843+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:35:35.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:35:35.852+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:35:35.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:35:35.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T12:36:06.237+0000] {processor.py:157} INFO - Started process (PID=63199) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:36:06.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:36:06.243+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:36:06.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:36:06.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:36:06.307+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:36:06.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:36:06.322+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:36:06.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:36:06.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-30T12:36:36.812+0000] {processor.py:157} INFO - Started process (PID=63225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:36:36.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:36:36.815+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:36:36.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:36:36.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:36:36.849+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:36:36.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:36:36.860+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:36:36.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:36:36.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-30T12:37:07.222+0000] {processor.py:157} INFO - Started process (PID=63250) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:37:07.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:37:07.226+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:37:07.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:37:07.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:37:07.261+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:37:07.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:37:07.274+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:37:07.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:37:07.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-30T12:37:37.686+0000] {processor.py:157} INFO - Started process (PID=63275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:37:37.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:37:37.690+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:37:37.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:37:37.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:37:37.733+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:37:37.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:37:37.746+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:37:37.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:37:37.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-30T12:38:08.493+0000] {processor.py:157} INFO - Started process (PID=63299) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:38:08.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:38:08.498+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:38:08.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:38:08.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:38:08.540+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:38:08.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:38:08.552+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:38:08.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:38:08.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-30T12:38:39.016+0000] {processor.py:157} INFO - Started process (PID=63325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:38:39.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:38:39.019+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:38:39.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:38:39.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:38:39.052+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:38:39.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:38:39.062+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:38:39.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:38:39.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-30T12:39:09.563+0000] {processor.py:157} INFO - Started process (PID=63350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:39:09.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:39:09.570+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:39:09.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:39:09.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:39:09.618+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:39:09.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:39:09.631+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:39:09.631+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:39:09.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-30T12:39:40.066+0000] {processor.py:157} INFO - Started process (PID=63375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:39:40.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:39:40.077+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:39:40.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:39:40.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:39:40.137+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:39:40.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:39:40.155+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:39:40.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:39:40.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-30T12:40:10.632+0000] {processor.py:157} INFO - Started process (PID=63400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:40:10.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:40:10.639+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:40:10.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:40:10.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:40:10.676+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:40:10.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:40:10.688+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:40:10.688+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:40:10.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-30T12:40:41.158+0000] {processor.py:157} INFO - Started process (PID=63425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:40:41.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:40:41.164+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:40:41.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:40:41.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:40:41.233+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:40:41.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:40:41.247+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:40:41.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:40:41.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-30T12:41:11.691+0000] {processor.py:157} INFO - Started process (PID=63450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:41:11.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:41:11.695+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:41:11.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:41:11.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:41:11.723+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:41:11.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:41:11.732+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:41:11.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:41:11.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T12:41:42.078+0000] {processor.py:157} INFO - Started process (PID=63475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:41:42.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:41:42.082+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:41:42.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:41:42.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:41:42.123+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:41:42.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:41:42.135+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:41:42.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:41:42.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-30T12:42:12.534+0000] {processor.py:157} INFO - Started process (PID=63500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:42:12.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:42:12.538+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:42:12.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:42:12.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:42:12.569+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:42:12.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:42:12.582+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:42:12.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:42:12.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-30T12:42:42.970+0000] {processor.py:157} INFO - Started process (PID=63525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:42:42.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:42:42.975+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:42:42.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:42:42.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:42:43.014+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:42:43.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:42:43.027+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:42:43.027+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:42:43.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-30T12:43:13.482+0000] {processor.py:157} INFO - Started process (PID=63550) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:43:13.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:43:13.485+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:43:13.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:43:13.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:43:13.512+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:43:13.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:43:13.523+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:43:13.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:43:13.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T12:43:43.953+0000] {processor.py:157} INFO - Started process (PID=63575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:43:43.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:43:43.967+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:43:43.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:43:43.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:43:44.010+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:43:44.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:43:44.023+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:43:44.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:43:44.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-30T12:44:14.497+0000] {processor.py:157} INFO - Started process (PID=63600) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:44:14.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:44:14.501+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:44:14.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:44:14.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:44:14.529+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:44:14.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:44:14.538+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:44:14.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:44:14.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T12:44:44.935+0000] {processor.py:157} INFO - Started process (PID=63625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:44:44.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:44:44.938+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:44:44.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:44:44.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:44:44.969+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:44:44.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:44:44.980+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:44:44.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:44:44.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T12:45:15.385+0000] {processor.py:157} INFO - Started process (PID=63650) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:45:15.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:45:15.390+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:45:15.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:45:15.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:45:15.429+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:45:15.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:45:15.442+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:45:15.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:45:15.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-30T12:45:45.881+0000] {processor.py:157} INFO - Started process (PID=63675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:45:45.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:45:45.884+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:45:45.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:45:45.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:45:45.915+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:45:45.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:45:45.924+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:45:45.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:45:45.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T12:46:16.280+0000] {processor.py:157} INFO - Started process (PID=63700) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:46:16.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:46:16.283+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:46:16.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:46:16.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:46:16.309+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:46:16.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:46:16.320+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:46:16.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:46:16.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-30T12:46:46.730+0000] {processor.py:157} INFO - Started process (PID=63725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:46:46.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:46:46.735+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:46:46.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:46:46.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:46:46.762+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:46:46.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:46:46.771+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:46:46.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:46:46.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-30T12:47:17.060+0000] {processor.py:157} INFO - Started process (PID=63750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:47:17.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:47:17.062+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:47:17.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:47:17.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:47:17.082+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:47:17.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:47:17.091+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:47:17.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:47:17.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-30T12:47:47.488+0000] {processor.py:157} INFO - Started process (PID=63775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:47:47.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:47:47.492+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:47:47.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:47:47.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:47:47.531+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:47:47.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:47:47.548+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:47:47.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:47:47.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-30T12:48:17.886+0000] {processor.py:157} INFO - Started process (PID=63800) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:48:17.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:48:17.889+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:48:17.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:48:17.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:48:17.919+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:48:17.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:48:17.928+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:48:17.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:48:17.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T12:48:48.310+0000] {processor.py:157} INFO - Started process (PID=63825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:48:48.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:48:48.318+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:48:48.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:48:48.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:48:48.341+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:48:48.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:48:48.351+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:48:48.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:48:48.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T12:49:18.753+0000] {processor.py:157} INFO - Started process (PID=63850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:49:18.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:49:18.756+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:49:18.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:49:18.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:49:18.787+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:49:18.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:49:18.799+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:49:18.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:49:18.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T12:49:49.203+0000] {processor.py:157} INFO - Started process (PID=63875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:49:49.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:49:49.210+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:49:49.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:49:49.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:49:49.273+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:49:49.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:49:49.285+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:49:49.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:49:49.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-30T12:50:19.709+0000] {processor.py:157} INFO - Started process (PID=63900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:50:19.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:50:19.712+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:50:19.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:50:19.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:50:19.743+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:50:19.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:50:19.754+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:50:19.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:50:19.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T12:50:50.077+0000] {processor.py:157} INFO - Started process (PID=63925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:50:50.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:50:50.081+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:50:50.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:50:50.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:50:50.115+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:50:50.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:50:50.126+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:50:50.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:50:50.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-30T12:51:20.473+0000] {processor.py:157} INFO - Started process (PID=63950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:51:20.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:51:20.476+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:51:20.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:51:20.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:51:20.503+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:51:20.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:51:20.515+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:51:20.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:51:20.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T12:51:50.930+0000] {processor.py:157} INFO - Started process (PID=63975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:51:50.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:51:50.932+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:51:50.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:51:50.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:51:50.961+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:51:50.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:51:50.972+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:51:50.972+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:51:50.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T12:52:21.359+0000] {processor.py:157} INFO - Started process (PID=64000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:52:21.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:52:21.362+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:52:21.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:52:21.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:52:21.397+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:52:21.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:52:21.408+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:52:21.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:52:21.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-30T12:52:51.766+0000] {processor.py:157} INFO - Started process (PID=64025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:52:51.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:52:51.770+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:52:51.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:52:51.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:52:51.799+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:52:51.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:52:51.809+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:52:51.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:52:51.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T12:53:22.264+0000] {processor.py:157} INFO - Started process (PID=64050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:53:22.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:53:22.268+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:53:22.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:53:22.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:53:22.299+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:53:22.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:53:22.310+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:53:22.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:53:22.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T12:53:52.740+0000] {processor.py:157} INFO - Started process (PID=64075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:53:52.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:53:52.748+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:53:52.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:53:52.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:53:52.782+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:53:52.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:53:52.794+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:53:52.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:53:52.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-30T12:54:23.153+0000] {processor.py:157} INFO - Started process (PID=64100) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:54:23.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:54:23.157+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:54:23.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:54:23.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:54:23.186+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:54:23.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:54:23.198+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:54:23.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:54:23.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T12:54:53.601+0000] {processor.py:157} INFO - Started process (PID=64125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:54:53.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:54:53.603+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:54:53.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:54:53.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:54:53.632+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:54:53.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:54:53.643+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:54:53.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:54:53.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T12:55:24.035+0000] {processor.py:157} INFO - Started process (PID=64150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:55:24.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:55:24.038+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:55:24.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:55:24.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:55:24.064+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:55:24.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:55:24.074+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:55:24.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:55:24.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-30T12:55:54.427+0000] {processor.py:157} INFO - Started process (PID=64175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:55:54.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:55:54.429+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:55:54.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:55:54.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:55:54.462+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:55:54.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:55:54.475+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:55:54.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:55:54.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-30T12:56:25.028+0000] {processor.py:157} INFO - Started process (PID=64200) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:56:25.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:56:25.033+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:56:25.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:56:25.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:56:25.073+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:56:25.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:56:25.087+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:56:25.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:56:25.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-30T12:56:55.474+0000] {processor.py:157} INFO - Started process (PID=64225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:56:55.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:56:55.477+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:56:55.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:56:55.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:56:55.511+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:56:55.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:56:55.525+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:56:55.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:56:55.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-30T12:57:26.018+0000] {processor.py:157} INFO - Started process (PID=64250) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:57:26.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:57:26.022+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:57:26.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:57:26.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:57:26.049+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:57:26.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:57:26.061+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:57:26.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:57:26.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T12:57:56.458+0000] {processor.py:157} INFO - Started process (PID=64275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:57:56.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:57:56.463+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:57:56.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:57:56.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:57:56.499+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:57:56.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:57:56.512+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:57:56.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:57:56.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-30T12:58:27.023+0000] {processor.py:157} INFO - Started process (PID=64300) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:58:27.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:58:27.026+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:58:27.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:58:27.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:58:27.053+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:58:27.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:58:27.064+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:58:27.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:58:27.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T12:58:57.526+0000] {processor.py:157} INFO - Started process (PID=64325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:58:57.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:58:57.528+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:58:57.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:58:57.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:58:57.555+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:58:57.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:58:57.567+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:58:57.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:58:57.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T12:59:28.013+0000] {processor.py:157} INFO - Started process (PID=64350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:59:28.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:59:28.016+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:59:28.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:59:28.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:59:28.047+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:59:28.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:59:28.058+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:59:28.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:59:28.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T12:59:58.527+0000] {processor.py:157} INFO - Started process (PID=64375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:59:58.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T12:59:58.531+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:59:58.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:59:58.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T12:59:58.571+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:59:58.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T12:59:58.583+0000] {logging_mixin.py:151} INFO - [2024-07-30T12:59:58.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T12:59:58.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-30T13:00:29.057+0000] {processor.py:157} INFO - Started process (PID=64400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:00:29.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:00:29.062+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:00:29.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:00:29.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:00:29.091+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:00:29.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:00:29.102+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:00:29.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:00:29.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T13:00:59.532+0000] {processor.py:157} INFO - Started process (PID=64425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:00:59.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:00:59.535+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:00:59.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:00:59.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:00:59.556+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:00:59.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:00:59.564+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:00:59.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:00:59.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-30T13:01:30.058+0000] {processor.py:157} INFO - Started process (PID=64450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:01:30.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:01:30.062+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:01:30.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:01:30.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:01:30.091+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:01:30.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:01:30.104+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:01:30.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:01:30.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-30T13:02:00.518+0000] {processor.py:157} INFO - Started process (PID=64475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:02:00.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:02:00.525+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:02:00.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:02:00.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:02:00.562+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:02:00.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:02:00.574+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:02:00.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:02:00.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-30T13:02:30.912+0000] {processor.py:157} INFO - Started process (PID=64500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:02:30.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:02:30.915+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:02:30.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:02:30.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:02:30.944+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:02:30.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:02:30.954+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:02:30.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:02:30.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T13:03:01.411+0000] {processor.py:157} INFO - Started process (PID=64525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:03:01.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:03:01.416+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:03:01.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:03:01.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:03:01.463+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:03:01.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:03:01.474+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:03:01.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:03:01.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-30T13:03:31.859+0000] {processor.py:157} INFO - Started process (PID=64550) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:03:31.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:03:31.862+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:03:31.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:03:31.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:03:31.891+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:03:31.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:03:31.902+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:03:31.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:03:31.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T13:04:02.353+0000] {processor.py:157} INFO - Started process (PID=64575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:04:02.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:04:02.356+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:04:02.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:04:02.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:04:02.384+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:04:02.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:04:02.393+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:04:02.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:04:02.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T13:04:32.806+0000] {processor.py:157} INFO - Started process (PID=64600) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:04:32.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:04:32.809+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:04:32.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:04:32.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:04:32.833+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:04:32.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:04:32.842+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:04:32.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:04:32.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-30T13:05:03.208+0000] {processor.py:157} INFO - Started process (PID=64625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:05:03.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:05:03.216+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:05:03.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:05:03.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:05:03.246+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:05:03.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:05:03.260+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:05:03.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:05:03.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-30T13:05:33.657+0000] {processor.py:157} INFO - Started process (PID=64650) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:05:33.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:05:33.662+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:05:33.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:05:33.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:05:33.703+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:05:33.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:05:33.714+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:05:33.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:05:33.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-30T13:06:04.076+0000] {processor.py:157} INFO - Started process (PID=64675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:06:04.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:06:04.080+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:06:04.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:06:04.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:06:04.112+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:06:04.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:06:04.123+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:06:04.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:06:04.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T13:06:34.576+0000] {processor.py:157} INFO - Started process (PID=64700) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:06:34.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:06:34.584+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:06:34.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:06:34.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:06:34.609+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:06:34.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:06:34.620+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:06:34.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:06:34.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T13:07:05.024+0000] {processor.py:157} INFO - Started process (PID=64725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:07:05.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:07:05.029+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:07:05.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:07:05.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:07:05.059+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:07:05.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:07:05.072+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:07:05.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:07:05.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-30T13:07:35.526+0000] {processor.py:157} INFO - Started process (PID=64750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:07:35.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:07:35.530+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:07:35.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:07:35.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:07:35.572+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:07:35.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:07:35.588+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:07:35.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:07:35.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-30T13:08:05.956+0000] {processor.py:157} INFO - Started process (PID=64775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:08:05.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:08:05.958+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:08:05.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:08:05.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:08:05.983+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:08:05.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:08:05.995+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:08:05.995+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:08:06.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-30T13:08:36.343+0000] {processor.py:157} INFO - Started process (PID=64800) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:08:36.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:08:36.346+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:08:36.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:08:36.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:08:36.374+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:08:36.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:08:36.384+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:08:36.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:08:36.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T13:09:06.863+0000] {processor.py:157} INFO - Started process (PID=64825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:09:06.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:09:06.870+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:09:06.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:09:06.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:09:06.906+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:09:06.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:09:06.920+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:09:06.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:09:06.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-30T13:09:37.342+0000] {processor.py:157} INFO - Started process (PID=64850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:09:37.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:09:37.346+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:09:37.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:09:37.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:09:37.379+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:09:37.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:09:37.389+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:09:37.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:09:37.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-30T13:10:07.839+0000] {processor.py:157} INFO - Started process (PID=64875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:10:07.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:10:07.843+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:10:07.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:10:07.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:10:07.870+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:10:07.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:10:07.881+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:10:07.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:10:07.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T13:10:38.291+0000] {processor.py:157} INFO - Started process (PID=64900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:10:38.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:10:38.298+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:10:38.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:10:38.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:10:38.352+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:10:38.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:10:38.365+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:10:38.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:10:38.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-30T13:11:08.812+0000] {processor.py:157} INFO - Started process (PID=64925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:11:08.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:11:08.815+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:11:08.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:11:08.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:11:08.843+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:11:08.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:11:08.856+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:11:08.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:11:08.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T13:11:39.293+0000] {processor.py:157} INFO - Started process (PID=64950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:11:39.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:11:39.296+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:11:39.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:11:39.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:11:39.325+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:11:39.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:11:39.337+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:11:39.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:11:39.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T13:12:09.781+0000] {processor.py:157} INFO - Started process (PID=64975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:12:09.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:12:09.784+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:12:09.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:12:09.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:12:09.814+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:12:09.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:12:09.823+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:12:09.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:12:09.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T13:12:40.270+0000] {processor.py:157} INFO - Started process (PID=65000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:12:40.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:12:40.275+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:12:40.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:12:40.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:12:40.314+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:12:40.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:12:40.325+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:12:40.325+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:12:40.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-30T13:13:10.783+0000] {processor.py:157} INFO - Started process (PID=65025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:13:10.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:13:10.788+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:13:10.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:13:10.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:13:10.819+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:13:10.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:13:10.831+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:13:10.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:13:10.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-30T13:13:41.195+0000] {processor.py:157} INFO - Started process (PID=65050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:13:41.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:13:41.197+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:13:41.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:13:41.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:13:41.226+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:13:41.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:13:41.240+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:13:41.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:13:41.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T13:14:11.664+0000] {processor.py:157} INFO - Started process (PID=65075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:14:11.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:14:11.667+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:14:11.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:14:11.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:14:11.696+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:14:11.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:14:11.708+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:14:11.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:14:11.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T13:14:42.126+0000] {processor.py:157} INFO - Started process (PID=65100) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:14:42.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:14:42.130+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:14:42.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:14:42.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:14:42.157+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:14:42.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:14:42.168+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:14:42.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:14:42.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T13:15:12.512+0000] {processor.py:157} INFO - Started process (PID=65125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:15:12.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:15:12.514+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:15:12.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:15:12.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:15:12.544+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:15:12.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:15:12.556+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:15:12.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:15:12.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T13:15:43.076+0000] {processor.py:157} INFO - Started process (PID=65150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:15:43.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:15:43.080+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:15:43.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:15:43.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:15:43.116+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:15:43.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:15:43.126+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:15:43.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:15:43.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-30T13:16:13.493+0000] {processor.py:157} INFO - Started process (PID=65175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:16:13.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:16:13.496+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:16:13.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:16:13.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:16:13.524+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:16:13.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:16:13.538+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:16:13.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:16:13.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T13:16:43.977+0000] {processor.py:157} INFO - Started process (PID=65200) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:16:43.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:16:43.980+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:16:43.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:16:43.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:16:44.007+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:16:44.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:16:44.017+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:16:44.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:16:44.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-30T13:17:14.443+0000] {processor.py:157} INFO - Started process (PID=65225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:17:14.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:17:14.450+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:17:14.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:17:14.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:17:14.483+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:17:14.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:17:14.492+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:17:14.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:17:14.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-30T13:17:44.894+0000] {processor.py:157} INFO - Started process (PID=65250) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:17:44.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:17:44.897+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:17:44.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:17:44.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:17:44.924+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:17:44.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:17:44.935+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:17:44.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:17:44.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T13:18:15.358+0000] {processor.py:157} INFO - Started process (PID=65275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:18:15.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:18:15.362+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:18:15.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:18:15.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:18:15.383+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:18:15.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:18:15.393+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:18:15.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:18:15.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-30T13:18:45.787+0000] {processor.py:157} INFO - Started process (PID=65300) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:18:45.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:18:45.791+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:18:45.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:18:45.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:18:45.818+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:18:45.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:18:45.828+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:18:45.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:18:45.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T13:19:16.295+0000] {processor.py:157} INFO - Started process (PID=65325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:19:16.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:19:16.301+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:19:16.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:19:16.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:19:16.331+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:19:16.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:19:16.345+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:19:16.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:19:16.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-30T13:19:46.679+0000] {processor.py:157} INFO - Started process (PID=65350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:19:46.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:19:46.685+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:19:46.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:19:46.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:19:46.718+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:19:46.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:19:46.728+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:19:46.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:19:46.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-30T13:20:17.169+0000] {processor.py:157} INFO - Started process (PID=65375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:20:17.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:20:17.174+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:20:17.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:20:17.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:20:17.212+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:20:17.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:20:17.224+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:20:17.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:20:17.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-30T13:20:47.583+0000] {processor.py:157} INFO - Started process (PID=65400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:20:47.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:20:47.586+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:20:47.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:20:47.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:20:47.613+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:20:47.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:20:47.622+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:20:47.622+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:20:47.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-30T13:21:18.061+0000] {processor.py:157} INFO - Started process (PID=65425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:21:18.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:21:18.064+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:21:18.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:21:18.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:21:18.093+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:21:18.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:21:18.105+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:21:18.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:21:18.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T13:21:48.540+0000] {processor.py:157} INFO - Started process (PID=65450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:21:48.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:21:48.542+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:21:48.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:21:48.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:21:48.561+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:21:48.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:21:48.569+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:21:48.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:21:48.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.039 seconds
[2024-07-30T13:22:18.931+0000] {processor.py:157} INFO - Started process (PID=65475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:22:18.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:22:18.934+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:22:18.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:22:18.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:22:18.959+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:22:18.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:22:18.969+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:22:18.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:22:18.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-30T13:22:49.420+0000] {processor.py:157} INFO - Started process (PID=65500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:22:49.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:22:49.424+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:22:49.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:22:49.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:22:49.467+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:22:49.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:22:49.479+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:22:49.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:22:49.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-30T13:23:19.946+0000] {processor.py:157} INFO - Started process (PID=65525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:23:19.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:23:19.949+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:23:19.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:23:19.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:23:19.978+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:23:19.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:23:19.988+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:23:19.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:23:19.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T13:23:50.484+0000] {processor.py:157} INFO - Started process (PID=65550) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:23:50.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:23:50.487+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:23:50.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:23:50.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:23:50.516+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:23:50.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:23:50.527+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:23:50.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:23:50.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T13:24:20.984+0000] {processor.py:157} INFO - Started process (PID=65575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:24:20.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:24:20.991+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:24:20.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:24:21.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:24:21.029+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:24:21.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:24:21.041+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:24:21.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:24:21.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-30T13:24:51.476+0000] {processor.py:157} INFO - Started process (PID=65600) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:24:51.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:24:51.480+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:24:51.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:24:51.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:24:51.505+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:24:51.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:24:51.515+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:24:51.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:24:51.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T13:25:21.879+0000] {processor.py:157} INFO - Started process (PID=65625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:25:21.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:25:21.881+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:25:21.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:25:21.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:25:21.907+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:25:21.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:25:21.918+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:25:21.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:25:21.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-30T13:25:52.325+0000] {processor.py:157} INFO - Started process (PID=65650) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:25:52.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:25:52.327+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:25:52.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:25:52.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:25:52.356+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:25:52.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:25:52.366+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:25:52.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:25:52.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T13:26:22.819+0000] {processor.py:157} INFO - Started process (PID=65675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:26:22.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:26:22.822+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:26:22.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:26:22.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:26:22.850+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:26:22.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:26:22.862+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:26:22.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:26:22.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T13:26:53.355+0000] {processor.py:157} INFO - Started process (PID=65700) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:26:53.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:26:53.361+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:26:53.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:26:53.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:26:53.386+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:26:53.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:26:53.396+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:26:53.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:26:53.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-30T13:27:23.796+0000] {processor.py:157} INFO - Started process (PID=65725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:27:23.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:27:23.799+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:27:23.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:27:23.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:27:23.829+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:27:23.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:27:23.842+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:27:23.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:27:23.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T13:27:54.243+0000] {processor.py:157} INFO - Started process (PID=65750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:27:54.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:27:54.246+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:27:54.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:27:54.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:27:54.275+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:27:54.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:27:54.284+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:27:54.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:27:54.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T13:28:24.669+0000] {processor.py:157} INFO - Started process (PID=65775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:28:24.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:28:24.672+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:28:24.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:28:24.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:28:24.705+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:28:24.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:28:24.715+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:28:24.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:28:24.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-30T13:28:55.071+0000] {processor.py:157} INFO - Started process (PID=65800) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:28:55.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:28:55.075+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:28:55.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:28:55.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:28:55.106+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:28:55.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:28:55.119+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:28:55.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:28:55.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-30T13:29:25.515+0000] {processor.py:157} INFO - Started process (PID=65825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:29:25.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:29:25.518+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:29:25.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:29:25.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:29:25.546+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:29:25.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:29:25.555+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:29:25.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:29:25.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T13:29:55.980+0000] {processor.py:157} INFO - Started process (PID=65850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:29:55.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:29:55.983+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:29:55.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:29:55.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:29:56.008+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:29:56.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:29:56.018+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:29:56.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:29:56.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-30T13:30:26.371+0000] {processor.py:157} INFO - Started process (PID=65875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:30:26.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:30:26.376+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:30:26.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:30:26.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:30:26.405+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:30:26.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:30:26.417+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:30:26.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:30:26.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T13:30:56.867+0000] {processor.py:157} INFO - Started process (PID=65900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:30:56.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:30:56.869+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:30:56.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:30:56.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:30:56.898+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:30:56.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:30:56.908+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:30:56.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:30:56.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T13:31:27.303+0000] {processor.py:157} INFO - Started process (PID=65925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:31:27.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:31:27.307+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:31:27.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:31:27.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:31:27.334+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:31:27.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:31:27.346+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:31:27.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:31:27.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T13:31:57.804+0000] {processor.py:157} INFO - Started process (PID=65950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:31:57.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:31:57.806+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:31:57.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:31:57.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:31:57.835+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:31:57.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:31:57.844+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:31:57.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:31:57.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-30T13:32:28.232+0000] {processor.py:157} INFO - Started process (PID=65975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:32:28.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:32:28.234+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:32:28.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:32:28.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:32:28.260+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:32:28.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:32:28.270+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:32:28.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:32:28.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-30T13:32:58.691+0000] {processor.py:157} INFO - Started process (PID=66000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:32:58.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:32:58.697+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:32:58.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:32:58.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:32:58.738+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:32:58.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:32:58.751+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:32:58.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:32:58.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-30T13:33:29.173+0000] {processor.py:157} INFO - Started process (PID=66025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:33:29.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:33:29.176+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:33:29.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:33:29.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:33:29.203+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:33:29.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:33:29.214+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:33:29.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:33:29.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-30T13:33:59.640+0000] {processor.py:157} INFO - Started process (PID=66050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:33:59.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:33:59.645+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:33:59.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:33:59.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:33:59.702+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:33:59.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:33:59.717+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:33:59.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:33:59.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-30T13:34:30.110+0000] {processor.py:157} INFO - Started process (PID=66075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:34:30.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:34:30.117+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:34:30.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:34:30.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:34:30.157+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:34:30.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:34:30.169+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:34:30.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:34:30.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-30T13:35:00.652+0000] {processor.py:157} INFO - Started process (PID=66100) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:35:00.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:35:00.655+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:35:00.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:35:00.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:35:00.682+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:35:00.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:35:00.693+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:35:00.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:35:00.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T13:35:31.082+0000] {processor.py:157} INFO - Started process (PID=66125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:35:31.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:35:31.086+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:35:31.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:35:31.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:35:31.118+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:35:31.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:35:31.129+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:35:31.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:35:31.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-30T13:36:01.459+0000] {processor.py:157} INFO - Started process (PID=66150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:36:01.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:36:01.464+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:36:01.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:36:01.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:36:01.501+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:36:01.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:36:01.512+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:36:01.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:36:01.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-30T13:36:31.927+0000] {processor.py:157} INFO - Started process (PID=66175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:36:31.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:36:31.929+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:36:31.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:36:31.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:36:31.958+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:36:31.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:36:31.970+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:36:31.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:36:31.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T13:37:02.357+0000] {processor.py:157} INFO - Started process (PID=66200) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:37:02.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:37:02.361+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:37:02.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:37:02.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:37:02.392+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:37:02.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:37:02.404+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:37:02.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:37:02.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-30T13:37:32.836+0000] {processor.py:157} INFO - Started process (PID=66225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:37:32.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:37:32.843+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:37:32.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:37:32.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:37:32.878+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:37:32.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:37:32.890+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:37:32.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:37:32.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-30T13:38:03.373+0000] {processor.py:157} INFO - Started process (PID=66250) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:38:03.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:38:03.377+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:38:03.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:38:03.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:38:03.416+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:38:03.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:38:03.426+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:38:03.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:38:03.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-30T13:38:33.911+0000] {processor.py:157} INFO - Started process (PID=66275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:38:33.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:38:33.918+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:38:33.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:38:33.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:38:33.955+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:38:33.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:38:33.967+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:38:33.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:38:33.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-30T13:39:04.384+0000] {processor.py:157} INFO - Started process (PID=66300) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:39:04.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:39:04.387+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:39:04.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:39:04.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:39:04.422+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:39:04.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:39:04.434+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:39:04.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:39:04.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-30T13:39:34.817+0000] {processor.py:157} INFO - Started process (PID=66325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:39:34.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:39:34.822+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:39:34.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:39:34.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:39:34.864+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:39:34.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:39:34.881+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:39:34.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:39:34.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-30T13:40:05.389+0000] {processor.py:157} INFO - Started process (PID=66350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:40:05.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:40:05.392+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:40:05.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:40:05.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:40:05.446+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:40:05.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:40:05.461+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:40:05.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:40:05.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-30T13:40:35.929+0000] {processor.py:157} INFO - Started process (PID=66375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:40:35.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:40:35.933+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:40:35.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:40:35.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:40:35.966+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:40:35.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:40:35.975+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:40:35.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:40:35.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-30T13:41:06.433+0000] {processor.py:157} INFO - Started process (PID=66400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:41:06.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:41:06.437+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:41:06.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:41:06.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:41:06.473+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:41:06.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:41:06.484+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:41:06.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:41:06.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-30T13:41:36.948+0000] {processor.py:157} INFO - Started process (PID=66425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:41:36.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:41:36.953+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:41:36.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:41:36.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:41:36.986+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:41:36.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:41:36.998+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:41:36.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:41:37.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-30T13:42:07.427+0000] {processor.py:157} INFO - Started process (PID=66450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:42:07.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:42:07.432+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:42:07.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:42:07.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:42:07.464+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:42:07.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:42:07.477+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:42:07.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:42:07.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-30T13:42:37.901+0000] {processor.py:157} INFO - Started process (PID=66475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:42:37.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:42:37.904+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:42:37.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:42:37.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:42:37.939+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:42:37.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:42:37.950+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:42:37.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:42:37.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-30T13:43:08.461+0000] {processor.py:157} INFO - Started process (PID=66500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:43:08.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:43:08.465+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:43:08.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:43:08.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:43:08.500+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:43:08.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:43:08.512+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:43:08.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:43:08.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-30T13:43:38.859+0000] {processor.py:157} INFO - Started process (PID=66525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:43:38.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:43:38.864+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:43:38.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:43:38.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:43:38.898+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:43:38.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:43:38.908+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:43:38.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:43:38.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-30T13:44:09.313+0000] {processor.py:157} INFO - Started process (PID=66550) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:44:09.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:44:09.317+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:44:09.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:44:09.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:44:09.342+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:44:09.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:44:09.352+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:44:09.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:44:09.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-30T13:44:39.787+0000] {processor.py:157} INFO - Started process (PID=66575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:44:39.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:44:39.792+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:44:39.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:44:39.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:44:39.849+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:44:39.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:44:39.863+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:44:39.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:44:39.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-30T13:45:10.305+0000] {processor.py:157} INFO - Started process (PID=66600) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:45:10.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:45:10.311+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:45:10.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:45:10.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:45:10.342+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:45:10.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:45:10.352+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:45:10.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:45:10.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T13:45:40.754+0000] {processor.py:157} INFO - Started process (PID=66625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:45:40.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:45:40.759+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:45:40.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:45:40.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:45:40.791+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:45:40.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:45:40.802+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:45:40.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:45:40.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-30T13:46:11.211+0000] {processor.py:157} INFO - Started process (PID=66649) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:46:11.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:46:11.216+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:46:11.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:46:11.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:46:11.243+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:46:11.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:46:11.251+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:46:11.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:46:11.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T13:46:41.629+0000] {processor.py:157} INFO - Started process (PID=66675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:46:41.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:46:41.635+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:46:41.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:46:41.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:46:41.665+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:46:41.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:46:41.674+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:46:41.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:46:41.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T13:47:11.978+0000] {processor.py:157} INFO - Started process (PID=66700) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:47:11.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:47:11.980+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:47:11.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:47:11.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:47:12.004+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:47:12.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:47:12.014+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:47:12.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:47:12.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-30T13:47:42.366+0000] {processor.py:157} INFO - Started process (PID=66725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:47:42.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:47:42.369+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:47:42.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:47:42.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:47:42.401+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:47:42.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:47:42.411+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:47:42.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:47:42.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T13:48:12.892+0000] {processor.py:157} INFO - Started process (PID=66750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:48:12.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:48:12.896+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:48:12.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:48:12.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:48:12.935+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:48:12.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:48:12.947+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:48:12.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:48:12.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-30T13:48:43.333+0000] {processor.py:157} INFO - Started process (PID=66775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:48:43.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:48:43.337+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:48:43.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:48:43.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:48:43.365+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:48:43.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:48:43.376+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:48:43.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:48:43.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T13:49:13.846+0000] {processor.py:157} INFO - Started process (PID=66800) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:49:13.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:49:13.852+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:49:13.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:49:13.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:49:13.887+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:49:13.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:49:13.899+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:49:13.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:49:13.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-30T13:49:44.321+0000] {processor.py:157} INFO - Started process (PID=66825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:49:44.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:49:44.326+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:49:44.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:49:44.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:49:44.362+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:49:44.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:49:44.373+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:49:44.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:49:44.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-30T13:50:14.771+0000] {processor.py:157} INFO - Started process (PID=66850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:50:14.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:50:14.777+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:50:14.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:50:14.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:50:14.808+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:50:14.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:50:14.820+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:50:14.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:50:14.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-30T13:50:45.251+0000] {processor.py:157} INFO - Started process (PID=66875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:50:45.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:50:45.256+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:50:45.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:50:45.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:50:45.289+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:50:45.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:50:45.299+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:50:45.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:50:45.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-30T13:51:15.699+0000] {processor.py:157} INFO - Started process (PID=66900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:51:15.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:51:15.704+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:51:15.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:51:15.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:51:15.739+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:51:15.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:51:15.749+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:51:15.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:51:15.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-30T13:51:46.154+0000] {processor.py:157} INFO - Started process (PID=66925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:51:46.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:51:46.159+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:51:46.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:51:46.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:51:46.209+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:51:46.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:51:46.234+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:51:46.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:51:46.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-30T13:52:16.732+0000] {processor.py:157} INFO - Started process (PID=66950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:52:16.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:52:16.734+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:52:16.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:52:16.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:52:16.762+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:52:16.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:52:16.771+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:52:16.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:52:16.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-30T13:52:47.220+0000] {processor.py:157} INFO - Started process (PID=66975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:52:47.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:52:47.224+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:52:47.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:52:47.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:52:47.251+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:52:47.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:52:47.259+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:52:47.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:52:47.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-30T13:53:17.653+0000] {processor.py:157} INFO - Started process (PID=67000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:53:17.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:53:17.658+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:53:17.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:53:17.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:53:17.694+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:53:17.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:53:17.707+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:53:17.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:53:17.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-30T13:53:48.204+0000] {processor.py:157} INFO - Started process (PID=67025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:53:48.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:53:48.210+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:53:48.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:53:48.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:53:48.236+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:53:48.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:53:48.247+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:53:48.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:53:48.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T13:54:18.746+0000] {processor.py:157} INFO - Started process (PID=67050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:54:18.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:54:18.750+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:54:18.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:54:18.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:54:18.796+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:54:18.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:54:18.811+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:54:18.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:54:18.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-30T13:54:49.295+0000] {processor.py:157} INFO - Started process (PID=67075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:54:49.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:54:49.302+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:54:49.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:54:49.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:54:49.337+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:54:49.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:54:49.350+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:54:49.349+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:54:49.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-30T13:55:19.799+0000] {processor.py:157} INFO - Started process (PID=67100) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:55:19.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:55:19.802+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:55:19.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:55:19.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:55:19.830+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:55:19.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:55:19.840+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:55:19.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:55:19.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T13:55:50.344+0000] {processor.py:157} INFO - Started process (PID=67125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:55:50.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:55:50.348+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:55:50.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:55:50.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:55:50.383+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:55:50.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:55:50.395+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:55:50.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:55:50.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-30T13:56:20.778+0000] {processor.py:157} INFO - Started process (PID=67150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:56:20.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:56:20.784+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:56:20.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:56:20.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:56:20.819+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:56:20.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:56:20.831+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:56:20.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:56:20.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-30T13:56:51.341+0000] {processor.py:157} INFO - Started process (PID=67175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:56:51.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:56:51.345+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:56:51.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:56:51.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:56:51.372+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:56:51.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:56:51.382+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:56:51.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:56:51.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T13:57:21.763+0000] {processor.py:157} INFO - Started process (PID=67200) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:57:21.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:57:21.768+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:57:21.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:57:21.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:57:21.805+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:57:21.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:57:21.816+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:57:21.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:57:21.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-30T13:57:52.296+0000] {processor.py:157} INFO - Started process (PID=67225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:57:52.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:57:52.299+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:57:52.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:57:52.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:57:52.329+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:57:52.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:57:52.342+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:57:52.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:57:52.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-30T13:58:22.698+0000] {processor.py:157} INFO - Started process (PID=67250) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:58:22.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:58:22.700+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:58:22.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:58:22.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:58:22.732+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:58:22.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:58:22.744+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:58:22.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:58:22.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-30T13:58:53.135+0000] {processor.py:157} INFO - Started process (PID=67275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:58:53.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:58:53.138+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:58:53.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:58:53.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:58:53.165+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:58:53.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:58:53.176+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:58:53.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:58:53.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T13:59:23.592+0000] {processor.py:157} INFO - Started process (PID=67300) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:59:23.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:59:23.596+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:59:23.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:59:23.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:59:23.628+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:59:23.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:59:23.639+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:59:23.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:59:23.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T13:59:54.120+0000] {processor.py:157} INFO - Started process (PID=67325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:59:54.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T13:59:54.124+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:59:54.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:59:54.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T13:59:54.159+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:59:54.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T13:59:54.174+0000] {logging_mixin.py:151} INFO - [2024-07-30T13:59:54.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T13:59:54.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-30T14:00:24.622+0000] {processor.py:157} INFO - Started process (PID=67350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:00:24.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:00:24.627+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:00:24.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:00:24.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:00:24.657+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:00:24.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:00:24.667+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:00:24.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:00:24.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T14:00:55.011+0000] {processor.py:157} INFO - Started process (PID=67375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:00:55.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:00:55.013+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:00:55.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:00:55.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:00:55.048+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:00:55.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:00:55.057+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:00:55.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:00:55.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T14:01:25.615+0000] {processor.py:157} INFO - Started process (PID=67400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:01:25.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:01:25.621+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:01:25.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:01:25.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:01:25.664+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:01:25.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:01:25.677+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:01:25.677+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:01:26.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.437 seconds
[2024-07-30T14:01:56.556+0000] {processor.py:157} INFO - Started process (PID=67425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:01:56.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:01:56.561+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:01:56.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:01:56.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:01:56.638+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:01:56.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:01:56.654+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:01:56.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:01:56.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-07-30T14:02:27.039+0000] {processor.py:157} INFO - Started process (PID=67450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:02:27.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:02:27.042+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:02:27.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:02:27.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:02:27.070+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:02:27.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:02:27.081+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:02:27.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:02:27.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T14:02:57.580+0000] {processor.py:157} INFO - Started process (PID=67475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:02:57.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:02:57.587+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:02:57.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:02:57.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:02:57.633+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:02:57.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:02:57.645+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:02:57.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:02:57.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-30T14:03:28.079+0000] {processor.py:157} INFO - Started process (PID=67500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:03:28.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:03:28.085+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:03:28.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:03:28.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:03:28.112+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:03:28.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:03:28.123+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:03:28.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:03:28.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T14:03:58.546+0000] {processor.py:157} INFO - Started process (PID=67525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:03:58.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:03:58.552+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:03:58.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:03:58.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:03:58.609+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:03:58.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:03:58.624+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:03:58.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:03:58.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-07-30T14:04:29.056+0000] {processor.py:157} INFO - Started process (PID=67550) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:04:29.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:04:29.061+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:04:29.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:04:29.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:04:29.092+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:04:29.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:04:29.104+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:04:29.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:04:29.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-30T14:04:59.482+0000] {processor.py:157} INFO - Started process (PID=67575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:04:59.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:04:59.486+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:04:59.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:04:59.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:04:59.543+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:04:59.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:04:59.556+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:04:59.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:04:59.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-30T14:05:29.932+0000] {processor.py:157} INFO - Started process (PID=67600) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:05:29.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:05:29.935+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:05:29.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:05:29.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:05:29.963+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:05:29.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:05:29.974+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:05:29.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:05:29.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T14:06:00.413+0000] {processor.py:157} INFO - Started process (PID=67625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:06:00.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:06:00.418+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:06:00.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:06:00.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:06:00.465+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:06:00.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:06:00.482+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:06:00.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:06:00.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-30T14:06:30.838+0000] {processor.py:157} INFO - Started process (PID=67650) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:06:30.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:06:30.842+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:06:30.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:06:30.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:06:30.869+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:06:30.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:06:30.879+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:06:30.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:06:30.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T14:07:01.313+0000] {processor.py:157} INFO - Started process (PID=67675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:07:01.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:07:01.316+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:07:01.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:07:01.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:07:01.345+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:07:01.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:07:01.356+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:07:01.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:07:01.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T14:07:31.774+0000] {processor.py:157} INFO - Started process (PID=67700) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:07:31.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:07:31.783+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:07:31.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:07:31.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:07:31.809+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:07:31.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:07:31.819+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:07:31.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:07:31.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-30T14:08:02.139+0000] {processor.py:157} INFO - Started process (PID=67725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:08:02.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:08:02.143+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:08:02.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:08:02.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:08:02.183+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:08:02.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:08:02.197+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:08:02.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:08:02.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-30T14:08:32.681+0000] {processor.py:157} INFO - Started process (PID=67750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:08:32.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:08:32.684+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:08:32.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:08:32.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:08:32.713+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:08:32.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:08:32.722+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:08:32.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:08:32.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T14:09:03.093+0000] {processor.py:157} INFO - Started process (PID=67774) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:09:03.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:09:03.098+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:09:03.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:09:03.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:09:03.146+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:09:03.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:09:03.158+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:09:03.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:09:03.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-30T14:09:33.517+0000] {processor.py:157} INFO - Started process (PID=67800) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:09:33.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:09:33.527+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:09:33.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:09:33.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:09:33.575+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:09:33.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:09:33.588+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:09:33.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:09:33.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-30T14:10:04.096+0000] {processor.py:157} INFO - Started process (PID=67824) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:10:04.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:10:04.102+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:10:04.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:10:04.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:10:04.180+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:10:04.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:10:04.195+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:10:04.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:10:04.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.274 seconds
[2024-07-30T14:10:35.036+0000] {processor.py:157} INFO - Started process (PID=67849) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:10:35.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:10:35.047+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:10:35.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:10:35.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:10:35.136+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:10:35.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:10:35.151+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:10:35.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:10:35.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-07-30T14:11:05.651+0000] {processor.py:157} INFO - Started process (PID=67875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:11:05.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:11:05.657+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:11:05.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:11:05.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:11:05.695+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:11:05.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:11:05.707+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:11:05.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:11:05.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-30T14:11:36.076+0000] {processor.py:157} INFO - Started process (PID=67900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:11:36.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:11:36.079+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:11:36.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:11:36.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:11:36.100+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:11:36.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:11:36.110+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:11:36.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:11:36.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-30T14:12:06.537+0000] {processor.py:157} INFO - Started process (PID=67925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:12:06.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:12:06.543+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:12:06.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:12:06.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:12:06.572+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:12:06.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:12:06.584+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:12:06.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:12:06.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T14:12:37.003+0000] {processor.py:157} INFO - Started process (PID=67950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:12:37.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:12:37.008+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:12:37.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:12:37.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:12:37.046+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:12:37.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:12:37.058+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:12:37.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:12:37.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-30T14:13:07.499+0000] {processor.py:157} INFO - Started process (PID=67975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:13:07.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:13:07.502+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:13:07.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:13:07.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:13:07.529+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:13:07.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:13:07.540+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:13:07.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:13:07.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.187 seconds
[2024-07-30T14:13:38.192+0000] {processor.py:157} INFO - Started process (PID=68000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:13:38.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:13:38.195+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:13:38.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:13:38.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:13:38.225+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:13:38.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:13:38.238+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:13:38.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:13:38.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T14:14:08.645+0000] {processor.py:157} INFO - Started process (PID=68025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:14:08.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:14:08.649+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:14:08.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:14:08.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:14:08.677+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:14:08.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:14:08.688+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:14:08.688+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:14:08.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T14:14:39.091+0000] {processor.py:157} INFO - Started process (PID=68050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:14:39.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:14:39.096+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:14:39.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:14:39.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:14:39.125+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:14:39.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:14:39.135+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:14:39.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:14:39.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T14:15:09.601+0000] {processor.py:157} INFO - Started process (PID=68075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:15:09.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:15:09.605+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:15:09.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:15:09.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:15:09.638+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:15:09.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:15:09.650+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:15:09.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:15:09.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-30T14:15:40.096+0000] {processor.py:157} INFO - Started process (PID=68100) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:15:40.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:15:40.101+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:15:40.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:15:40.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:15:40.127+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:15:40.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:15:40.137+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:15:40.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:15:40.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-30T14:16:10.501+0000] {processor.py:157} INFO - Started process (PID=68125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:16:10.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:16:10.504+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:16:10.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:16:10.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:16:10.531+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:16:10.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:16:10.544+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:16:10.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:16:10.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T14:16:40.919+0000] {processor.py:157} INFO - Started process (PID=68150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:16:40.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:16:40.923+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:16:40.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:16:40.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:16:40.950+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:16:40.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:16:40.960+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:16:40.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:16:40.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-30T14:17:11.367+0000] {processor.py:157} INFO - Started process (PID=68175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:17:11.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:17:11.370+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:17:11.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:17:11.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:17:11.398+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:17:11.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:17:11.411+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:17:11.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:17:11.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T14:17:41.899+0000] {processor.py:157} INFO - Started process (PID=68200) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:17:41.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:17:41.908+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:17:41.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:17:41.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:17:41.952+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:17:41.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:17:41.968+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:17:41.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:17:41.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-30T14:18:12.353+0000] {processor.py:157} INFO - Started process (PID=68225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:18:12.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:18:12.356+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:18:12.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:18:12.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:18:12.379+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:18:12.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:18:12.389+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:18:12.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:18:12.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-30T14:18:42.793+0000] {processor.py:157} INFO - Started process (PID=68250) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:18:42.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:18:42.796+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:18:42.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:18:42.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:18:42.826+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:18:42.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:18:42.836+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:18:42.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:18:42.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.196 seconds
[2024-07-30T14:19:13.537+0000] {processor.py:157} INFO - Started process (PID=68275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:19:13.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:19:13.540+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:19:13.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:19:13.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:19:13.579+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:19:13.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:19:13.591+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:19:13.591+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:19:13.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-30T14:19:44.039+0000] {processor.py:157} INFO - Started process (PID=68300) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:19:44.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:19:44.043+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:19:44.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:19:44.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:19:44.077+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:19:44.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:19:44.089+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:19:44.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:19:44.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-30T14:20:14.493+0000] {processor.py:157} INFO - Started process (PID=68325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:20:14.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:20:14.497+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:20:14.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:20:14.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:20:14.526+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:20:14.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:20:14.536+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:20:14.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:20:14.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T14:20:44.918+0000] {processor.py:157} INFO - Started process (PID=68350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:20:44.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:20:44.921+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:20:44.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:20:44.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:20:44.950+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:20:44.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:20:44.960+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:20:44.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:20:44.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T14:21:15.353+0000] {processor.py:157} INFO - Started process (PID=68375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:21:15.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:21:15.358+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:21:15.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:21:15.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:21:15.399+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:21:15.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:21:15.413+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:21:15.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:21:15.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-30T14:21:45.913+0000] {processor.py:157} INFO - Started process (PID=68400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:21:45.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:21:45.920+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:21:45.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:21:45.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:21:45.987+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:21:45.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:21:46.130+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:21:46.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:21:46.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.233 seconds
[2024-07-30T14:22:16.685+0000] {processor.py:157} INFO - Started process (PID=68423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:22:16.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:22:16.691+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:22:16.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:22:16.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:22:16.741+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:22:16.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:22:16.754+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:22:16.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:22:16.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-30T14:22:47.275+0000] {processor.py:157} INFO - Started process (PID=68450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:22:47.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:22:47.287+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:22:47.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:22:47.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:22:47.353+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:22:47.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:22:47.370+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:22:47.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:22:47.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-30T14:23:17.868+0000] {processor.py:157} INFO - Started process (PID=68475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:23:17.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:23:17.879+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:23:17.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:23:17.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:23:17.927+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:23:17.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:23:17.939+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:23:17.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:23:17.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-30T14:23:48.373+0000] {processor.py:157} INFO - Started process (PID=68500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:23:48.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:23:48.376+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:23:48.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:23:48.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:23:48.406+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:23:48.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:23:48.417+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:23:48.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:23:48.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T14:24:18.858+0000] {processor.py:157} INFO - Started process (PID=68525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:24:18.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:24:18.868+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:24:18.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:24:18.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:24:18.979+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:24:18.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:24:19.068+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:24:19.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:24:19.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.503 seconds
[2024-07-30T14:24:49.980+0000] {processor.py:157} INFO - Started process (PID=68550) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:24:49.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:24:49.987+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:24:49.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:24:50.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:24:50.046+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:24:50.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:24:50.248+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:24:50.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:24:50.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.302 seconds
[2024-07-30T14:25:20.763+0000] {processor.py:157} INFO - Started process (PID=68575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:25:20.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:25:20.774+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:25:20.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:25:20.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:25:20.842+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:25:20.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:25:20.860+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:25:20.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:25:20.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-30T14:25:51.311+0000] {processor.py:157} INFO - Started process (PID=68599) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:25:51.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:25:51.325+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:25:51.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:25:51.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:25:51.393+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:25:51.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:25:51.407+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:25:51.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:25:51.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-30T14:26:21.915+0000] {processor.py:157} INFO - Started process (PID=68625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:26:21.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:26:21.926+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:26:21.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:26:21.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:26:21.982+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:26:21.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:26:22.006+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:26:22.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:26:22.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-30T14:26:52.336+0000] {processor.py:157} INFO - Started process (PID=68650) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:26:52.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:26:52.338+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:26:52.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:26:52.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:26:52.365+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:26:52.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:26:52.376+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:26:52.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:26:52.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T14:27:22.756+0000] {processor.py:157} INFO - Started process (PID=68675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:27:22.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:27:22.762+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:27:22.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:27:22.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:27:22.812+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:27:22.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:27:22.826+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:27:22.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:27:22.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.218 seconds
[2024-07-30T14:27:53.423+0000] {processor.py:157} INFO - Started process (PID=68700) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:27:53.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:27:53.428+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:27:53.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:27:53.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:27:53.469+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:27:53.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:27:53.482+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:27:53.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:27:53.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-30T14:28:24.248+0000] {processor.py:157} INFO - Started process (PID=68725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:28:24.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:28:24.257+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:28:24.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:28:24.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:28:24.335+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:28:24.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:28:24.351+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:28:24.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:28:24.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-07-30T14:28:54.724+0000] {processor.py:157} INFO - Started process (PID=68750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:28:54.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:28:54.728+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:28:54.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:28:54.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:28:54.759+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:28:54.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:28:54.771+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:28:54.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:28:54.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-30T14:29:25.260+0000] {processor.py:157} INFO - Started process (PID=68774) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:29:25.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:29:25.275+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:29:25.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:29:25.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:29:25.344+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:29:25.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:29:25.360+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:29:25.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:29:25.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-30T14:29:55.862+0000] {processor.py:157} INFO - Started process (PID=68800) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:29:55.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:29:55.878+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:29:55.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:29:55.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:29:55.934+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:29:55.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:29:55.958+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:29:55.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:29:55.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-30T14:30:26.424+0000] {processor.py:157} INFO - Started process (PID=68824) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:30:26.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:30:26.431+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:30:26.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:30:26.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:30:26.480+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:30:26.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:30:26.648+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:30:26.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:30:26.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.242 seconds
[2024-07-30T14:30:57.052+0000] {processor.py:157} INFO - Started process (PID=68850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:30:57.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:30:57.058+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:30:57.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:30:57.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:30:57.084+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:30:57.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:30:57.094+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:30:57.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:30:57.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T14:31:27.509+0000] {processor.py:157} INFO - Started process (PID=68875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:31:27.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:31:27.520+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:31:27.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:31:27.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:31:27.659+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:31:27.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:31:27.677+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:31:27.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:31:27.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.189 seconds
[2024-07-30T14:31:58.070+0000] {processor.py:157} INFO - Started process (PID=68899) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:31:58.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:31:58.079+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:31:58.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:31:58.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:31:58.156+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:31:58.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:31:58.174+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:31:58.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:31:58.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-07-30T14:32:28.642+0000] {processor.py:157} INFO - Started process (PID=68925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:32:28.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:32:28.649+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:32:28.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:32:28.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:32:28.701+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:32:28.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:32:28.717+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:32:28.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:32:28.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-30T14:32:59.148+0000] {processor.py:157} INFO - Started process (PID=68950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:32:59.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:32:59.158+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:32:59.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:32:59.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:32:59.236+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:32:59.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:32:59.254+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:32:59.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:32:59.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.281 seconds
[2024-07-30T14:33:29.979+0000] {processor.py:157} INFO - Started process (PID=68975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:33:29.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:33:29.986+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:33:29.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:33:30.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:33:30.026+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:33:30.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:33:30.149+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:33:30.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:33:30.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-07-30T14:34:00.563+0000] {processor.py:157} INFO - Started process (PID=69000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:34:00.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:34:00.572+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:34:00.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:34:00.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:34:00.597+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:34:00.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:34:00.607+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:34:00.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:34:00.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T14:34:30.952+0000] {processor.py:157} INFO - Started process (PID=69024) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:34:30.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:34:30.958+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:34:30.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:34:30.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:34:31.042+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:34:31.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:34:31.069+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:34:31.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:34:31.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-07-30T14:35:01.513+0000] {processor.py:157} INFO - Started process (PID=69050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:35:01.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:35:01.521+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:35:01.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:35:01.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:35:01.624+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:35:01.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:35:01.655+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:35:01.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:35:01.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-07-30T14:35:32.089+0000] {processor.py:157} INFO - Started process (PID=69075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:35:32.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:35:32.095+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:35:32.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:35:32.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:35:32.137+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:35:32.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:35:32.152+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:35:32.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:35:32.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-30T14:36:02.598+0000] {processor.py:157} INFO - Started process (PID=69100) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:36:02.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:36:02.632+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:36:02.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:36:02.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:36:02.699+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:36:02.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:36:02.731+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:36:02.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:36:02.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.323 seconds
[2024-07-30T14:36:33.517+0000] {processor.py:157} INFO - Started process (PID=69125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:36:33.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:36:33.533+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:36:33.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:36:33.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:36:33.600+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:36:33.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:36:33.837+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:36:33.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:36:33.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.338 seconds
[2024-07-30T14:37:04.191+0000] {processor.py:157} INFO - Started process (PID=69150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:37:04.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:37:04.198+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:37:04.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:37:04.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:37:04.249+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:37:04.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:37:04.265+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:37:04.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:37:04.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-30T14:37:34.786+0000] {processor.py:157} INFO - Started process (PID=69175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:37:34.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:37:34.811+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:37:34.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:37:34.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:37:34.854+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:37:34.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:37:34.866+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:37:34.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:37:34.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-30T14:38:05.349+0000] {processor.py:157} INFO - Started process (PID=69200) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:38:05.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:38:05.357+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:38:05.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:38:05.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:38:05.427+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:38:05.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:38:05.466+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:38:05.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:38:05.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-07-30T14:38:36.014+0000] {processor.py:157} INFO - Started process (PID=69225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:38:36.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:38:36.030+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:38:36.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:38:36.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:38:36.090+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:38:36.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:38:36.112+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:38:36.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:38:36.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.259 seconds
[2024-07-30T14:39:07.199+0000] {processor.py:157} INFO - Started process (PID=69250) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:39:07.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:39:07.216+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:39:07.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:39:07.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:39:07.266+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:39:07.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:39:07.414+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:39:07.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:39:07.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.232 seconds
[2024-07-30T14:39:37.820+0000] {processor.py:157} INFO - Started process (PID=69275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:39:37.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:39:37.824+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:39:37.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:39:37.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:39:37.854+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:39:37.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:39:37.864+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:39:37.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:39:37.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T14:40:08.288+0000] {processor.py:157} INFO - Started process (PID=69300) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:40:08.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:40:08.294+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:40:08.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:40:08.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:40:08.333+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:40:08.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:40:08.346+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:40:08.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:40:08.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-30T14:40:38.803+0000] {processor.py:157} INFO - Started process (PID=69325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:40:38.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:40:38.808+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:40:38.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:40:38.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:40:38.841+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:40:38.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:40:38.852+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:40:38.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:40:38.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-30T14:41:09.202+0000] {processor.py:157} INFO - Started process (PID=69350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:41:09.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:41:09.206+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:41:09.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:41:09.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:41:09.233+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:41:09.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:41:09.243+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:41:09.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:41:09.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T14:41:39.625+0000] {processor.py:157} INFO - Started process (PID=69375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:41:39.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:41:39.629+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:41:39.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:41:39.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:41:39.658+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:41:39.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:41:39.671+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:41:39.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:41:39.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.217 seconds
[2024-07-30T14:42:10.397+0000] {processor.py:157} INFO - Started process (PID=69400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:42:10.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:42:10.403+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:42:10.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:42:10.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:42:10.436+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:42:10.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:42:10.513+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:42:10.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:42:10.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-30T14:42:40.975+0000] {processor.py:157} INFO - Started process (PID=69425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:42:40.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:42:40.979+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:42:40.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:42:40.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:42:41.016+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:42:41.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:42:41.029+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:42:41.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:42:41.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-30T14:43:11.442+0000] {processor.py:157} INFO - Started process (PID=69450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:43:11.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:43:11.449+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:43:11.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:43:11.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:43:11.481+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:43:11.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:43:11.491+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:43:11.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:43:11.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-30T14:43:41.933+0000] {processor.py:157} INFO - Started process (PID=69475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:43:41.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:43:41.936+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:43:41.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:43:41.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:43:41.965+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:43:41.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:43:41.974+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:43:41.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:43:41.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T14:44:12.362+0000] {processor.py:157} INFO - Started process (PID=69500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:44:12.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:44:12.364+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:44:12.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:44:12.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:44:12.392+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:44:12.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:44:12.403+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:44:12.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:44:12.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T14:44:42.793+0000] {processor.py:157} INFO - Started process (PID=69525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:44:42.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:44:42.799+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:44:42.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:44:42.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:44:42.838+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:44:42.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:44:43.008+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:44:43.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:44:43.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.227 seconds
[2024-07-30T14:45:13.499+0000] {processor.py:157} INFO - Started process (PID=69550) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:45:13.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:45:13.504+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:45:13.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:45:13.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:45:13.530+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:45:13.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:45:13.608+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:45:13.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:45:13.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-30T14:45:44.169+0000] {processor.py:157} INFO - Started process (PID=69575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:45:44.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:45:44.172+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:45:44.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:45:44.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:45:44.198+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:45:44.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:45:44.207+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:45:44.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:45:44.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-30T14:46:14.638+0000] {processor.py:157} INFO - Started process (PID=69600) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:46:14.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:46:14.640+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:46:14.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:46:14.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:46:14.669+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:46:14.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:46:14.682+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:46:14.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:46:14.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T14:46:45.029+0000] {processor.py:157} INFO - Started process (PID=69625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:46:45.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:46:45.032+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:46:45.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:46:45.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:46:45.059+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:46:45.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:46:45.071+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:46:45.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:46:45.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T14:47:15.400+0000] {processor.py:157} INFO - Started process (PID=69650) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:47:15.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:47:15.403+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:47:15.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:47:15.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:47:15.432+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:47:15.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:47:15.442+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:47:15.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:47:15.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-07-30T14:47:46.090+0000] {processor.py:157} INFO - Started process (PID=69674) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:47:46.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:47:46.098+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:47:46.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:47:46.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:47:46.163+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:47:46.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:47:46.269+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:47:46.269+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:47:46.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.194 seconds
[2024-07-30T14:48:16.725+0000] {processor.py:157} INFO - Started process (PID=69700) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:48:16.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:48:16.729+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:48:16.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:48:16.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:48:16.759+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:48:16.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:48:16.772+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:48:16.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:48:16.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-30T14:48:47.147+0000] {processor.py:157} INFO - Started process (PID=69725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:48:47.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:48:47.151+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:48:47.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:48:47.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:48:47.176+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:48:47.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:48:47.188+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:48:47.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:48:47.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T14:49:17.557+0000] {processor.py:157} INFO - Started process (PID=69750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:49:17.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:49:17.563+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:49:17.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:49:17.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:49:17.600+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:49:17.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:49:17.613+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:49:17.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:49:17.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-30T14:49:48.081+0000] {processor.py:157} INFO - Started process (PID=69775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:49:48.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:49:48.084+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:49:48.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:49:48.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:49:48.116+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:49:48.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:49:48.126+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:49:48.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:49:48.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T14:50:18.485+0000] {processor.py:157} INFO - Started process (PID=69800) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:50:18.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:50:18.488+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:50:18.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:50:18.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:50:18.517+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:50:18.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:50:18.527+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:50:18.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:50:18.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.200 seconds
[2024-07-30T14:50:49.238+0000] {processor.py:157} INFO - Started process (PID=69825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:50:49.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:50:49.241+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:50:49.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:50:49.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:50:49.271+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:50:49.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:50:49.354+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:50:49.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:50:49.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-30T14:51:19.761+0000] {processor.py:157} INFO - Started process (PID=69850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:51:19.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:51:19.764+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:51:19.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:51:19.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:51:19.794+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:51:19.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:51:19.804+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:51:19.804+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:51:19.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T14:51:50.303+0000] {processor.py:157} INFO - Started process (PID=69875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:51:50.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:51:50.308+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:51:50.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:51:50.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:51:50.339+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:51:50.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:51:50.348+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:51:50.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:51:50.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T14:52:20.729+0000] {processor.py:157} INFO - Started process (PID=69900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:52:20.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:52:20.734+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:52:20.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:52:20.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:52:20.775+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:52:20.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:52:20.787+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:52:20.787+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:52:20.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-30T14:52:51.182+0000] {processor.py:157} INFO - Started process (PID=69925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:52:51.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:52:51.186+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:52:51.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:52:51.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:52:51.215+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:52:51.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:52:51.224+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:52:51.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:52:51.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T14:53:21.614+0000] {processor.py:157} INFO - Started process (PID=69950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:53:21.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:53:21.618+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:53:21.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:53:21.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:53:21.657+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:53:21.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:53:21.811+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:53:21.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:53:21.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.211 seconds
[2024-07-30T14:53:52.249+0000] {processor.py:157} INFO - Started process (PID=69975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:53:52.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:53:52.251+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:53:52.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:53:52.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:53:52.282+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:53:52.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:53:52.368+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:53:52.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:53:52.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-07-30T14:54:22.742+0000] {processor.py:157} INFO - Started process (PID=70000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:54:22.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:54:22.749+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:54:22.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:54:22.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:54:22.770+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:54:22.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:54:22.782+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:54:22.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:54:22.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T14:54:53.146+0000] {processor.py:157} INFO - Started process (PID=70025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:54:53.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:54:53.151+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:54:53.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:54:53.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:54:53.196+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:54:53.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:54:53.209+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:54:53.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:54:53.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-30T14:55:23.602+0000] {processor.py:157} INFO - Started process (PID=70050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:55:23.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:55:23.606+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:55:23.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:55:23.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:55:23.635+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:55:23.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:55:23.647+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:55:23.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:55:23.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T14:55:54.046+0000] {processor.py:157} INFO - Started process (PID=70075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:55:54.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:55:54.052+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:55:54.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:55:54.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:55:54.080+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:55:54.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:55:54.091+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:55:54.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:55:54.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.179 seconds
[2024-07-30T14:56:24.649+0000] {processor.py:157} INFO - Started process (PID=70100) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:56:24.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:56:24.656+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:56:24.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:56:24.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:56:24.711+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:56:24.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:56:24.798+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:56:24.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:56:24.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-07-30T14:56:55.231+0000] {processor.py:157} INFO - Started process (PID=70125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:56:55.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:56:55.235+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:56:55.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:56:55.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:56:55.266+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:56:55.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:56:55.400+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:56:55.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:56:55.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.182 seconds
[2024-07-30T14:57:25.780+0000] {processor.py:157} INFO - Started process (PID=70150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:57:25.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:57:25.783+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:57:25.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:57:25.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:57:25.815+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:57:25.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:57:25.829+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:57:25.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:57:25.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-30T14:57:56.249+0000] {processor.py:157} INFO - Started process (PID=70175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:57:56.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:57:56.253+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:57:56.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:57:56.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:57:56.280+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:57:56.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:57:56.290+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:57:56.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:57:56.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T14:58:26.653+0000] {processor.py:157} INFO - Started process (PID=70200) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:58:26.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:58:26.656+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:58:26.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:58:26.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:58:26.683+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:58:26.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:58:26.693+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:58:26.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:58:26.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T14:58:57.069+0000] {processor.py:157} INFO - Started process (PID=70225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:58:57.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:58:57.072+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:58:57.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:58:57.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:58:57.105+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:58:57.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:58:57.184+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:58:57.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:58:57.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-07-30T14:59:27.722+0000] {processor.py:157} INFO - Started process (PID=70250) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:59:27.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:59:27.728+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:59:27.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:59:27.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:59:27.755+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:59:27.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:59:27.834+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:59:27.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:59:27.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-30T14:59:58.410+0000] {processor.py:157} INFO - Started process (PID=70275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:59:58.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T14:59:58.419+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:59:58.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:59:58.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T14:59:58.441+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:59:58.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T14:59:58.451+0000] {logging_mixin.py:151} INFO - [2024-07-30T14:59:58.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T14:59:58.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T15:00:28.745+0000] {processor.py:157} INFO - Started process (PID=70300) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:00:28.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:00:28.747+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:00:28.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:00:28.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:00:28.772+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:00:28.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:00:28.780+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:00:28.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:00:28.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-30T15:00:59.188+0000] {processor.py:157} INFO - Started process (PID=70325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:00:59.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:00:59.191+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:00:59.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:00:59.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:00:59.219+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:00:59.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:00:59.229+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:00:59.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:00:59.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T15:01:29.602+0000] {processor.py:157} INFO - Started process (PID=70350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:01:29.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:01:29.608+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:01:29.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:01:29.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:01:29.641+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:01:29.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:01:29.651+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:01:29.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:01:29.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.203 seconds
[2024-07-30T15:02:00.207+0000] {processor.py:157} INFO - Started process (PID=70375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:02:00.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:02:00.210+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:02:00.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:02:00.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:02:00.237+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:02:00.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:02:00.317+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:02:00.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:02:00.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-30T15:02:30.733+0000] {processor.py:157} INFO - Started process (PID=70400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:02:30.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:02:30.736+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:02:30.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:02:30.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:02:30.765+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:02:30.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:02:30.841+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:02:30.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:02:30.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-30T15:03:01.267+0000] {processor.py:157} INFO - Started process (PID=70425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:03:01.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:03:01.271+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:03:01.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:03:01.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:03:01.302+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:03:01.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:03:01.312+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:03:01.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:03:01.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-30T15:03:31.737+0000] {processor.py:157} INFO - Started process (PID=70450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:03:31.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:03:31.741+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:03:31.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:03:31.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:03:31.771+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:03:31.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:03:31.781+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:03:31.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:03:31.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T15:04:02.230+0000] {processor.py:157} INFO - Started process (PID=70475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:04:02.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:04:02.237+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:04:02.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:04:02.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:04:02.274+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:04:02.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:04:02.288+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:04:02.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:04:02.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-30T15:04:32.627+0000] {processor.py:157} INFO - Started process (PID=70500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:04:32.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:04:32.631+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:04:32.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:04:32.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:04:32.662+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:04:32.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:04:32.672+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:04:32.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:04:32.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.210 seconds
[2024-07-30T15:05:03.391+0000] {processor.py:157} INFO - Started process (PID=70525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:05:03.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:05:03.396+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:05:03.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:05:03.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:05:03.436+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:05:03.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:05:03.545+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:05:03.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:05:03.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-07-30T15:05:34.000+0000] {processor.py:157} INFO - Started process (PID=70550) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:05:34.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:05:34.004+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:05:34.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:05:34.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:05:34.034+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:05:34.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:05:34.117+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:05:34.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:05:34.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-07-30T15:06:04.670+0000] {processor.py:157} INFO - Started process (PID=70575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:06:04.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:06:04.674+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:06:04.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:06:04.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:06:04.702+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:06:04.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:06:04.711+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:06:04.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:06:04.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T15:06:35.135+0000] {processor.py:157} INFO - Started process (PID=70600) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:06:35.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:06:35.139+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:06:35.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:06:35.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:06:35.175+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:06:35.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:06:35.188+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:06:35.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:06:35.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-30T15:07:05.581+0000] {processor.py:157} INFO - Started process (PID=70625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:07:05.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:07:05.584+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:07:05.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:07:05.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:07:05.614+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:07:05.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:07:05.628+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:07:05.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:07:05.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-30T15:07:36.048+0000] {processor.py:157} INFO - Started process (PID=70650) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:07:36.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:07:36.051+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:07:36.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:07:36.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:07:36.078+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:07:36.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:07:36.224+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:07:36.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:07:36.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.187 seconds
[2024-07-30T15:08:06.706+0000] {processor.py:157} INFO - Started process (PID=70675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:08:06.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:08:06.711+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:08:06.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:08:06.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:08:06.750+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:08:06.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:08:06.834+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:08:06.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:08:06.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-07-30T15:08:37.355+0000] {processor.py:157} INFO - Started process (PID=70700) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:08:37.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:08:37.358+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:08:37.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:08:37.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:08:37.460+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:08:37.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:08:37.472+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:08:37.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:08:37.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-30T15:09:07.939+0000] {processor.py:157} INFO - Started process (PID=70725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:09:07.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:09:07.942+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:09:07.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:09:07.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:09:07.971+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:09:07.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:09:07.981+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:09:07.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:09:07.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T15:09:38.372+0000] {processor.py:157} INFO - Started process (PID=70750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:09:38.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:09:38.376+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:09:38.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:09:38.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:09:38.411+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:09:38.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:09:38.421+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:09:38.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:09:38.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-30T15:10:08.822+0000] {processor.py:157} INFO - Started process (PID=70775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:10:08.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:10:08.825+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:10:08.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:10:08.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:10:08.860+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:10:08.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:10:08.871+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:10:08.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:10:09.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.183 seconds
[2024-07-30T15:10:39.893+0000] {processor.py:157} INFO - Started process (PID=70800) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:10:39.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:10:39.900+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:10:39.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:10:39.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:10:39.952+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:10:39.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:10:40.130+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:10:40.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:10:40.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.256 seconds
[2024-07-30T15:11:10.669+0000] {processor.py:157} INFO - Started process (PID=70825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:11:10.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:11:10.672+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:11:10.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:11:10.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:11:10.703+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:11:10.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:11:10.789+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:11:10.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:11:10.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-07-30T15:11:41.421+0000] {processor.py:157} INFO - Started process (PID=70850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:11:41.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:11:41.429+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:11:41.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:11:41.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:11:41.476+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:11:41.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:11:41.488+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:11:41.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:11:41.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-30T15:12:11.923+0000] {processor.py:157} INFO - Started process (PID=70875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:12:11.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:12:11.929+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:12:11.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:12:11.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:12:11.954+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:12:11.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:12:11.966+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:12:11.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:12:11.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T15:12:42.412+0000] {processor.py:157} INFO - Started process (PID=70900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:12:42.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:12:42.417+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:12:42.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:12:42.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:12:42.448+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:12:42.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:12:42.458+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:12:42.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:12:42.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-30T15:13:12.840+0000] {processor.py:157} INFO - Started process (PID=70925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:13:12.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:13:12.843+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:13:12.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:13:12.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:13:12.878+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:13:12.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:13:12.891+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:13:12.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:13:13.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.225 seconds
[2024-07-30T15:13:43.487+0000] {processor.py:157} INFO - Started process (PID=70950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:13:43.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:13:43.489+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:13:43.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:13:43.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:13:43.513+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:13:43.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:13:43.595+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:13:43.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:13:43.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-30T15:14:14.178+0000] {processor.py:157} INFO - Started process (PID=70975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:14:14.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:14:14.181+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:14:14.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:14:14.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:14:14.276+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:14:14.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:14:14.285+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:14:14.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:14:14.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-30T15:14:44.857+0000] {processor.py:157} INFO - Started process (PID=71000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:14:44.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:14:44.864+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:14:44.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:14:44.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:14:44.915+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:14:44.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:14:44.928+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:14:44.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:14:44.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-30T15:15:15.406+0000] {processor.py:157} INFO - Started process (PID=71025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:15:15.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:15:15.419+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:15:15.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:15:15.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:15:15.494+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:15:15.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:15:15.516+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:15:15.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:15:15.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-07-30T15:15:46.008+0000] {processor.py:157} INFO - Started process (PID=71050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:15:46.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:15:46.035+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:15:46.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:15:46.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:15:46.086+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:15:46.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:15:46.099+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:15:46.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:15:46.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-07-30T15:16:16.518+0000] {processor.py:157} INFO - Started process (PID=71075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:16:16.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:16:16.523+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:16:16.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:16:16.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:16:16.553+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:16:16.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:16:16.709+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:16:16.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:16:16.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.202 seconds
[2024-07-30T15:16:47.135+0000] {processor.py:157} INFO - Started process (PID=71100) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:16:47.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:16:47.140+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:16:47.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:16:47.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:16:47.182+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:16:47.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:16:47.263+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:16:47.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:16:47.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-07-30T15:17:17.664+0000] {processor.py:157} INFO - Started process (PID=71125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:17:17.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:17:17.671+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:17:17.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:17:17.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:17:17.803+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:17:17.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:17:17.810+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:17:17.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:17:17.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-07-30T15:17:48.373+0000] {processor.py:157} INFO - Started process (PID=71150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:17:48.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:17:48.376+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:17:48.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:17:48.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:17:48.405+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:17:48.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:17:48.415+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:17:48.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:17:48.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T15:18:18.749+0000] {processor.py:157} INFO - Started process (PID=71175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:18:18.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:18:18.754+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:18:18.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:18:18.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:18:18.794+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:18:18.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:18:18.806+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:18:18.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:18:18.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-30T15:18:49.197+0000] {processor.py:157} INFO - Started process (PID=71200) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:18:49.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:18:49.201+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:18:49.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:18:49.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:18:49.229+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:18:49.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:18:49.242+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:18:49.242+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:18:49.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-07-30T15:19:19.762+0000] {processor.py:157} INFO - Started process (PID=71225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:19:19.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:19:19.768+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:19:19.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:19:19.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:19:19.796+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:19:19.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:19:19.908+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:19:19.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:19:19.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-07-30T15:19:50.362+0000] {processor.py:157} INFO - Started process (PID=71250) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:19:50.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:19:50.365+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:19:50.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:19:50.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:19:50.395+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:19:50.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:19:50.473+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:19:50.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:19:50.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-30T15:20:20.837+0000] {processor.py:157} INFO - Started process (PID=71275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:20:20.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:20:20.841+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:20:20.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:20:20.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:20:20.943+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:20:20.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:20:20.951+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:20:20.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:20:20.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-07-30T15:20:51.330+0000] {processor.py:157} INFO - Started process (PID=71300) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:20:51.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:20:51.332+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:20:51.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:20:51.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:20:51.358+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:20:51.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:20:51.368+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:20:51.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:20:51.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-30T15:21:21.804+0000] {processor.py:157} INFO - Started process (PID=71325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:21:21.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:21:21.809+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:21:21.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:21:21.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:21:21.838+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:21:21.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:21:21.849+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:21:21.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:21:21.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T15:21:52.305+0000] {processor.py:157} INFO - Started process (PID=71350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:21:52.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:21:52.309+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:21:52.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:21:52.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:21:52.346+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:21:52.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:21:52.360+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:21:52.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:21:52.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-07-30T15:22:22.807+0000] {processor.py:157} INFO - Started process (PID=71375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:22:22.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:22:22.809+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:22:22.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:22:22.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:22:22.834+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:22:22.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:22:22.919+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:22:22.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:22:22.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-30T15:22:53.358+0000] {processor.py:157} INFO - Started process (PID=71400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:22:53.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:22:53.363+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:22:53.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:22:53.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:22:53.512+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:22:53.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:22:53.520+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:22:53.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:22:53.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-07-30T15:23:23.892+0000] {processor.py:157} INFO - Started process (PID=71425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:23:23.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:23:23.894+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:23:23.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:23:23.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:23:23.919+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:23:23.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:23:23.928+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:23:23.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:23:23.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-30T15:23:54.403+0000] {processor.py:157} INFO - Started process (PID=71450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:23:54.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:23:54.409+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:23:54.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:23:54.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:23:54.448+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:23:54.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:23:54.460+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:23:54.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:23:54.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-30T15:24:24.873+0000] {processor.py:157} INFO - Started process (PID=71475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:24:24.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:24:24.877+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:24:24.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:24:24.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:24:24.907+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:24:24.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:24:24.916+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:24:24.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:24:24.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T15:24:55.346+0000] {processor.py:157} INFO - Started process (PID=71500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:24:55.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:24:55.363+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:24:55.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:24:55.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:24:55.444+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:24:55.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:24:55.637+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:24:55.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:24:55.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.312 seconds
[2024-07-30T15:25:26.187+0000] {processor.py:157} INFO - Started process (PID=71525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:25:26.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:25:26.191+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:25:26.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:25:26.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:25:26.235+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:25:26.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:25:26.344+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:25:26.344+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:25:26.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-07-30T15:25:56.879+0000] {processor.py:157} INFO - Started process (PID=71550) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:25:56.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:25:56.881+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:25:56.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:25:56.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:25:57.018+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:25:57.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:25:57.026+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:25:57.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:25:57.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-07-30T15:26:27.582+0000] {processor.py:157} INFO - Started process (PID=71575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:26:27.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:26:27.586+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:26:27.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:26:27.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:26:27.628+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:26:27.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:26:27.641+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:26:27.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:26:27.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-30T15:26:58.020+0000] {processor.py:157} INFO - Started process (PID=71600) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:26:58.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:26:58.022+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:26:58.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:26:58.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:26:58.056+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:26:58.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:26:58.068+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:26:58.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:26:58.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-30T15:27:28.561+0000] {processor.py:157} INFO - Started process (PID=71625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:27:28.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:27:28.567+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:27:28.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:27:28.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:27:28.609+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:27:28.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:27:28.622+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:27:28.622+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:27:28.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.280 seconds
[2024-07-30T15:27:59.268+0000] {processor.py:157} INFO - Started process (PID=71650) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:27:59.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:27:59.271+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:27:59.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:27:59.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:27:59.308+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:27:59.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:27:59.396+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:27:59.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:27:59.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-07-30T15:28:29.853+0000] {processor.py:157} INFO - Started process (PID=71675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:28:29.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:28:29.859+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:28:29.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:28:29.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:28:29.900+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:28:29.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:28:30.010+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:28:30.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:28:30.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-07-30T15:29:00.418+0000] {processor.py:157} INFO - Started process (PID=71700) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:29:00.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:29:00.421+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:29:00.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:29:00.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:29:00.519+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:29:00.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:29:00.526+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:29:00.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:29:00.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-30T15:29:31.036+0000] {processor.py:157} INFO - Started process (PID=71725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:29:31.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:29:31.038+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:29:31.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:29:31.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:29:31.066+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:29:31.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:29:31.077+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:29:31.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:29:31.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T15:30:01.520+0000] {processor.py:157} INFO - Started process (PID=71750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:30:01.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:30:01.524+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:30:01.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:30:01.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:30:01.568+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:30:01.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:30:01.581+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:30:01.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:30:01.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-30T15:30:32.028+0000] {processor.py:157} INFO - Started process (PID=71775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:30:32.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:30:32.031+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:30:32.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:30:32.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:30:32.058+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:30:32.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:30:32.068+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:30:32.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:30:32.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.185 seconds
[2024-07-30T15:31:02.773+0000] {processor.py:157} INFO - Started process (PID=71800) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:31:02.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:31:02.776+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:31:02.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:31:02.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:31:02.803+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:31:02.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:31:02.887+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:31:02.886+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:31:02.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-30T15:31:33.330+0000] {processor.py:157} INFO - Started process (PID=71825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:31:33.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:31:33.336+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:31:33.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:31:33.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:31:33.445+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:31:33.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:31:33.453+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:31:33.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:31:33.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-07-30T15:32:04.028+0000] {processor.py:157} INFO - Started process (PID=71850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:32:04.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:32:04.040+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:32:04.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:32:04.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:32:04.232+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:32:04.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:32:04.239+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:32:04.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:32:04.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.225 seconds
[2024-07-30T15:32:34.756+0000] {processor.py:157} INFO - Started process (PID=71875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:32:34.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:32:34.759+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:32:34.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:32:34.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:32:34.794+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:32:34.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:32:34.807+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:32:34.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:32:34.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-30T15:33:05.218+0000] {processor.py:157} INFO - Started process (PID=71900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:33:05.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:33:05.223+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:33:05.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:33:05.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:33:05.278+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:33:05.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:33:05.288+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:33:05.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:33:05.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.207 seconds
[2024-07-30T15:33:35.821+0000] {processor.py:157} INFO - Started process (PID=71925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:33:35.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:33:35.826+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:33:35.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:33:35.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:33:35.857+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:33:35.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:33:35.941+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:33:35.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:33:35.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-07-30T15:34:06.355+0000] {processor.py:157} INFO - Started process (PID=71950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:34:06.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:34:06.361+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:34:06.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:34:06.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:34:06.401+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:34:06.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:34:06.580+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:34:06.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:34:06.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.239 seconds
[2024-07-30T15:34:37.031+0000] {processor.py:157} INFO - Started process (PID=71974) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:34:37.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:34:37.041+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:34:37.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:34:37.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:34:37.235+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:34:37.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:34:37.248+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:34:37.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:34:37.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.233 seconds
[2024-07-30T15:35:07.702+0000] {processor.py:157} INFO - Started process (PID=72000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:35:07.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:35:07.715+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:35:07.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:35:07.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:35:07.746+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:35:07.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:35:07.760+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:35:07.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:35:07.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-30T15:35:38.200+0000] {processor.py:157} INFO - Started process (PID=72025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:35:38.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:35:38.205+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:35:38.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:35:38.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:35:38.231+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:35:38.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:35:38.242+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:35:38.242+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:35:38.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T15:36:08.682+0000] {processor.py:157} INFO - Started process (PID=72050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:36:08.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:36:08.685+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:36:08.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:36:08.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:36:08.710+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:36:08.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:36:08.720+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:36:08.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:36:08.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.197 seconds
[2024-07-30T15:36:39.245+0000] {processor.py:157} INFO - Started process (PID=72075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:36:39.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:36:39.248+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:36:39.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:36:39.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:36:39.284+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:36:39.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:36:39.371+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:36:39.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:36:39.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-07-30T15:37:09.817+0000] {processor.py:157} INFO - Started process (PID=72100) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:37:09.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:37:09.820+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:37:09.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:37:09.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:37:09.847+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:37:09.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:37:09.957+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:37:09.957+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:37:09.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-07-30T15:37:40.471+0000] {processor.py:157} INFO - Started process (PID=72125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:37:40.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:37:40.479+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:37:40.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:37:40.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:37:40.579+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:37:40.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:37:40.587+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:37:40.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:37:40.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-30T15:38:11.066+0000] {processor.py:157} INFO - Started process (PID=72150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:38:11.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:38:11.072+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:38:11.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:38:11.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:38:11.130+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:38:11.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:38:11.142+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:38:11.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:38:11.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-30T15:38:41.545+0000] {processor.py:157} INFO - Started process (PID=72175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:38:41.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:38:41.548+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:38:41.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:38:41.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:38:41.577+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:38:41.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:38:41.587+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:38:41.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:38:41.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T15:39:11.963+0000] {processor.py:157} INFO - Started process (PID=72200) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:39:11.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:39:11.967+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:39:11.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:39:11.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:39:11.998+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:39:11.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:39:12.131+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:39:12.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:39:12.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.178 seconds
[2024-07-30T15:39:42.524+0000] {processor.py:157} INFO - Started process (PID=72225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:39:42.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:39:42.529+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:39:42.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:39:42.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:39:42.566+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:39:42.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:39:42.652+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:39:42.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:39:42.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-07-30T15:40:13.118+0000] {processor.py:157} INFO - Started process (PID=72250) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:40:13.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:40:13.121+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:40:13.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:40:13.133+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:40:13.218+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:40:13.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:40:13.225+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:40:13.225+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:40:13.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-30T15:40:43.749+0000] {processor.py:157} INFO - Started process (PID=72275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:40:43.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:40:43.752+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:40:43.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:40:43.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:40:43.886+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:40:43.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:40:43.895+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:40:43.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:40:43.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-07-30T15:41:14.361+0000] {processor.py:157} INFO - Started process (PID=72300) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:41:14.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:41:14.366+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:41:14.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:41:14.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:41:14.438+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:41:14.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:41:14.457+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:41:14.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:41:14.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-07-30T15:41:44.890+0000] {processor.py:157} INFO - Started process (PID=72325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:41:44.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:41:44.893+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:41:44.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:41:44.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:41:44.923+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:41:44.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:41:44.934+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:41:44.934+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:41:45.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-07-30T15:42:15.570+0000] {processor.py:157} INFO - Started process (PID=72350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:42:15.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:42:15.572+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:42:15.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:42:15.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:42:15.592+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:42:15.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:42:15.670+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:42:15.670+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:42:15.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-30T15:42:46.105+0000] {processor.py:157} INFO - Started process (PID=72375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:42:46.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:42:46.110+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:42:46.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:42:46.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:42:46.149+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:42:46.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:42:46.230+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:42:46.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:42:46.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-07-30T15:43:16.768+0000] {processor.py:157} INFO - Started process (PID=72400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:43:16.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:43:16.772+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:43:16.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:43:16.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:43:16.909+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:43:16.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:43:16.917+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:43:16.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:43:16.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-07-30T15:43:47.468+0000] {processor.py:157} INFO - Started process (PID=72425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:43:47.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:43:47.472+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:43:47.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:43:47.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:43:47.504+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:43:47.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:43:47.515+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:43:47.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:43:47.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-30T15:44:17.853+0000] {processor.py:157} INFO - Started process (PID=72450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:44:17.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:44:17.858+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:44:17.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:44:17.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:44:17.918+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:44:17.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:44:17.934+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:44:17.934+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:44:17.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-30T15:44:48.431+0000] {processor.py:157} INFO - Started process (PID=72475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:44:48.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:44:48.435+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:44:48.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:44:48.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:44:48.464+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:44:48.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:44:48.475+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:44:48.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:44:48.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.185 seconds
[2024-07-30T15:45:19.246+0000] {processor.py:157} INFO - Started process (PID=72500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:45:19.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:45:19.261+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:45:19.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:45:19.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:45:19.326+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:45:19.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:45:19.494+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:45:19.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:45:19.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.278 seconds
[2024-07-30T15:45:50.118+0000] {processor.py:157} INFO - Started process (PID=72525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:45:50.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:45:50.122+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:45:50.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:45:50.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:45:50.248+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:45:50.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:45:50.257+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:45:50.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:45:50.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-07-30T15:46:20.717+0000] {processor.py:157} INFO - Started process (PID=72549) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:46:20.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:46:20.723+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:46:20.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:46:20.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:46:20.947+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:46:20.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:46:20.955+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:46:20.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:46:20.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.251 seconds
[2024-07-30T15:46:51.420+0000] {processor.py:157} INFO - Started process (PID=72575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:46:51.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:46:51.424+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:46:51.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:46:51.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:46:51.454+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:46:51.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:46:51.464+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:46:51.464+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:46:51.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T15:47:21.992+0000] {processor.py:157} INFO - Started process (PID=72600) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:47:21.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:47:21.998+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:47:21.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:47:22.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:47:22.064+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:47:22.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:47:22.077+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:47:22.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:47:22.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-30T15:47:52.514+0000] {processor.py:157} INFO - Started process (PID=72625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:47:52.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:47:52.517+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:47:52.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:47:52.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:47:52.549+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:47:52.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:47:52.708+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:47:52.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:47:52.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.204 seconds
[2024-07-30T15:48:23.126+0000] {processor.py:157} INFO - Started process (PID=72650) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:48:23.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:48:23.133+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:48:23.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:48:23.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:48:23.171+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:48:23.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:48:23.252+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:48:23.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:48:23.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-07-30T15:48:53.665+0000] {processor.py:157} INFO - Started process (PID=72675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:48:53.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:48:53.666+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:48:53.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:48:53.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:48:53.764+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:48:53.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:48:53.771+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:48:53.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:48:53.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-30T15:49:24.288+0000] {processor.py:157} INFO - Started process (PID=72700) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:49:24.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:49:24.292+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:49:24.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:49:24.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:49:24.421+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:49:24.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:49:24.428+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:49:24.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:49:24.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-07-30T15:49:55.036+0000] {processor.py:157} INFO - Started process (PID=72725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:49:55.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:49:55.045+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:49:55.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:49:55.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:49:55.066+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:49:55.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:49:55.074+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:49:55.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:49:55.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-30T15:50:25.481+0000] {processor.py:157} INFO - Started process (PID=72750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:50:25.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:50:25.486+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:50:25.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:50:25.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:50:25.515+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:50:25.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:50:25.527+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:50:25.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:50:25.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-30T15:50:55.851+0000] {processor.py:157} INFO - Started process (PID=72775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:50:55.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:50:55.853+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:50:55.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:50:55.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:50:55.881+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:50:55.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:50:55.891+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:50:55.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:50:55.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-30T15:51:26.332+0000] {processor.py:157} INFO - Started process (PID=72800) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:51:26.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:51:26.338+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:51:26.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:51:26.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:51:26.373+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:51:26.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:51:26.386+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:51:26.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:51:26.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-30T15:51:56.736+0000] {processor.py:157} INFO - Started process (PID=72825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:51:56.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:51:56.742+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:51:56.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:51:56.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:51:56.778+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:51:56.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:51:56.791+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:51:56.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:51:56.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-30T15:52:27.254+0000] {processor.py:157} INFO - Started process (PID=72850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:52:27.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:52:27.259+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:52:27.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:52:27.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:52:27.292+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:52:27.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:52:27.304+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:52:27.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:52:27.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-30T15:52:57.744+0000] {processor.py:157} INFO - Started process (PID=72875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:52:57.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:52:57.748+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:52:57.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:52:57.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:52:57.818+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:52:57.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:52:57.843+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:52:57.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:52:57.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-07-30T15:53:28.182+0000] {processor.py:157} INFO - Started process (PID=72900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:53:28.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:53:28.184+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:53:28.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:53:28.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:53:28.211+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:53:28.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:53:28.222+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:53:28.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:53:28.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T15:53:58.594+0000] {processor.py:157} INFO - Started process (PID=72925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:53:58.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:53:58.599+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:53:58.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:53:58.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:53:58.639+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:53:58.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:53:58.684+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:53:58.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:53:58.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-07-30T15:54:29.089+0000] {processor.py:157} INFO - Started process (PID=72950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:54:29.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:54:29.094+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:54:29.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:54:29.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:54:29.123+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:54:29.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:54:29.134+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:54:29.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:54:29.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T15:54:59.595+0000] {processor.py:157} INFO - Started process (PID=72975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:54:59.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:54:59.601+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:54:59.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:54:59.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:54:59.645+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:54:59.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:54:59.658+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:54:59.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:54:59.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-30T15:55:30.050+0000] {processor.py:157} INFO - Started process (PID=73000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:55:30.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:55:30.054+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:55:30.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:55:30.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:55:30.088+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:55:30.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:55:30.100+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:55:30.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:55:30.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-30T15:56:00.464+0000] {processor.py:157} INFO - Started process (PID=73024) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:56:00.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:56:00.469+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:56:00.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:56:00.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:56:00.532+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:56:00.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:56:00.549+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:56:00.549+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:56:00.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-30T15:56:30.938+0000] {processor.py:157} INFO - Started process (PID=73050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:56:30.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:56:30.940+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:56:30.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:56:30.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:56:30.967+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:56:30.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:56:30.980+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:56:30.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:56:30.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T15:57:01.395+0000] {processor.py:157} INFO - Started process (PID=73075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:57:01.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:57:01.401+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:57:01.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:57:01.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:57:01.423+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:57:01.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:57:01.432+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:57:01.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:57:01.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-30T15:57:31.849+0000] {processor.py:157} INFO - Started process (PID=73100) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:57:31.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:57:31.854+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:57:31.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:57:31.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:57:31.916+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:57:31.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:57:31.931+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:57:31.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:57:31.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-30T15:58:02.340+0000] {processor.py:157} INFO - Started process (PID=73125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:58:02.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:58:02.346+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:58:02.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:58:02.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:58:02.373+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:58:02.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:58:02.385+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:58:02.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:58:02.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T15:58:32.816+0000] {processor.py:157} INFO - Started process (PID=73150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:58:32.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:58:32.821+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:58:32.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:58:32.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:58:32.868+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:58:32.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:58:32.882+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:58:32.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:58:32.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-30T15:59:03.211+0000] {processor.py:157} INFO - Started process (PID=73175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:59:03.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:59:03.214+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:59:03.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:59:03.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:59:03.244+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:59:03.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:59:03.253+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:59:03.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:59:03.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T15:59:33.680+0000] {processor.py:157} INFO - Started process (PID=73200) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:59:33.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T15:59:33.683+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:59:33.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:59:33.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T15:59:33.712+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:59:33.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T15:59:33.726+0000] {logging_mixin.py:151} INFO - [2024-07-30T15:59:33.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T15:59:33.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T16:00:04.077+0000] {processor.py:157} INFO - Started process (PID=73224) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:00:04.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:00:04.091+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:00:04.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:00:04.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:00:04.135+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:00:04.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:00:04.160+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:00:04.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:00:04.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-30T16:00:34.604+0000] {processor.py:157} INFO - Started process (PID=73250) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:00:34.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:00:34.606+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:00:34.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:00:34.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:00:34.631+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:00:34.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:00:34.641+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:00:34.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:00:34.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-30T16:01:05.055+0000] {processor.py:157} INFO - Started process (PID=73275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:01:05.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:01:05.060+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:01:05.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:01:05.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:01:05.091+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:01:05.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:01:05.101+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:01:05.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:01:05.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T16:01:35.509+0000] {processor.py:157} INFO - Started process (PID=73300) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:01:35.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:01:35.513+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:01:35.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:01:35.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:01:35.547+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:01:35.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:01:35.561+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:01:35.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:01:35.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-30T16:02:05.939+0000] {processor.py:157} INFO - Started process (PID=73325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:02:05.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:02:05.942+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:02:05.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:02:05.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:02:05.967+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:02:05.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:02:05.978+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:02:05.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:02:05.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-30T16:02:36.378+0000] {processor.py:157} INFO - Started process (PID=73350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:02:36.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:02:36.382+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:02:36.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:02:36.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:02:36.408+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:02:36.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:02:36.418+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:02:36.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:02:36.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-30T16:03:06.862+0000] {processor.py:157} INFO - Started process (PID=73375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:03:06.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:03:06.867+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:03:06.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:03:06.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:03:06.934+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:03:06.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:03:06.950+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:03:06.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:03:06.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-30T16:03:37.352+0000] {processor.py:157} INFO - Started process (PID=73400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:03:37.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:03:37.355+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:03:37.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:03:37.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:03:37.379+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:03:37.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:03:37.390+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:03:37.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:03:37.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-30T16:04:07.863+0000] {processor.py:157} INFO - Started process (PID=73425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:04:07.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:04:07.870+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:04:07.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:04:07.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:04:07.949+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:04:07.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:04:07.973+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:04:07.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:04:07.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-30T16:04:38.348+0000] {processor.py:157} INFO - Started process (PID=73450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:04:38.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:04:38.351+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:04:38.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:04:38.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:04:38.377+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:04:38.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:04:38.389+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:04:38.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:04:38.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T16:05:08.752+0000] {processor.py:157} INFO - Started process (PID=73475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:05:08.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:05:08.757+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:05:08.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:05:08.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:05:08.829+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:05:08.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:05:08.843+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:05:08.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:05:08.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-30T16:05:39.249+0000] {processor.py:157} INFO - Started process (PID=73500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:05:39.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:05:39.256+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:05:39.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:05:39.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:05:39.280+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:05:39.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:05:39.292+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:05:39.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:05:39.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T16:06:09.695+0000] {processor.py:157} INFO - Started process (PID=73525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:06:09.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:06:09.698+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:06:09.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:06:09.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:06:09.727+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:06:09.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:06:09.738+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:06:09.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:06:09.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T16:06:40.159+0000] {processor.py:157} INFO - Started process (PID=73550) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:06:40.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:06:40.164+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:06:40.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:06:40.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:06:40.193+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:06:40.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:06:40.203+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:06:40.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:06:40.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T16:07:10.578+0000] {processor.py:157} INFO - Started process (PID=73575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:07:10.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:07:10.581+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:07:10.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:07:10.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:07:10.616+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:07:10.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:07:10.629+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:07:10.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:07:10.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-30T16:07:41.099+0000] {processor.py:157} INFO - Started process (PID=73600) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:07:41.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:07:41.102+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:07:41.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:07:41.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:07:41.130+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:07:41.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:07:41.141+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:07:41.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:07:41.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T16:08:11.523+0000] {processor.py:157} INFO - Started process (PID=73625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:08:11.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:08:11.528+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:08:11.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:08:11.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:08:11.559+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:08:11.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:08:11.573+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:08:11.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:08:11.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-30T16:08:41.930+0000] {processor.py:157} INFO - Started process (PID=73650) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:08:41.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:08:41.933+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:08:41.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:08:41.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:08:41.963+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:08:41.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:08:41.975+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:08:41.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:08:41.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T16:09:12.356+0000] {processor.py:157} INFO - Started process (PID=73675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:09:12.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:09:12.359+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:09:12.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:09:12.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:09:12.394+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:09:12.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:09:12.408+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:09:12.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:09:12.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-30T16:09:42.822+0000] {processor.py:157} INFO - Started process (PID=73700) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:09:42.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:09:42.825+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:09:42.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:09:42.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:09:42.855+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:09:42.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:09:42.868+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:09:42.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:09:42.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-30T16:10:13.204+0000] {processor.py:157} INFO - Started process (PID=73725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:10:13.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:10:13.206+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:10:13.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:10:13.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:10:13.234+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:10:13.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:10:13.249+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:10:13.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:10:13.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T16:10:43.653+0000] {processor.py:157} INFO - Started process (PID=73750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:10:43.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:10:43.659+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:10:43.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:10:43.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:10:43.695+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:10:43.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:10:43.708+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:10:43.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:10:43.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-30T16:11:14.086+0000] {processor.py:157} INFO - Started process (PID=73775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:11:14.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:11:14.088+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:11:14.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:11:14.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:11:14.121+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:11:14.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:11:14.134+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:11:14.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:11:14.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-30T16:11:44.527+0000] {processor.py:157} INFO - Started process (PID=73800) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:11:44.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:11:44.530+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:11:44.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:11:44.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:11:44.554+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:11:44.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:11:44.563+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:11:44.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:11:44.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-30T16:12:14.930+0000] {processor.py:157} INFO - Started process (PID=73825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:12:14.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:12:14.936+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:12:14.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:12:14.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:12:14.972+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:12:14.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:12:14.984+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:12:14.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:12:14.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-30T16:12:45.375+0000] {processor.py:157} INFO - Started process (PID=73850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:12:45.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:12:45.379+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:12:45.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:12:45.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:12:45.407+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:12:45.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:12:45.420+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:12:45.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:12:45.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T16:13:15.786+0000] {processor.py:157} INFO - Started process (PID=73875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:13:15.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:13:15.788+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:13:15.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:13:15.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:13:15.816+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:13:15.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:13:15.827+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:13:15.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:13:15.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T16:13:46.270+0000] {processor.py:157} INFO - Started process (PID=73899) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:13:46.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:13:46.275+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:13:46.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:13:46.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:13:46.317+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:13:46.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:13:46.331+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:13:46.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:13:46.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-30T16:14:16.735+0000] {processor.py:157} INFO - Started process (PID=73925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:14:16.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:14:16.739+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:14:16.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:14:16.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:14:16.766+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:14:16.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:14:16.776+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:14:16.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:14:16.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T16:14:47.209+0000] {processor.py:157} INFO - Started process (PID=73950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:14:47.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:14:47.214+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:14:47.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:14:47.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:14:47.252+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:14:47.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:14:47.265+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:14:47.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:14:47.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-30T16:15:17.651+0000] {processor.py:157} INFO - Started process (PID=73975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:15:17.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:15:17.653+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:15:17.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:15:17.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:15:17.686+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:15:17.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:15:17.700+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:15:17.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:15:17.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-30T16:15:48.129+0000] {processor.py:157} INFO - Started process (PID=74000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:15:48.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:15:48.134+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:15:48.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:15:48.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:15:48.175+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:15:48.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:15:48.190+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:15:48.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:15:48.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-30T16:16:18.541+0000] {processor.py:157} INFO - Started process (PID=74025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:16:18.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:16:18.544+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:16:18.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:16:18.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:16:18.574+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:16:18.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:16:18.589+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:16:18.589+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:16:18.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-30T16:16:49.001+0000] {processor.py:157} INFO - Started process (PID=74050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:16:49.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:16:49.006+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:16:49.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:16:49.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:16:49.035+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:16:49.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:16:49.046+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:16:49.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:16:49.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T16:17:19.487+0000] {processor.py:157} INFO - Started process (PID=74075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:17:19.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:17:19.491+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:17:19.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:17:19.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:17:19.528+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:17:19.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:17:19.541+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:17:19.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:17:19.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-30T16:17:49.882+0000] {processor.py:157} INFO - Started process (PID=74100) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:17:49.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:17:49.884+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:17:49.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:17:49.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:17:49.910+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:17:49.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:17:49.922+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:17:49.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:17:49.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T16:18:20.300+0000] {processor.py:157} INFO - Started process (PID=74125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:18:20.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:18:20.302+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:18:20.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:18:20.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:18:20.331+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:18:20.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:18:20.343+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:18:20.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:18:20.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T16:18:50.752+0000] {processor.py:157} INFO - Started process (PID=74150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:18:50.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:18:50.755+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:18:50.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:18:50.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:18:50.783+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:18:50.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:18:50.794+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:18:50.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:18:50.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T16:19:21.195+0000] {processor.py:157} INFO - Started process (PID=74175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:19:21.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:19:21.198+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:19:21.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:19:21.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:19:21.227+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:19:21.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:19:21.239+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:19:21.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:19:21.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T16:19:51.653+0000] {processor.py:157} INFO - Started process (PID=74200) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:19:51.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:19:51.657+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:19:51.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:19:51.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:19:51.687+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:19:51.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:19:51.699+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:19:51.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:19:51.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T16:20:22.039+0000] {processor.py:157} INFO - Started process (PID=74225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:20:22.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:20:22.045+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:20:22.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:20:22.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:20:22.081+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:20:22.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:20:22.093+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:20:22.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:20:22.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-30T16:20:52.477+0000] {processor.py:157} INFO - Started process (PID=74250) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:20:52.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:20:52.480+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:20:52.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:20:52.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:20:52.509+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:20:52.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:20:52.519+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:20:52.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:20:52.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T16:21:22.815+0000] {processor.py:157} INFO - Started process (PID=74275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:21:22.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:21:22.817+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:21:22.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:21:22.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:21:22.839+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:21:22.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:21:22.849+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:21:22.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:21:22.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-30T16:21:53.264+0000] {processor.py:157} INFO - Started process (PID=74300) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:21:53.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:21:53.268+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:21:53.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:21:53.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:21:53.296+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:21:53.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:21:53.307+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:21:53.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:21:53.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T16:22:23.735+0000] {processor.py:157} INFO - Started process (PID=74325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:22:23.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:22:23.740+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:22:23.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:22:23.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:22:23.770+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:22:23.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:22:23.782+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:22:23.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:22:23.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T16:22:54.199+0000] {processor.py:157} INFO - Started process (PID=74350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:22:54.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:22:54.204+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:22:54.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:22:54.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:22:54.254+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:22:54.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:22:54.266+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:22:54.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:22:54.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-30T16:23:24.738+0000] {processor.py:157} INFO - Started process (PID=74375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:23:24.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:23:24.742+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:23:24.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:23:24.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:23:24.774+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:23:24.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:23:24.787+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:23:24.787+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:23:24.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-30T16:23:55.184+0000] {processor.py:157} INFO - Started process (PID=74400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:23:55.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:23:55.189+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:23:55.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:23:55.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:23:55.253+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:23:55.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:23:55.269+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:23:55.269+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:23:55.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-30T16:24:25.694+0000] {processor.py:157} INFO - Started process (PID=74425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:24:25.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:24:25.697+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:24:25.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:24:25.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:24:25.732+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:24:25.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:24:25.743+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:24:25.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:24:25.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-30T16:24:56.162+0000] {processor.py:157} INFO - Started process (PID=74450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:24:56.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:24:56.166+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:24:56.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:24:56.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:24:56.202+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:24:56.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:24:56.213+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:24:56.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:24:56.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-30T16:25:26.626+0000] {processor.py:157} INFO - Started process (PID=74475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:25:26.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:25:26.630+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:25:26.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:25:26.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:25:26.657+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:25:26.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:25:26.671+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:25:26.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:25:26.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T16:25:57.032+0000] {processor.py:157} INFO - Started process (PID=74500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:25:57.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:25:57.034+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:25:57.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:25:57.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:25:57.057+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:25:57.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:25:57.066+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:25:57.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:25:57.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-30T16:26:27.497+0000] {processor.py:157} INFO - Started process (PID=74525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:26:27.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:26:27.500+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:26:27.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:26:27.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:26:27.529+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:26:27.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:26:27.539+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:26:27.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:26:27.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T16:26:57.923+0000] {processor.py:157} INFO - Started process (PID=74550) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:26:57.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:26:57.926+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:26:57.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:26:57.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:26:57.964+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:26:57.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:26:57.974+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:26:57.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:26:57.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-30T16:27:28.352+0000] {processor.py:157} INFO - Started process (PID=74575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:27:28.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:27:28.365+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:27:28.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:27:28.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:27:28.401+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:27:28.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:27:28.416+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:27:28.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:27:28.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-30T16:27:58.859+0000] {processor.py:157} INFO - Started process (PID=74600) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:27:58.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:27:58.862+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:27:58.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:27:58.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:27:58.889+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:27:58.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:27:58.900+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:27:58.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:27:58.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T16:28:29.215+0000] {processor.py:157} INFO - Started process (PID=74625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:28:29.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:28:29.218+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:28:29.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:28:29.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:28:29.244+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:28:29.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:28:29.253+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:28:29.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:28:29.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-30T16:28:59.672+0000] {processor.py:157} INFO - Started process (PID=74650) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:28:59.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:28:59.675+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:28:59.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:28:59.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:28:59.700+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:28:59.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:28:59.710+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:28:59.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:28:59.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-30T16:29:30.136+0000] {processor.py:157} INFO - Started process (PID=74675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:29:30.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:29:30.139+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:29:30.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:29:30.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:29:30.173+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:29:30.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:29:30.183+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:29:30.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:29:30.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-30T16:30:00.572+0000] {processor.py:157} INFO - Started process (PID=74700) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:30:00.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:30:00.574+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:30:00.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:30:00.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:30:00.601+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:30:00.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:30:00.612+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:30:00.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:30:00.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-30T16:30:31.042+0000] {processor.py:157} INFO - Started process (PID=74725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:30:31.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:30:31.046+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:30:31.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:30:31.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:30:31.078+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:30:31.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:30:31.091+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:30:31.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:30:31.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-30T16:31:01.529+0000] {processor.py:157} INFO - Started process (PID=74750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:31:01.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:31:01.532+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:31:01.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:31:01.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:31:01.557+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:31:01.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:31:01.568+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:31:01.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:31:01.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T16:31:31.988+0000] {processor.py:157} INFO - Started process (PID=74775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:31:31.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:31:31.992+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:31:31.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:31:32.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:31:32.018+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:31:32.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:31:32.028+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:31:32.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:31:32.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-30T16:32:02.484+0000] {processor.py:157} INFO - Started process (PID=74800) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:32:02.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:32:02.487+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:32:02.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:32:02.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:32:02.512+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:32:02.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:32:02.522+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:32:02.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:32:02.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-30T16:32:32.973+0000] {processor.py:157} INFO - Started process (PID=74825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:32:32.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:32:32.977+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:32:32.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:32:32.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:32:33.012+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:32:33.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:32:33.023+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:32:33.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:32:33.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-30T16:33:03.394+0000] {processor.py:157} INFO - Started process (PID=74850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:33:03.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:33:03.398+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:33:03.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:33:03.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:33:03.428+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:33:03.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:33:03.441+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:33:03.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:33:03.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T16:33:33.846+0000] {processor.py:157} INFO - Started process (PID=74875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:33:33.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:33:33.848+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:33:33.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:33:33.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:33:33.879+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:33:33.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:33:33.894+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:33:33.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:33:33.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-30T16:34:04.343+0000] {processor.py:157} INFO - Started process (PID=74899) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:34:04.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:34:04.350+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:34:04.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:34:04.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:34:04.432+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:34:04.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:34:04.451+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:34:04.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:34:04.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-30T16:34:34.862+0000] {processor.py:157} INFO - Started process (PID=74925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:34:34.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:34:34.868+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:34:34.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:34:34.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:34:34.901+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:34:34.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:34:34.912+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:34:34.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:34:34.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-30T16:35:05.332+0000] {processor.py:157} INFO - Started process (PID=74950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:35:05.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:35:05.337+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:35:05.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:35:05.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:35:05.397+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:35:05.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:35:05.416+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:35:05.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:35:05.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-30T16:35:35.840+0000] {processor.py:157} INFO - Started process (PID=74975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:35:35.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:35:35.842+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:35:35.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:35:35.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:35:35.875+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:35:35.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:35:35.887+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:35:35.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:35:35.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-30T16:36:06.312+0000] {processor.py:157} INFO - Started process (PID=75000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:36:06.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:36:06.333+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:36:06.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:36:06.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:36:06.380+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:36:06.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:36:06.410+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:36:06.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:36:06.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-07-30T16:36:36.855+0000] {processor.py:157} INFO - Started process (PID=75025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:36:36.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:36:36.857+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:36:36.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:36:36.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:36:36.889+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:36:36.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:36:36.903+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:36:36.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:36:36.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-30T16:37:07.354+0000] {processor.py:157} INFO - Started process (PID=75050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:37:07.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:37:07.359+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:37:07.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:37:07.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:37:07.409+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:37:07.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:37:07.445+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:37:07.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:37:07.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-30T16:37:37.876+0000] {processor.py:157} INFO - Started process (PID=75075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:37:37.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:37:37.879+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:37:37.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:37:37.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:37:37.916+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:37:37.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:37:37.928+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:37:37.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:37:37.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-30T16:38:08.347+0000] {processor.py:157} INFO - Started process (PID=75100) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:38:08.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:38:08.352+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:38:08.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:38:08.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:38:08.419+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:38:08.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:38:08.435+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:38:08.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:38:08.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-30T16:38:38.859+0000] {processor.py:157} INFO - Started process (PID=75125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:38:38.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:38:38.863+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:38:38.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:38:38.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:38:38.899+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:38:38.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:38:38.912+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:38:38.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:38:38.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-30T16:39:09.291+0000] {processor.py:157} INFO - Started process (PID=75149) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:39:09.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:39:09.296+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:39:09.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:39:09.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:39:09.354+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:39:09.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:39:09.369+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:39:09.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:39:09.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-30T16:39:39.807+0000] {processor.py:157} INFO - Started process (PID=75175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:39:39.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:39:39.813+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:39:39.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:39:39.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:39:39.844+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:39:39.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:39:39.856+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:39:39.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:39:39.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-30T16:40:10.250+0000] {processor.py:157} INFO - Started process (PID=75200) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:40:10.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:40:10.255+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:40:10.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:40:10.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:40:10.316+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:40:10.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:40:10.331+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:40:10.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:40:10.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-30T16:40:40.684+0000] {processor.py:157} INFO - Started process (PID=75225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:40:40.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:40:40.688+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:40:40.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:40:40.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:40:40.730+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:40:40.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:40:40.744+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:40:40.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:40:40.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-30T16:41:11.226+0000] {processor.py:157} INFO - Started process (PID=75250) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:41:11.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:41:11.234+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:41:11.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:41:11.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:41:11.276+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:41:11.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:41:11.291+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:41:11.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:41:11.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-30T16:41:41.719+0000] {processor.py:157} INFO - Started process (PID=75275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:41:41.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:41:41.726+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:41:41.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:41:41.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:41:41.781+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:41:41.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:41:41.807+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:41:41.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:41:41.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-30T16:42:12.223+0000] {processor.py:157} INFO - Started process (PID=75300) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:42:12.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:42:12.226+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:42:12.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:42:12.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:42:12.252+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:42:12.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:42:12.262+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:42:12.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:42:12.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-30T16:42:42.601+0000] {processor.py:157} INFO - Started process (PID=75325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:42:42.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:42:42.604+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:42:42.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:42:42.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:42:42.645+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:42:42.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:42:42.658+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:42:42.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:42:42.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-30T16:43:13.062+0000] {processor.py:157} INFO - Started process (PID=75350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:43:13.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:43:13.065+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:43:13.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:43:13.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:43:13.090+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:43:13.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:43:13.103+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:43:13.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:43:13.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-30T16:43:43.522+0000] {processor.py:157} INFO - Started process (PID=75375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:43:43.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:43:43.525+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:43:43.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:43:43.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:43:43.551+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:43:43.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:43:43.561+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:43:43.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:43:43.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-30T16:44:13.900+0000] {processor.py:157} INFO - Started process (PID=75400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:44:13.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:44:13.902+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:44:13.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:44:13.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:44:13.928+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:44:13.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:44:13.938+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:44:13.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:44:13.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-30T16:44:44.346+0000] {processor.py:157} INFO - Started process (PID=75425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:44:44.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:44:44.350+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:44:44.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:44:44.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:44:44.391+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:44:44.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:44:44.406+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:44:44.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:44:44.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-30T16:45:14.819+0000] {processor.py:157} INFO - Started process (PID=75450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:45:14.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:45:14.823+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:45:14.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:45:14.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:45:14.860+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:45:14.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:45:14.871+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:45:14.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:45:14.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-30T16:45:45.349+0000] {processor.py:157} INFO - Started process (PID=75475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:45:45.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:45:45.355+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:45:45.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:45:45.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:45:45.390+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:45:45.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:45:45.405+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:45:45.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:45:45.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-30T16:46:15.793+0000] {processor.py:157} INFO - Started process (PID=75500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:46:15.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:46:15.798+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:46:15.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:46:15.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:46:15.839+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:46:15.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:46:15.852+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:46:15.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:46:15.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-30T16:46:46.262+0000] {processor.py:157} INFO - Started process (PID=75525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:46:46.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:46:46.266+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:46:46.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:46:46.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:46:46.294+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:46:46.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:46:46.303+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:46:46.303+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:46:46.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T16:47:16.755+0000] {processor.py:157} INFO - Started process (PID=75550) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:47:16.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:47:16.759+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:47:16.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:47:16.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:47:16.791+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:47:16.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:47:16.802+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:47:16.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:47:16.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-30T16:47:47.196+0000] {processor.py:157} INFO - Started process (PID=75575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:47:47.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:47:47.203+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:47:47.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:47:47.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:47:47.236+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:47:47.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:47:47.249+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:47:47.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:47:47.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-30T16:48:17.640+0000] {processor.py:157} INFO - Started process (PID=75600) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:48:17.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:48:17.645+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:48:17.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:48:17.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:48:17.678+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:48:17.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:48:17.690+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:48:17.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:48:17.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-30T16:48:48.135+0000] {processor.py:157} INFO - Started process (PID=75625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:48:48.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:48:48.140+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:48:48.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:48:48.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:48:48.176+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:48:48.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:48:48.189+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:48:48.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:48:48.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-30T16:49:18.658+0000] {processor.py:157} INFO - Started process (PID=75650) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:49:18.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:49:18.666+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:49:18.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:49:18.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:49:18.701+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:49:18.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:49:18.712+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:49:18.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:49:18.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-30T16:49:49.105+0000] {processor.py:157} INFO - Started process (PID=75675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:49:49.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:49:49.110+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:49:49.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:49:49.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:49:49.151+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:49:49.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:49:49.171+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:49:49.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:49:49.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-30T16:50:19.628+0000] {processor.py:157} INFO - Started process (PID=75700) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:50:19.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:50:19.634+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:50:19.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:50:19.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:50:19.697+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:50:19.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:50:19.710+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:50:19.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:50:19.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-30T16:50:50.092+0000] {processor.py:157} INFO - Started process (PID=75724) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:50:50.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:50:50.097+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:50:50.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:50:50.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:50:50.136+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:50:50.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:50:50.152+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:50:50.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:50:50.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-30T16:51:20.540+0000] {processor.py:157} INFO - Started process (PID=75750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:51:20.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:51:20.546+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:51:20.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:51:20.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:51:20.591+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:51:20.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:51:20.604+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:51:20.604+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:51:20.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-30T16:51:50.990+0000] {processor.py:157} INFO - Started process (PID=75775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:51:50.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:51:50.992+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:51:50.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:51:51.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:51:51.019+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:51:51.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:51:51.028+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:51:51.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:51:51.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T16:52:21.434+0000] {processor.py:157} INFO - Started process (PID=75800) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:52:21.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:52:21.443+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:52:21.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:52:21.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:52:21.506+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:52:21.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:52:21.523+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:52:21.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:52:21.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-07-30T16:52:52.005+0000] {processor.py:157} INFO - Started process (PID=75825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:52:52.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:52:52.013+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:52:52.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:52:52.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:52:52.050+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:52:52.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:52:52.062+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:52:52.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:52:52.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-30T16:53:22.462+0000] {processor.py:157} INFO - Started process (PID=75850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:53:22.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:53:22.466+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:53:22.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:53:22.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:53:22.500+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:53:22.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:53:22.511+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:53:22.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:53:22.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-30T16:53:52.927+0000] {processor.py:157} INFO - Started process (PID=75875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:53:52.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:53:52.932+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:53:52.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:53:52.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:53:52.972+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:53:52.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:53:52.986+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:53:52.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:53:52.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-30T16:54:23.409+0000] {processor.py:157} INFO - Started process (PID=75900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:54:23.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:54:23.413+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:54:23.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:54:23.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:54:23.443+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:54:23.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:54:23.456+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:54:23.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:54:23.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-30T16:54:53.850+0000] {processor.py:157} INFO - Started process (PID=75925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:54:53.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:54:53.856+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:54:53.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:54:53.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:54:53.896+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:54:53.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:54:53.910+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:54:53.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:54:53.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-30T16:55:24.359+0000] {processor.py:157} INFO - Started process (PID=75950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:55:24.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:55:24.365+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:55:24.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:55:24.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:55:24.406+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:55:24.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:55:24.418+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:55:24.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:55:24.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-30T16:55:54.801+0000] {processor.py:157} INFO - Started process (PID=75975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:55:54.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:55:54.804+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:55:54.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:55:54.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:55:54.835+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:55:54.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:55:54.850+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:55:54.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:55:54.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-30T16:56:25.202+0000] {processor.py:157} INFO - Started process (PID=76000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:56:25.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:56:25.207+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:56:25.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:56:25.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:56:25.245+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:56:25.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:56:25.257+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:56:25.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:56:25.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-30T16:56:55.635+0000] {processor.py:157} INFO - Started process (PID=76025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:56:55.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:56:55.641+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:56:55.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:56:55.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:56:55.677+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:56:55.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:56:55.693+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:56:55.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:56:55.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-30T16:57:26.130+0000] {processor.py:157} INFO - Started process (PID=76050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:57:26.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:57:26.139+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:57:26.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:57:26.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:57:26.178+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:57:26.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:57:26.188+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:57:26.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:57:26.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-30T16:57:56.663+0000] {processor.py:157} INFO - Started process (PID=76075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:57:56.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:57:56.666+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:57:56.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:57:56.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:57:56.695+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:57:56.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:57:56.708+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:57:56.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:57:56.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-30T16:58:27.434+0000] {processor.py:157} INFO - Started process (PID=76099) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:58:27.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:58:27.441+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:58:27.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:58:27.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:58:27.485+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:58:27.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:58:27.502+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:58:27.502+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:58:27.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-30T16:59:18.229+0000] {processor.py:157} INFO - Started process (PID=76125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:59:18.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T16:59:18.232+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:59:18.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:59:18.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T16:59:18.263+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:59:18.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T16:59:18.275+0000] {logging_mixin.py:151} INFO - [2024-07-30T16:59:18.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T16:59:18.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T17:15:02.449+0000] {processor.py:157} INFO - Started process (PID=76153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:15:02.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T17:15:02.455+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:15:02.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:15:02.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:15:02.516+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:15:02.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:15:02.533+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:15:02.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T17:15:02.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-30T17:15:33.110+0000] {processor.py:157} INFO - Started process (PID=76178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:15:33.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T17:15:33.115+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:15:33.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:15:33.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:15:33.158+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:15:33.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:15:33.171+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:15:33.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T17:15:33.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-30T17:16:03.525+0000] {processor.py:157} INFO - Started process (PID=76203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:16:03.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T17:16:03.527+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:16:03.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:16:03.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:16:03.551+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:16:03.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:16:03.562+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:16:03.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T17:16:03.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-30T17:16:34.023+0000] {processor.py:157} INFO - Started process (PID=76228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:16:34.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T17:16:34.027+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:16:34.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:16:34.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:16:34.056+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:16:34.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:16:34.066+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:16:34.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T17:16:34.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T17:17:04.894+0000] {processor.py:157} INFO - Started process (PID=76253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:17:04.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T17:17:04.902+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:17:04.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:17:04.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:17:04.938+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:17:04.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:17:04.951+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:17:04.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T17:17:04.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-30T17:17:35.370+0000] {processor.py:157} INFO - Started process (PID=76278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:17:35.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T17:17:35.374+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:17:35.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:17:35.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:17:35.400+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:17:35.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:17:35.411+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:17:35.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T17:17:35.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T17:18:08.199+0000] {processor.py:157} INFO - Started process (PID=76303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:18:08.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T17:18:08.203+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:18:08.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:18:08.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:18:08.228+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:18:08.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:18:08.238+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:18:08.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T17:18:08.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-30T17:18:38.677+0000] {processor.py:157} INFO - Started process (PID=76328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:18:38.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T17:18:38.681+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:18:38.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:18:38.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:18:38.721+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:18:38.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:18:38.735+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:18:38.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T17:18:38.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-30T17:19:09.158+0000] {processor.py:157} INFO - Started process (PID=76353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:19:09.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T17:19:09.161+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:19:09.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:19:09.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:19:09.190+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:19:09.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:19:09.203+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:19:09.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T17:19:09.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-30T17:19:39.544+0000] {processor.py:157} INFO - Started process (PID=76377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:19:39.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T17:19:39.547+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:19:39.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:19:39.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:19:39.571+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:19:39.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:19:39.581+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:19:39.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T17:19:39.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-30T17:35:22.592+0000] {processor.py:157} INFO - Started process (PID=76403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:35:22.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T17:35:22.597+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:35:22.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:35:22.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:35:22.662+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:35:22.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:35:22.691+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:35:22.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T17:35:22.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-30T17:35:53.182+0000] {processor.py:157} INFO - Started process (PID=76428) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:35:53.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T17:35:53.189+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:35:53.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:35:53.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:35:53.253+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:35:53.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:35:53.271+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:35:53.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T17:35:53.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-30T17:51:31.647+0000] {processor.py:157} INFO - Started process (PID=76455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:51:31.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T17:51:31.655+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:51:31.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:51:31.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:51:31.700+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:51:31.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:51:31.725+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:51:31.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T17:51:31.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-30T17:52:02.123+0000] {processor.py:157} INFO - Started process (PID=76480) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:52:02.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T17:52:02.128+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:52:02.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:52:02.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:52:02.158+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:52:02.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:52:02.168+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:52:02.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T17:52:02.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T17:52:32.566+0000] {processor.py:157} INFO - Started process (PID=76505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:52:32.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T17:52:32.571+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:52:32.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:52:32.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:52:32.607+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:52:32.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:52:32.623+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:52:32.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T17:52:32.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-30T17:53:03.023+0000] {processor.py:157} INFO - Started process (PID=76530) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:53:03.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T17:53:03.026+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:53:03.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:53:03.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:53:03.057+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:53:03.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:53:03.066+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:53:03.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T17:53:03.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T17:53:36.824+0000] {processor.py:157} INFO - Started process (PID=76555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:53:36.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T17:53:36.826+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:53:36.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:53:36.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:53:36.854+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:53:36.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:53:36.865+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:53:36.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T17:53:36.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T17:54:07.332+0000] {processor.py:157} INFO - Started process (PID=76580) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:54:07.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T17:54:07.337+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:54:07.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:54:07.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:54:07.372+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:54:07.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:54:07.384+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:54:07.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T17:54:07.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-30T17:54:37.726+0000] {processor.py:157} INFO - Started process (PID=76605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:54:37.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T17:54:37.731+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:54:37.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:54:37.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:54:37.766+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:54:37.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:54:37.779+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:54:37.779+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T17:54:37.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-30T17:55:08.204+0000] {processor.py:157} INFO - Started process (PID=76630) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:55:08.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T17:55:08.208+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:55:08.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:55:08.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:55:08.234+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:55:08.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:55:08.245+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:55:08.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T17:55:08.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T17:55:38.642+0000] {processor.py:157} INFO - Started process (PID=76655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:55:38.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T17:55:38.646+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:55:38.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:55:38.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:55:38.677+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:55:38.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:55:38.686+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:55:38.686+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T17:55:38.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T17:56:11.341+0000] {processor.py:157} INFO - Started process (PID=76680) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:56:11.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T17:56:11.346+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:56:11.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:56:11.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:56:11.378+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:56:11.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:56:11.391+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:56:11.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T17:56:11.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-30T17:56:41.780+0000] {processor.py:157} INFO - Started process (PID=76705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:56:41.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T17:56:41.786+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:56:41.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:56:41.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:56:41.821+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:56:41.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:56:41.832+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:56:41.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T17:56:41.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-30T17:57:12.296+0000] {processor.py:157} INFO - Started process (PID=76730) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:57:12.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T17:57:12.299+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:57:12.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:57:12.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:57:12.327+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:57:12.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:57:12.339+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:57:12.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T17:57:12.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T17:57:42.801+0000] {processor.py:157} INFO - Started process (PID=76755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:57:42.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T17:57:42.806+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:57:42.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:57:42.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:57:42.840+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:57:42.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:57:42.852+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:57:42.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T17:57:42.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-30T17:58:13.271+0000] {processor.py:157} INFO - Started process (PID=76780) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:58:13.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T17:58:13.275+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:58:13.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:58:13.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:58:13.306+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:58:13.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:58:13.318+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:58:13.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T17:58:13.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-30T17:58:43.675+0000] {processor.py:157} INFO - Started process (PID=76805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:58:43.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T17:58:43.681+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:58:43.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:58:43.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:58:43.717+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:58:43.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:58:43.728+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:58:43.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T17:58:43.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-30T17:59:14.130+0000] {processor.py:157} INFO - Started process (PID=76830) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:59:14.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T17:59:14.132+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:59:14.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:59:14.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:59:14.157+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:59:14.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:59:14.168+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:59:14.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T17:59:14.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-30T17:59:44.583+0000] {processor.py:157} INFO - Started process (PID=76855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:59:44.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T17:59:44.588+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:59:44.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:59:44.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T17:59:44.615+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:59:44.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T17:59:44.626+0000] {logging_mixin.py:151} INFO - [2024-07-30T17:59:44.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T17:59:44.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T18:00:14.999+0000] {processor.py:157} INFO - Started process (PID=76880) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:00:15.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T18:00:15.004+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:00:15.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:00:15.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:00:15.036+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:00:15.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:00:15.049+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:00:15.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T18:00:15.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-30T18:00:45.432+0000] {processor.py:157} INFO - Started process (PID=76905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:00:45.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T18:00:45.437+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:00:45.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:00:45.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:00:45.475+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:00:45.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:00:45.492+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:00:45.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T18:00:45.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-30T18:17:24.885+0000] {processor.py:157} INFO - Started process (PID=76930) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:17:24.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T18:17:24.889+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:17:24.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:17:24.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:17:24.962+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:17:24.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:17:24.984+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:17:24.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T18:17:25.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-30T18:17:55.446+0000] {processor.py:157} INFO - Started process (PID=76957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:17:55.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T18:17:55.452+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:17:55.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:17:55.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:17:55.496+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:17:55.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:17:55.509+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:17:55.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T18:17:55.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-30T18:18:25.903+0000] {processor.py:157} INFO - Started process (PID=76982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:18:25.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T18:18:25.906+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:18:25.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:18:25.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:18:25.931+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:18:25.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:18:25.941+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:18:25.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T18:18:25.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-30T18:18:56.287+0000] {processor.py:157} INFO - Started process (PID=77007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:18:56.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T18:18:56.291+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:18:56.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:18:56.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:18:56.321+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:18:56.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:18:56.333+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:18:56.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T18:18:56.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T18:19:26.997+0000] {processor.py:157} INFO - Started process (PID=77032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:19:27.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T18:19:27.006+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:19:27.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:19:27.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:19:27.046+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:19:27.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:19:27.058+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:19:27.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T18:19:27.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-30T18:35:43.557+0000] {processor.py:157} INFO - Started process (PID=77057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:35:43.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T18:35:43.567+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:35:43.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:35:43.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:35:43.620+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:35:43.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:35:43.638+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:35:43.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T18:35:43.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-30T18:53:43.702+0000] {processor.py:157} INFO - Started process (PID=77084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:53:43.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T18:53:43.707+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:53:43.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:53:43.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:53:43.793+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:53:43.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:53:43.815+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:53:43.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T18:53:43.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-07-30T18:54:14.347+0000] {processor.py:157} INFO - Started process (PID=77108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:54:14.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T18:54:14.354+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:54:14.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:54:14.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:54:14.403+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:54:14.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:54:14.432+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:54:14.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T18:54:14.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-07-30T18:54:44.811+0000] {processor.py:157} INFO - Started process (PID=77134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:54:44.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T18:54:44.815+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:54:44.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:54:44.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:54:44.843+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:54:44.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:54:44.856+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:54:44.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T18:54:44.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-30T18:55:15.313+0000] {processor.py:157} INFO - Started process (PID=77158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:55:15.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T18:55:15.319+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:55:15.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:55:15.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:55:15.376+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:55:15.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:55:15.397+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:55:15.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T18:55:15.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-30T18:55:45.870+0000] {processor.py:157} INFO - Started process (PID=77182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:55:45.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T18:55:45.875+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:55:45.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:55:45.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:55:45.921+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:55:45.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:55:45.936+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:55:45.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T18:55:45.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-30T18:56:16.335+0000] {processor.py:157} INFO - Started process (PID=77209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:56:16.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T18:56:16.339+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:56:16.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:56:16.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:56:16.367+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:56:16.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:56:16.377+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:56:16.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T18:56:16.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T18:56:46.810+0000] {processor.py:157} INFO - Started process (PID=77234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:56:46.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T18:56:46.814+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:56:46.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:56:46.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:56:46.852+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:56:46.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:56:46.864+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:56:46.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T18:56:46.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-30T18:57:17.301+0000] {processor.py:157} INFO - Started process (PID=77259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:57:17.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T18:57:17.304+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:57:17.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:57:17.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:57:17.335+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:57:17.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:57:17.345+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:57:17.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T18:57:17.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T18:57:47.781+0000] {processor.py:157} INFO - Started process (PID=77284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:57:47.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T18:57:47.785+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:57:47.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:57:47.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:57:47.814+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:57:47.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:57:47.824+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:57:47.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T18:57:47.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T18:58:18.141+0000] {processor.py:157} INFO - Started process (PID=77309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:58:18.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T18:58:18.145+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:58:18.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:58:18.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:58:18.173+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:58:18.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:58:18.184+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:58:18.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T18:58:18.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T18:58:48.621+0000] {processor.py:157} INFO - Started process (PID=77334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:58:48.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T18:58:48.623+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:58:48.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:58:48.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:58:48.653+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:58:48.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:58:48.664+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:58:48.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T18:58:48.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T18:59:19.093+0000] {processor.py:157} INFO - Started process (PID=77359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:59:19.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T18:59:19.095+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:59:19.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:59:19.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:59:19.119+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:59:19.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:59:19.130+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:59:19.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T18:59:19.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-30T18:59:49.493+0000] {processor.py:157} INFO - Started process (PID=77384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:59:49.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T18:59:49.495+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:59:49.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:59:49.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T18:59:49.520+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:59:49.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T18:59:49.529+0000] {logging_mixin.py:151} INFO - [2024-07-30T18:59:49.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T18:59:49.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-30T19:00:19.977+0000] {processor.py:157} INFO - Started process (PID=77409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:00:19.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:00:19.983+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:00:19.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:00:20.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:00:20.023+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:00:20.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:00:20.036+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:00:20.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:00:20.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-30T19:00:50.450+0000] {processor.py:157} INFO - Started process (PID=77434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:00:50.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:00:50.455+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:00:50.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:00:50.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:00:50.482+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:00:50.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:00:50.492+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:00:50.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:00:50.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-30T19:01:20.908+0000] {processor.py:157} INFO - Started process (PID=77459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:01:20.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:01:20.911+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:01:20.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:01:20.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:01:20.943+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:01:20.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:01:20.952+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:01:20.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:01:20.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T19:01:51.316+0000] {processor.py:157} INFO - Started process (PID=77484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:01:51.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:01:51.318+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:01:51.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:01:51.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:01:51.344+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:01:51.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:01:51.356+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:01:51.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:01:51.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-30T19:02:21.789+0000] {processor.py:157} INFO - Started process (PID=77509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:02:21.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:02:21.793+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:02:21.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:02:21.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:02:21.820+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:02:21.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:02:21.829+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:02:21.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:02:21.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-30T19:02:52.246+0000] {processor.py:157} INFO - Started process (PID=77534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:02:52.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:02:52.248+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:02:52.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:02:52.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:02:52.267+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:02:52.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:02:52.275+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:02:52.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:02:52.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.039 seconds
[2024-07-30T19:03:22.722+0000] {processor.py:157} INFO - Started process (PID=77559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:03:22.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:03:22.726+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:03:22.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:03:22.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:03:22.751+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:03:22.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:03:22.761+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:03:22.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:03:22.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-30T19:03:53.205+0000] {processor.py:157} INFO - Started process (PID=77584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:03:53.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:03:53.209+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:03:53.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:03:53.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:03:53.248+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:03:53.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:03:53.260+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:03:53.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:03:53.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-30T19:04:23.730+0000] {processor.py:157} INFO - Started process (PID=77609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:04:23.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:04:23.733+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:04:23.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:04:23.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:04:23.759+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:04:23.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:04:23.769+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:04:23.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:04:23.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-30T19:04:54.245+0000] {processor.py:157} INFO - Started process (PID=77634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:04:54.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:04:54.247+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:04:54.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:04:54.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:04:54.283+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:04:54.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:04:54.292+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:04:54.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:04:54.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T19:05:24.658+0000] {processor.py:157} INFO - Started process (PID=77659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:05:24.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:05:24.661+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:05:24.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:05:24.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:05:24.689+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:05:24.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:05:24.699+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:05:24.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:05:24.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T19:05:55.106+0000] {processor.py:157} INFO - Started process (PID=77684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:05:55.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:05:55.109+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:05:55.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:05:55.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:05:55.142+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:05:55.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:05:55.151+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:05:55.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:05:55.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T19:06:25.575+0000] {processor.py:157} INFO - Started process (PID=77709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:06:25.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:06:25.580+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:06:25.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:06:25.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:06:25.619+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:06:25.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:06:25.631+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:06:25.631+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:06:25.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-30T19:06:56.052+0000] {processor.py:157} INFO - Started process (PID=77734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:06:56.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:06:56.055+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:06:56.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:06:56.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:06:56.082+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:06:56.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:06:56.093+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:06:56.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:06:56.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T19:07:26.469+0000] {processor.py:157} INFO - Started process (PID=77759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:07:26.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:07:26.472+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:07:26.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:07:26.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:07:26.501+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:07:26.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:07:26.511+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:07:26.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:07:26.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T19:07:56.893+0000] {processor.py:157} INFO - Started process (PID=77784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:07:56.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:07:56.897+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:07:56.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:07:56.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:07:56.932+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:07:56.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:07:56.941+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:07:56.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:07:56.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T19:08:27.341+0000] {processor.py:157} INFO - Started process (PID=77809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:08:27.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:08:27.345+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:08:27.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:08:27.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:08:27.379+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:08:27.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:08:27.390+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:08:27.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:08:27.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-30T19:08:57.864+0000] {processor.py:157} INFO - Started process (PID=77834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:08:57.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:08:57.870+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:08:57.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:08:57.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:08:57.907+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:08:57.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:08:57.920+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:08:57.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:08:57.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-30T19:09:28.433+0000] {processor.py:157} INFO - Started process (PID=77859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:09:28.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:09:28.436+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:09:28.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:09:28.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:09:28.465+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:09:28.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:09:28.476+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:09:28.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:09:28.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T19:09:58.939+0000] {processor.py:157} INFO - Started process (PID=77884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:09:58.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:09:58.943+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:09:58.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:09:58.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:09:58.973+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:09:58.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:09:58.986+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:09:58.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:09:58.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-30T19:10:29.386+0000] {processor.py:157} INFO - Started process (PID=77909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:10:29.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:10:29.391+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:10:29.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:10:29.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:10:29.421+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:10:29.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:10:29.430+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:10:29.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:10:29.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T19:10:59.881+0000] {processor.py:157} INFO - Started process (PID=77934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:10:59.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:10:59.887+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:10:59.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:10:59.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:10:59.952+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:10:59.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:10:59.965+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:10:59.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:10:59.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-30T19:11:30.424+0000] {processor.py:157} INFO - Started process (PID=77959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:11:30.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:11:30.429+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:11:30.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:11:30.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:11:30.456+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:11:30.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:11:30.469+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:11:30.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:11:30.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T19:12:00.885+0000] {processor.py:157} INFO - Started process (PID=77984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:12:00.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:12:00.888+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:12:00.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:12:00.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:12:00.918+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:12:00.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:12:00.929+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:12:00.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:12:00.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T19:12:31.341+0000] {processor.py:157} INFO - Started process (PID=78009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:12:31.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:12:31.344+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:12:31.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:12:31.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:12:31.372+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:12:31.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:12:31.381+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:12:31.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:12:31.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T19:13:01.820+0000] {processor.py:157} INFO - Started process (PID=78034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:13:01.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:13:01.824+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:13:01.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:13:01.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:13:01.860+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:13:01.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:13:01.873+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:13:01.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:13:01.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-30T19:13:32.297+0000] {processor.py:157} INFO - Started process (PID=78059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:13:32.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:13:32.300+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:13:32.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:13:32.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:13:32.326+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:13:32.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:13:32.335+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:13:32.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:13:32.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-30T19:14:02.799+0000] {processor.py:157} INFO - Started process (PID=78084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:14:02.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:14:02.803+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:14:02.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:14:02.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:14:02.832+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:14:02.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:14:02.846+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:14:02.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:14:02.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-30T19:14:33.223+0000] {processor.py:157} INFO - Started process (PID=78109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:14:33.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:14:33.227+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:14:33.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:14:33.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:14:33.255+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:14:33.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:14:33.266+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:14:33.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:14:33.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T19:15:03.677+0000] {processor.py:157} INFO - Started process (PID=78134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:15:03.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:15:03.681+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:15:03.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:15:03.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:15:03.712+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:15:03.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:15:03.724+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:15:03.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:15:03.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-30T19:15:34.105+0000] {processor.py:157} INFO - Started process (PID=78159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:15:34.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:15:34.110+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:15:34.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:15:34.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:15:34.140+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:15:34.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:15:34.150+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:15:34.150+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:15:34.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T19:16:04.595+0000] {processor.py:157} INFO - Started process (PID=78184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:16:04.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:16:04.597+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:16:04.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:16:04.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:16:04.636+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:16:04.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:16:04.649+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:16:04.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:16:04.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-30T19:16:35.006+0000] {processor.py:157} INFO - Started process (PID=78209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:16:35.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:16:35.008+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:16:35.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:16:35.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:16:35.034+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:16:35.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:16:35.045+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:16:35.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:16:35.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-30T19:17:05.491+0000] {processor.py:157} INFO - Started process (PID=78234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:17:05.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:17:05.493+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:17:05.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:17:05.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:17:05.522+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:17:05.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:17:05.533+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:17:05.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:17:05.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T19:17:35.959+0000] {processor.py:157} INFO - Started process (PID=78259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:17:35.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:17:35.961+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:17:35.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:17:35.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:17:35.990+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:17:35.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:17:35.999+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:17:35.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:17:36.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-30T19:18:06.361+0000] {processor.py:157} INFO - Started process (PID=78284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:18:06.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:18:06.366+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:18:06.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:18:06.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:18:06.392+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:18:06.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:18:06.403+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:18:06.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:18:06.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T19:18:36.829+0000] {processor.py:157} INFO - Started process (PID=78309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:18:36.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:18:36.832+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:18:36.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:18:36.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:18:36.858+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:18:36.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:18:36.867+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:18:36.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:18:36.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-30T19:19:07.207+0000] {processor.py:157} INFO - Started process (PID=78334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:19:07.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:19:07.211+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:19:07.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:19:07.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:19:07.242+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:19:07.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:19:07.254+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:19:07.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:19:07.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-30T19:19:37.674+0000] {processor.py:157} INFO - Started process (PID=78359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:19:37.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:19:37.680+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:19:37.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:19:37.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:19:37.710+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:19:37.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:19:37.721+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:19:37.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:19:37.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-30T19:20:08.079+0000] {processor.py:157} INFO - Started process (PID=78384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:20:08.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:20:08.081+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:20:08.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:20:08.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:20:08.107+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:20:08.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:20:08.119+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:20:08.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:20:08.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-30T19:20:38.529+0000] {processor.py:157} INFO - Started process (PID=78409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:20:38.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:20:38.533+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:20:38.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:20:38.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:20:38.561+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:20:38.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:20:38.574+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:20:38.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:20:38.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T19:21:09.063+0000] {processor.py:157} INFO - Started process (PID=78434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:21:09.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:21:09.067+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:21:09.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:21:09.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:21:09.096+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:21:09.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:21:09.106+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:21:09.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:21:09.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T19:21:39.456+0000] {processor.py:157} INFO - Started process (PID=78459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:21:39.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:21:39.460+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:21:39.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:21:39.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:21:39.486+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:21:39.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:21:39.496+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:21:39.496+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:21:39.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T19:22:09.945+0000] {processor.py:157} INFO - Started process (PID=78484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:22:09.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:22:09.949+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:22:09.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:22:09.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:22:09.982+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:22:09.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:22:09.991+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:22:09.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:22:09.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T19:22:40.400+0000] {processor.py:157} INFO - Started process (PID=78509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:22:40.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:22:40.406+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:22:40.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:22:40.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:22:40.442+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:22:40.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:22:40.455+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:22:40.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:22:40.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-30T19:23:10.859+0000] {processor.py:157} INFO - Started process (PID=78534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:23:10.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:23:10.862+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:23:10.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:23:10.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:23:10.893+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:23:10.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:23:10.905+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:23:10.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:23:10.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-30T19:23:41.326+0000] {processor.py:157} INFO - Started process (PID=78559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:23:41.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:23:41.327+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:23:41.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:23:41.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:23:41.347+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:23:41.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:23:41.355+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:23:41.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:23:41.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.039 seconds
[2024-07-30T19:24:11.771+0000] {processor.py:157} INFO - Started process (PID=78584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:24:11.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:24:11.776+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:24:11.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:24:11.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:24:11.807+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:24:11.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:24:11.818+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:24:11.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:24:11.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-30T19:24:42.235+0000] {processor.py:157} INFO - Started process (PID=78609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:24:42.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:24:42.239+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:24:42.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:24:42.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:24:42.265+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:24:42.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:24:42.274+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:24:42.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:24:42.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-30T19:25:12.635+0000] {processor.py:157} INFO - Started process (PID=78634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:25:12.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:25:12.641+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:25:12.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:25:12.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:25:12.676+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:25:12.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:25:12.687+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:25:12.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:25:12.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-30T19:25:43.189+0000] {processor.py:157} INFO - Started process (PID=78659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:25:43.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:25:43.193+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:25:43.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:25:43.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:25:43.222+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:25:43.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:25:43.235+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:25:43.235+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:25:43.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-30T19:26:13.609+0000] {processor.py:157} INFO - Started process (PID=78684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:26:13.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:26:13.614+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:26:13.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:26:13.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:26:13.643+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:26:13.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:26:13.653+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:26:13.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:26:13.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T19:26:44.084+0000] {processor.py:157} INFO - Started process (PID=78709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:26:44.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:26:44.088+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:26:44.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:26:44.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:26:44.118+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:26:44.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:26:44.130+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:26:44.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:26:44.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T19:27:14.483+0000] {processor.py:157} INFO - Started process (PID=78734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:27:14.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:27:14.486+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:27:14.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:27:14.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:27:14.511+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:27:14.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:27:14.520+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:27:14.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:27:14.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-30T19:27:44.932+0000] {processor.py:157} INFO - Started process (PID=78759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:27:44.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:27:44.935+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:27:44.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:27:44.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:27:44.961+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:27:44.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:27:44.970+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:27:44.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:27:44.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-30T19:28:15.419+0000] {processor.py:157} INFO - Started process (PID=78784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:28:15.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:28:15.423+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:28:15.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:28:15.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:28:15.448+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:28:15.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:28:15.460+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:28:15.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:28:15.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T19:28:45.830+0000] {processor.py:157} INFO - Started process (PID=78809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:28:45.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:28:45.835+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:28:45.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:28:45.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:28:45.862+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:28:45.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:28:45.871+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:28:45.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:28:45.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T19:29:16.329+0000] {processor.py:157} INFO - Started process (PID=78834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:29:16.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:29:16.332+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:29:16.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:29:16.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:29:16.361+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:29:16.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:29:16.371+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:29:16.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:29:16.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T19:29:46.700+0000] {processor.py:157} INFO - Started process (PID=78859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:29:46.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:29:46.704+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:29:46.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:29:46.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:29:46.737+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:29:46.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:29:46.749+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:29:46.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:29:46.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-30T19:30:17.196+0000] {processor.py:157} INFO - Started process (PID=78884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:30:17.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:30:17.199+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:30:17.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:30:17.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:30:17.227+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:30:17.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:30:17.236+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:30:17.236+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:30:17.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T19:30:47.633+0000] {processor.py:157} INFO - Started process (PID=78909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:30:47.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:30:47.637+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:30:47.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:30:47.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:30:47.661+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:30:47.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:30:47.672+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:30:47.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:30:47.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-30T19:47:19.341+0000] {processor.py:157} INFO - Started process (PID=78935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:47:19.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:47:19.357+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:47:19.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:47:19.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:47:19.451+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:47:19.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:47:19.490+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:47:19.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:47:19.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-07-30T19:47:50.121+0000] {processor.py:157} INFO - Started process (PID=78960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:47:50.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T19:47:50.131+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:47:50.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:47:50.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T19:47:50.194+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:47:50.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T19:47:50.209+0000] {logging_mixin.py:151} INFO - [2024-07-30T19:47:50.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T19:47:50.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-30T20:03:37.650+0000] {processor.py:157} INFO - Started process (PID=78986) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:03:37.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T20:03:37.653+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:03:37.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:03:37.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:03:37.689+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:03:37.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:03:37.716+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:03:37.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T20:03:37.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-30T20:04:08.345+0000] {processor.py:157} INFO - Started process (PID=79011) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:04:08.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T20:04:08.350+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:04:08.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:04:08.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:04:08.387+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:04:08.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:04:08.399+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:04:08.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T20:04:08.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-30T20:04:38.772+0000] {processor.py:157} INFO - Started process (PID=79036) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:04:38.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T20:04:38.776+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:04:38.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:04:38.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:04:38.806+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:04:38.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:04:38.817+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:04:38.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T20:04:38.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T20:05:09.288+0000] {processor.py:157} INFO - Started process (PID=79061) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:05:09.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T20:05:09.292+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:05:09.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:05:09.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:05:09.321+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:05:09.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:05:09.331+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:05:09.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T20:05:09.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T20:05:39.815+0000] {processor.py:157} INFO - Started process (PID=79086) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:05:39.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T20:05:39.818+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:05:39.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:05:39.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:05:39.846+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:05:39.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:05:39.857+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:05:39.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T20:05:39.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-30T20:23:29.204+0000] {processor.py:157} INFO - Started process (PID=79113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:23:29.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T20:23:29.222+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:23:29.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:23:29.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:23:29.302+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:23:29.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:23:29.331+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:23:29.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T20:23:29.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-07-30T20:23:59.959+0000] {processor.py:157} INFO - Started process (PID=79138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:23:59.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T20:23:59.964+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:23:59.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:23:59.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:24:00.003+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:24:00.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:24:00.020+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:24:00.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T20:24:00.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-30T20:24:30.400+0000] {processor.py:157} INFO - Started process (PID=79163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:24:30.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T20:24:30.405+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:24:30.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:24:30.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:24:30.438+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:24:30.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:24:30.450+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:24:30.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T20:24:30.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-30T20:25:00.922+0000] {processor.py:157} INFO - Started process (PID=79188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:25:00.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T20:25:00.926+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:25:00.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:25:00.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:25:00.953+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:25:00.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:25:00.965+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:25:00.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T20:25:00.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T20:25:31.367+0000] {processor.py:157} INFO - Started process (PID=79213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:25:31.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T20:25:31.370+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:25:31.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:25:31.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:25:31.402+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:25:31.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:25:31.414+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:25:31.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T20:25:31.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T20:26:01.771+0000] {processor.py:157} INFO - Started process (PID=79238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:26:01.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T20:26:01.774+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:26:01.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:26:01.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:26:01.806+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:26:01.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:26:01.817+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:26:01.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T20:26:01.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T20:26:32.194+0000] {processor.py:157} INFO - Started process (PID=79263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:26:32.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T20:26:32.198+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:26:32.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:26:32.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:26:32.226+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:26:32.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:26:32.240+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:26:32.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T20:26:32.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T20:27:02.652+0000] {processor.py:157} INFO - Started process (PID=79288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:27:02.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T20:27:02.657+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:27:02.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:27:02.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:27:02.689+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:27:02.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:27:02.699+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:27:02.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T20:27:02.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-30T20:27:33.102+0000] {processor.py:157} INFO - Started process (PID=79313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:27:33.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T20:27:33.107+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:27:33.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:27:33.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:27:33.138+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:27:33.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:27:33.149+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:27:33.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T20:27:33.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-30T20:43:04.267+0000] {processor.py:157} INFO - Started process (PID=79339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:43:04.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T20:43:04.272+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:43:04.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:43:04.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:43:04.338+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:43:04.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:43:04.360+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:43:04.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T20:43:04.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-30T20:43:34.782+0000] {processor.py:157} INFO - Started process (PID=79365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:43:34.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T20:43:34.788+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:43:34.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:43:34.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:43:34.829+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:43:34.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:43:34.842+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:43:34.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T20:43:34.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-30T20:44:05.335+0000] {processor.py:157} INFO - Started process (PID=79390) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:44:05.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T20:44:05.338+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:44:05.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:44:05.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:44:05.369+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:44:05.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:44:05.382+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:44:05.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T20:44:05.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T20:44:35.854+0000] {processor.py:157} INFO - Started process (PID=79415) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:44:35.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T20:44:35.859+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:44:35.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:44:35.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:44:35.897+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:44:35.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:44:35.910+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:44:35.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T20:44:35.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-30T20:45:06.377+0000] {processor.py:157} INFO - Started process (PID=79440) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:45:06.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T20:45:06.387+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:45:06.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:45:06.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T20:45:06.408+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:45:06.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T20:45:06.418+0000] {logging_mixin.py:151} INFO - [2024-07-30T20:45:06.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T20:45:06.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-30T21:01:41.292+0000] {processor.py:157} INFO - Started process (PID=79465) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:01:41.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T21:01:41.301+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:01:41.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:01:41.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:01:41.380+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:01:41.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:01:41.406+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:01:41.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T21:01:41.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-07-30T21:02:12.055+0000] {processor.py:157} INFO - Started process (PID=79491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:02:12.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T21:02:12.061+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:02:12.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:02:12.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:02:12.120+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:02:12.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:02:12.134+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:02:12.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T21:02:12.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-30T21:02:42.543+0000] {processor.py:157} INFO - Started process (PID=79517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:02:42.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T21:02:42.545+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:02:42.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:02:42.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:02:42.572+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:02:42.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:02:42.582+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:02:42.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T21:02:42.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-30T21:03:13.001+0000] {processor.py:157} INFO - Started process (PID=79542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:03:13.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T21:03:13.005+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:03:13.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:03:13.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:03:13.029+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:03:13.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:03:13.040+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:03:13.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T21:03:13.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-30T21:03:43.467+0000] {processor.py:157} INFO - Started process (PID=79567) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:03:43.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T21:03:43.472+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:03:43.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:03:43.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:03:43.511+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:03:43.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:03:43.523+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:03:43.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T21:03:43.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-30T21:04:13.950+0000] {processor.py:157} INFO - Started process (PID=79590) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:04:13.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T21:04:13.955+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:04:13.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:04:13.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:04:13.988+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:04:13.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:04:14.001+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:04:14.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T21:04:14.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-30T21:19:58.469+0000] {processor.py:157} INFO - Started process (PID=79618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:19:58.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T21:19:58.482+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:19:58.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:19:58.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:19:58.517+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:19:58.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:19:58.530+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:19:58.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T21:19:58.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-30T21:35:59.057+0000] {processor.py:157} INFO - Started process (PID=79643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:35:59.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T21:35:59.068+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:35:59.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:35:59.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:35:59.140+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:35:59.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:35:59.189+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:35:59.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T21:35:59.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-07-30T21:36:29.837+0000] {processor.py:157} INFO - Started process (PID=79669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:36:29.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T21:36:29.854+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:36:29.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:36:29.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:36:29.921+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:36:29.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:36:29.935+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:36:29.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T21:36:29.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-30T21:37:00.331+0000] {processor.py:157} INFO - Started process (PID=79694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:37:00.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T21:37:00.338+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:37:00.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:37:00.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:37:00.393+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:37:00.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:37:00.420+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:37:00.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T21:37:00.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-30T21:37:30.872+0000] {processor.py:157} INFO - Started process (PID=79719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:37:30.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T21:37:30.874+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:37:30.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:37:30.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:37:30.907+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:37:30.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:37:30.917+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:37:30.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T21:37:30.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T21:38:01.355+0000] {processor.py:157} INFO - Started process (PID=79744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:38:01.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T21:38:01.358+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:38:01.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:38:01.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:38:01.387+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:38:01.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:38:01.399+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:38:01.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T21:38:01.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T21:38:31.810+0000] {processor.py:157} INFO - Started process (PID=79769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:38:31.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T21:38:31.815+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:38:31.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:38:31.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:38:31.850+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:38:31.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:38:31.864+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:38:31.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T21:38:31.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-30T21:39:02.193+0000] {processor.py:157} INFO - Started process (PID=79794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:39:02.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T21:39:02.198+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:39:02.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:39:02.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:39:02.229+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:39:02.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:39:02.241+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:39:02.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T21:39:02.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-30T21:39:32.569+0000] {processor.py:157} INFO - Started process (PID=79819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:39:32.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T21:39:32.574+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:39:32.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:39:32.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:39:32.605+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:39:32.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:39:32.615+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:39:32.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T21:39:32.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-30T21:40:03.060+0000] {processor.py:157} INFO - Started process (PID=79844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:40:03.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T21:40:03.064+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:40:03.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:40:03.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:40:03.101+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:40:03.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:40:03.115+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:40:03.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T21:40:03.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-30T21:56:03.000+0000] {processor.py:157} INFO - Started process (PID=79871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:56:03.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T21:56:03.009+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:56:03.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:56:03.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:56:03.092+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:56:03.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:56:03.116+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:56:03.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T21:56:03.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-07-30T21:56:33.893+0000] {processor.py:157} INFO - Started process (PID=79896) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:56:33.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T21:56:33.906+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:56:33.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:56:33.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:56:33.965+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:56:33.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:56:33.978+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:56:33.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T21:56:33.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-30T21:57:04.415+0000] {processor.py:157} INFO - Started process (PID=79921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:57:04.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T21:57:04.418+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:57:04.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:57:04.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T21:57:04.449+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:57:04.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T21:57:04.460+0000] {logging_mixin.py:151} INFO - [2024-07-30T21:57:04.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T21:57:04.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T22:12:52.167+0000] {processor.py:157} INFO - Started process (PID=79944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:12:52.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T22:12:52.173+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:12:52.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:12:52.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:12:52.253+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:12:52.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T22:12:52.284+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:12:52.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T22:12:52.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-07-30T22:13:22.796+0000] {processor.py:157} INFO - Started process (PID=79970) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:13:22.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T22:13:22.801+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:13:22.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:13:22.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:13:22.866+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:13:22.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T22:13:22.879+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:13:22.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T22:13:22.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-30T22:13:53.302+0000] {processor.py:157} INFO - Started process (PID=79996) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:13:53.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T22:13:53.306+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:13:53.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:13:53.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:13:53.332+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:13:53.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T22:13:53.343+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:13:53.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T22:13:53.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T22:14:23.805+0000] {processor.py:157} INFO - Started process (PID=80021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:14:23.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T22:14:23.810+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:14:23.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:14:23.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:14:23.848+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:14:23.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T22:14:23.861+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:14:23.861+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T22:14:23.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-30T22:14:54.241+0000] {processor.py:157} INFO - Started process (PID=80046) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:14:54.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T22:14:54.243+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:14:54.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:14:54.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:14:54.266+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:14:54.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T22:14:54.277+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:14:54.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T22:14:54.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-30T22:31:10.267+0000] {processor.py:157} INFO - Started process (PID=80070) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:31:10.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T22:31:10.275+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:31:10.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:31:10.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:31:10.328+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:31:10.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T22:31:10.353+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:31:10.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T22:31:10.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-07-30T22:31:40.894+0000] {processor.py:157} INFO - Started process (PID=80096) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:31:40.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T22:31:40.901+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:31:40.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:31:40.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:31:40.954+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:31:40.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T22:31:40.969+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:31:40.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T22:31:40.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-30T22:47:29.382+0000] {processor.py:157} INFO - Started process (PID=80121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:47:29.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T22:47:29.401+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:47:29.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:47:29.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:47:29.516+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:47:29.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T22:47:29.553+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:47:29.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T22:47:29.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.210 seconds
[2024-07-30T22:48:00.217+0000] {processor.py:157} INFO - Started process (PID=80146) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:48:00.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T22:48:00.223+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:48:00.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:48:00.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:48:00.294+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:48:00.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T22:48:00.310+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:48:00.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T22:48:00.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-30T22:48:30.719+0000] {processor.py:157} INFO - Started process (PID=80171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:48:30.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T22:48:30.725+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:48:30.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:48:30.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:48:30.745+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:48:30.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T22:48:30.755+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:48:30.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T22:48:30.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-30T22:49:01.203+0000] {processor.py:157} INFO - Started process (PID=80196) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:49:01.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T22:49:01.207+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:49:01.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:49:01.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:49:01.245+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:49:01.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T22:49:01.257+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:49:01.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T22:49:01.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-30T22:49:31.622+0000] {processor.py:157} INFO - Started process (PID=80221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:49:31.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T22:49:31.628+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:49:31.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:49:31.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:49:31.655+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:49:31.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T22:49:31.669+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:49:31.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T22:49:31.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-30T22:50:02.016+0000] {processor.py:157} INFO - Started process (PID=80246) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:50:02.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T22:50:02.021+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:50:02.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:50:02.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:50:02.050+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:50:02.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T22:50:02.063+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:50:02.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T22:50:02.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T22:50:32.481+0000] {processor.py:157} INFO - Started process (PID=80271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:50:32.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T22:50:32.483+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:50:32.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:50:32.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:50:32.514+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:50:32.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T22:50:32.524+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:50:32.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T22:50:32.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-30T22:51:02.899+0000] {processor.py:157} INFO - Started process (PID=80296) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:51:02.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T22:51:02.902+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:51:02.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:51:02.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T22:51:02.928+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:51:02.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T22:51:02.940+0000] {logging_mixin.py:151} INFO - [2024-07-30T22:51:02.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T22:51:02.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-30T23:09:00.590+0000] {processor.py:157} INFO - Started process (PID=80323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:09:00.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T23:09:00.595+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:09:00.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:09:00.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:09:00.645+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:09:00.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T23:09:00.678+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:09:00.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T23:09:00.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-07-30T23:09:31.127+0000] {processor.py:157} INFO - Started process (PID=80348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:09:31.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T23:09:31.153+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:09:31.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:09:31.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:09:31.195+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:09:31.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T23:09:31.208+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:09:31.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T23:09:31.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-30T23:10:01.735+0000] {processor.py:157} INFO - Started process (PID=80373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:10:01.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T23:10:01.739+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:10:01.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:10:01.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:10:01.766+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:10:01.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T23:10:01.776+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:10:01.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T23:10:01.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-30T23:10:32.175+0000] {processor.py:157} INFO - Started process (PID=80398) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:10:32.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T23:10:32.177+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:10:32.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:10:32.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:10:32.199+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:10:32.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T23:10:32.208+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:10:32.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T23:10:32.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-30T23:11:02.657+0000] {processor.py:157} INFO - Started process (PID=80423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:11:02.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T23:11:02.663+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:11:02.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:11:02.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:11:02.701+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:11:02.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T23:11:02.714+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:11:02.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T23:11:02.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-30T23:27:44.245+0000] {processor.py:157} INFO - Started process (PID=80448) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:27:44.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T23:27:44.253+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:27:44.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:27:44.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:27:44.297+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:27:44.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T23:27:44.327+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:27:44.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T23:27:44.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-07-30T23:28:14.959+0000] {processor.py:157} INFO - Started process (PID=80472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:28:14.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T23:28:14.964+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:28:14.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:28:14.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:28:15.012+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:28:15.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T23:28:15.026+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:28:15.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T23:28:15.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-30T23:28:45.500+0000] {processor.py:157} INFO - Started process (PID=80498) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:28:45.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T23:28:45.504+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:28:45.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:28:45.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:28:45.533+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:28:45.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T23:28:45.545+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:28:45.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T23:28:45.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-30T23:29:15.896+0000] {processor.py:157} INFO - Started process (PID=80523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:29:15.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T23:29:15.898+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:29:15.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:29:15.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:29:15.925+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:29:15.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T23:29:15.936+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:29:15.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T23:29:15.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-30T23:44:46.077+0000] {processor.py:157} INFO - Started process (PID=80547) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:44:46.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T23:44:46.089+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:44:46.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:44:46.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:44:46.176+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:44:46.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T23:44:46.200+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:44:46.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T23:44:46.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-07-30T23:45:16.718+0000] {processor.py:157} INFO - Started process (PID=80573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:45:16.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-30T23:45:16.723+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:45:16.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:45:16.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-30T23:45:16.768+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:45:16.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-30T23:45:16.781+0000] {logging_mixin.py:151} INFO - [2024-07-30T23:45:16.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-30T01:00:00+00:00, run_after=2024-07-31T01:00:00+00:00
[2024-07-30T23:45:16.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
