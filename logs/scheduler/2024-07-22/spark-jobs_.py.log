[2024-07-22T00:00:08.613+0000] {processor.py:157} INFO - Started process (PID=78271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:00:08.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:00:08.615+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:00:08.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:00:08.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:00:08.642+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:00:08.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:00:08.650+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:00:08.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:00:08.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-22T00:01:00.036+0000] {processor.py:157} INFO - Started process (PID=78296) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:01:00.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:01:00.049+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:01:00.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:01:00.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:01:00.091+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:01:00.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:01:00.102+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:01:00.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:01:00.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-22T00:01:30.528+0000] {processor.py:157} INFO - Started process (PID=78323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:01:30.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:01:30.531+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:01:30.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:01:30.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:01:30.555+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:01:30.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:01:30.566+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:01:30.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:01:30.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T00:02:01.055+0000] {processor.py:157} INFO - Started process (PID=78348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:02:01.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:02:01.059+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:02:01.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:02:01.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:02:01.088+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:02:01.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:02:01.099+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:02:01.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:02:01.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T00:02:31.562+0000] {processor.py:157} INFO - Started process (PID=78372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:02:31.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:02:31.567+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:02:31.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:02:31.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:02:31.620+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:02:31.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:02:31.635+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:02:31.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:02:31.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-22T00:03:02.063+0000] {processor.py:157} INFO - Started process (PID=78398) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:03:02.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:03:02.066+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:03:02.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:03:02.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:03:02.096+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:03:02.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:03:02.107+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:03:02.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:03:02.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T00:03:32.555+0000] {processor.py:157} INFO - Started process (PID=78423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:03:32.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:03:32.558+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:03:32.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:03:32.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:03:32.587+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:03:32.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:03:32.599+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:03:32.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:03:32.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T00:04:02.995+0000] {processor.py:157} INFO - Started process (PID=78448) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:04:02.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:04:02.997+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:04:02.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:04:03.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:04:03.029+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:04:03.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:04:03.040+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:04:03.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:04:03.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T00:04:33.521+0000] {processor.py:157} INFO - Started process (PID=78472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:04:33.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:04:33.526+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:04:33.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:04:33.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:04:33.566+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:04:33.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:04:33.578+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:04:33.578+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:04:33.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-22T00:05:03.964+0000] {processor.py:157} INFO - Started process (PID=78498) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:05:03.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:05:03.967+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:05:03.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:05:03.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:05:03.998+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:05:03.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:05:04.011+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:05:04.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:05:04.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T00:05:34.509+0000] {processor.py:157} INFO - Started process (PID=78523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:05:34.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:05:34.513+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:05:34.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:05:34.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:05:34.545+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:05:34.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:05:34.556+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:05:34.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:05:34.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T00:06:04.997+0000] {processor.py:157} INFO - Started process (PID=78548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:06:04.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:06:05.001+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:06:05.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:06:05.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:06:05.031+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:06:05.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:06:05.044+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:06:05.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:06:05.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T00:06:35.514+0000] {processor.py:157} INFO - Started process (PID=78573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:06:35.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:06:35.520+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:06:35.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:06:35.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:06:35.556+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:06:35.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:06:35.570+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:06:35.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:06:35.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T00:07:05.916+0000] {processor.py:157} INFO - Started process (PID=78598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:07:05.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:07:05.919+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:07:05.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:07:05.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:07:05.949+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:07:05.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:07:05.960+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:07:05.959+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:07:05.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T00:07:36.359+0000] {processor.py:157} INFO - Started process (PID=78623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:07:36.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:07:36.362+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:07:36.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:07:36.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:07:36.393+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:07:36.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:07:36.405+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:07:36.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:07:36.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T00:08:06.861+0000] {processor.py:157} INFO - Started process (PID=78648) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:08:06.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:08:06.866+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:08:06.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:08:06.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:08:06.895+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:08:06.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:08:06.908+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:08:06.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:08:06.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T00:08:37.303+0000] {processor.py:157} INFO - Started process (PID=78673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:08:37.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:08:37.306+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:08:37.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:08:37.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:08:37.336+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:08:37.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:08:37.345+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:08:37.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:08:37.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T00:09:07.803+0000] {processor.py:157} INFO - Started process (PID=78698) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:09:07.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:09:07.805+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:09:07.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:09:07.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:09:07.834+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:09:07.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:09:07.845+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:09:07.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:09:07.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T00:09:38.155+0000] {processor.py:157} INFO - Started process (PID=78723) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:09:38.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:09:38.159+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:09:38.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:09:38.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:09:38.186+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:09:38.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:09:38.196+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:09:38.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:09:38.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T00:10:08.645+0000] {processor.py:157} INFO - Started process (PID=78748) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:10:08.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:10:08.648+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:10:08.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:10:08.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:10:08.676+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:10:08.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:10:08.687+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:10:08.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:10:08.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T00:10:39.072+0000] {processor.py:157} INFO - Started process (PID=78773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:10:39.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:10:39.076+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:10:39.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:10:39.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:10:39.103+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:10:39.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:10:39.115+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:10:39.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:10:39.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T00:11:09.690+0000] {processor.py:157} INFO - Started process (PID=78798) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:11:09.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:11:09.694+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:11:09.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:11:09.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:11:09.722+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:11:09.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:11:09.733+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:11:09.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:11:09.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T00:11:40.178+0000] {processor.py:157} INFO - Started process (PID=78823) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:11:40.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:11:40.183+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:11:40.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:11:40.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:11:40.217+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:11:40.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:11:40.229+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:11:40.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:11:40.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-22T00:12:10.720+0000] {processor.py:157} INFO - Started process (PID=78848) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:12:10.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:12:10.727+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:12:10.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:12:10.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:12:10.757+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:12:10.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:12:10.769+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:12:10.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:12:10.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-22T00:12:41.157+0000] {processor.py:157} INFO - Started process (PID=78873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:12:41.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:12:41.160+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:12:41.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:12:41.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:12:41.185+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:12:41.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:12:41.195+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:12:41.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:12:41.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-22T00:13:11.613+0000] {processor.py:157} INFO - Started process (PID=78898) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:13:11.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:13:11.622+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:13:11.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:13:11.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:13:11.648+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:13:11.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:13:11.658+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:13:11.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:13:11.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T00:13:42.097+0000] {processor.py:157} INFO - Started process (PID=78923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:13:42.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:13:42.100+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:13:42.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:13:42.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:13:42.131+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:13:42.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:13:42.143+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:13:42.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:13:42.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T00:14:12.565+0000] {processor.py:157} INFO - Started process (PID=78948) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:14:12.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:14:12.568+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:14:12.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:14:12.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:14:12.597+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:14:12.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:14:12.608+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:14:12.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:14:12.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T00:14:43.028+0000] {processor.py:157} INFO - Started process (PID=78973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:14:43.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:14:43.032+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:14:43.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:14:43.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:14:43.065+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:14:43.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:14:43.074+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:14:43.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:14:43.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T00:15:13.529+0000] {processor.py:157} INFO - Started process (PID=78998) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:15:13.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:15:13.531+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:15:13.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:15:13.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:15:13.560+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:15:13.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:15:13.570+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:15:13.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:15:13.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T00:15:44.010+0000] {processor.py:157} INFO - Started process (PID=79023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:15:44.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:15:44.013+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:15:44.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:15:44.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:15:44.040+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:15:44.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:15:44.050+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:15:44.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:15:44.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T00:16:14.446+0000] {processor.py:157} INFO - Started process (PID=79048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:16:14.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:16:14.450+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:16:14.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:16:14.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:16:14.480+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:16:14.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:16:14.491+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:16:14.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:16:14.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T00:16:44.901+0000] {processor.py:157} INFO - Started process (PID=79073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:16:44.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:16:44.904+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:16:44.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:16:44.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:16:44.932+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:16:44.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:16:44.944+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:16:44.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:16:44.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T00:17:15.325+0000] {processor.py:157} INFO - Started process (PID=79098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:17:15.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:17:15.330+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:17:15.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:17:15.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:17:15.361+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:17:15.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:17:15.374+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:17:15.374+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:17:15.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T00:17:45.789+0000] {processor.py:157} INFO - Started process (PID=79123) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:17:45.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:17:45.792+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:17:45.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:17:45.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:17:45.819+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:17:45.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:17:45.831+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:17:45.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:17:45.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T00:18:16.305+0000] {processor.py:157} INFO - Started process (PID=79148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:18:16.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:18:16.307+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:18:16.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:18:16.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:18:16.336+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:18:16.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:18:16.349+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:18:16.349+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:18:16.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T00:18:46.792+0000] {processor.py:157} INFO - Started process (PID=79173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:18:46.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:18:46.795+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:18:46.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:18:46.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:18:46.822+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:18:46.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:18:46.833+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:18:46.833+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:18:46.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T00:19:17.219+0000] {processor.py:157} INFO - Started process (PID=79198) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:19:17.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:19:17.224+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:19:17.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:19:17.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:19:17.252+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:19:17.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:19:17.265+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:19:17.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:19:17.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T00:19:47.632+0000] {processor.py:157} INFO - Started process (PID=79223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:19:47.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:19:47.635+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:19:47.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:19:47.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:19:47.665+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:19:47.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:19:47.675+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:19:47.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:19:47.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T00:20:18.061+0000] {processor.py:157} INFO - Started process (PID=79248) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:20:18.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:20:18.065+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:20:18.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:20:18.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:20:18.096+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:20:18.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:20:18.109+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:20:18.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:20:18.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T00:20:48.520+0000] {processor.py:157} INFO - Started process (PID=79273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:20:48.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:20:48.523+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:20:48.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:20:48.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:20:48.541+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:20:48.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:20:48.550+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:20:48.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:20:48.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.040 seconds
[2024-07-22T00:21:18.986+0000] {processor.py:157} INFO - Started process (PID=79298) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:21:18.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:21:18.989+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:21:18.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:21:19.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:21:19.021+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:21:19.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:21:19.033+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:21:19.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:21:19.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-22T00:21:49.444+0000] {processor.py:157} INFO - Started process (PID=79323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:21:49.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:21:49.447+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:21:49.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:21:49.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:21:49.473+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:21:49.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:21:49.485+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:21:49.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:21:49.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T00:22:19.868+0000] {processor.py:157} INFO - Started process (PID=79348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:22:19.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:22:19.873+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:22:19.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:22:19.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:22:19.901+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:22:19.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:22:19.912+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:22:19.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:22:19.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T00:22:50.392+0000] {processor.py:157} INFO - Started process (PID=79373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:22:50.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:22:50.395+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:22:50.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:22:50.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:22:50.426+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:22:50.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:22:50.435+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:22:50.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:22:50.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T00:23:20.795+0000] {processor.py:157} INFO - Started process (PID=79398) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:23:20.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:23:20.798+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:23:20.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:23:20.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:23:20.828+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:23:20.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:23:20.839+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:23:20.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:23:20.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T00:23:51.241+0000] {processor.py:157} INFO - Started process (PID=79423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:23:51.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:23:51.245+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:23:51.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:23:51.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:23:51.276+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:23:51.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:23:51.287+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:23:51.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:23:51.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T00:24:21.673+0000] {processor.py:157} INFO - Started process (PID=79448) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:24:21.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:24:21.675+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:24:21.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:24:21.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:24:21.700+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:24:21.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:24:21.710+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:24:21.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:24:21.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-22T00:24:52.098+0000] {processor.py:157} INFO - Started process (PID=79473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:24:52.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:24:52.102+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:24:52.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:24:52.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:24:52.137+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:24:52.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:24:52.149+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:24:52.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:24:52.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-22T00:25:22.634+0000] {processor.py:157} INFO - Started process (PID=79498) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:25:22.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:25:22.637+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:25:22.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:25:22.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:25:22.664+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:25:22.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:25:22.674+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:25:22.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:25:22.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T00:25:53.115+0000] {processor.py:157} INFO - Started process (PID=79523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:25:53.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:25:53.117+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:25:53.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:25:53.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:25:53.150+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:25:53.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:25:53.162+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:25:53.162+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:25:53.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T00:26:23.669+0000] {processor.py:157} INFO - Started process (PID=79548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:26:23.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:26:23.673+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:26:23.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:26:23.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:26:23.701+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:26:23.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:26:23.716+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:26:23.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:26:23.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T00:26:54.134+0000] {processor.py:157} INFO - Started process (PID=79573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:26:54.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:26:54.138+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:26:54.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:26:54.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:26:54.166+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:26:54.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:26:54.175+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:26:54.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:26:54.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T00:27:24.520+0000] {processor.py:157} INFO - Started process (PID=79598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:27:24.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:27:24.524+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:27:24.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:27:24.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:27:24.553+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:27:24.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:27:24.565+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:27:24.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:27:24.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T00:27:54.911+0000] {processor.py:157} INFO - Started process (PID=79623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:27:54.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:27:54.913+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:27:54.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:27:54.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:27:54.933+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:27:54.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:27:54.942+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:27:54.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:27:54.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-22T00:28:25.393+0000] {processor.py:157} INFO - Started process (PID=79648) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:28:25.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:28:25.397+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:28:25.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:28:25.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:28:25.429+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:28:25.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:28:25.439+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:28:25.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:28:25.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T00:28:55.860+0000] {processor.py:157} INFO - Started process (PID=79673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:28:55.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:28:55.865+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:28:55.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:28:55.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:28:55.896+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:28:55.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:28:55.909+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:28:55.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:28:55.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T00:29:26.325+0000] {processor.py:157} INFO - Started process (PID=79698) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:29:26.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:29:26.331+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:29:26.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:29:26.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:29:26.365+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:29:26.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:29:26.380+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:29:26.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:29:26.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-22T00:29:56.853+0000] {processor.py:157} INFO - Started process (PID=79723) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:29:56.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:29:56.858+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:29:56.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:29:56.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:29:56.888+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:29:56.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:29:56.899+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:29:56.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:29:56.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T00:30:27.229+0000] {processor.py:157} INFO - Started process (PID=80142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:30:27.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:30:27.237+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:30:27.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:30:27.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:30:27.272+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:30:27.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:30:27.283+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:30:27.283+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:30:27.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-22T00:30:57.763+0000] {processor.py:157} INFO - Started process (PID=80167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:30:57.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:30:57.769+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:30:57.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:30:57.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:30:57.807+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:30:57.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:30:57.822+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:30:57.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:30:57.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-22T00:31:28.269+0000] {processor.py:157} INFO - Started process (PID=80192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:31:28.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:31:28.274+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:31:28.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:31:28.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:31:28.311+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:31:28.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:31:28.322+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:31:28.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:31:28.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-22T00:31:58.797+0000] {processor.py:157} INFO - Started process (PID=80217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:31:58.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:31:58.801+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:31:58.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:31:58.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:31:58.827+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:31:58.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:31:58.837+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:31:58.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:31:58.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T00:32:29.279+0000] {processor.py:157} INFO - Started process (PID=80245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:32:29.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:32:29.284+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:32:29.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:32:29.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:32:29.318+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:32:29.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:32:29.329+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:32:29.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:32:29.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-22T00:32:59.784+0000] {processor.py:157} INFO - Started process (PID=80270) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:32:59.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:32:59.788+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:32:59.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:32:59.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:32:59.821+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:32:59.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:32:59.834+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:32:59.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:32:59.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-22T00:33:30.238+0000] {processor.py:157} INFO - Started process (PID=80295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:33:30.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:33:30.243+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:33:30.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:33:30.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:33:30.282+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:33:30.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:33:30.295+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:33:30.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:33:30.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-22T00:34:00.771+0000] {processor.py:157} INFO - Started process (PID=80320) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:34:00.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:34:00.776+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:34:00.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:34:00.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:34:00.815+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:34:00.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:34:00.830+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:34:00.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:34:00.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-22T00:34:31.251+0000] {processor.py:157} INFO - Started process (PID=80345) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:34:31.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:34:31.254+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:34:31.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:34:31.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:34:31.284+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:34:31.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:34:31.296+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:34:31.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:34:31.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T00:35:01.769+0000] {processor.py:157} INFO - Started process (PID=80370) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:35:01.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:35:01.772+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:35:01.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:35:01.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:35:01.801+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:35:01.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:35:01.813+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:35:01.813+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:35:01.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T00:35:32.267+0000] {processor.py:157} INFO - Started process (PID=80395) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:35:32.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:35:32.275+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:35:32.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:35:32.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:35:32.302+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:35:32.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:35:32.312+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:35:32.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:35:32.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T00:36:02.779+0000] {processor.py:157} INFO - Started process (PID=80420) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:36:02.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:36:02.783+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:36:02.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:36:02.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:36:02.827+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:36:02.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:36:02.840+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:36:02.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:36:02.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-22T00:36:33.291+0000] {processor.py:157} INFO - Started process (PID=80445) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:36:33.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:36:33.295+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:36:33.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:36:33.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:36:33.325+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:36:33.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:36:33.337+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:36:33.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:36:33.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T00:37:03.769+0000] {processor.py:157} INFO - Started process (PID=80470) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:37:03.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:37:03.773+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:37:03.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:37:03.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:37:03.808+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:37:03.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:37:03.819+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:37:03.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:37:03.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T00:37:34.230+0000] {processor.py:157} INFO - Started process (PID=80495) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:37:34.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:37:34.235+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:37:34.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:37:34.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:37:34.270+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:37:34.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:37:34.283+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:37:34.283+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:37:34.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-22T00:38:04.650+0000] {processor.py:157} INFO - Started process (PID=80520) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:38:04.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:38:04.654+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:38:04.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:38:04.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:38:04.683+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:38:04.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:38:04.692+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:38:04.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:38:04.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T00:38:35.142+0000] {processor.py:157} INFO - Started process (PID=80545) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:38:35.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:38:35.145+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:38:35.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:38:35.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:38:35.175+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:38:35.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:38:35.189+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:38:35.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:38:35.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-22T00:39:05.595+0000] {processor.py:157} INFO - Started process (PID=80570) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:39:05.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:39:05.599+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:39:05.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:39:05.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:39:05.628+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:39:05.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:39:05.638+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:39:05.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:39:05.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T00:39:36.011+0000] {processor.py:157} INFO - Started process (PID=80595) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:39:36.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:39:36.014+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:39:36.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:39:36.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:39:36.058+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:39:36.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:39:36.070+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:39:36.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:39:36.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-22T00:40:06.492+0000] {processor.py:157} INFO - Started process (PID=80620) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:40:06.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:40:06.494+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:40:06.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:40:06.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:40:06.524+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:40:06.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:40:06.535+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:40:06.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:40:06.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T00:40:37.012+0000] {processor.py:157} INFO - Started process (PID=80645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:40:37.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:40:37.016+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:40:37.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:40:37.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:40:37.046+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:40:37.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:40:37.056+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:40:37.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:40:37.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T00:41:07.521+0000] {processor.py:157} INFO - Started process (PID=80670) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:41:07.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:41:07.524+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:41:07.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:41:07.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:41:07.556+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:41:07.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:41:07.566+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:41:07.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:41:07.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T00:41:38.004+0000] {processor.py:157} INFO - Started process (PID=80695) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:41:38.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:41:38.006+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:41:38.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:41:38.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:41:38.033+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:41:38.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:41:38.043+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:41:38.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:41:38.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T00:42:08.494+0000] {processor.py:157} INFO - Started process (PID=80719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:42:08.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:42:08.507+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:42:08.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:42:08.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:42:08.565+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:42:08.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:42:08.587+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:42:08.586+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:42:08.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-22T00:42:39.037+0000] {processor.py:157} INFO - Started process (PID=80745) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:42:39.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:42:39.041+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:42:39.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:42:39.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:42:39.073+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:42:39.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:42:39.083+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:42:39.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:42:39.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T00:43:09.554+0000] {processor.py:157} INFO - Started process (PID=80770) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:43:09.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:43:09.565+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:43:09.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:43:09.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:43:09.593+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:43:09.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:43:09.604+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:43:09.604+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:43:09.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-22T00:43:40.031+0000] {processor.py:157} INFO - Started process (PID=80795) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:43:40.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:43:40.035+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:43:40.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:43:40.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:43:40.063+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:43:40.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:43:40.075+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:43:40.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:43:40.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T00:44:10.488+0000] {processor.py:157} INFO - Started process (PID=80820) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:44:10.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:44:10.494+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:44:10.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:44:10.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:44:10.527+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:44:10.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:44:10.539+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:44:10.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:44:10.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-22T00:44:40.969+0000] {processor.py:157} INFO - Started process (PID=80845) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:44:40.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:44:40.972+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:44:40.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:44:40.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:44:41.002+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:44:41.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:44:41.013+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:44:41.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:44:41.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T00:45:11.463+0000] {processor.py:157} INFO - Started process (PID=80870) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:45:11.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:45:11.466+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:45:11.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:45:11.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:45:11.493+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:45:11.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:45:11.503+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:45:11.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:45:11.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T00:45:41.901+0000] {processor.py:157} INFO - Started process (PID=80895) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:45:41.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:45:41.904+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:45:41.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:45:41.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:45:41.935+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:45:41.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:45:41.945+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:45:41.945+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:45:41.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T00:46:12.344+0000] {processor.py:157} INFO - Started process (PID=80920) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:46:12.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:46:12.349+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:46:12.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:46:12.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:46:12.381+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:46:12.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:46:12.392+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:46:12.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:46:12.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T00:46:42.834+0000] {processor.py:157} INFO - Started process (PID=80945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:46:42.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:46:42.838+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:46:42.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:46:42.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:46:42.868+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:46:42.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:46:42.877+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:46:42.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:46:42.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T00:47:13.312+0000] {processor.py:157} INFO - Started process (PID=80970) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:47:13.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:47:13.317+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:47:13.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:47:13.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:47:13.353+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:47:13.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:47:13.367+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:47:13.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:47:13.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-22T00:47:43.756+0000] {processor.py:157} INFO - Started process (PID=80995) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:47:43.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:47:43.762+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:47:43.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:47:43.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:47:43.794+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:47:43.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:47:43.808+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:47:43.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:47:43.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-22T00:48:14.321+0000] {processor.py:157} INFO - Started process (PID=81020) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:48:14.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:48:14.325+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:48:14.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:48:14.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:48:14.354+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:48:14.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:48:14.365+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:48:14.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:48:14.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T00:48:44.718+0000] {processor.py:157} INFO - Started process (PID=81045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:48:44.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:48:44.722+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:48:44.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:48:44.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:48:44.751+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:48:44.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:48:44.762+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:48:44.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:48:44.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T00:49:15.083+0000] {processor.py:157} INFO - Started process (PID=81070) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:49:15.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:49:15.087+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:49:15.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:49:15.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:49:15.119+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:49:15.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:49:15.129+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:49:15.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:49:15.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T00:49:45.519+0000] {processor.py:157} INFO - Started process (PID=81095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:49:45.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:49:45.522+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:49:45.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:49:45.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:49:45.551+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:49:45.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:49:45.561+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:49:45.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:49:45.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T00:50:15.988+0000] {processor.py:157} INFO - Started process (PID=81120) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:50:15.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:50:16.003+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:50:16.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:50:16.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:50:16.041+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:50:16.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:50:16.054+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:50:16.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:50:16.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-22T00:50:46.525+0000] {processor.py:157} INFO - Started process (PID=81145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:50:46.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:50:46.530+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:50:46.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:50:46.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:50:46.569+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:50:46.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:50:46.582+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:50:46.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:50:46.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-22T00:51:17.065+0000] {processor.py:157} INFO - Started process (PID=81170) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:51:17.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:51:17.069+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:51:17.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:51:17.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:51:17.099+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:51:17.099+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:51:17.109+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:51:17.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:51:17.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T00:51:47.510+0000] {processor.py:157} INFO - Started process (PID=81195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:51:47.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:51:47.516+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:51:47.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:51:47.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:51:47.553+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:51:47.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:51:47.566+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:51:47.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:51:47.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-22T00:52:18.006+0000] {processor.py:157} INFO - Started process (PID=81220) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:52:18.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:52:18.011+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:52:18.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:52:18.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:52:18.044+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:52:18.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:52:18.055+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:52:18.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:52:18.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-22T00:52:48.570+0000] {processor.py:157} INFO - Started process (PID=81245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:52:48.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:52:48.574+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:52:48.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:52:48.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:52:48.607+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:52:48.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:52:48.619+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:52:48.619+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:52:48.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-22T00:53:18.993+0000] {processor.py:157} INFO - Started process (PID=81270) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:53:18.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:53:18.996+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:53:18.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:53:19.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:53:19.024+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:53:19.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:53:19.035+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:53:19.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:53:19.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T00:53:49.437+0000] {processor.py:157} INFO - Started process (PID=81295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:53:49.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:53:49.440+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:53:49.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:53:49.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:53:49.473+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:53:49.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:53:49.484+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:53:49.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:53:49.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T00:54:19.877+0000] {processor.py:157} INFO - Started process (PID=81320) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:54:19.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:54:19.881+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:54:19.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:54:19.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:54:19.916+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:54:19.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:54:19.928+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:54:19.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:54:19.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-22T00:54:50.296+0000] {processor.py:157} INFO - Started process (PID=81345) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:54:50.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:54:50.298+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:54:50.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:54:50.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:54:50.322+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:54:50.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:54:50.332+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:54:50.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:54:50.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-22T00:55:20.748+0000] {processor.py:157} INFO - Started process (PID=81370) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:55:20.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:55:20.752+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:55:20.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:55:20.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:55:20.778+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:55:20.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:55:20.788+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:55:20.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:55:20.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T00:55:51.243+0000] {processor.py:157} INFO - Started process (PID=81395) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:55:51.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:55:51.247+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:55:51.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:55:51.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:55:51.272+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:55:51.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:55:51.282+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:55:51.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:55:51.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T00:56:21.768+0000] {processor.py:157} INFO - Started process (PID=81420) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:56:21.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:56:21.772+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:56:21.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:56:21.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:56:21.803+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:56:21.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:56:21.815+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:56:21.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:56:21.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T00:56:52.267+0000] {processor.py:157} INFO - Started process (PID=81445) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:56:52.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:56:52.270+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:56:52.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:56:52.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:56:52.297+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:56:52.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:56:52.307+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:56:52.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:56:52.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T00:57:22.772+0000] {processor.py:157} INFO - Started process (PID=81470) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:57:22.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:57:22.777+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:57:22.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:57:22.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:57:22.813+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:57:22.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:57:22.825+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:57:22.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:57:22.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-22T00:57:53.265+0000] {processor.py:157} INFO - Started process (PID=81495) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:57:53.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:57:53.267+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:57:53.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:57:53.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:57:53.301+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:57:53.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:57:53.311+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:57:53.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:57:53.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T00:58:23.801+0000] {processor.py:157} INFO - Started process (PID=81519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:58:23.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:58:23.806+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:58:23.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:58:23.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:58:23.858+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:58:23.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:58:23.870+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:58:23.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:58:23.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-22T00:58:54.336+0000] {processor.py:157} INFO - Started process (PID=81545) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:58:54.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:58:54.341+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:58:54.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:58:54.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:58:54.370+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:58:54.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:58:54.380+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:58:54.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:58:54.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T00:59:24.776+0000] {processor.py:157} INFO - Started process (PID=81570) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:59:24.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:59:24.779+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:59:24.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:59:24.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:59:24.812+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:59:24.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:59:24.829+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:59:24.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:59:24.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-22T00:59:55.252+0000] {processor.py:157} INFO - Started process (PID=81595) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:59:55.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T00:59:55.258+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:59:55.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:59:55.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T00:59:55.281+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:59:55.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T00:59:55.291+0000] {logging_mixin.py:151} INFO - [2024-07-22T00:59:55.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-22T00:59:55.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T01:00:25.697+0000] {processor.py:157} INFO - Started process (PID=82013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:00:25.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T01:00:25.710+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:00:25.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:00:25.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:00:25.756+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:00:25.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T01:00:25.771+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:00:25.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T01:00:25.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-22T01:00:56.669+0000] {processor.py:157} INFO - Started process (PID=82038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:00:56.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T01:00:56.681+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:00:56.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:00:56.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:00:56.853+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:00:56.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T01:00:56.872+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:00:56.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T01:00:56.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.252 seconds
[2024-07-22T01:14:53.379+0000] {processor.py:157} INFO - Started process (PID=82065) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:14:53.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T01:14:53.390+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:14:53.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:14:53.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:14:53.451+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:14:53.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T01:14:53.479+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:14:53.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T01:14:53.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-22T01:15:23.931+0000] {processor.py:157} INFO - Started process (PID=82090) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:15:23.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T01:15:23.936+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:15:23.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:15:23.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:15:23.976+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:15:23.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T01:15:23.989+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:15:23.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T01:15:23.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T01:31:15.851+0000] {processor.py:157} INFO - Started process (PID=82115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:31:15.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T01:31:15.853+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:31:15.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:31:15.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:31:15.882+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:31:15.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T01:31:15.898+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:31:15.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T01:31:15.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T01:48:41.285+0000] {processor.py:157} INFO - Started process (PID=82141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:48:41.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T01:48:41.290+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:48:41.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:48:41.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:48:41.336+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:48:41.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T01:48:41.361+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:48:41.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T01:48:41.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-22T01:49:11.832+0000] {processor.py:157} INFO - Started process (PID=82167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:49:11.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T01:49:11.838+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:49:11.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:49:11.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:49:11.897+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:49:11.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T01:49:11.911+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:49:11.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T01:49:11.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-22T01:49:42.333+0000] {processor.py:157} INFO - Started process (PID=82192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:49:42.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T01:49:42.338+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:49:42.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:49:42.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:49:42.371+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:49:42.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T01:49:42.381+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:49:42.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T01:49:42.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T01:50:12.796+0000] {processor.py:157} INFO - Started process (PID=82217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:50:12.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T01:50:12.800+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:50:12.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:50:12.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:50:12.829+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:50:12.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T01:50:12.841+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:50:12.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T01:50:12.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T01:50:43.200+0000] {processor.py:157} INFO - Started process (PID=82242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:50:43.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T01:50:43.203+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:50:43.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:50:43.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:50:43.229+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:50:43.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T01:50:43.243+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:50:43.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T01:50:43.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T01:51:13.603+0000] {processor.py:157} INFO - Started process (PID=82267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:51:13.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T01:51:13.605+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:51:13.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:51:13.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T01:51:13.632+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:51:13.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T01:51:13.645+0000] {logging_mixin.py:151} INFO - [2024-07-22T01:51:13.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T01:51:13.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T02:00:16.830+0000] {processor.py:157} INFO - Started process (PID=82292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:00:16.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:00:16.840+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:00:16.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:00:16.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:00:16.886+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:00:16.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:00:16.905+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:00:16.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:00:16.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-22T02:00:47.341+0000] {processor.py:157} INFO - Started process (PID=82317) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:00:47.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:00:47.345+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:00:47.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:00:47.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:00:47.371+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:00:47.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:00:47.383+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:00:47.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:00:47.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T02:01:17.800+0000] {processor.py:157} INFO - Started process (PID=82342) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:01:17.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:01:17.802+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:01:17.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:01:17.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:01:17.829+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:01:17.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:01:17.839+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:01:17.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:01:17.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T02:01:48.183+0000] {processor.py:157} INFO - Started process (PID=82367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:01:48.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:01:48.186+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:01:48.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:01:48.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:01:48.221+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:01:48.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:01:48.234+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:01:48.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:01:48.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-22T02:18:40.630+0000] {processor.py:157} INFO - Started process (PID=82392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:18:40.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:18:40.636+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:18:40.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:18:40.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:18:40.669+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:18:40.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:18:40.685+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:18:40.685+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:18:40.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T02:19:11.134+0000] {processor.py:157} INFO - Started process (PID=82419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:19:11.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:19:11.142+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:19:11.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:19:11.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:19:11.180+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:19:11.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:19:11.191+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:19:11.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:19:11.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-22T02:35:11.724+0000] {processor.py:157} INFO - Started process (PID=82444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:35:11.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:35:11.729+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:35:11.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:35:11.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:35:11.761+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:35:11.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:35:11.772+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:35:11.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:35:11.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-22T02:35:42.264+0000] {processor.py:157} INFO - Started process (PID=82469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:35:42.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:35:42.268+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:35:42.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:35:42.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:35:42.305+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:35:42.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:35:42.316+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:35:42.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:35:42.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-22T02:36:12.795+0000] {processor.py:157} INFO - Started process (PID=82494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:36:12.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:36:12.798+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:36:12.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:36:12.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:36:12.826+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:36:12.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:36:12.838+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:36:12.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:36:12.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T02:36:43.232+0000] {processor.py:157} INFO - Started process (PID=82519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:36:43.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:36:43.234+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:36:43.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:36:43.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:36:43.264+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:36:43.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:36:43.274+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:36:43.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:36:43.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T02:37:13.699+0000] {processor.py:157} INFO - Started process (PID=82544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:37:13.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:37:13.702+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:37:13.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:37:13.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:37:13.731+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:37:13.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:37:13.741+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:37:13.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:37:13.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T02:37:44.118+0000] {processor.py:157} INFO - Started process (PID=82569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:37:44.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:37:44.123+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:37:44.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:37:44.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:37:44.153+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:37:44.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:37:44.165+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:37:44.165+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:37:44.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T02:38:14.561+0000] {processor.py:157} INFO - Started process (PID=82594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:38:14.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:38:14.563+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:38:14.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:38:14.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:38:14.586+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:38:14.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:38:14.596+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:38:14.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:38:14.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-22T02:38:45.041+0000] {processor.py:157} INFO - Started process (PID=82619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:38:45.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:38:45.045+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:38:45.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:38:45.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:38:45.071+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:38:45.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:38:45.082+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:38:45.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:38:45.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T02:39:15.561+0000] {processor.py:157} INFO - Started process (PID=82644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:39:15.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:39:15.565+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:39:15.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:39:15.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:39:15.595+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:39:15.595+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:39:15.605+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:39:15.605+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:39:15.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T02:39:46.005+0000] {processor.py:157} INFO - Started process (PID=82669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:39:46.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:39:46.008+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:39:46.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:39:46.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:39:46.037+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:39:46.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:39:46.047+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:39:46.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:39:46.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T02:40:16.517+0000] {processor.py:157} INFO - Started process (PID=82694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:40:16.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:40:16.521+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:40:16.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:40:16.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:40:16.553+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:40:16.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:40:16.566+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:40:16.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:40:16.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-22T02:40:47.001+0000] {processor.py:157} INFO - Started process (PID=82719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:40:47.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:40:47.004+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:40:47.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:40:47.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:40:47.032+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:40:47.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:40:47.044+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:40:47.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:40:47.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T02:41:17.515+0000] {processor.py:157} INFO - Started process (PID=82744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:41:17.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:41:17.520+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:41:17.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:41:17.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:41:17.550+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:41:17.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:41:17.561+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:41:17.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:41:17.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T02:41:47.892+0000] {processor.py:157} INFO - Started process (PID=82769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:41:47.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:41:47.895+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:41:47.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:41:47.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:41:47.920+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:41:47.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:41:47.931+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:41:47.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:41:47.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T02:42:18.338+0000] {processor.py:157} INFO - Started process (PID=82794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:42:18.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:42:18.342+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:42:18.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:42:18.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:42:18.366+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:42:18.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:42:18.379+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:42:18.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:42:18.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T02:42:48.794+0000] {processor.py:157} INFO - Started process (PID=82819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:42:48.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:42:48.798+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:42:48.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:42:48.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:42:48.824+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:42:48.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:42:48.835+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:42:48.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:42:48.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T02:43:19.280+0000] {processor.py:157} INFO - Started process (PID=82844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:43:19.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:43:19.284+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:43:19.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:43:19.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:43:19.311+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:43:19.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:43:19.320+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:43:19.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:43:19.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T02:43:49.807+0000] {processor.py:157} INFO - Started process (PID=82869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:43:49.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:43:49.811+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:43:49.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:43:49.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:43:49.839+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:43:49.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:43:49.851+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:43:49.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:43:49.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T02:44:20.367+0000] {processor.py:157} INFO - Started process (PID=82894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:44:20.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:44:20.370+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:44:20.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:44:20.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:44:20.405+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:44:20.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:44:20.417+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:44:20.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:44:20.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-22T02:44:50.845+0000] {processor.py:157} INFO - Started process (PID=82919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:44:50.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:44:50.847+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:44:50.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:44:50.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:44:50.872+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:44:50.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:44:50.882+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:44:50.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:44:50.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-22T02:45:21.317+0000] {processor.py:157} INFO - Started process (PID=82944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:45:21.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:45:21.321+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:45:21.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:45:21.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:45:21.350+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:45:21.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:45:21.359+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:45:21.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:45:21.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T02:45:51.832+0000] {processor.py:157} INFO - Started process (PID=82969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:45:51.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:45:51.837+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:45:51.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:45:51.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:45:51.863+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:45:51.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:45:51.873+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:45:51.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:45:51.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T02:46:22.392+0000] {processor.py:157} INFO - Started process (PID=82994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:46:22.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:46:22.398+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:46:22.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:46:22.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:46:22.425+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:46:22.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:46:22.435+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:46:22.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:46:22.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T02:46:52.938+0000] {processor.py:157} INFO - Started process (PID=83019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:46:52.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:46:52.943+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:46:52.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:46:52.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:46:52.974+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:46:52.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:46:52.983+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:46:52.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:46:52.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T02:47:23.383+0000] {processor.py:157} INFO - Started process (PID=83044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:47:23.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:47:23.386+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:47:23.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:47:23.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:47:23.415+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:47:23.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:47:23.426+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:47:23.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:47:23.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T02:47:53.900+0000] {processor.py:157} INFO - Started process (PID=83069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:47:53.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:47:53.903+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:47:53.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:47:53.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:47:53.932+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:47:53.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:47:53.945+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:47:53.945+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:47:53.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T02:48:24.333+0000] {processor.py:157} INFO - Started process (PID=83094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:48:24.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:48:24.336+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:48:24.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:48:24.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:48:24.367+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:48:24.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:48:24.377+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:48:24.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:48:24.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T02:48:54.782+0000] {processor.py:157} INFO - Started process (PID=83119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:48:54.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:48:54.786+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:48:54.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:48:54.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:48:54.815+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:48:54.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:48:54.825+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:48:54.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:48:54.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T02:49:25.209+0000] {processor.py:157} INFO - Started process (PID=83144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:49:25.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:49:25.214+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:49:25.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:49:25.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:49:25.243+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:49:25.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:49:25.255+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:49:25.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:49:25.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T02:49:55.750+0000] {processor.py:157} INFO - Started process (PID=83169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:49:55.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:49:55.754+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:49:55.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:49:55.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:49:55.780+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:49:55.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:49:55.790+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:49:55.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:49:55.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T02:50:26.268+0000] {processor.py:157} INFO - Started process (PID=83194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:50:26.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:50:26.274+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:50:26.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:50:26.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:50:26.308+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:50:26.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:50:26.319+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:50:26.319+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:50:26.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-22T02:50:56.782+0000] {processor.py:157} INFO - Started process (PID=83219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:50:56.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:50:56.785+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:50:56.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:50:56.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:50:56.814+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:50:56.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:50:56.824+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:50:56.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:50:56.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T02:51:27.248+0000] {processor.py:157} INFO - Started process (PID=83244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:51:27.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:51:27.250+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:51:27.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:51:27.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:51:27.273+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:51:27.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:51:27.283+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:51:27.283+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:51:27.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-22T02:51:57.797+0000] {processor.py:157} INFO - Started process (PID=83269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:51:57.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:51:57.800+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:51:57.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:51:57.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:51:57.829+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:51:57.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:51:57.839+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:51:57.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:51:57.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T02:52:28.198+0000] {processor.py:157} INFO - Started process (PID=83294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:52:28.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:52:28.202+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:52:28.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:52:28.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:52:28.228+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:52:28.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:52:28.240+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:52:28.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:52:28.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T02:52:58.706+0000] {processor.py:157} INFO - Started process (PID=83319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:52:58.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:52:58.710+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:52:58.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:52:58.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:52:58.736+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:52:58.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:52:58.745+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:52:58.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:52:58.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T02:53:29.208+0000] {processor.py:157} INFO - Started process (PID=83344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:53:29.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:53:29.212+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:53:29.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:53:29.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:53:29.240+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:53:29.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:53:29.253+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:53:29.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:53:29.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T02:53:59.643+0000] {processor.py:157} INFO - Started process (PID=83369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:53:59.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:53:59.646+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:53:59.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:53:59.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:53:59.675+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:53:59.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:53:59.686+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:53:59.686+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:53:59.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T02:54:30.168+0000] {processor.py:157} INFO - Started process (PID=83394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:54:30.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:54:30.171+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:54:30.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:54:30.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:54:30.201+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:54:30.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:54:30.213+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:54:30.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:54:30.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T02:55:00.688+0000] {processor.py:157} INFO - Started process (PID=83419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:55:00.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:55:00.691+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:55:00.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:55:00.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:55:00.721+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:55:00.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:55:00.730+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:55:00.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:55:00.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T02:55:31.154+0000] {processor.py:157} INFO - Started process (PID=83444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:55:31.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:55:31.158+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:55:31.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:55:31.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:55:31.185+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:55:31.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:55:31.196+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:55:31.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:55:31.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T02:56:01.559+0000] {processor.py:157} INFO - Started process (PID=83469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:56:01.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:56:01.563+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:56:01.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:56:01.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:56:01.592+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:56:01.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:56:01.603+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:56:01.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:56:01.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T02:56:32.141+0000] {processor.py:157} INFO - Started process (PID=83494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:56:32.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:56:32.148+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:56:32.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:56:32.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:56:32.172+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:56:32.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:56:32.184+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:56:32.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:56:32.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T02:57:02.611+0000] {processor.py:157} INFO - Started process (PID=83519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:57:02.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:57:02.615+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:57:02.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:57:02.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:57:02.649+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:57:02.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:57:02.662+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:57:02.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:57:02.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-22T02:57:33.061+0000] {processor.py:157} INFO - Started process (PID=83543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:57:33.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:57:33.065+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:57:33.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:57:33.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:57:33.096+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:57:33.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:57:33.107+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:57:33.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:57:33.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T02:58:03.458+0000] {processor.py:157} INFO - Started process (PID=83569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:58:03.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:58:03.460+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:58:03.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:58:03.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:58:03.482+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:58:03.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:58:03.491+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:58:03.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:58:03.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-22T02:58:33.874+0000] {processor.py:157} INFO - Started process (PID=83594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:58:33.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:58:33.878+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:58:33.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:58:33.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:58:33.909+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:58:33.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:58:33.920+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:58:33.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:58:33.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T02:59:04.431+0000] {processor.py:157} INFO - Started process (PID=83619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:59:04.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:59:04.435+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:59:04.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:59:04.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:59:04.466+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:59:04.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:59:04.477+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:59:04.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:59:04.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T02:59:34.874+0000] {processor.py:157} INFO - Started process (PID=83644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:59:34.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T02:59:34.879+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:59:34.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:59:34.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T02:59:34.906+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:59:34.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T02:59:34.917+0000] {logging_mixin.py:151} INFO - [2024-07-22T02:59:34.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T02:59:34.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T03:00:05.333+0000] {processor.py:157} INFO - Started process (PID=83669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:00:05.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T03:00:05.337+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:00:05.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:00:05.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:00:05.372+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:00:05.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T03:00:05.384+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:00:05.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T03:00:05.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-22T03:00:35.794+0000] {processor.py:157} INFO - Started process (PID=83694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:00:35.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T03:00:35.798+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:00:35.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:00:35.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:00:35.827+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:00:35.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T03:00:35.837+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:00:35.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T03:00:35.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T03:01:06.306+0000] {processor.py:157} INFO - Started process (PID=83719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:01:06.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T03:01:06.307+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:01:06.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:01:06.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:01:06.333+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:01:06.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T03:01:06.342+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:01:06.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T03:01:06.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-22T03:01:36.813+0000] {processor.py:157} INFO - Started process (PID=83744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:01:36.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T03:01:36.817+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:01:36.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:01:36.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:01:36.846+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:01:36.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T03:01:36.857+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:01:36.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T03:01:36.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T03:02:07.296+0000] {processor.py:157} INFO - Started process (PID=83769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:02:07.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T03:02:07.299+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:02:07.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:02:07.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:02:07.329+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:02:07.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T03:02:07.341+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:02:07.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T03:02:07.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T03:02:37.721+0000] {processor.py:157} INFO - Started process (PID=83794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:02:37.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T03:02:37.725+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:02:37.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:02:37.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:02:37.759+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:02:37.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T03:02:37.771+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:02:37.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T03:02:37.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-22T03:03:08.239+0000] {processor.py:157} INFO - Started process (PID=83819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:03:08.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T03:03:08.244+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:03:08.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:03:08.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:03:08.275+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:03:08.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T03:03:08.284+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:03:08.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T03:03:08.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T03:03:38.682+0000] {processor.py:157} INFO - Started process (PID=83844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:03:38.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T03:03:38.685+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:03:38.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:03:38.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:03:38.712+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:03:38.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T03:03:38.724+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:03:38.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T03:03:38.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T03:04:09.152+0000] {processor.py:157} INFO - Started process (PID=83869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:04:09.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T03:04:09.158+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:04:09.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:04:09.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:04:09.189+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:04:09.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T03:04:09.198+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:04:09.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T03:04:09.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T03:04:39.616+0000] {processor.py:157} INFO - Started process (PID=83894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:04:39.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T03:04:39.620+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:04:39.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:04:39.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:04:39.646+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:04:39.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T03:04:39.657+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:04:39.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T03:04:39.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T03:05:09.956+0000] {processor.py:157} INFO - Started process (PID=83919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:05:09.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T03:05:09.960+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:05:09.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:05:09.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:05:09.991+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:05:09.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T03:05:10.003+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:05:10.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T03:05:10.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T03:05:40.459+0000] {processor.py:157} INFO - Started process (PID=83944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:05:40.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T03:05:40.461+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:05:40.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:05:40.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:05:40.486+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:05:40.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T03:05:40.497+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:05:40.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T03:05:40.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T03:06:11.022+0000] {processor.py:157} INFO - Started process (PID=83969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:06:11.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T03:06:11.027+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:06:11.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:06:11.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:06:11.069+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:06:11.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T03:06:11.082+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:06:11.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T03:06:11.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-22T03:06:41.642+0000] {processor.py:157} INFO - Started process (PID=83996) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:06:41.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T03:06:41.647+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:06:41.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:06:41.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:06:41.675+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:06:41.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T03:06:41.688+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:06:41.688+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T03:06:41.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T03:08:44.017+0000] {processor.py:157} INFO - Started process (PID=84021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:08:44.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T03:08:44.021+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:08:44.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:08:44.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:08:44.064+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:08:44.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T03:08:44.091+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:08:44.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T03:08:44.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-22T03:09:14.600+0000] {processor.py:157} INFO - Started process (PID=84046) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:09:14.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T03:09:14.606+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:09:14.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:09:14.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:09:14.644+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:09:14.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T03:09:14.656+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:09:14.656+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T03:09:14.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T03:11:20.085+0000] {processor.py:157} INFO - Started process (PID=84071) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:11:20.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T03:11:20.091+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:11:20.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:11:20.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:11:20.142+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:11:20.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T03:11:20.167+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:11:20.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T03:11:20.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-22T03:11:50.847+0000] {processor.py:157} INFO - Started process (PID=84096) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:11:50.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T03:11:50.852+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:11:50.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:11:50.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T03:11:50.901+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:11:50.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T03:11:50.920+0000] {logging_mixin.py:151} INFO - [2024-07-22T03:11:50.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T03:11:50.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-22T04:52:29.088+0000] {processor.py:157} INFO - Started process (PID=84123) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T04:52:29.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T04:52:29.091+0000] {logging_mixin.py:151} INFO - [2024-07-22T04:52:29.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T04:52:29.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T04:52:29.144+0000] {logging_mixin.py:151} INFO - [2024-07-22T04:52:29.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T04:52:29.166+0000] {logging_mixin.py:151} INFO - [2024-07-22T04:52:29.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T04:52:29.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-22T05:07:15.367+0000] {processor.py:157} INFO - Started process (PID=84148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T05:07:15.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T05:07:15.373+0000] {logging_mixin.py:151} INFO - [2024-07-22T05:07:15.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T05:07:15.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T05:07:15.417+0000] {logging_mixin.py:151} INFO - [2024-07-22T05:07:15.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T05:07:15.432+0000] {logging_mixin.py:151} INFO - [2024-07-22T05:07:15.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T05:07:15.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-22T05:40:56.414+0000] {processor.py:157} INFO - Started process (PID=84173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T05:40:56.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T05:40:56.418+0000] {logging_mixin.py:151} INFO - [2024-07-22T05:40:56.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T05:40:56.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T05:40:56.452+0000] {logging_mixin.py:151} INFO - [2024-07-22T05:40:56.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T05:40:56.463+0000] {logging_mixin.py:151} INFO - [2024-07-22T05:40:56.463+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T05:40:56.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-22T06:07:38.136+0000] {processor.py:157} INFO - Started process (PID=84198) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:07:38.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T06:07:38.140+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:07:38.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:07:38.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:07:38.182+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:07:38.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T06:07:38.194+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:07:38.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T06:07:38.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T06:08:14.009+0000] {processor.py:157} INFO - Started process (PID=84222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:08:14.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T06:08:14.014+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:08:14.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:08:14.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:08:14.054+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:08:14.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T06:08:14.067+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:08:14.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T06:08:14.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-22T06:08:44.523+0000] {processor.py:157} INFO - Started process (PID=84248) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:08:44.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T06:08:44.527+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:08:44.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:08:44.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:08:44.557+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:08:44.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T06:08:44.568+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:08:44.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T06:08:44.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T06:18:54.628+0000] {processor.py:157} INFO - Started process (PID=84272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:18:54.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T06:18:54.659+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:18:54.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:18:54.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:18:54.731+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:18:54.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T06:18:54.753+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:18:54.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T06:18:54.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-07-22T06:36:06.617+0000] {processor.py:157} INFO - Started process (PID=84299) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:36:06.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T06:36:06.631+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:36:06.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:36:06.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:36:06.669+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:36:06.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T06:36:06.692+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:36:06.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T06:36:06.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-22T06:55:44.467+0000] {processor.py:157} INFO - Started process (PID=84325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:55:44.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T06:55:44.474+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:55:44.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:55:44.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:55:44.552+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:55:44.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T06:55:44.574+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:55:44.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T06:55:44.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-07-22T06:56:15.037+0000] {processor.py:157} INFO - Started process (PID=84350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:56:15.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T06:56:15.042+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:56:15.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:56:15.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:56:15.089+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:56:15.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T06:56:15.103+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:56:15.103+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T06:56:15.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-22T06:56:45.467+0000] {processor.py:157} INFO - Started process (PID=84375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:56:45.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T06:56:45.469+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:56:45.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:56:45.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:56:45.498+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:56:45.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T06:56:45.510+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:56:45.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T06:56:45.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T06:57:15.921+0000] {processor.py:157} INFO - Started process (PID=84400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:57:15.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T06:57:15.924+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:57:15.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:57:15.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:57:15.956+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:57:15.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T06:57:15.966+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:57:15.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T06:57:15.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T06:57:46.420+0000] {processor.py:157} INFO - Started process (PID=84425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:57:46.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T06:57:46.427+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:57:46.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:57:46.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:57:46.459+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:57:46.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T06:57:46.471+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:57:46.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T06:57:46.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-22T06:58:16.909+0000] {processor.py:157} INFO - Started process (PID=84450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:58:16.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T06:58:16.912+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:58:16.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:58:16.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:58:16.941+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:58:16.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T06:58:16.951+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:58:16.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T06:58:16.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T06:58:47.370+0000] {processor.py:157} INFO - Started process (PID=84475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:58:47.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T06:58:47.374+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:58:47.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:58:47.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:58:47.403+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:58:47.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T06:58:47.415+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:58:47.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T06:58:47.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T06:59:17.745+0000] {processor.py:157} INFO - Started process (PID=84500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:59:17.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T06:59:17.750+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:59:17.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:59:17.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:59:17.778+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:59:17.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T06:59:17.788+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:59:17.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T06:59:17.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T06:59:48.154+0000] {processor.py:157} INFO - Started process (PID=84525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:59:48.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T06:59:48.157+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:59:48.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:59:48.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T06:59:48.188+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:59:48.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T06:59:48.201+0000] {logging_mixin.py:151} INFO - [2024-07-22T06:59:48.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T06:59:48.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T07:00:18.592+0000] {processor.py:157} INFO - Started process (PID=84550) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:00:18.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:00:18.594+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:00:18.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:00:18.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:00:18.623+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:00:18.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:00:18.635+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:00:18.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:00:18.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T07:00:49.058+0000] {processor.py:157} INFO - Started process (PID=84575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:00:49.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:00:49.061+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:00:49.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:00:49.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:00:49.091+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:00:49.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:00:49.102+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:00:49.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:00:49.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T07:01:19.487+0000] {processor.py:157} INFO - Started process (PID=84600) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:01:19.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:01:19.490+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:01:19.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:01:19.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:01:19.519+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:01:19.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:01:19.529+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:01:19.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:01:19.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T07:01:49.920+0000] {processor.py:157} INFO - Started process (PID=84625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:01:49.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:01:49.926+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:01:49.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:01:49.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:01:49.963+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:01:49.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:01:49.978+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:01:49.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:01:49.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T07:02:20.429+0000] {processor.py:157} INFO - Started process (PID=84650) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:02:20.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:02:20.435+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:02:20.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:02:20.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:02:20.470+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:02:20.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:02:20.482+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:02:20.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:02:20.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-22T07:02:50.922+0000] {processor.py:157} INFO - Started process (PID=84675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:02:50.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:02:50.927+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:02:50.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:02:50.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:02:50.968+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:02:50.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:02:50.981+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:02:50.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:02:50.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-22T07:03:21.418+0000] {processor.py:157} INFO - Started process (PID=84700) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:03:21.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:03:21.421+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:03:21.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:03:21.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:03:21.448+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:03:21.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:03:21.460+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:03:21.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:03:21.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T07:03:51.853+0000] {processor.py:157} INFO - Started process (PID=84725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:03:51.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:03:51.855+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:03:51.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:03:51.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:03:51.879+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:03:51.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:03:51.889+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:03:51.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:03:51.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-22T07:04:22.245+0000] {processor.py:157} INFO - Started process (PID=84750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:04:22.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:04:22.247+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:04:22.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:04:22.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:04:22.275+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:04:22.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:04:22.285+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:04:22.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:04:22.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T07:04:52.710+0000] {processor.py:157} INFO - Started process (PID=84775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:04:52.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:04:52.713+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:04:52.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:04:52.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:04:52.744+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:04:52.744+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:04:52.755+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:04:52.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:04:52.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T07:05:23.208+0000] {processor.py:157} INFO - Started process (PID=84800) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:05:23.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:05:23.211+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:05:23.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:05:23.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:05:23.242+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:05:23.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:05:23.252+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:05:23.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:05:23.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T07:05:53.739+0000] {processor.py:157} INFO - Started process (PID=84825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:05:53.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:05:53.743+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:05:53.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:05:53.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:05:53.780+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:05:53.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:05:53.792+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:05:53.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:05:53.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-22T07:06:24.195+0000] {processor.py:157} INFO - Started process (PID=84850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:06:24.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:06:24.198+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:06:24.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:06:24.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:06:24.227+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:06:24.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:06:24.238+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:06:24.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:06:24.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T07:06:54.686+0000] {processor.py:157} INFO - Started process (PID=84875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:06:54.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:06:54.689+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:06:54.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:06:54.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:06:54.717+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:06:54.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:06:54.727+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:06:54.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:06:54.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T07:07:25.128+0000] {processor.py:157} INFO - Started process (PID=84900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:07:25.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:07:25.133+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:07:25.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:07:25.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:07:25.164+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:07:25.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:07:25.175+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:07:25.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:07:25.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T07:07:55.523+0000] {processor.py:157} INFO - Started process (PID=84925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:07:55.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:07:55.527+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:07:55.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:07:55.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:07:55.558+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:07:55.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:07:55.570+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:07:55.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:07:55.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T07:08:25.924+0000] {processor.py:157} INFO - Started process (PID=84950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:08:25.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:08:25.926+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:08:25.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:08:25.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:08:25.957+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:08:25.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:08:25.967+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:08:25.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:08:25.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T07:08:56.336+0000] {processor.py:157} INFO - Started process (PID=84975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:08:56.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:08:56.341+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:08:56.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:08:56.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:08:56.367+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:08:56.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:08:56.379+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:08:56.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:08:56.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T07:09:26.755+0000] {processor.py:157} INFO - Started process (PID=85000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:09:26.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:09:26.758+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:09:26.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:09:26.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:09:26.787+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:09:26.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:09:26.795+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:09:26.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:09:26.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T07:09:57.184+0000] {processor.py:157} INFO - Started process (PID=85025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:09:57.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:09:57.187+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:09:57.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:09:57.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:09:57.215+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:09:57.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:09:57.227+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:09:57.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:09:57.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T07:10:27.635+0000] {processor.py:157} INFO - Started process (PID=85050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:10:27.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:10:27.640+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:10:27.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:10:27.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:10:27.666+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:10:27.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:10:27.675+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:10:27.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:10:27.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T07:10:58.078+0000] {processor.py:157} INFO - Started process (PID=85075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:10:58.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:10:58.081+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:10:58.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:10:58.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:10:58.109+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:10:58.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:10:58.118+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:10:58.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:10:58.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T07:11:28.643+0000] {processor.py:157} INFO - Started process (PID=85100) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:11:28.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:11:28.647+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:11:28.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:11:28.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:11:28.680+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:11:28.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:11:28.693+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:11:28.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:11:28.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-22T07:11:59.070+0000] {processor.py:157} INFO - Started process (PID=85125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:11:59.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:11:59.073+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:11:59.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:11:59.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:11:59.099+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:11:59.099+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:11:59.110+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:11:59.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:11:59.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T07:12:29.552+0000] {processor.py:157} INFO - Started process (PID=85150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:12:29.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:12:29.555+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:12:29.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:12:29.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:12:29.581+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:12:29.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:12:29.591+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:12:29.591+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:12:29.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T07:13:00.030+0000] {processor.py:157} INFO - Started process (PID=85175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:13:00.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:13:00.050+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:13:00.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:13:00.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:13:00.092+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:13:00.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:13:00.106+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:13:00.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:13:00.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-22T07:30:22.207+0000] {processor.py:157} INFO - Started process (PID=85202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:30:22.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:30:22.220+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:30:22.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:30:22.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:30:22.278+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:30:22.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:30:22.294+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:30:22.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:30:22.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-22T07:30:52.830+0000] {processor.py:157} INFO - Started process (PID=85227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:30:52.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:30:52.835+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:30:52.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:30:52.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:30:52.872+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:30:52.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:30:52.885+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:30:52.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:30:52.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T07:31:23.342+0000] {processor.py:157} INFO - Started process (PID=85252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:31:23.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:31:23.345+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:31:23.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:31:23.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:31:23.377+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:31:23.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:31:23.387+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:31:23.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:31:23.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T07:31:53.759+0000] {processor.py:157} INFO - Started process (PID=85277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:31:53.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:31:53.763+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:31:53.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:31:53.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:31:53.791+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:31:53.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:31:53.801+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:31:53.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:31:53.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T07:32:24.197+0000] {processor.py:157} INFO - Started process (PID=85302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:32:24.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:32:24.200+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:32:24.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:32:24.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:32:24.229+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:32:24.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:32:24.241+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:32:24.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:32:24.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T07:32:54.621+0000] {processor.py:157} INFO - Started process (PID=85327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:32:54.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:32:54.625+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:32:54.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:32:54.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:32:54.656+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:32:54.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:32:54.667+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:32:54.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:32:54.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T07:33:25.090+0000] {processor.py:157} INFO - Started process (PID=85352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:33:25.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:33:25.093+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:33:25.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:33:25.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:33:25.124+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:33:25.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:33:25.136+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:33:25.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:33:25.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T07:33:55.569+0000] {processor.py:157} INFO - Started process (PID=85377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:33:55.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:33:55.574+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:33:55.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:33:55.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:33:55.603+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:33:55.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:33:55.615+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:33:55.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:33:55.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T07:34:26.019+0000] {processor.py:157} INFO - Started process (PID=85402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:34:26.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:34:26.024+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:34:26.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:34:26.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:34:26.052+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:34:26.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:34:26.062+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:34:26.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:34:26.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T07:34:56.497+0000] {processor.py:157} INFO - Started process (PID=85427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:34:56.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:34:56.501+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:34:56.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:34:56.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:34:56.526+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:34:56.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:34:56.536+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:34:56.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:34:56.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-22T07:35:26.937+0000] {processor.py:157} INFO - Started process (PID=85452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:35:26.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:35:26.940+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:35:26.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:35:26.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:35:26.970+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:35:26.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:35:26.981+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:35:26.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:35:26.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T07:35:57.397+0000] {processor.py:157} INFO - Started process (PID=85477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:35:57.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:35:57.401+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:35:57.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:35:57.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:35:57.429+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:35:57.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:35:57.441+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:35:57.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:35:57.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T07:36:27.842+0000] {processor.py:157} INFO - Started process (PID=85502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:36:27.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:36:27.845+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:36:27.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:36:27.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:36:27.872+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:36:27.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:36:27.884+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:36:27.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:36:27.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T07:36:58.341+0000] {processor.py:157} INFO - Started process (PID=85527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:36:58.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:36:58.344+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:36:58.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:36:58.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:36:58.372+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:36:58.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:36:58.384+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:36:58.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:36:58.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T07:37:28.780+0000] {processor.py:157} INFO - Started process (PID=85552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:37:28.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:37:28.784+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:37:28.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:37:28.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:37:28.810+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:37:28.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:37:28.820+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:37:28.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:37:28.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T07:37:59.257+0000] {processor.py:157} INFO - Started process (PID=85577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:37:59.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:37:59.261+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:37:59.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:37:59.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:37:59.297+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:37:59.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:37:59.310+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:37:59.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:37:59.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-22T07:38:29.696+0000] {processor.py:157} INFO - Started process (PID=85602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:38:29.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:38:29.699+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:38:29.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:38:29.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:38:29.729+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:38:29.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:38:29.738+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:38:29.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:38:29.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T07:39:00.197+0000] {processor.py:157} INFO - Started process (PID=85627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:39:00.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:39:00.200+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:39:00.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:39:00.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:39:00.222+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:39:00.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:39:00.233+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:39:00.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:39:00.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-22T07:56:18.294+0000] {processor.py:157} INFO - Started process (PID=85654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:56:18.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:56:18.299+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:56:18.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:56:18.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:56:18.367+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:56:18.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:56:18.383+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:56:18.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:56:18.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-22T07:56:48.834+0000] {processor.py:157} INFO - Started process (PID=85678) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:56:48.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T07:56:48.837+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:56:48.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:56:48.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T07:56:48.866+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:56:48.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T07:56:48.877+0000] {logging_mixin.py:151} INFO - [2024-07-22T07:56:48.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T07:56:48.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T08:12:23.844+0000] {processor.py:157} INFO - Started process (PID=85704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:12:23.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T08:12:23.850+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:12:23.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:12:23.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:12:23.903+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:12:23.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T08:12:23.918+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:12:23.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T08:12:23.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-22T08:12:54.457+0000] {processor.py:157} INFO - Started process (PID=85731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:12:54.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T08:12:54.462+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:12:54.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:12:54.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:12:54.492+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:12:54.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T08:12:54.503+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:12:54.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T08:12:54.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T08:13:24.946+0000] {processor.py:157} INFO - Started process (PID=85756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:13:24.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T08:13:24.951+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:13:24.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:13:24.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:13:24.985+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:13:24.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T08:13:24.999+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:13:24.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T08:13:25.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-22T08:13:55.406+0000] {processor.py:157} INFO - Started process (PID=85781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:13:55.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T08:13:55.411+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:13:55.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:13:55.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:13:55.445+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:13:55.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T08:13:55.456+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:13:55.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T08:13:55.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-22T08:14:25.817+0000] {processor.py:157} INFO - Started process (PID=85806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:14:25.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T08:14:25.820+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:14:25.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:14:25.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:14:25.848+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:14:25.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T08:14:25.861+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:14:25.861+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T08:14:25.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T08:30:49.414+0000] {processor.py:157} INFO - Started process (PID=85831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:30:49.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T08:30:49.417+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:30:49.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:30:49.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:30:49.447+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:30:49.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T08:30:49.457+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:30:49.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T08:30:49.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T08:47:23.775+0000] {processor.py:157} INFO - Started process (PID=85854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:47:23.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T08:47:23.780+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:47:23.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:47:23.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:47:23.825+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:47:23.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T08:47:23.840+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:47:23.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T08:47:23.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-22T08:47:54.290+0000] {processor.py:157} INFO - Started process (PID=85881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:47:54.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T08:47:54.292+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:47:54.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:47:54.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:47:54.320+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:47:54.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T08:47:54.329+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:47:54.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T08:47:54.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T08:48:24.824+0000] {processor.py:157} INFO - Started process (PID=85906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:48:24.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T08:48:24.831+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:48:24.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:48:24.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:48:24.867+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:48:24.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T08:48:24.880+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:48:24.880+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T08:48:24.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T08:48:55.414+0000] {processor.py:157} INFO - Started process (PID=85931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:48:55.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T08:48:55.417+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:48:55.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:48:55.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:48:55.447+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:48:55.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T08:48:55.457+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:48:55.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T08:48:55.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T08:49:25.903+0000] {processor.py:157} INFO - Started process (PID=85956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:49:25.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T08:49:25.905+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:49:25.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:49:25.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:49:25.924+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:49:25.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T08:49:25.935+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:49:25.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T08:49:25.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-22T08:49:56.421+0000] {processor.py:157} INFO - Started process (PID=85981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:49:56.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T08:49:56.423+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:49:56.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:49:56.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:49:56.456+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:49:56.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T08:49:56.466+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:49:56.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T08:49:56.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T08:50:26.857+0000] {processor.py:157} INFO - Started process (PID=86006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:50:26.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T08:50:26.860+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:50:26.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:50:26.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:50:26.889+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:50:26.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T08:50:26.899+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:50:26.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T08:50:26.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T08:50:57.350+0000] {processor.py:157} INFO - Started process (PID=86031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:50:57.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T08:50:57.352+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:50:57.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:50:57.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:50:57.381+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:50:57.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T08:50:57.391+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:50:57.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T08:50:57.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T08:51:27.817+0000] {processor.py:157} INFO - Started process (PID=86056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:51:27.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T08:51:27.820+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:51:27.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:51:27.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:51:27.850+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:51:27.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T08:51:27.860+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:51:27.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T08:51:27.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T08:51:58.217+0000] {processor.py:157} INFO - Started process (PID=86081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:51:58.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T08:51:58.220+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:51:58.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:51:58.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:51:58.249+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:51:58.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T08:51:58.259+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:51:58.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T08:51:58.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T08:52:28.724+0000] {processor.py:157} INFO - Started process (PID=86106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:52:28.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T08:52:28.727+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:52:28.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:52:28.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:52:28.754+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:52:28.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T08:52:28.764+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:52:28.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T08:52:28.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T08:52:59.169+0000] {processor.py:157} INFO - Started process (PID=86131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:52:59.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T08:52:59.171+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:52:59.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:52:59.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:52:59.192+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:52:59.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T08:52:59.201+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:52:59.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T08:52:59.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-22T08:53:29.650+0000] {processor.py:157} INFO - Started process (PID=86156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:53:29.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T08:53:29.653+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:53:29.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:53:29.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:53:29.680+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:53:29.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T08:53:29.692+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:53:29.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T08:53:29.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T08:54:00.169+0000] {processor.py:157} INFO - Started process (PID=86181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:54:00.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T08:54:00.173+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:54:00.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:54:00.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:54:00.202+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:54:00.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T08:54:00.212+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:54:00.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T08:54:00.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T08:54:30.701+0000] {processor.py:157} INFO - Started process (PID=86206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:54:30.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T08:54:30.704+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:54:30.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:54:30.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:54:30.730+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:54:30.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T08:54:30.740+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:54:30.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T08:54:30.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T08:55:01.179+0000] {processor.py:157} INFO - Started process (PID=86231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:55:01.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T08:55:01.181+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:55:01.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:55:01.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:55:01.213+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:55:01.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T08:55:01.224+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:55:01.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T08:55:01.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T08:55:31.614+0000] {processor.py:157} INFO - Started process (PID=86256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:55:31.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T08:55:31.616+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:55:31.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:55:31.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:55:31.645+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:55:31.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T08:55:31.654+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:55:31.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T08:55:31.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T08:56:02.163+0000] {processor.py:157} INFO - Started process (PID=86281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:56:02.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T08:56:02.168+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:56:02.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:56:02.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:56:02.193+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:56:02.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T08:56:02.203+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:56:02.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T08:56:02.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T08:56:32.683+0000] {processor.py:157} INFO - Started process (PID=86306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:56:32.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T08:56:32.687+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:56:32.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:56:32.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:56:32.714+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:56:32.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T08:56:32.725+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:56:32.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T08:56:32.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T08:57:03.136+0000] {processor.py:157} INFO - Started process (PID=86331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:57:03.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T08:57:03.140+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:57:03.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:57:03.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:57:03.170+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:57:03.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T08:57:03.181+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:57:03.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T08:57:03.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T08:57:33.634+0000] {processor.py:157} INFO - Started process (PID=86356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:57:33.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T08:57:33.636+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:57:33.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:57:33.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:57:33.663+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:57:33.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T08:57:33.672+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:57:33.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T08:57:33.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T08:58:04.145+0000] {processor.py:157} INFO - Started process (PID=86381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:58:04.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T08:58:04.150+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:58:04.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:58:04.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:58:04.182+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:58:04.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T08:58:04.193+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:58:04.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T08:58:04.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-22T08:58:34.567+0000] {processor.py:157} INFO - Started process (PID=86406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:58:34.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T08:58:34.572+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:58:34.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:58:34.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:58:34.607+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:58:34.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T08:58:34.620+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:58:34.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T08:58:34.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-22T08:59:05.055+0000] {processor.py:157} INFO - Started process (PID=86431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:59:05.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T08:59:05.057+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:59:05.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:59:05.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:59:05.085+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:59:05.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T08:59:05.095+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:59:05.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T08:59:05.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T08:59:35.529+0000] {processor.py:157} INFO - Started process (PID=86456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:59:35.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T08:59:35.532+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:59:35.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:59:35.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T08:59:35.557+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:59:35.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T08:59:35.568+0000] {logging_mixin.py:151} INFO - [2024-07-22T08:59:35.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T08:59:35.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T09:00:05.958+0000] {processor.py:157} INFO - Started process (PID=86481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:00:05.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:00:05.961+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:00:05.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:00:05.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:00:05.985+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:00:05.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:00:05.995+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:00:05.995+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:00:06.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-22T09:00:36.538+0000] {processor.py:157} INFO - Started process (PID=86506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:00:36.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:00:36.541+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:00:36.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:00:36.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:00:36.573+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:00:36.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:00:36.584+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:00:36.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:00:36.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T09:01:07.043+0000] {processor.py:157} INFO - Started process (PID=86531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:01:07.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:01:07.046+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:01:07.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:01:07.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:01:07.074+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:01:07.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:01:07.085+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:01:07.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:01:07.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T09:01:37.499+0000] {processor.py:157} INFO - Started process (PID=86556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:01:37.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:01:37.503+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:01:37.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:01:37.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:01:37.532+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:01:37.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:01:37.544+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:01:37.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:01:37.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T09:02:08.008+0000] {processor.py:157} INFO - Started process (PID=86581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:02:08.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:02:08.012+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:02:08.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:02:08.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:02:08.039+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:02:08.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:02:08.051+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:02:08.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:02:08.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T09:02:38.482+0000] {processor.py:157} INFO - Started process (PID=86606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:02:38.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:02:38.485+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:02:38.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:02:38.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:02:38.512+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:02:38.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:02:38.523+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:02:38.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:02:38.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T09:03:08.953+0000] {processor.py:157} INFO - Started process (PID=86631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:03:08.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:03:08.958+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:03:08.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:03:08.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:03:08.987+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:03:08.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:03:09.000+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:03:09.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:03:09.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T09:03:39.389+0000] {processor.py:157} INFO - Started process (PID=86656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:03:39.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:03:39.393+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:03:39.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:03:39.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:03:39.423+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:03:39.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:03:39.436+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:03:39.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:03:39.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T09:04:09.840+0000] {processor.py:157} INFO - Started process (PID=86681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:04:09.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:04:09.843+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:04:09.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:04:09.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:04:09.873+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:04:09.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:04:09.882+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:04:09.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:04:09.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T09:04:40.363+0000] {processor.py:157} INFO - Started process (PID=86706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:04:40.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:04:40.366+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:04:40.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:04:40.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:04:40.392+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:04:40.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:04:40.403+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:04:40.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:04:40.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T09:05:10.788+0000] {processor.py:157} INFO - Started process (PID=86731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:05:10.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:05:10.791+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:05:10.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:05:10.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:05:10.819+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:05:10.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:05:10.831+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:05:10.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:05:10.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T09:05:41.235+0000] {processor.py:157} INFO - Started process (PID=86756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:05:41.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:05:41.238+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:05:41.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:05:41.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:05:41.266+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:05:41.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:05:41.277+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:05:41.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:05:41.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T09:06:11.652+0000] {processor.py:157} INFO - Started process (PID=86781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:06:11.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:06:11.655+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:06:11.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:06:11.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:06:11.684+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:06:11.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:06:11.698+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:06:11.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:06:11.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T09:06:42.063+0000] {processor.py:157} INFO - Started process (PID=86806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:06:42.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:06:42.065+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:06:42.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:06:42.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:06:42.093+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:06:42.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:06:42.102+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:06:42.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:06:42.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T09:07:12.565+0000] {processor.py:157} INFO - Started process (PID=86831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:07:12.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:07:12.569+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:07:12.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:07:12.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:07:12.594+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:07:12.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:07:12.604+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:07:12.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:07:12.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-22T09:07:42.957+0000] {processor.py:157} INFO - Started process (PID=86856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:07:42.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:07:42.960+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:07:42.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:07:42.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:07:42.987+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:07:42.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:07:42.997+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:07:42.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:07:43.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T09:08:13.436+0000] {processor.py:157} INFO - Started process (PID=86881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:08:13.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:08:13.438+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:08:13.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:08:13.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:08:13.465+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:08:13.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:08:13.474+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:08:13.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:08:13.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T09:08:43.939+0000] {processor.py:157} INFO - Started process (PID=86906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:08:43.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:08:43.942+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:08:43.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:08:43.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:08:43.971+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:08:43.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:08:43.983+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:08:43.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:08:43.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T09:09:14.392+0000] {processor.py:157} INFO - Started process (PID=86931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:09:14.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:09:14.394+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:09:14.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:09:14.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:09:14.425+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:09:14.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:09:14.438+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:09:14.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:09:14.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T09:09:44.840+0000] {processor.py:157} INFO - Started process (PID=86956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:09:44.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:09:44.843+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:09:44.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:09:44.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:09:44.870+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:09:44.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:09:44.881+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:09:44.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:09:44.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T09:10:15.287+0000] {processor.py:157} INFO - Started process (PID=86981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:10:15.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:10:15.289+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:10:15.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:10:15.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:10:15.317+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:10:15.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:10:15.327+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:10:15.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:10:15.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T09:10:45.855+0000] {processor.py:157} INFO - Started process (PID=87006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:10:45.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:10:45.860+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:10:45.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:10:45.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:10:45.894+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:10:45.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:10:45.907+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:10:45.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:10:45.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-22T09:11:16.372+0000] {processor.py:157} INFO - Started process (PID=87031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:11:16.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:11:16.378+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:11:16.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:11:16.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:11:16.408+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:11:16.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:11:16.418+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:11:16.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:11:16.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T09:11:46.829+0000] {processor.py:157} INFO - Started process (PID=87056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:11:46.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:11:46.832+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:11:46.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:11:46.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:11:46.863+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:11:46.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:11:46.876+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:11:46.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:11:46.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T09:12:17.320+0000] {processor.py:157} INFO - Started process (PID=87081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:12:17.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:12:17.322+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:12:17.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:12:17.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:12:17.350+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:12:17.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:12:17.359+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:12:17.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:12:17.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T09:12:47.771+0000] {processor.py:157} INFO - Started process (PID=87106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:12:47.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:12:47.774+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:12:47.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:12:47.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:12:47.807+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:12:47.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:12:47.818+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:12:47.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:12:47.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T09:13:18.200+0000] {processor.py:157} INFO - Started process (PID=87131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:13:18.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:13:18.203+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:13:18.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:13:18.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:13:18.227+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:13:18.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:13:18.237+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:13:18.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:13:18.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-22T09:13:48.658+0000] {processor.py:157} INFO - Started process (PID=87156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:13:48.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:13:48.662+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:13:48.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:13:48.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:13:48.693+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:13:48.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:13:48.702+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:13:48.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:13:48.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T09:14:19.144+0000] {processor.py:157} INFO - Started process (PID=87181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:14:19.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:14:19.148+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:14:19.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:14:19.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:14:19.178+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:14:19.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:14:19.187+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:14:19.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:14:19.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T09:14:49.529+0000] {processor.py:157} INFO - Started process (PID=87206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:14:49.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:14:49.531+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:14:49.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:14:49.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:14:49.555+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:14:49.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:14:49.566+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:14:49.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:14:49.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-22T09:15:20.017+0000] {processor.py:157} INFO - Started process (PID=87231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:15:20.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:15:20.020+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:15:20.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:15:20.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:15:20.047+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:15:20.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:15:20.060+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:15:20.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:15:20.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T09:15:50.428+0000] {processor.py:157} INFO - Started process (PID=87256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:15:50.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:15:50.432+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:15:50.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:15:50.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:15:50.460+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:15:50.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:15:50.469+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:15:50.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:15:50.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T09:16:20.934+0000] {processor.py:157} INFO - Started process (PID=87281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:16:20.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:16:20.936+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:16:20.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:16:20.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:16:20.967+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:16:20.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:16:20.978+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:16:20.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:16:20.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T09:16:51.340+0000] {processor.py:157} INFO - Started process (PID=87306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:16:51.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:16:51.343+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:16:51.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:16:51.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:16:51.364+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:16:51.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:16:51.373+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:16:51.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:16:51.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-22T09:17:21.818+0000] {processor.py:157} INFO - Started process (PID=87331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:17:21.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:17:21.821+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:17:21.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:17:21.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:17:21.851+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:17:21.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:17:21.861+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:17:21.861+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:17:21.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T09:17:52.323+0000] {processor.py:157} INFO - Started process (PID=87356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:17:52.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:17:52.327+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:17:52.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:17:52.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:17:52.356+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:17:52.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:17:52.366+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:17:52.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:17:52.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T09:18:22.867+0000] {processor.py:157} INFO - Started process (PID=87381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:18:22.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:18:22.872+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:18:22.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:18:22.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:18:22.898+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:18:22.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:18:22.908+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:18:22.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:18:22.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T09:18:53.302+0000] {processor.py:157} INFO - Started process (PID=87406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:18:53.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:18:53.305+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:18:53.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:18:53.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:18:53.337+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:18:53.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:18:53.347+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:18:53.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:18:53.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T09:19:23.793+0000] {processor.py:157} INFO - Started process (PID=87431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:19:23.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:19:23.798+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:19:23.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:19:23.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:19:23.830+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:19:23.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:19:23.842+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:19:23.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:19:23.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T09:19:54.201+0000] {processor.py:157} INFO - Started process (PID=87456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:19:54.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:19:54.204+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:19:54.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:19:54.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:19:54.233+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:19:54.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:19:54.244+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:19:54.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:19:54.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T09:20:24.673+0000] {processor.py:157} INFO - Started process (PID=87481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:20:24.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:20:24.675+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:20:24.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:20:24.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:20:24.702+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:20:24.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:20:24.715+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:20:24.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:20:24.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T09:20:55.173+0000] {processor.py:157} INFO - Started process (PID=87506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:20:55.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:20:55.176+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:20:55.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:20:55.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:20:55.202+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:20:55.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:20:55.212+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:20:55.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:20:55.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T09:21:25.629+0000] {processor.py:157} INFO - Started process (PID=87531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:21:25.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:21:25.632+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:21:25.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:21:25.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:21:25.661+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:21:25.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:21:25.672+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:21:25.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:21:25.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T09:21:56.191+0000] {processor.py:157} INFO - Started process (PID=87556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:21:56.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:21:56.196+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:21:56.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:21:56.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:21:56.232+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:21:56.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:21:56.246+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:21:56.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:21:56.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T09:22:26.682+0000] {processor.py:157} INFO - Started process (PID=87581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:22:26.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:22:26.686+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:22:26.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:22:26.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:22:26.714+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:22:26.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:22:26.725+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:22:26.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:22:26.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T09:22:57.163+0000] {processor.py:157} INFO - Started process (PID=87606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:22:57.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:22:57.166+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:22:57.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:22:57.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:22:57.197+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:22:57.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:22:57.209+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:22:57.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:22:57.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T09:23:27.653+0000] {processor.py:157} INFO - Started process (PID=87631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:23:27.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:23:27.655+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:23:27.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:23:27.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:23:27.681+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:23:27.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:23:27.691+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:23:27.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:23:27.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T09:23:58.128+0000] {processor.py:157} INFO - Started process (PID=87656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:23:58.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:23:58.133+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:23:58.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:23:58.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:23:58.162+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:23:58.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:23:58.172+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:23:58.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:23:58.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T09:24:28.604+0000] {processor.py:157} INFO - Started process (PID=87681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:24:28.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:24:28.609+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:24:28.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:24:28.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:24:28.640+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:24:28.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:24:28.651+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:24:28.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:24:28.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T09:24:58.996+0000] {processor.py:157} INFO - Started process (PID=87706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:24:58.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:24:58.999+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:24:58.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:24:59.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:24:59.023+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:24:59.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:24:59.033+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:24:59.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:24:59.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-22T09:25:29.444+0000] {processor.py:157} INFO - Started process (PID=87731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:25:29.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:25:29.447+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:25:29.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:25:29.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:25:29.478+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:25:29.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:25:29.489+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:25:29.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:25:29.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T09:25:59.926+0000] {processor.py:157} INFO - Started process (PID=87756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:25:59.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:25:59.931+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:25:59.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:25:59.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:25:59.961+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:25:59.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:25:59.974+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:25:59.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:25:59.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T09:26:30.364+0000] {processor.py:157} INFO - Started process (PID=87781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:26:30.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:26:30.367+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:26:30.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:26:30.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:26:30.398+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:26:30.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:26:30.410+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:26:30.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:26:30.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T09:27:00.813+0000] {processor.py:157} INFO - Started process (PID=87806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:27:00.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:27:00.815+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:27:00.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:27:00.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:27:00.841+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:27:00.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:27:00.853+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:27:00.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:27:00.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T09:27:31.348+0000] {processor.py:157} INFO - Started process (PID=87831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:27:31.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:27:31.351+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:27:31.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:27:31.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:27:31.376+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:27:31.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:27:31.386+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:27:31.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:27:31.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T09:28:01.913+0000] {processor.py:157} INFO - Started process (PID=87856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:28:01.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:28:01.921+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:28:01.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:28:01.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:28:01.945+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:28:01.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:28:01.954+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:28:01.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:28:01.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T09:28:32.408+0000] {processor.py:157} INFO - Started process (PID=87881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:28:32.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:28:32.411+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:28:32.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:28:32.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:28:32.438+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:28:32.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:28:32.452+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:28:32.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:28:32.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T09:29:02.923+0000] {processor.py:157} INFO - Started process (PID=87906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:29:02.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:29:02.927+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:29:02.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:29:02.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:29:02.952+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:29:02.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:29:02.962+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:29:02.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:29:02.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T09:29:33.428+0000] {processor.py:157} INFO - Started process (PID=87931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:29:33.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:29:33.431+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:29:33.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:29:33.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:29:33.459+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:29:33.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:29:33.471+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:29:33.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:29:33.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T09:30:03.927+0000] {processor.py:157} INFO - Started process (PID=87956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:30:03.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:30:03.931+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:30:03.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:30:03.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:30:03.960+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:30:03.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:30:03.970+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:30:03.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:30:03.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T09:30:34.495+0000] {processor.py:157} INFO - Started process (PID=87981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:30:34.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:30:34.497+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:30:34.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:30:34.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:30:34.525+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:30:34.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:30:34.537+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:30:34.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:30:34.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T09:31:04.933+0000] {processor.py:157} INFO - Started process (PID=88006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:31:04.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:31:04.935+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:31:04.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:31:04.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:31:04.965+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:31:04.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:31:04.976+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:31:04.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:31:04.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T09:31:35.302+0000] {processor.py:157} INFO - Started process (PID=88031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:31:35.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:31:35.305+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:31:35.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:31:35.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:31:35.331+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:31:35.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:31:35.341+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:31:35.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:31:35.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T09:32:05.834+0000] {processor.py:157} INFO - Started process (PID=88056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:32:05.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:32:05.838+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:32:05.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:32:05.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:32:05.866+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:32:05.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:32:05.876+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:32:05.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:32:05.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T09:32:36.333+0000] {processor.py:157} INFO - Started process (PID=88081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:32:36.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:32:36.336+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:32:36.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:32:36.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:32:36.362+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:32:36.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:32:36.371+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:32:36.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:32:36.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-22T09:33:06.877+0000] {processor.py:157} INFO - Started process (PID=88106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:33:06.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:33:06.880+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:33:06.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:33:06.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:33:06.907+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:33:06.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:33:06.920+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:33:06.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:33:06.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T09:33:37.321+0000] {processor.py:157} INFO - Started process (PID=88131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:33:37.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:33:37.324+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:33:37.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:33:37.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:33:37.361+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:33:37.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:33:37.373+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:33:37.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:33:37.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-22T09:34:07.873+0000] {processor.py:157} INFO - Started process (PID=88156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:34:07.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:34:07.876+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:34:07.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:34:07.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:34:07.902+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:34:07.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:34:07.912+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:34:07.911+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:34:07.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T09:34:38.294+0000] {processor.py:157} INFO - Started process (PID=88181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:34:38.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:34:38.298+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:34:38.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:34:38.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:34:38.326+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:34:38.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:34:38.339+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:34:38.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:34:38.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T09:35:08.794+0000] {processor.py:157} INFO - Started process (PID=88206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:35:08.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:35:08.798+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:35:08.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:35:08.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:35:08.832+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:35:08.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:35:08.841+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:35:08.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:35:08.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T09:35:39.245+0000] {processor.py:157} INFO - Started process (PID=88231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:35:39.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:35:39.249+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:35:39.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:35:39.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:35:39.276+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:35:39.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:35:39.285+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:35:39.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:35:39.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T09:36:09.758+0000] {processor.py:157} INFO - Started process (PID=88256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:36:09.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:36:09.764+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:36:09.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:36:09.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:36:09.792+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:36:09.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:36:09.804+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:36:09.804+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:36:09.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T09:36:40.294+0000] {processor.py:157} INFO - Started process (PID=88281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:36:40.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:36:40.298+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:36:40.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:36:40.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:36:40.329+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:36:40.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:36:40.340+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:36:40.340+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:36:40.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T09:37:10.786+0000] {processor.py:157} INFO - Started process (PID=88306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:37:10.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:37:10.791+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:37:10.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:37:10.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:37:10.822+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:37:10.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:37:10.834+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:37:10.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:37:10.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T09:37:41.258+0000] {processor.py:157} INFO - Started process (PID=88331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:37:41.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:37:41.261+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:37:41.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:37:41.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:37:41.292+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:37:41.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:37:41.303+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:37:41.303+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:37:41.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T09:38:11.769+0000] {processor.py:157} INFO - Started process (PID=88356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:38:11.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:38:11.771+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:38:11.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:38:11.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:38:11.798+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:38:11.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:38:11.808+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:38:11.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:38:11.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T09:38:42.271+0000] {processor.py:157} INFO - Started process (PID=88381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:38:42.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:38:42.274+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:38:42.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:38:42.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:38:42.302+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:38:42.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:38:42.313+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:38:42.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:38:42.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T09:39:12.781+0000] {processor.py:157} INFO - Started process (PID=88406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:39:12.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:39:12.784+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:39:12.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:39:12.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:39:12.812+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:39:12.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:39:12.822+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:39:12.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:39:12.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T09:39:43.216+0000] {processor.py:157} INFO - Started process (PID=88431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:39:43.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:39:43.220+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:39:43.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:39:43.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:39:43.247+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:39:43.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:39:43.257+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:39:43.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:39:43.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T09:40:13.609+0000] {processor.py:157} INFO - Started process (PID=88456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:40:13.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:40:13.611+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:40:13.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:40:13.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:40:13.636+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:40:13.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:40:13.646+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:40:13.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:40:13.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-22T09:40:44.088+0000] {processor.py:157} INFO - Started process (PID=88481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:40:44.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:40:44.092+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:40:44.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:40:44.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:40:44.118+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:40:44.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:40:44.129+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:40:44.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:40:44.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T09:41:14.571+0000] {processor.py:157} INFO - Started process (PID=88506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:41:14.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:41:14.573+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:41:14.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:41:14.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:41:14.597+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:41:14.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:41:14.607+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:41:14.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:41:14.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-22T09:41:44.981+0000] {processor.py:157} INFO - Started process (PID=88531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:41:44.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:41:44.984+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:41:44.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:41:44.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:41:45.013+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:41:45.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:41:45.024+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:41:45.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:41:45.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T09:42:15.493+0000] {processor.py:157} INFO - Started process (PID=88556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:42:15.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:42:15.496+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:42:15.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:42:15.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:42:15.521+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:42:15.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:42:15.533+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:42:15.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:42:15.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T09:42:46.035+0000] {processor.py:157} INFO - Started process (PID=88581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:42:46.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:42:46.039+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:42:46.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:42:46.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:42:46.071+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:42:46.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:42:46.082+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:42:46.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:42:46.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T09:43:16.527+0000] {processor.py:157} INFO - Started process (PID=88606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:43:16.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:43:16.531+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:43:16.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:43:16.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:43:16.566+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:43:16.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:43:16.582+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:43:16.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:43:16.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-22T09:43:47.021+0000] {processor.py:157} INFO - Started process (PID=88631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:43:47.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:43:47.025+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:43:47.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:43:47.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:43:47.053+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:43:47.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:43:47.066+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:43:47.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:43:47.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T09:44:17.580+0000] {processor.py:157} INFO - Started process (PID=88656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:44:17.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:44:17.583+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:44:17.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:44:17.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:44:17.611+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:44:17.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:44:17.621+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:44:17.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:44:17.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T09:44:47.970+0000] {processor.py:157} INFO - Started process (PID=88681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:44:47.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:44:47.974+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:44:47.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:44:47.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:44:48.011+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:44:48.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:44:48.019+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:44:48.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:44:48.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T09:45:18.434+0000] {processor.py:157} INFO - Started process (PID=88706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:45:18.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:45:18.436+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:45:18.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:45:18.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:45:18.462+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:45:18.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:45:18.472+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:45:18.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:45:18.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T09:45:48.889+0000] {processor.py:157} INFO - Started process (PID=88731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:45:48.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:45:48.893+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:45:48.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:45:48.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:45:48.919+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:45:48.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:45:48.929+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:45:48.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:45:48.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T09:46:19.512+0000] {processor.py:157} INFO - Started process (PID=88756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:46:19.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:46:19.515+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:46:19.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:46:19.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:46:19.541+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:46:19.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:46:19.555+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:46:19.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:46:19.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T09:46:49.901+0000] {processor.py:157} INFO - Started process (PID=88781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:46:49.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:46:49.903+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:46:49.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:46:49.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:46:49.924+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:46:49.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:46:49.933+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:46:49.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:46:49.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-22T09:47:20.363+0000] {processor.py:157} INFO - Started process (PID=88806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:47:20.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T09:47:20.365+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:47:20.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:47:20.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T09:47:20.390+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:47:20.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T09:47:20.399+0000] {logging_mixin.py:151} INFO - [2024-07-22T09:47:20.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T09:47:20.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-22T10:03:27.782+0000] {processor.py:157} INFO - Started process (PID=88833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:03:27.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T10:03:27.791+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:03:27.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:03:27.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:03:27.839+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:03:27.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T10:03:27.856+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:03:27.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T10:03:27.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-22T10:03:58.224+0000] {processor.py:157} INFO - Started process (PID=88857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:03:58.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T10:03:58.227+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:03:58.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:03:58.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:03:58.252+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:03:58.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T10:03:58.263+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:03:58.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T10:03:58.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T10:04:28.674+0000] {processor.py:157} INFO - Started process (PID=88883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:04:28.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T10:04:28.677+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:04:28.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:04:28.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:04:28.708+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:04:28.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T10:04:28.720+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:04:28.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T10:04:28.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T10:13:32.897+0000] {processor.py:157} INFO - Started process (PID=88908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:13:32.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T10:13:32.901+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:13:32.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:13:32.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:13:32.928+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:13:32.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T10:13:32.939+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:13:32.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T10:13:32.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T10:14:03.349+0000] {processor.py:157} INFO - Started process (PID=88932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:14:03.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T10:14:03.354+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:14:03.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:14:03.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:14:03.389+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:14:03.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T10:14:03.402+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:14:03.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T10:14:03.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-22T10:14:33.913+0000] {processor.py:157} INFO - Started process (PID=88958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:14:33.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T10:14:33.917+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:14:33.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:14:33.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:14:33.946+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:14:33.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T10:14:33.958+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:14:33.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T10:14:33.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T10:15:04.403+0000] {processor.py:157} INFO - Started process (PID=88983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:15:04.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T10:15:04.407+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:15:04.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:15:04.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:15:04.439+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:15:04.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T10:15:04.449+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:15:04.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T10:15:04.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T10:19:31.430+0000] {processor.py:157} INFO - Started process (PID=89008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:19:31.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T10:19:31.432+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:19:31.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:19:31.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:19:31.463+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:19:31.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T10:19:31.472+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:19:31.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T10:19:31.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T10:20:01.919+0000] {processor.py:157} INFO - Started process (PID=89033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:20:01.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T10:20:01.923+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:20:01.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:20:01.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:20:01.955+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:20:01.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T10:20:01.964+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:20:01.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T10:20:01.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T10:20:32.383+0000] {processor.py:157} INFO - Started process (PID=89058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:20:32.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T10:20:32.387+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:20:32.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:20:32.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:20:32.418+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:20:32.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T10:20:32.430+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:20:32.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T10:20:32.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T10:21:02.775+0000] {processor.py:157} INFO - Started process (PID=89083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:21:02.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T10:21:02.780+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:21:02.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:21:02.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:21:02.815+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:21:02.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T10:21:02.826+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:21:02.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T10:21:02.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-22T10:21:33.284+0000] {processor.py:157} INFO - Started process (PID=89108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:21:33.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T10:21:33.287+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:21:33.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:21:33.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:21:33.316+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:21:33.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T10:21:33.326+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:21:33.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T10:21:33.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T10:39:02.154+0000] {processor.py:157} INFO - Started process (PID=89133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:39:02.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T10:39:02.157+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:39:02.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:39:02.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:39:02.208+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:39:02.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T10:39:02.230+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:39:02.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T10:39:02.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-22T10:39:32.759+0000] {processor.py:157} INFO - Started process (PID=89159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:39:32.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T10:39:32.763+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:39:32.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:39:32.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:39:32.798+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:39:32.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T10:39:32.810+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:39:32.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T10:39:32.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-22T10:55:15.081+0000] {processor.py:157} INFO - Started process (PID=89186) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:55:15.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T10:55:15.085+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:55:15.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:55:15.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:55:15.116+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:55:15.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T10:55:15.127+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:55:15.127+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T10:55:15.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T10:55:45.670+0000] {processor.py:157} INFO - Started process (PID=89211) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:55:45.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T10:55:45.675+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:55:45.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:55:45.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:55:45.716+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:55:45.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T10:55:45.727+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:55:45.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T10:55:45.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-22T10:56:16.107+0000] {processor.py:157} INFO - Started process (PID=89236) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:56:16.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T10:56:16.112+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:56:16.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:56:16.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:56:16.144+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:56:16.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T10:56:16.155+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:56:16.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T10:56:16.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T10:56:46.637+0000] {processor.py:157} INFO - Started process (PID=89261) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:56:46.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T10:56:46.643+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:56:46.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:56:46.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:56:46.678+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:56:46.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T10:56:46.691+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:56:46.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T10:56:46.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-22T10:57:17.078+0000] {processor.py:157} INFO - Started process (PID=89286) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:57:17.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T10:57:17.080+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:57:17.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:57:17.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T10:57:17.100+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:57:17.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T10:57:17.109+0000] {logging_mixin.py:151} INFO - [2024-07-22T10:57:17.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T10:57:17.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.040 seconds
[2024-07-22T11:03:20.875+0000] {processor.py:157} INFO - Started process (PID=89313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:03:20.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:03:20.879+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:03:20.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:03:20.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:03:20.916+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:03:20.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:03:20.935+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:03:20.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:03:20.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-22T11:03:51.426+0000] {processor.py:157} INFO - Started process (PID=89338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:03:51.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:03:51.429+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:03:51.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:03:51.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:03:51.457+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:03:51.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:03:51.468+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:03:51.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:03:51.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T11:04:21.831+0000] {processor.py:157} INFO - Started process (PID=89363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:04:21.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:04:21.834+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:04:21.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:04:21.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:04:21.868+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:04:21.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:04:21.879+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:04:21.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:04:21.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T11:04:52.345+0000] {processor.py:157} INFO - Started process (PID=89388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:04:52.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:04:52.349+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:04:52.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:04:52.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:04:52.378+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:04:52.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:04:52.388+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:04:52.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:04:52.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T11:10:32.891+0000] {processor.py:157} INFO - Started process (PID=89413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:10:32.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:10:32.898+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:10:32.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:10:32.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:10:32.966+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:10:32.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:10:32.996+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:10:32.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:10:33.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-07-22T11:11:03.466+0000] {processor.py:157} INFO - Started process (PID=89438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:11:03.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:11:03.483+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:11:03.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:11:03.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:11:03.573+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:11:03.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:11:03.588+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:11:03.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:11:03.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-07-22T11:11:34.028+0000] {processor.py:157} INFO - Started process (PID=89463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:11:34.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:11:34.034+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:11:34.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:11:34.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:11:34.089+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:11:34.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:11:34.103+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:11:34.103+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:11:34.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-22T11:12:04.601+0000] {processor.py:157} INFO - Started process (PID=89488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:12:04.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:12:04.608+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:12:04.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:12:04.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:12:04.664+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:12:04.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:12:04.679+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:12:04.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:12:04.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-22T11:12:35.120+0000] {processor.py:157} INFO - Started process (PID=89513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:12:35.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:12:35.129+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:12:35.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:12:35.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:12:35.187+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:12:35.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:12:35.202+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:12:35.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:12:35.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-22T11:13:05.643+0000] {processor.py:157} INFO - Started process (PID=89538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:13:05.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:13:05.648+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:13:05.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:13:05.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:13:05.686+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:13:05.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:13:05.698+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:13:05.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:13:05.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T11:13:36.088+0000] {processor.py:157} INFO - Started process (PID=89563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:13:36.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:13:36.092+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:13:36.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:13:36.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:13:36.121+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:13:36.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:13:36.132+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:13:36.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:13:36.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T11:14:06.470+0000] {processor.py:157} INFO - Started process (PID=89588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:14:06.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:14:06.474+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:14:06.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:14:06.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:14:06.501+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:14:06.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:14:06.513+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:14:06.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:14:06.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T11:14:36.872+0000] {processor.py:157} INFO - Started process (PID=89613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:14:36.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:14:36.875+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:14:36.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:14:36.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:14:36.906+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:14:36.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:14:36.917+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:14:36.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:14:36.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T11:15:07.329+0000] {processor.py:157} INFO - Started process (PID=89638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:15:07.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:15:07.333+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:15:07.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:15:07.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:15:07.362+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:15:07.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:15:07.372+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:15:07.372+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:15:07.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T11:15:37.768+0000] {processor.py:157} INFO - Started process (PID=89663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:15:37.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:15:37.772+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:15:37.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:15:37.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:15:37.798+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:15:37.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:15:37.808+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:15:37.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:15:37.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T11:16:08.196+0000] {processor.py:157} INFO - Started process (PID=89688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:16:08.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:16:08.201+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:16:08.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:16:08.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:16:08.229+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:16:08.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:16:08.240+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:16:08.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:16:08.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T11:16:38.618+0000] {processor.py:157} INFO - Started process (PID=89713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:16:38.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:16:38.621+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:16:38.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:16:38.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:16:38.656+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:16:38.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:16:38.666+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:16:38.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:16:38.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T11:17:08.970+0000] {processor.py:157} INFO - Started process (PID=89738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:17:08.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:17:08.973+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:17:08.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:17:08.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:17:09.004+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:17:09.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:17:09.018+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:17:09.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:17:09.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T11:17:39.423+0000] {processor.py:157} INFO - Started process (PID=89763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:17:39.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:17:39.427+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:17:39.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:17:39.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:17:39.457+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:17:39.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:17:39.468+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:17:39.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:17:39.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T11:18:09.893+0000] {processor.py:157} INFO - Started process (PID=89788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:18:09.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:18:09.899+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:18:09.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:18:09.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:18:09.943+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:18:09.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:18:09.953+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:18:09.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:18:09.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T11:18:40.375+0000] {processor.py:157} INFO - Started process (PID=89813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:18:40.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:18:40.378+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:18:40.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:18:40.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:18:40.407+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:18:40.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:18:40.417+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:18:40.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:18:40.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T11:19:10.810+0000] {processor.py:157} INFO - Started process (PID=89838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:19:10.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:19:10.813+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:19:10.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:19:10.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:19:10.842+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:19:10.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:19:10.851+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:19:10.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:19:10.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T11:19:41.215+0000] {processor.py:157} INFO - Started process (PID=89863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:19:41.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:19:41.217+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:19:41.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:19:41.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:19:41.244+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:19:41.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:19:41.254+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:19:41.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:19:41.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T11:20:11.638+0000] {processor.py:157} INFO - Started process (PID=89888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:20:11.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:20:11.641+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:20:11.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:20:11.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:20:11.670+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:20:11.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:20:11.680+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:20:11.680+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:20:11.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T11:20:42.098+0000] {processor.py:157} INFO - Started process (PID=89913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:20:42.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:20:42.103+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:20:42.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:20:42.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:20:42.132+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:20:42.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:20:42.144+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:20:42.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:20:42.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T11:21:12.552+0000] {processor.py:157} INFO - Started process (PID=89938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:21:12.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:21:12.558+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:21:12.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:21:12.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:21:12.594+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:21:12.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:21:12.607+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:21:12.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:21:12.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-22T11:21:42.966+0000] {processor.py:157} INFO - Started process (PID=89963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:21:42.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:21:42.972+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:21:42.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:21:42.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:21:43.010+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:21:43.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:21:43.020+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:21:43.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:21:43.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-22T11:22:13.357+0000] {processor.py:157} INFO - Started process (PID=89988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:22:13.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:22:13.360+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:22:13.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:22:13.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:22:13.388+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:22:13.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:22:13.397+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:22:13.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:22:13.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T11:22:43.784+0000] {processor.py:157} INFO - Started process (PID=90013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:22:43.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:22:43.788+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:22:43.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:22:43.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:22:43.815+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:22:43.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:22:43.825+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:22:43.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:22:43.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T11:23:14.170+0000] {processor.py:157} INFO - Started process (PID=90038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:23:14.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:23:14.172+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:23:14.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:23:14.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:23:14.200+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:23:14.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:23:14.210+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:23:14.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:23:14.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T11:23:44.576+0000] {processor.py:157} INFO - Started process (PID=90063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:23:44.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:23:44.578+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:23:44.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:23:44.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:23:44.606+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:23:44.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:23:44.617+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:23:44.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:23:44.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T11:24:14.973+0000] {processor.py:157} INFO - Started process (PID=90088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:24:14.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:24:14.976+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:24:14.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:24:14.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:24:15.007+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:24:15.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:24:15.016+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:24:15.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:24:15.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T11:24:45.310+0000] {processor.py:157} INFO - Started process (PID=90113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:24:45.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:24:45.313+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:24:45.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:24:45.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:24:45.340+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:24:45.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:24:45.350+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:24:45.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:24:45.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T11:25:15.740+0000] {processor.py:157} INFO - Started process (PID=90138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:25:15.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:25:15.742+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:25:15.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:25:15.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:25:15.769+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:25:15.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:25:15.781+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:25:15.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:25:15.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T11:25:46.267+0000] {processor.py:157} INFO - Started process (PID=90163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:25:46.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:25:46.275+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:25:46.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:25:46.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:25:46.328+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:25:46.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:25:46.342+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:25:46.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:25:46.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-22T11:26:16.764+0000] {processor.py:157} INFO - Started process (PID=90188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:26:16.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:26:16.767+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:26:16.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:26:16.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:26:16.795+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:26:16.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:26:16.807+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:26:16.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:26:16.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T11:26:47.160+0000] {processor.py:157} INFO - Started process (PID=90213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:26:47.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:26:47.163+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:26:47.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:26:47.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:26:47.191+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:26:47.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:26:47.201+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:26:47.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:26:47.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T11:27:17.581+0000] {processor.py:157} INFO - Started process (PID=90238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:27:17.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:27:17.584+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:27:17.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:27:17.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:27:17.608+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:27:17.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:27:17.618+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:27:17.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:27:17.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T11:27:47.986+0000] {processor.py:157} INFO - Started process (PID=90263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:27:47.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:27:47.989+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:27:47.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:27:48.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:27:48.020+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:27:48.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:27:48.030+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:27:48.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:27:48.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T11:28:18.389+0000] {processor.py:157} INFO - Started process (PID=90288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:28:18.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:28:18.393+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:28:18.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:28:18.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:28:18.434+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:28:18.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:28:18.449+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:28:18.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:28:18.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-22T11:28:48.845+0000] {processor.py:157} INFO - Started process (PID=90313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:28:48.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:28:48.848+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:28:48.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:28:48.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:28:48.873+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:28:48.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:28:48.884+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:28:48.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:28:48.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T11:29:19.245+0000] {processor.py:157} INFO - Started process (PID=90338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:29:19.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:29:19.249+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:29:19.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:29:19.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:29:19.276+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:29:19.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:29:19.286+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:29:19.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:29:19.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T11:29:49.625+0000] {processor.py:157} INFO - Started process (PID=90363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:29:49.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:29:49.630+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:29:49.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:29:49.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:29:49.655+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:29:49.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:29:49.664+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:29:49.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:29:49.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T11:30:20.033+0000] {processor.py:157} INFO - Started process (PID=90388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:30:20.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:30:20.036+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:30:20.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:30:20.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:30:20.064+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:30:20.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:30:20.075+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:30:20.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:30:20.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T11:30:50.504+0000] {processor.py:157} INFO - Started process (PID=90413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:30:50.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:30:50.508+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:30:50.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:30:50.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:30:50.555+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:30:50.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:30:50.568+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:30:50.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:30:50.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-22T11:31:20.988+0000] {processor.py:157} INFO - Started process (PID=90438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:31:20.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:31:20.992+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:31:20.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:31:21.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:31:21.031+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:31:21.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:31:21.047+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:31:21.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:31:21.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-22T11:31:51.488+0000] {processor.py:157} INFO - Started process (PID=90463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:31:51.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:31:51.493+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:31:51.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:31:51.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:31:51.526+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:31:51.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:31:51.536+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:31:51.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:31:51.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T11:32:21.930+0000] {processor.py:157} INFO - Started process (PID=90488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:32:21.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:32:21.934+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:32:21.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:32:21.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:32:21.958+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:32:21.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:32:21.967+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:32:21.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:32:21.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-22T11:32:52.414+0000] {processor.py:157} INFO - Started process (PID=90513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:32:52.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:32:52.419+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:32:52.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:32:52.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:32:52.449+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:32:52.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:32:52.460+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:32:52.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:32:52.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T11:33:22.809+0000] {processor.py:157} INFO - Started process (PID=90538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:33:22.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:33:22.812+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:33:22.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:33:22.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:33:22.834+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:33:22.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:33:22.844+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:33:22.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:33:22.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-22T11:33:53.229+0000] {processor.py:157} INFO - Started process (PID=90563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:33:53.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:33:53.232+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:33:53.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:33:53.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:33:53.262+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:33:53.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:33:53.274+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:33:53.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:33:53.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T11:34:23.671+0000] {processor.py:157} INFO - Started process (PID=90588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:34:23.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:34:23.678+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:34:23.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:34:23.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:34:23.718+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:34:23.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:34:23.731+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:34:23.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:34:23.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-22T11:34:54.166+0000] {processor.py:157} INFO - Started process (PID=90613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:34:54.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:34:54.170+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:34:54.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:34:54.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:34:54.199+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:34:54.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:34:54.210+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:34:54.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:34:54.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T11:35:24.600+0000] {processor.py:157} INFO - Started process (PID=90638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:35:24.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:35:24.602+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:35:24.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:35:24.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:35:24.629+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:35:24.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:35:24.639+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:35:24.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:35:24.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T11:35:55.075+0000] {processor.py:157} INFO - Started process (PID=90663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:35:55.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:35:55.080+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:35:55.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:35:55.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:35:55.113+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:35:55.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:35:55.125+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:35:55.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:35:55.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-22T11:36:25.545+0000] {processor.py:157} INFO - Started process (PID=90688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:36:25.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:36:25.550+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:36:25.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:36:25.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:36:25.585+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:36:25.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:36:25.597+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:36:25.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:36:25.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-22T11:36:55.899+0000] {processor.py:157} INFO - Started process (PID=90713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:36:55.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:36:55.902+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:36:55.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:36:55.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:36:55.929+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:36:55.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:36:55.939+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:36:55.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:36:55.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T11:37:26.389+0000] {processor.py:157} INFO - Started process (PID=90738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:37:26.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:37:26.394+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:37:26.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:37:26.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:37:26.437+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:37:26.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:37:26.450+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:37:26.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:37:26.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-22T11:37:56.884+0000] {processor.py:157} INFO - Started process (PID=90763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:37:56.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:37:56.887+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:37:56.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:37:56.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:37:56.913+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:37:56.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:37:56.923+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:37:56.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:37:56.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T11:38:27.346+0000] {processor.py:157} INFO - Started process (PID=90788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:38:27.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:38:27.349+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:38:27.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:38:27.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:38:27.376+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:38:27.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:38:27.386+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:38:27.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:38:27.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T11:38:57.807+0000] {processor.py:157} INFO - Started process (PID=90813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:38:57.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:38:57.810+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:38:57.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:38:57.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:38:57.842+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:38:57.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:38:57.851+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:38:57.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:38:57.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T11:39:28.215+0000] {processor.py:157} INFO - Started process (PID=90838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:39:28.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:39:28.220+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:39:28.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:39:28.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:39:28.250+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:39:28.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:39:28.259+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:39:28.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:39:28.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T11:39:58.627+0000] {processor.py:157} INFO - Started process (PID=90863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:39:58.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:39:58.634+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:39:58.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:39:58.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:39:58.673+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:39:58.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:39:58.686+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:39:58.686+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:39:58.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-22T11:40:29.017+0000] {processor.py:157} INFO - Started process (PID=90888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:40:29.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:40:29.022+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:40:29.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:40:29.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:40:29.050+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:40:29.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:40:29.063+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:40:29.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:40:29.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T11:40:59.472+0000] {processor.py:157} INFO - Started process (PID=90913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:40:59.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:40:59.475+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:40:59.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:40:59.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:40:59.505+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:40:59.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:40:59.515+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:40:59.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:40:59.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T11:41:29.948+0000] {processor.py:157} INFO - Started process (PID=90938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:41:29.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:41:29.950+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:41:29.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:41:29.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:41:29.981+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:41:29.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:41:29.990+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:41:29.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:41:30.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T11:42:00.371+0000] {processor.py:157} INFO - Started process (PID=90963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:42:00.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:42:00.375+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:42:00.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:42:00.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:42:00.406+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:42:00.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:42:00.415+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:42:00.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:42:00.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T11:42:30.825+0000] {processor.py:157} INFO - Started process (PID=90988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:42:30.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:42:30.830+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:42:30.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:42:30.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:42:30.865+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:42:30.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:42:30.877+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:42:30.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:42:30.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-22T11:43:01.255+0000] {processor.py:157} INFO - Started process (PID=91013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:43:01.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:43:01.259+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:43:01.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:43:01.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:43:01.295+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:43:01.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:43:01.310+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:43:01.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:43:01.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T11:43:31.690+0000] {processor.py:157} INFO - Started process (PID=91038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:43:31.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:43:31.694+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:43:31.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:43:31.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:43:31.720+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:43:31.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:43:31.732+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:43:31.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:43:31.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T11:44:02.112+0000] {processor.py:157} INFO - Started process (PID=91063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:44:02.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:44:02.115+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:44:02.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:44:02.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:44:02.136+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:44:02.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:44:02.147+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:44:02.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:44:02.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-22T11:44:32.559+0000] {processor.py:157} INFO - Started process (PID=91088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:44:32.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:44:32.562+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:44:32.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:44:32.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:44:32.591+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:44:32.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:44:32.603+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:44:32.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:44:32.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T11:45:03.004+0000] {processor.py:157} INFO - Started process (PID=91113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:45:03.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:45:03.008+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:45:03.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:45:03.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:45:03.035+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:45:03.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:45:03.048+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:45:03.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:45:03.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T11:45:33.419+0000] {processor.py:157} INFO - Started process (PID=91137) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:45:33.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:45:33.426+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:45:33.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:45:33.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:45:33.498+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:45:33.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:45:33.514+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:45:33.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:45:33.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-22T11:46:03.989+0000] {processor.py:157} INFO - Started process (PID=91163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:46:03.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:46:03.995+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:46:03.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:46:04.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:46:04.036+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:46:04.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:46:04.050+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:46:04.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:46:04.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-22T11:46:34.485+0000] {processor.py:157} INFO - Started process (PID=91188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:46:34.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:46:34.499+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:46:34.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:46:34.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:46:34.549+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:46:34.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:46:34.563+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:46:34.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:46:34.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-07-22T11:47:05.058+0000] {processor.py:157} INFO - Started process (PID=91213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:47:05.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:47:05.071+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:47:05.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:47:05.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:47:05.137+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:47:05.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:47:05.155+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:47:05.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:47:05.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-22T11:47:35.568+0000] {processor.py:157} INFO - Started process (PID=91236) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:47:35.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:47:35.574+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:47:35.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:47:35.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:47:35.613+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:47:35.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:47:35.625+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:47:35.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:47:35.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T11:48:06.019+0000] {processor.py:157} INFO - Started process (PID=91263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:48:06.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:48:06.023+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:48:06.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:48:06.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:48:06.056+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:48:06.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:48:06.065+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:48:06.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:48:06.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-22T11:48:36.481+0000] {processor.py:157} INFO - Started process (PID=91288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:48:36.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:48:36.486+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:48:36.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:48:36.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:48:36.517+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:48:36.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:48:36.529+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:48:36.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:48:36.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T11:49:06.943+0000] {processor.py:157} INFO - Started process (PID=91313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:49:06.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:49:06.947+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:49:06.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:49:06.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:49:06.988+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:49:06.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:49:07.003+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:49:07.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:49:07.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-22T11:49:37.382+0000] {processor.py:157} INFO - Started process (PID=91338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:49:37.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:49:37.385+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:49:37.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:49:37.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:49:37.416+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:49:37.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:49:37.426+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:49:37.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:49:37.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T11:50:07.791+0000] {processor.py:157} INFO - Started process (PID=91363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:50:07.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:50:07.796+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:50:07.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:50:07.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:50:07.837+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:50:07.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:50:07.852+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:50:07.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:50:07.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-22T11:50:38.192+0000] {processor.py:157} INFO - Started process (PID=91388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:50:38.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:50:38.194+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:50:38.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:50:38.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:50:38.225+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:50:38.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:50:38.238+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:50:38.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:50:38.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T11:51:08.648+0000] {processor.py:157} INFO - Started process (PID=91413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:51:08.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:51:08.654+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:51:08.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:51:08.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:51:08.688+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:51:08.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:51:08.699+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:51:08.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:51:08.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-22T11:51:39.110+0000] {processor.py:157} INFO - Started process (PID=91438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:51:39.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:51:39.112+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:51:39.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:51:39.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:51:39.145+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:51:39.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:51:39.159+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:51:39.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:51:39.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-22T11:52:09.527+0000] {processor.py:157} INFO - Started process (PID=91463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:52:09.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:52:09.531+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:52:09.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:52:09.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:52:09.560+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:52:09.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:52:09.572+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:52:09.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:52:09.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T11:52:39.984+0000] {processor.py:157} INFO - Started process (PID=91488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:52:39.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:52:39.991+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:52:39.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:52:40.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:52:40.025+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:52:40.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:52:40.034+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:52:40.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:52:40.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-22T11:53:10.418+0000] {processor.py:157} INFO - Started process (PID=91513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:53:10.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:53:10.422+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:53:10.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:53:10.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:53:10.454+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:53:10.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:53:10.469+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:53:10.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:53:10.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-22T11:53:40.887+0000] {processor.py:157} INFO - Started process (PID=91538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:53:40.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:53:40.892+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:53:40.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:53:40.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:53:40.928+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:53:40.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:53:40.939+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:53:40.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:53:40.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-22T11:54:11.372+0000] {processor.py:157} INFO - Started process (PID=91563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:54:11.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:54:11.375+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:54:11.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:54:11.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:54:11.409+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:54:11.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:54:11.422+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:54:11.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:54:11.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-22T11:54:41.833+0000] {processor.py:157} INFO - Started process (PID=91588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:54:41.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:54:41.836+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:54:41.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:54:41.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:54:41.861+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:54:41.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:54:41.872+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:54:41.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:54:41.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T11:55:12.237+0000] {processor.py:157} INFO - Started process (PID=91613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:55:12.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:55:12.240+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:55:12.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:55:12.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:55:12.269+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:55:12.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:55:12.278+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:55:12.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:55:12.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T11:55:42.692+0000] {processor.py:157} INFO - Started process (PID=91638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:55:42.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:55:42.705+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:55:42.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:55:42.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:55:42.743+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:55:42.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:55:42.772+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:55:42.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:55:42.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-22T11:56:13.219+0000] {processor.py:157} INFO - Started process (PID=91663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:56:13.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:56:13.227+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:56:13.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:56:13.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:56:13.279+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:56:13.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:56:13.293+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:56:13.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:56:13.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-22T11:56:43.790+0000] {processor.py:157} INFO - Started process (PID=91688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:56:43.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:56:43.797+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:56:43.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:56:43.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:56:43.837+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:56:43.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:56:43.847+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:56:43.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:56:43.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-22T11:57:14.208+0000] {processor.py:157} INFO - Started process (PID=91713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:57:14.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:57:14.217+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:57:14.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:57:14.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:57:14.267+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:57:14.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:57:14.287+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:57:14.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:57:14.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-22T11:57:44.697+0000] {processor.py:157} INFO - Started process (PID=91738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:57:44.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:57:44.705+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:57:44.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:57:44.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:57:44.724+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:57:44.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:57:44.733+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:57:44.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:57:44.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-22T11:58:15.136+0000] {processor.py:157} INFO - Started process (PID=91763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:58:15.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:58:15.141+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:58:15.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:58:15.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:58:15.173+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:58:15.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:58:15.183+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:58:15.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:58:15.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T11:58:45.588+0000] {processor.py:157} INFO - Started process (PID=91788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:58:45.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:58:45.602+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:58:45.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:58:45.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:58:45.660+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:58:45.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:58:45.673+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:58:45.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:58:45.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-22T11:59:16.110+0000] {processor.py:157} INFO - Started process (PID=91813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:59:16.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:59:16.116+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:59:16.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:59:16.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:59:16.147+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:59:16.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:59:16.157+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:59:16.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:59:16.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-22T11:59:46.524+0000] {processor.py:157} INFO - Started process (PID=91838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:59:46.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T11:59:46.527+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:59:46.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:59:46.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T11:59:46.579+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:59:46.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T11:59:46.596+0000] {logging_mixin.py:151} INFO - [2024-07-22T11:59:46.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T11:59:46.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-22T12:00:17.054+0000] {processor.py:157} INFO - Started process (PID=91863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:00:17.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:00:17.068+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:00:17.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:00:17.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:00:17.110+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:00:17.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:00:17.125+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:00:17.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:00:17.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-22T12:00:47.714+0000] {processor.py:157} INFO - Started process (PID=91888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:00:47.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:00:47.720+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:00:47.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:00:47.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:00:47.786+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:00:47.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:00:47.814+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:00:47.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:00:47.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-07-22T12:01:18.302+0000] {processor.py:157} INFO - Started process (PID=91913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:01:18.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:01:18.312+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:01:18.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:01:18.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:01:18.390+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:01:18.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:01:18.408+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:01:18.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:01:18.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-22T12:01:48.812+0000] {processor.py:157} INFO - Started process (PID=91938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:01:48.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:01:48.815+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:01:48.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:01:48.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:01:48.853+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:01:48.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:01:48.863+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:01:48.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:01:48.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-22T12:02:19.267+0000] {processor.py:157} INFO - Started process (PID=91963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:02:19.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:02:19.274+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:02:19.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:02:19.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:02:19.301+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:02:19.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:02:19.312+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:02:19.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:02:19.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-22T12:02:49.812+0000] {processor.py:157} INFO - Started process (PID=91988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:02:49.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:02:49.822+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:02:49.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:02:49.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:02:49.880+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:02:49.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:02:49.896+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:02:49.896+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:02:49.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-07-22T12:03:20.240+0000] {processor.py:157} INFO - Started process (PID=92013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:03:20.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:03:20.248+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:03:20.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:03:20.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:03:20.281+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:03:20.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:03:20.294+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:03:20.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:03:20.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-22T12:03:50.640+0000] {processor.py:157} INFO - Started process (PID=92038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:03:50.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:03:50.644+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:03:50.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:03:50.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:03:50.681+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:03:50.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:03:50.693+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:03:50.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:03:50.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T12:04:21.020+0000] {processor.py:157} INFO - Started process (PID=92063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:04:21.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:04:21.029+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:04:21.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:04:21.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:04:21.079+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:04:21.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:04:21.097+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:04:21.097+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:04:21.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-22T12:04:51.508+0000] {processor.py:157} INFO - Started process (PID=92088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:04:51.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:04:51.513+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:04:51.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:04:51.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:04:51.551+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:04:51.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:04:51.563+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:04:51.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:04:51.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T12:05:22.188+0000] {processor.py:157} INFO - Started process (PID=92113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:05:22.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:05:22.198+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:05:22.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:05:22.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:05:22.269+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:05:22.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:05:22.287+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:05:22.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:05:22.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-22T12:05:52.712+0000] {processor.py:157} INFO - Started process (PID=92138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:05:52.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:05:52.715+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:05:52.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:05:52.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:05:52.751+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:05:52.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:05:52.765+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:05:52.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:05:52.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-22T12:06:23.138+0000] {processor.py:157} INFO - Started process (PID=92163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:06:23.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:06:23.145+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:06:23.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:06:23.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:06:23.213+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:06:23.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:06:23.233+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:06:23.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:06:23.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-07-22T12:06:53.655+0000] {processor.py:157} INFO - Started process (PID=92188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:06:53.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:06:53.659+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:06:53.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:06:53.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:06:53.694+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:06:53.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:06:53.708+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:06:53.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:06:53.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-22T12:07:24.103+0000] {processor.py:157} INFO - Started process (PID=92213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:07:24.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:07:24.107+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:07:24.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:07:24.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:07:24.152+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:07:24.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:07:24.169+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:07:24.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:07:24.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-22T12:07:54.526+0000] {processor.py:157} INFO - Started process (PID=92238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:07:54.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:07:54.529+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:07:54.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:07:54.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:07:54.563+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:07:54.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:07:54.575+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:07:54.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:07:54.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-22T12:08:24.995+0000] {processor.py:157} INFO - Started process (PID=92263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:08:24.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:08:24.999+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:08:24.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:08:25.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:08:25.038+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:08:25.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:08:25.051+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:08:25.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:08:25.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T12:08:55.468+0000] {processor.py:157} INFO - Started process (PID=92288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:08:55.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:08:55.477+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:08:55.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:08:55.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:08:55.524+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:08:55.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:08:55.542+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:08:55.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:08:55.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-22T12:09:25.954+0000] {processor.py:157} INFO - Started process (PID=92313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:09:25.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:09:25.957+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:09:25.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:09:25.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:09:25.985+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:09:25.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:09:25.999+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:09:25.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:09:26.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T12:09:56.325+0000] {processor.py:157} INFO - Started process (PID=92338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:09:56.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:09:56.328+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:09:56.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:09:56.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:09:56.366+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:09:56.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:09:56.380+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:09:56.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:09:56.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T12:10:26.726+0000] {processor.py:157} INFO - Started process (PID=92363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:10:26.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:10:26.729+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:10:26.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:10:26.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:10:26.763+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:10:26.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:10:26.775+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:10:26.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:10:26.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-22T12:10:57.181+0000] {processor.py:157} INFO - Started process (PID=92388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:10:57.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:10:57.183+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:10:57.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:10:57.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:10:57.213+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:10:57.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:10:57.226+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:10:57.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:10:57.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-22T12:11:27.647+0000] {processor.py:157} INFO - Started process (PID=92413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:11:27.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:11:27.657+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:11:27.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:11:27.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:11:27.700+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:11:27.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:11:27.716+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:11:27.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:11:27.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-22T12:11:58.114+0000] {processor.py:157} INFO - Started process (PID=92438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:11:58.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:11:58.118+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:11:58.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:11:58.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:11:58.154+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:11:58.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:11:58.167+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:11:58.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:11:58.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T12:12:28.493+0000] {processor.py:157} INFO - Started process (PID=92463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:12:28.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:12:28.496+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:12:28.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:12:28.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:12:28.527+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:12:28.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:12:28.538+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:12:28.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:12:28.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T12:12:58.866+0000] {processor.py:157} INFO - Started process (PID=92488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:12:58.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:12:58.870+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:12:58.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:12:58.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:12:58.906+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:12:58.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:12:58.920+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:12:58.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:12:58.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-22T12:13:29.322+0000] {processor.py:157} INFO - Started process (PID=92512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:13:29.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:13:29.329+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:13:29.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:13:29.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:13:29.391+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:13:29.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:13:29.426+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:13:29.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:13:29.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-22T12:13:59.792+0000] {processor.py:157} INFO - Started process (PID=92538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:13:59.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:13:59.797+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:13:59.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:13:59.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:13:59.831+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:13:59.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:13:59.843+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:13:59.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:13:59.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-22T12:14:30.253+0000] {processor.py:157} INFO - Started process (PID=92563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:14:30.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:14:30.255+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:14:30.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:14:30.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:14:30.291+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:14:30.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:14:30.305+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:14:30.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:14:30.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-22T12:15:00.642+0000] {processor.py:157} INFO - Started process (PID=92588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:15:00.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:15:00.645+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:15:00.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:15:00.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:15:00.684+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:15:00.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:15:00.699+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:15:00.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:15:00.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-22T12:15:31.067+0000] {processor.py:157} INFO - Started process (PID=92613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:15:31.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:15:31.074+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:15:31.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:15:31.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:15:31.120+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:15:31.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:15:31.134+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:15:31.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:15:31.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-22T12:16:01.554+0000] {processor.py:157} INFO - Started process (PID=92638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:16:01.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:16:01.557+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:16:01.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:16:01.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:16:01.588+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:16:01.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:16:01.602+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:16:01.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:16:01.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-22T12:16:31.961+0000] {processor.py:157} INFO - Started process (PID=92663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:16:31.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:16:31.966+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:16:31.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:16:31.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:16:32.001+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:16:32.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:16:32.016+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:16:32.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:16:32.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-22T12:17:02.345+0000] {processor.py:157} INFO - Started process (PID=92688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:17:02.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:17:02.348+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:17:02.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:17:02.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:17:02.381+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:17:02.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:17:02.399+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:17:02.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:17:02.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-22T12:17:32.810+0000] {processor.py:157} INFO - Started process (PID=92713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:17:32.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:17:32.815+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:17:32.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:17:32.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:17:32.853+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:17:32.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:17:32.864+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:17:32.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:17:32.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-22T12:18:03.283+0000] {processor.py:157} INFO - Started process (PID=92738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:18:03.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:18:03.287+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:18:03.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:18:03.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:18:03.330+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:18:03.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:18:03.341+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:18:03.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:18:03.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-22T12:18:33.756+0000] {processor.py:157} INFO - Started process (PID=92763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:18:33.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:18:33.763+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:18:33.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:18:33.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:18:33.809+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:18:33.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:18:33.824+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:18:33.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:18:33.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-22T12:19:04.260+0000] {processor.py:157} INFO - Started process (PID=92788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:19:04.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:19:04.271+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:19:04.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:19:04.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:19:04.316+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:19:04.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:19:04.328+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:19:04.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:19:04.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-22T12:19:34.751+0000] {processor.py:157} INFO - Started process (PID=92813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:19:34.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:19:34.754+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:19:34.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:19:34.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:19:34.782+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:19:34.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:19:34.794+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:19:34.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:19:34.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T12:20:05.188+0000] {processor.py:157} INFO - Started process (PID=92838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:20:05.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:20:05.193+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:20:05.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:20:05.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:20:05.220+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:20:05.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:20:05.230+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:20:05.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:20:05.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T12:20:35.535+0000] {processor.py:157} INFO - Started process (PID=92863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:20:35.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:20:35.538+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:20:35.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:20:35.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:20:35.566+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:20:35.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:20:35.577+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:20:35.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:20:35.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T12:21:06.011+0000] {processor.py:157} INFO - Started process (PID=92888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:21:06.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:21:06.015+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:21:06.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:21:06.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:21:06.046+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:21:06.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:21:06.057+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:21:06.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:21:06.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T12:21:36.436+0000] {processor.py:157} INFO - Started process (PID=92913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:21:36.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:21:36.438+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:21:36.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:21:36.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:21:36.462+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:21:36.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:21:36.474+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:21:36.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:21:36.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-22T12:22:06.839+0000] {processor.py:157} INFO - Started process (PID=92938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:22:06.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:22:06.843+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:22:06.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:22:06.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:22:06.873+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:22:06.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:22:06.883+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:22:06.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:22:06.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T12:22:37.258+0000] {processor.py:157} INFO - Started process (PID=92963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:22:37.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:22:37.261+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:22:37.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:22:37.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:22:37.287+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:22:37.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:22:37.298+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:22:37.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:22:37.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T12:23:07.675+0000] {processor.py:157} INFO - Started process (PID=92988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:23:07.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:23:07.678+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:23:07.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:23:07.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:23:07.704+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:23:07.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:23:07.715+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:23:07.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:23:07.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T12:23:38.158+0000] {processor.py:157} INFO - Started process (PID=93013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:23:38.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:23:38.161+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:23:38.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:23:38.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:23:38.189+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:23:38.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:23:38.199+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:23:38.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:23:38.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T12:24:08.573+0000] {processor.py:157} INFO - Started process (PID=93038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:24:08.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:24:08.576+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:24:08.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:24:08.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:24:08.600+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:24:08.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:24:08.613+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:24:08.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:24:08.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T12:24:39.051+0000] {processor.py:157} INFO - Started process (PID=93063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:24:39.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:24:39.054+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:24:39.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:24:39.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:24:39.082+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:24:39.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:24:39.091+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:24:39.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:24:39.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T12:25:09.496+0000] {processor.py:157} INFO - Started process (PID=93088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:25:09.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:25:09.500+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:25:09.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:25:09.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:25:09.529+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:25:09.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:25:09.541+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:25:09.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:25:09.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T12:25:39.999+0000] {processor.py:157} INFO - Started process (PID=93113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:25:39.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:25:40.001+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:25:40.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:25:40.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:25:40.038+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:25:40.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:25:40.049+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:25:40.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:25:40.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-22T12:26:10.503+0000] {processor.py:157} INFO - Started process (PID=93138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:26:10.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:26:10.506+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:26:10.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:26:10.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:26:10.536+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:26:10.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:26:10.551+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:26:10.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:26:10.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T12:26:40.942+0000] {processor.py:157} INFO - Started process (PID=93163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:26:40.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:26:40.945+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:26:40.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:26:40.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:26:40.971+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:26:40.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:26:40.981+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:26:40.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:26:40.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T12:27:11.404+0000] {processor.py:157} INFO - Started process (PID=93188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:27:11.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:27:11.408+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:27:11.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:27:11.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:27:11.435+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:27:11.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:27:11.445+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:27:11.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:27:11.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T12:27:41.808+0000] {processor.py:157} INFO - Started process (PID=93213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:27:41.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:27:41.812+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:27:41.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:27:41.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:27:41.839+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:27:41.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:27:41.849+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:27:41.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:27:41.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T12:28:12.267+0000] {processor.py:157} INFO - Started process (PID=93238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:28:12.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:28:12.270+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:28:12.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:28:12.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:28:12.296+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:28:12.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:28:12.307+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:28:12.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:28:12.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T12:28:42.689+0000] {processor.py:157} INFO - Started process (PID=93263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:28:42.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:28:42.694+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:28:42.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:28:42.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:28:42.719+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:28:42.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:28:42.729+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:28:42.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:28:42.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T12:29:13.106+0000] {processor.py:157} INFO - Started process (PID=93288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:29:13.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:29:13.111+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:29:13.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:29:13.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:29:13.141+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:29:13.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:29:13.152+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:29:13.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:29:13.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T12:29:43.581+0000] {processor.py:157} INFO - Started process (PID=93313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:29:43.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:29:43.582+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:29:43.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:29:43.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:29:43.609+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:29:43.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:29:43.618+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:29:43.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:29:43.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T12:30:13.997+0000] {processor.py:157} INFO - Started process (PID=93338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:30:13.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:30:14.000+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:30:14.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:30:14.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:30:14.029+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:30:14.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:30:14.038+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:30:14.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:30:14.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T12:30:44.427+0000] {processor.py:157} INFO - Started process (PID=93363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:30:44.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:30:44.429+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:30:44.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:30:44.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:30:44.458+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:30:44.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:30:44.469+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:30:44.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:30:44.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T12:31:14.859+0000] {processor.py:157} INFO - Started process (PID=93388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:31:14.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:31:14.863+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:31:14.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:31:14.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:31:14.892+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:31:14.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:31:14.904+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:31:14.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:31:14.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T12:31:45.267+0000] {processor.py:157} INFO - Started process (PID=93413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:31:45.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:31:45.271+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:31:45.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:31:45.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:31:45.302+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:31:45.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:31:45.315+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:31:45.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:31:45.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T12:32:15.791+0000] {processor.py:157} INFO - Started process (PID=93438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:32:15.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:32:15.797+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:32:15.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:32:15.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:32:15.852+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:32:15.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:32:15.867+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:32:15.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:32:15.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-22T12:32:46.265+0000] {processor.py:157} INFO - Started process (PID=93463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:32:46.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:32:46.268+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:32:46.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:32:46.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:32:46.291+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:32:46.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:32:46.302+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:32:46.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:32:46.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-22T12:33:16.761+0000] {processor.py:157} INFO - Started process (PID=93487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:33:16.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:33:16.766+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:33:16.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:33:16.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:33:16.808+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:33:16.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:33:16.826+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:33:16.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:33:16.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-22T12:33:47.215+0000] {processor.py:157} INFO - Started process (PID=93513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:33:47.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:33:47.221+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:33:47.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:33:47.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:33:47.251+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:33:47.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:33:47.261+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:33:47.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:33:47.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T12:34:17.657+0000] {processor.py:157} INFO - Started process (PID=93538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:34:17.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:34:17.660+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:34:17.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:34:17.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:34:17.687+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:34:17.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:34:17.697+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:34:17.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:34:17.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T12:34:48.055+0000] {processor.py:157} INFO - Started process (PID=93563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:34:48.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:34:48.058+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:34:48.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:34:48.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:34:48.085+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:34:48.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:34:48.095+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:34:48.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:34:48.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T12:35:18.516+0000] {processor.py:157} INFO - Started process (PID=93588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:35:18.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:35:18.522+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:35:18.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:35:18.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:35:18.560+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:35:18.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:35:18.572+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:35:18.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:35:18.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-22T12:35:48.970+0000] {processor.py:157} INFO - Started process (PID=93613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:35:48.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:35:48.979+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:35:48.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:35:48.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:35:49.001+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:35:49.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:35:49.012+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:35:49.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:35:49.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T12:36:19.357+0000] {processor.py:157} INFO - Started process (PID=93638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:36:19.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:36:19.359+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:36:19.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:36:19.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:36:19.386+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:36:19.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:36:19.395+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:36:19.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:36:19.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T12:36:49.759+0000] {processor.py:157} INFO - Started process (PID=93663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:36:49.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:36:49.762+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:36:49.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:36:49.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:36:49.795+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:36:49.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:36:49.807+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:36:49.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:36:49.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T12:37:20.159+0000] {processor.py:157} INFO - Started process (PID=93688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:37:20.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:37:20.162+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:37:20.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:37:20.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:37:20.192+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:37:20.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:37:20.202+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:37:20.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:37:20.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T12:37:50.587+0000] {processor.py:157} INFO - Started process (PID=93713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:37:50.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:37:50.590+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:37:50.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:37:50.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:37:50.615+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:37:50.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:37:50.625+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:37:50.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:37:50.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T12:38:20.995+0000] {processor.py:157} INFO - Started process (PID=93738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:38:20.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:38:20.998+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:38:20.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:38:21.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:38:21.031+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:38:21.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:38:21.043+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:38:21.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:38:21.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T12:38:51.436+0000] {processor.py:157} INFO - Started process (PID=93762) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:38:51.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:38:51.443+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:38:51.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:38:51.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:38:51.493+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:38:51.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:38:51.505+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:38:51.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:38:51.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-22T12:39:21.933+0000] {processor.py:157} INFO - Started process (PID=93788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:39:21.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:39:21.938+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:39:21.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:39:21.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:39:21.966+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:39:21.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:39:21.979+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:39:21.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:39:21.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T12:39:52.321+0000] {processor.py:157} INFO - Started process (PID=93813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:39:52.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:39:52.325+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:39:52.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:39:52.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:39:52.354+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:39:52.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:39:52.366+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:39:52.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:39:52.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T12:40:22.757+0000] {processor.py:157} INFO - Started process (PID=93838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:40:22.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:40:22.765+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:40:22.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:40:22.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:40:22.802+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:40:22.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:40:22.816+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:40:22.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:40:22.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-22T12:40:53.211+0000] {processor.py:157} INFO - Started process (PID=93863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:40:53.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:40:53.216+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:40:53.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:40:53.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:40:53.245+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:40:53.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:40:53.257+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:40:53.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:40:53.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T12:41:23.620+0000] {processor.py:157} INFO - Started process (PID=93888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:41:23.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:41:23.623+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:41:23.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:41:23.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:41:23.650+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:41:23.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:41:23.664+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:41:23.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:41:23.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T12:41:54.079+0000] {processor.py:157} INFO - Started process (PID=93913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:41:54.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:41:54.082+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:41:54.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:41:54.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:41:54.110+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:41:54.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:41:54.122+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:41:54.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:41:54.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T12:42:24.436+0000] {processor.py:157} INFO - Started process (PID=93938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:42:24.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:42:24.439+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:42:24.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:42:24.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:42:24.467+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:42:24.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:42:24.477+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:42:24.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:42:24.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T12:42:54.854+0000] {processor.py:157} INFO - Started process (PID=93963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:42:54.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:42:54.858+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:42:54.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:42:54.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:42:54.883+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:42:54.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:42:54.894+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:42:54.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:42:54.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T12:43:25.278+0000] {processor.py:157} INFO - Started process (PID=93988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:43:25.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:43:25.283+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:43:25.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:43:25.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:43:25.319+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:43:25.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:43:25.332+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:43:25.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:43:25.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T12:43:55.697+0000] {processor.py:157} INFO - Started process (PID=94013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:43:55.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:43:55.702+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:43:55.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:43:55.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:43:55.733+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:43:55.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:43:55.742+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:43:55.742+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:43:55.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T12:44:26.119+0000] {processor.py:157} INFO - Started process (PID=94038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:44:26.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:44:26.121+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:44:26.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:44:26.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:44:26.148+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:44:26.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:44:26.159+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:44:26.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:44:26.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T12:44:56.498+0000] {processor.py:157} INFO - Started process (PID=94063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:44:56.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:44:56.501+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:44:56.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:44:56.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:44:56.529+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:44:56.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:44:56.539+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:44:56.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:44:56.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T12:45:26.918+0000] {processor.py:157} INFO - Started process (PID=94088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:45:26.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:45:26.922+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:45:26.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:45:26.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:45:26.952+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:45:26.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:45:26.964+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:45:26.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:45:26.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T12:45:57.416+0000] {processor.py:157} INFO - Started process (PID=94113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:45:57.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:45:57.422+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:45:57.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:45:57.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:45:57.462+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:45:57.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:45:57.474+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:45:57.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:45:57.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T12:46:27.851+0000] {processor.py:157} INFO - Started process (PID=94138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:46:27.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:46:27.856+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:46:27.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:46:27.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:46:27.886+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:46:27.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:46:27.897+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:46:27.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:46:27.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T12:46:58.294+0000] {processor.py:157} INFO - Started process (PID=94163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:46:58.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:46:58.299+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:46:58.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:46:58.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:46:58.332+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:46:58.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:46:58.342+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:46:58.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:46:58.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T12:47:28.678+0000] {processor.py:157} INFO - Started process (PID=94188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:47:28.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:47:28.680+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:47:28.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:47:28.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:47:28.706+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:47:28.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:47:28.716+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:47:28.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:47:28.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T12:47:59.095+0000] {processor.py:157} INFO - Started process (PID=94213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:47:59.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:47:59.101+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:47:59.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:47:59.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:47:59.151+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:47:59.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:47:59.170+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:47:59.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:47:59.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-22T12:48:29.799+0000] {processor.py:157} INFO - Started process (PID=94238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:48:29.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:48:29.821+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:48:29.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:48:29.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:48:29.928+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:48:29.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:48:29.953+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:48:29.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:48:29.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.178 seconds
[2024-07-22T12:49:00.462+0000] {processor.py:157} INFO - Started process (PID=94263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:49:00.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:49:00.471+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:49:00.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:49:00.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:49:00.584+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:49:00.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:49:00.603+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:49:00.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:49:00.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.175 seconds
[2024-07-22T12:49:31.076+0000] {processor.py:157} INFO - Started process (PID=94288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:49:31.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:49:31.085+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:49:31.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:49:31.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:49:31.164+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:49:31.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:49:31.189+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:49:31.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:49:31.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-07-22T12:50:01.693+0000] {processor.py:157} INFO - Started process (PID=94313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:50:01.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:50:01.703+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:50:01.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:50:01.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:50:01.753+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:50:01.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:50:01.766+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:50:01.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:50:01.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-22T12:50:32.262+0000] {processor.py:157} INFO - Started process (PID=94338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:50:32.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:50:32.273+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:50:32.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:50:32.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:50:32.328+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:50:32.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:50:32.351+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:50:32.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:50:32.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-07-22T12:51:02.826+0000] {processor.py:157} INFO - Started process (PID=94363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:51:02.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:51:02.836+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:51:02.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:51:02.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:51:02.910+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:51:02.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:51:02.926+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:51:02.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:51:02.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-22T12:51:33.405+0000] {processor.py:157} INFO - Started process (PID=94388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:51:33.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:51:33.414+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:51:33.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:51:33.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:51:33.464+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:51:33.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:51:33.478+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:51:33.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:51:33.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-22T12:52:03.857+0000] {processor.py:157} INFO - Started process (PID=94413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:52:03.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:52:03.864+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:52:03.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:52:03.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:52:03.903+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:52:03.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:52:03.916+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:52:03.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:52:03.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-22T12:52:34.347+0000] {processor.py:157} INFO - Started process (PID=94438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:52:34.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:52:34.354+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:52:34.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:52:34.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:52:34.397+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:52:34.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:52:34.413+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:52:34.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:52:34.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-22T12:53:04.774+0000] {processor.py:157} INFO - Started process (PID=94463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:53:04.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:53:04.776+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:53:04.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:53:04.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:53:04.822+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:53:04.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:53:04.833+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:53:04.833+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:53:04.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-22T12:53:35.286+0000] {processor.py:157} INFO - Started process (PID=94488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:53:35.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:53:35.297+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:53:35.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:53:35.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:53:35.345+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:53:35.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:53:35.367+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:53:35.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:53:35.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-22T12:54:05.806+0000] {processor.py:157} INFO - Started process (PID=94511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:54:05.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:54:05.812+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:54:05.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:54:05.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:54:05.871+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:54:05.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:54:05.892+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:54:05.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:54:05.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-22T12:54:36.498+0000] {processor.py:157} INFO - Started process (PID=94538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:54:36.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:54:36.511+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:54:36.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:54:36.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:54:36.573+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:54:36.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:54:36.593+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:54:36.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:54:36.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-07-22T12:55:07.028+0000] {processor.py:157} INFO - Started process (PID=94562) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:55:07.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:55:07.034+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:55:07.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:55:07.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:55:07.074+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:55:07.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:55:07.088+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:55:07.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:55:07.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-22T12:55:37.542+0000] {processor.py:157} INFO - Started process (PID=94588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:55:37.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:55:37.553+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:55:37.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:55:37.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:55:37.595+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:55:37.595+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:55:37.607+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:55:37.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:55:37.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-22T12:56:07.994+0000] {processor.py:157} INFO - Started process (PID=94613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:56:07.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:56:08.008+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:56:08.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:56:08.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:56:08.109+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:56:08.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:56:08.127+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:56:08.127+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:56:08.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-07-22T12:56:38.611+0000] {processor.py:157} INFO - Started process (PID=94638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:56:38.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:56:38.619+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:56:38.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:56:38.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:56:38.670+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:56:38.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:56:38.685+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:56:38.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:56:38.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-22T12:57:09.090+0000] {processor.py:157} INFO - Started process (PID=94663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:57:09.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:57:09.096+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:57:09.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:57:09.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:57:09.125+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:57:09.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:57:09.135+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:57:09.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:57:09.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T12:57:39.506+0000] {processor.py:157} INFO - Started process (PID=94688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:57:39.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:57:39.510+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:57:39.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:57:39.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:57:39.573+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:57:39.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:57:39.593+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:57:39.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:57:39.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-22T12:58:09.975+0000] {processor.py:157} INFO - Started process (PID=94713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:58:09.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:58:09.982+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:58:09.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:58:10.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:58:10.022+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:58:10.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:58:10.036+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:58:10.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:58:10.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-22T12:58:40.452+0000] {processor.py:157} INFO - Started process (PID=94738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:58:40.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:58:40.458+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:58:40.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:58:40.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:58:40.488+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:58:40.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:58:40.503+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:58:40.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:58:40.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-22T12:59:10.859+0000] {processor.py:157} INFO - Started process (PID=94763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:59:10.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:59:10.861+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:59:10.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:59:10.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:59:10.909+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:59:10.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:59:10.931+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:59:10.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:59:10.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-22T12:59:41.350+0000] {processor.py:157} INFO - Started process (PID=94788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:59:41.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T12:59:41.365+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:59:41.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:59:41.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T12:59:41.409+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:59:41.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T12:59:41.422+0000] {logging_mixin.py:151} INFO - [2024-07-22T12:59:41.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T12:59:41.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-22T13:00:11.854+0000] {processor.py:157} INFO - Started process (PID=94813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:00:11.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:00:11.863+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:00:11.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:00:11.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:00:11.917+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:00:11.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:00:11.935+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:00:11.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:00:11.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-22T13:00:42.426+0000] {processor.py:157} INFO - Started process (PID=94838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:00:42.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:00:42.433+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:00:42.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:00:42.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:00:42.475+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:00:42.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:00:42.496+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:00:42.496+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:00:42.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-22T13:01:12.930+0000] {processor.py:157} INFO - Started process (PID=94863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:01:12.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:01:12.933+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:01:12.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:01:12.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:01:12.963+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:01:12.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:01:12.975+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:01:12.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:01:12.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T13:01:43.399+0000] {processor.py:157} INFO - Started process (PID=94888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:01:43.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:01:43.421+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:01:43.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:01:43.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:01:43.469+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:01:43.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:01:43.481+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:01:43.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:01:43.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-22T13:02:13.864+0000] {processor.py:157} INFO - Started process (PID=94913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:02:13.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:02:13.866+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:02:13.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:02:13.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:02:13.890+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:02:13.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:02:13.900+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:02:13.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:02:13.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-22T13:02:44.272+0000] {processor.py:157} INFO - Started process (PID=94938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:02:44.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:02:44.283+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:02:44.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:02:44.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:02:44.339+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:02:44.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:02:44.357+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:02:44.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:02:44.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-07-22T13:03:14.799+0000] {processor.py:157} INFO - Started process (PID=94963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:03:14.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:03:14.803+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:03:14.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:03:14.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:03:14.833+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:03:14.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:03:14.844+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:03:14.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:03:14.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T13:03:45.172+0000] {processor.py:157} INFO - Started process (PID=94988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:03:45.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:03:45.179+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:03:45.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:03:45.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:03:45.230+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:03:45.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:03:45.245+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:03:45.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:03:45.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-22T13:04:15.607+0000] {processor.py:157} INFO - Started process (PID=95013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:04:15.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:04:15.614+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:04:15.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:04:15.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:04:15.668+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:04:15.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:04:15.685+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:04:15.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:04:15.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-22T13:04:46.126+0000] {processor.py:157} INFO - Started process (PID=95037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:04:46.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:04:46.129+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:04:46.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:04:46.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:04:46.155+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:04:46.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:04:46.167+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:04:46.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:04:46.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T13:05:16.604+0000] {processor.py:157} INFO - Started process (PID=95063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:05:16.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:05:16.611+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:05:16.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:05:16.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:05:16.650+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:05:16.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:05:16.663+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:05:16.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:05:16.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-22T13:05:47.141+0000] {processor.py:157} INFO - Started process (PID=95087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:05:47.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:05:47.154+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:05:47.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:05:47.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:05:47.199+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:05:47.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:05:47.213+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:05:47.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:05:47.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-22T13:06:17.652+0000] {processor.py:157} INFO - Started process (PID=95113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:06:17.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:06:17.655+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:06:17.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:06:17.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:06:17.680+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:06:17.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:06:17.689+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:06:17.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:06:17.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-22T13:06:48.162+0000] {processor.py:157} INFO - Started process (PID=95138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:06:48.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:06:48.167+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:06:48.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:06:48.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:06:48.206+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:06:48.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:06:48.219+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:06:48.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:06:48.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-22T13:07:18.593+0000] {processor.py:157} INFO - Started process (PID=95163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:07:18.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:07:18.597+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:07:18.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:07:18.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:07:18.626+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:07:18.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:07:18.638+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:07:18.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:07:18.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T13:07:49.009+0000] {processor.py:157} INFO - Started process (PID=95188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:07:49.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:07:49.011+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:07:49.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:07:49.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:07:49.041+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:07:49.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:07:49.053+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:07:49.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:07:49.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T13:08:19.416+0000] {processor.py:157} INFO - Started process (PID=95213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:08:19.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:08:19.422+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:08:19.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:08:19.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:08:19.451+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:08:19.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:08:19.463+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:08:19.463+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:08:19.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T13:08:49.902+0000] {processor.py:157} INFO - Started process (PID=95238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:08:49.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:08:49.910+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:08:49.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:08:49.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:08:49.975+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:08:49.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:08:49.988+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:08:49.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:08:49.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-22T13:09:20.393+0000] {processor.py:157} INFO - Started process (PID=95263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:09:20.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:09:20.396+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:09:20.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:09:20.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:09:20.425+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:09:20.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:09:20.436+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:09:20.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:09:20.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T13:09:50.783+0000] {processor.py:157} INFO - Started process (PID=95288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:09:50.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:09:50.810+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:09:50.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:09:50.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:09:50.856+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:09:50.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:09:50.869+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:09:50.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:09:50.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-22T13:10:21.323+0000] {processor.py:157} INFO - Started process (PID=95313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:10:21.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:10:21.325+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:10:21.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:10:21.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:10:21.356+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:10:21.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:10:21.367+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:10:21.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:10:21.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T13:10:51.858+0000] {processor.py:157} INFO - Started process (PID=95338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:10:51.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:10:51.862+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:10:51.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:10:51.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:10:51.903+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:10:51.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:10:51.915+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:10:51.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:10:51.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-22T13:11:22.356+0000] {processor.py:157} INFO - Started process (PID=95363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:11:22.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:11:22.361+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:11:22.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:11:22.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:11:22.392+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:11:22.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:11:22.402+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:11:22.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:11:22.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-22T13:11:52.824+0000] {processor.py:157} INFO - Started process (PID=95388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:11:52.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:11:52.832+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:11:52.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:11:52.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:11:52.884+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:11:52.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:11:52.900+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:11:52.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:11:52.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-22T13:12:23.332+0000] {processor.py:157} INFO - Started process (PID=95413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:12:23.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:12:23.341+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:12:23.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:12:23.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:12:23.394+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:12:23.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:12:23.421+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:12:23.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:12:23.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-22T13:12:53.858+0000] {processor.py:157} INFO - Started process (PID=95438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:12:53.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:12:53.864+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:12:53.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:12:53.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:12:53.904+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:12:53.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:12:53.916+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:12:53.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:12:53.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-22T13:13:24.336+0000] {processor.py:157} INFO - Started process (PID=95463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:13:24.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:13:24.339+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:13:24.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:13:24.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:13:24.370+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:13:24.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:13:24.381+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:13:24.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:13:24.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T13:13:54.764+0000] {processor.py:157} INFO - Started process (PID=95488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:13:54.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:13:54.767+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:13:54.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:13:54.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:13:54.821+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:13:54.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:13:54.834+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:13:54.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:13:54.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-22T13:14:25.251+0000] {processor.py:157} INFO - Started process (PID=95513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:14:25.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:14:25.254+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:14:25.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:14:25.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:14:25.287+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:14:25.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:14:25.301+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:14:25.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:14:25.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-22T13:14:55.765+0000] {processor.py:157} INFO - Started process (PID=95538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:14:55.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:14:55.771+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:14:55.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:14:55.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:14:55.828+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:14:55.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:14:55.848+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:14:55.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:14:55.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-22T13:15:26.351+0000] {processor.py:157} INFO - Started process (PID=95563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:15:26.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:15:26.358+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:15:26.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:15:26.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:15:26.411+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:15:26.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:15:26.425+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:15:26.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:15:26.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-22T13:15:56.934+0000] {processor.py:157} INFO - Started process (PID=95588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:15:56.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:15:56.938+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:15:56.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:15:56.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:15:56.962+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:15:56.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:15:56.973+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:15:56.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:15:56.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T13:16:27.409+0000] {processor.py:157} INFO - Started process (PID=95613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:16:27.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:16:27.416+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:16:27.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:16:27.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:16:27.450+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:16:27.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:16:27.462+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:16:27.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:16:27.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-22T13:16:57.865+0000] {processor.py:157} INFO - Started process (PID=95638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:16:57.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:16:57.868+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:16:57.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:16:57.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:16:57.904+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:16:57.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:16:57.919+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:16:57.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:16:57.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-22T13:17:28.363+0000] {processor.py:157} INFO - Started process (PID=95663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:17:28.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:17:28.369+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:17:28.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:17:28.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:17:28.412+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:17:28.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:17:28.426+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:17:28.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:17:28.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-22T13:17:58.811+0000] {processor.py:157} INFO - Started process (PID=95688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:17:58.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:17:58.814+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:17:58.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:17:58.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:17:58.842+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:17:58.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:17:58.852+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:17:58.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:17:58.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T13:18:29.273+0000] {processor.py:157} INFO - Started process (PID=95713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:18:29.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:18:29.275+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:18:29.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:18:29.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:18:29.304+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:18:29.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:18:29.314+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:18:29.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:18:29.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T13:18:59.702+0000] {processor.py:157} INFO - Started process (PID=95737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:18:59.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:18:59.706+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:18:59.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:18:59.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:18:59.746+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:18:59.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:18:59.759+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:18:59.759+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:18:59.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-22T13:19:30.184+0000] {processor.py:157} INFO - Started process (PID=95763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:19:30.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:19:30.189+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:19:30.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:19:30.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:19:30.217+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:19:30.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:19:30.228+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:19:30.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:19:30.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T13:20:00.563+0000] {processor.py:157} INFO - Started process (PID=95788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:20:00.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:20:00.568+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:20:00.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:20:00.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:20:00.593+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:20:00.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:20:00.604+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:20:00.604+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:20:00.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T13:20:30.938+0000] {processor.py:157} INFO - Started process (PID=95813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:20:30.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:20:30.942+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:20:30.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:20:30.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:20:30.970+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:20:30.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:20:30.980+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:20:30.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:20:30.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T13:21:01.431+0000] {processor.py:157} INFO - Started process (PID=95838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:21:01.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:21:01.434+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:21:01.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:21:01.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:21:01.474+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:21:01.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:21:01.487+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:21:01.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:21:01.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T13:21:31.956+0000] {processor.py:157} INFO - Started process (PID=95862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:21:31.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:21:31.965+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:21:31.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:21:31.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:21:32.019+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:21:32.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:21:32.035+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:21:32.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:21:32.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-22T13:22:02.432+0000] {processor.py:157} INFO - Started process (PID=95888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:22:02.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:22:02.435+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:22:02.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:22:02.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:22:02.467+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:22:02.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:22:02.478+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:22:02.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:22:02.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T13:22:32.849+0000] {processor.py:157} INFO - Started process (PID=95913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:22:32.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:22:32.856+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:22:32.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:22:32.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:22:32.880+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:22:32.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:22:32.890+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:22:32.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:22:32.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T13:23:03.390+0000] {processor.py:157} INFO - Started process (PID=95937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:23:03.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:23:03.399+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:23:03.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:23:03.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:23:03.453+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:23:03.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:23:03.468+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:23:03.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:23:03.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-22T13:23:33.901+0000] {processor.py:157} INFO - Started process (PID=95963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:23:33.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:23:33.926+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:23:33.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:23:33.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:23:33.969+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:23:33.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:23:33.982+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:23:33.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:23:33.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-22T13:24:04.399+0000] {processor.py:157} INFO - Started process (PID=95988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:24:04.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:24:04.402+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:24:04.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:24:04.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:24:04.427+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:24:04.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:24:04.437+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:24:04.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:24:04.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T13:24:34.899+0000] {processor.py:157} INFO - Started process (PID=96011) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:24:34.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:24:34.906+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:24:34.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:24:34.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:24:34.975+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:24:34.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:24:34.991+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:24:34.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:24:35.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-22T13:25:05.493+0000] {processor.py:157} INFO - Started process (PID=96038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:25:05.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:25:05.501+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:25:05.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:25:05.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:25:05.559+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:25:05.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:25:05.576+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:25:05.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:25:05.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-22T13:25:36.011+0000] {processor.py:157} INFO - Started process (PID=96062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:25:36.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:25:36.022+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:25:36.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:25:36.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:25:36.077+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:25:36.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:25:36.091+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:25:36.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:25:36.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-22T13:26:06.576+0000] {processor.py:157} INFO - Started process (PID=96087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:26:06.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:26:06.593+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:26:06.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:26:06.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:26:06.645+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:26:06.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:26:06.658+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:26:06.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:26:06.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-22T13:26:37.032+0000] {processor.py:157} INFO - Started process (PID=96113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:26:37.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:26:37.037+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:26:37.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:26:37.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:26:37.065+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:26:37.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:26:37.078+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:26:37.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:26:37.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T13:27:07.480+0000] {processor.py:157} INFO - Started process (PID=96138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:27:07.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:27:07.483+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:27:07.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:27:07.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:27:07.513+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:27:07.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:27:07.524+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:27:07.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:27:07.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T13:27:37.873+0000] {processor.py:157} INFO - Started process (PID=96163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:27:37.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:27:37.879+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:27:37.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:27:37.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:27:37.919+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:27:37.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:27:37.932+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:27:37.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:27:37.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-22T13:28:08.387+0000] {processor.py:157} INFO - Started process (PID=96188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:28:08.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:28:08.393+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:28:08.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:28:08.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:28:08.444+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:28:08.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:28:08.461+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:28:08.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:28:08.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-22T13:28:38.851+0000] {processor.py:157} INFO - Started process (PID=96213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:28:38.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:28:38.858+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:28:38.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:28:38.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:28:38.907+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:28:38.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:28:38.923+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:28:38.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:28:38.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-22T13:29:09.333+0000] {processor.py:157} INFO - Started process (PID=96238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:29:09.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:29:09.337+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:29:09.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:29:09.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:29:09.365+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:29:09.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:29:09.375+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:29:09.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:29:09.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T13:29:39.837+0000] {processor.py:157} INFO - Started process (PID=96263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:29:39.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:29:39.846+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:29:39.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:29:39.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:29:39.928+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:29:39.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:29:39.946+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:29:39.945+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:29:39.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-07-22T13:30:10.360+0000] {processor.py:157} INFO - Started process (PID=96288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:30:10.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:30:10.367+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:30:10.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:30:10.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:30:10.424+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:30:10.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:30:10.438+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:30:10.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:30:10.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-22T13:30:40.936+0000] {processor.py:157} INFO - Started process (PID=96312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:30:40.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:30:40.946+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:30:40.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:30:40.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:30:41.009+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:30:41.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:30:41.024+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:30:41.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:30:41.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-07-22T13:31:11.446+0000] {processor.py:157} INFO - Started process (PID=96338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:31:11.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:31:11.451+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:31:11.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:31:11.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:31:11.486+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:31:11.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:31:11.498+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:31:11.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:31:11.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-22T13:31:41.987+0000] {processor.py:157} INFO - Started process (PID=96362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:31:41.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:31:41.994+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:31:41.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:31:42.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:31:42.055+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:31:42.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:31:42.076+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:31:42.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:31:42.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-07-22T13:32:12.427+0000] {processor.py:157} INFO - Started process (PID=96388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:32:12.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:32:12.446+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:32:12.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:32:12.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:32:12.488+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:32:12.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:32:12.501+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:32:12.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:32:12.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-22T13:32:42.978+0000] {processor.py:157} INFO - Started process (PID=96413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:32:42.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:32:42.983+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:32:42.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:32:42.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:32:43.021+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:32:43.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:32:43.033+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:32:43.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:32:43.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T13:33:13.399+0000] {processor.py:157} INFO - Started process (PID=96438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:33:13.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:33:13.401+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:33:13.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:33:13.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:33:13.432+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:33:13.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:33:13.444+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:33:13.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:33:13.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T13:33:44.014+0000] {processor.py:157} INFO - Started process (PID=96463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:33:44.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:33:44.020+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:33:44.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:33:44.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:33:44.073+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:33:44.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:33:44.087+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:33:44.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:33:44.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-22T13:34:14.416+0000] {processor.py:157} INFO - Started process (PID=96488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:34:14.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:34:14.420+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:34:14.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:34:14.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:34:14.447+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:34:14.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:34:14.459+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:34:14.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:34:14.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T13:34:44.848+0000] {processor.py:157} INFO - Started process (PID=96511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:34:44.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:34:44.865+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:34:44.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:34:44.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:34:44.913+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:34:44.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:34:44.929+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:34:44.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:34:44.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-22T13:35:15.298+0000] {processor.py:157} INFO - Started process (PID=96538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:35:15.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:35:15.300+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:35:15.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:35:15.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:35:15.326+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:35:15.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:35:15.336+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:35:15.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:35:15.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T13:35:45.848+0000] {processor.py:157} INFO - Started process (PID=96563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:35:45.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:35:45.854+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:35:45.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:35:45.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:35:45.962+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:35:45.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:35:45.988+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:35:45.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:35:46.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-07-22T13:36:16.461+0000] {processor.py:157} INFO - Started process (PID=96588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:36:16.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:36:16.470+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:36:16.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:36:16.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:36:16.549+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:36:16.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:36:16.567+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:36:16.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:36:16.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-07-22T13:36:47.029+0000] {processor.py:157} INFO - Started process (PID=96613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:36:47.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:36:47.033+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:36:47.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:36:47.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:36:47.067+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:36:47.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:36:47.079+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:36:47.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:36:47.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-22T13:37:17.452+0000] {processor.py:157} INFO - Started process (PID=96638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:37:17.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:37:17.458+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:37:17.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:37:17.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:37:17.496+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:37:17.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:37:17.511+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:37:17.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:37:17.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-22T13:37:47.907+0000] {processor.py:157} INFO - Started process (PID=96663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:37:47.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:37:47.911+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:37:47.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:37:47.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:37:47.936+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:37:47.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:37:47.946+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:37:47.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:37:47.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-22T13:38:18.282+0000] {processor.py:157} INFO - Started process (PID=96688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:38:18.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:38:18.285+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:38:18.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:38:18.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:38:18.309+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:38:18.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:38:18.318+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:38:18.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:38:18.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-22T13:38:48.669+0000] {processor.py:157} INFO - Started process (PID=96713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:38:48.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:38:48.672+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:38:48.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:38:48.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:38:48.701+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:38:48.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:38:48.713+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:38:48.713+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:38:48.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T13:39:19.091+0000] {processor.py:157} INFO - Started process (PID=96737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:39:19.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:39:19.098+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:39:19.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:39:19.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:39:19.153+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:39:19.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:39:19.167+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:39:19.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:39:19.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-22T13:39:49.544+0000] {processor.py:157} INFO - Started process (PID=96763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:39:49.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:39:49.547+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:39:49.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:39:49.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:39:49.575+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:39:49.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:39:49.586+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:39:49.586+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:39:49.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T13:40:20.055+0000] {processor.py:157} INFO - Started process (PID=96788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:40:20.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:40:20.062+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:40:20.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:40:20.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:40:20.123+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:40:20.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:40:20.138+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:40:20.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:40:20.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-22T13:40:50.636+0000] {processor.py:157} INFO - Started process (PID=96813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:40:50.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:40:50.647+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:40:50.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:40:50.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:40:50.713+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:40:50.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:40:50.728+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:40:50.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:40:50.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-22T13:41:21.169+0000] {processor.py:157} INFO - Started process (PID=96838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:41:21.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:41:21.186+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:41:21.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:41:21.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:41:21.231+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:41:21.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:41:21.244+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:41:21.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:41:21.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-22T13:41:51.620+0000] {processor.py:157} INFO - Started process (PID=96863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:41:51.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:41:51.623+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:41:51.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:41:51.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:41:51.649+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:41:51.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:41:51.663+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:41:51.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:41:51.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T13:42:22.016+0000] {processor.py:157} INFO - Started process (PID=96888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:42:22.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:42:22.018+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:42:22.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:42:22.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:42:22.047+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:42:22.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:42:22.059+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:42:22.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:42:22.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T13:42:52.428+0000] {processor.py:157} INFO - Started process (PID=96913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:42:52.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:42:52.431+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:42:52.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:42:52.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:42:52.458+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:42:52.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:42:52.470+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:42:52.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:42:52.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T13:43:22.870+0000] {processor.py:157} INFO - Started process (PID=96938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:43:22.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:43:22.874+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:43:22.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:43:22.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:43:22.901+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:43:22.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:43:22.912+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:43:22.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:43:22.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T13:43:53.285+0000] {processor.py:157} INFO - Started process (PID=96962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:43:53.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:43:53.295+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:43:53.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:43:53.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:43:53.365+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:43:53.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:43:53.392+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:43:53.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:43:53.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-22T13:44:23.712+0000] {processor.py:157} INFO - Started process (PID=96988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:44:23.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:44:23.714+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:44:23.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:44:23.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:44:23.741+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:44:23.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:44:23.752+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:44:23.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:44:23.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T13:44:54.166+0000] {processor.py:157} INFO - Started process (PID=97013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:44:54.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:44:54.169+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:44:54.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:44:54.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:44:54.197+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:44:54.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:44:54.206+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:44:54.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:44:54.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T13:45:24.552+0000] {processor.py:157} INFO - Started process (PID=97038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:45:24.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:45:24.556+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:45:24.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:45:24.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:45:24.590+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:45:24.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:45:24.605+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:45:24.605+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:45:24.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-22T13:45:55.033+0000] {processor.py:157} INFO - Started process (PID=97063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:45:55.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:45:55.036+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:45:55.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:45:55.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:45:55.062+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:45:55.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:45:55.073+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:45:55.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:45:55.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T13:46:25.501+0000] {processor.py:157} INFO - Started process (PID=97088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:46:25.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:46:25.509+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:46:25.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:46:25.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:46:25.559+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:46:25.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:46:25.572+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:46:25.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:46:25.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-22T13:46:55.999+0000] {processor.py:157} INFO - Started process (PID=97113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:46:56.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:46:56.002+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:46:56.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:46:56.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:46:56.031+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:46:56.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:46:56.041+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:46:56.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:46:56.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T13:47:26.416+0000] {processor.py:157} INFO - Started process (PID=97138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:47:26.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:47:26.419+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:47:26.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:47:26.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:47:26.448+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:47:26.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:47:26.458+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:47:26.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:47:26.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T13:47:56.809+0000] {processor.py:157} INFO - Started process (PID=97163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:47:56.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:47:56.813+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:47:56.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:47:56.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:47:56.840+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:47:56.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:47:56.851+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:47:56.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:47:56.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T13:48:27.253+0000] {processor.py:157} INFO - Started process (PID=97187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:48:27.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:48:27.260+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:48:27.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:48:27.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:48:27.308+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:48:27.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:48:27.321+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:48:27.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:48:27.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-22T13:48:57.693+0000] {processor.py:157} INFO - Started process (PID=97213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:48:57.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:48:57.696+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:48:57.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:48:57.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:48:57.722+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:48:57.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:48:57.732+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:48:57.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:48:57.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-22T13:49:28.129+0000] {processor.py:157} INFO - Started process (PID=97238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:49:28.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:49:28.133+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:49:28.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:49:28.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:49:28.160+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:49:28.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:49:28.170+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:49:28.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:49:28.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T13:49:58.671+0000] {processor.py:157} INFO - Started process (PID=97261) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:49:58.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:49:58.680+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:49:58.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:49:58.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:49:58.759+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:49:58.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:49:58.782+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:49:58.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:49:58.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-07-22T13:50:29.244+0000] {processor.py:157} INFO - Started process (PID=97287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:50:29.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:50:29.250+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:50:29.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:50:29.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:50:29.305+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:50:29.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:50:29.318+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:50:29.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:50:29.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-22T13:50:59.758+0000] {processor.py:157} INFO - Started process (PID=97313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:50:59.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:50:59.760+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:50:59.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:50:59.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:50:59.791+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:50:59.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:50:59.801+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:50:59.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:50:59.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T13:51:30.192+0000] {processor.py:157} INFO - Started process (PID=97338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:51:30.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:51:30.198+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:51:30.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:51:30.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:51:30.234+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:51:30.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:51:30.247+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:51:30.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:51:30.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-22T13:52:00.652+0000] {processor.py:157} INFO - Started process (PID=97363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:52:00.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:52:00.655+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:52:00.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:52:00.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:52:00.685+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:52:00.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:52:00.696+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:52:00.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:52:00.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T13:52:31.083+0000] {processor.py:157} INFO - Started process (PID=97388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:52:31.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:52:31.086+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:52:31.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:52:31.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:52:31.113+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:52:31.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:52:31.123+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:52:31.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:52:31.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T13:53:01.550+0000] {processor.py:157} INFO - Started process (PID=97413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:53:01.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:53:01.557+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:53:01.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:53:01.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:53:01.605+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:53:01.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:53:01.618+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:53:01.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:53:01.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-22T13:53:32.079+0000] {processor.py:157} INFO - Started process (PID=97437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:53:32.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:53:32.086+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:53:32.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:53:32.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:53:32.143+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:53:32.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:53:32.159+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:53:32.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:53:32.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-22T13:54:02.533+0000] {processor.py:157} INFO - Started process (PID=97462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:54:02.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:54:02.541+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:54:02.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:54:02.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:54:02.619+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:54:02.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:54:02.635+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:54:02.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:54:02.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-22T13:54:33.043+0000] {processor.py:157} INFO - Started process (PID=97487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:54:33.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:54:33.065+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:54:33.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:54:33.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:54:33.136+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:54:33.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:54:33.156+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:54:33.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:54:33.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-07-22T13:55:03.687+0000] {processor.py:157} INFO - Started process (PID=97513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:55:03.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:55:03.694+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:55:03.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:55:03.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:55:03.739+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:55:03.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:55:03.756+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:55:03.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:55:03.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-22T13:55:34.206+0000] {processor.py:157} INFO - Started process (PID=97537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:55:34.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:55:34.218+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:55:34.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:55:34.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:55:34.261+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:55:34.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:55:34.274+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:55:34.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:55:34.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-07-22T13:56:04.750+0000] {processor.py:157} INFO - Started process (PID=97562) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:56:04.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:56:04.760+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:56:04.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:56:04.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:56:04.811+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:56:04.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:56:04.826+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:56:04.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:56:04.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-22T13:56:35.254+0000] {processor.py:157} INFO - Started process (PID=97588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:56:35.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:56:35.266+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:56:35.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:56:35.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:56:35.303+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:56:35.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:56:35.316+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:56:35.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:56:35.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-22T13:57:05.700+0000] {processor.py:157} INFO - Started process (PID=97613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:57:05.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:57:05.709+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:57:05.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:57:05.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:57:05.751+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:57:05.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:57:05.766+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:57:05.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:57:05.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-22T13:57:36.217+0000] {processor.py:157} INFO - Started process (PID=97638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:57:36.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:57:36.227+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:57:36.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:57:36.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:57:36.290+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:57:36.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:57:36.304+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:57:36.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:57:36.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-22T13:58:06.734+0000] {processor.py:157} INFO - Started process (PID=97663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:58:06.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:58:06.738+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:58:06.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:58:06.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:58:06.766+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:58:06.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:58:06.777+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:58:06.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:58:06.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T13:58:37.138+0000] {processor.py:157} INFO - Started process (PID=97688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:58:37.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:58:37.143+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:58:37.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:58:37.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:58:37.187+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:58:37.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:58:37.202+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:58:37.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:58:37.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-22T13:59:07.573+0000] {processor.py:157} INFO - Started process (PID=97713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:59:07.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:59:07.579+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:59:07.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:59:07.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:59:07.612+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:59:07.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:59:07.625+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:59:07.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:59:07.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-22T13:59:38.048+0000] {processor.py:157} INFO - Started process (PID=97738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:59:38.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T13:59:38.055+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:59:38.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:59:38.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T13:59:38.098+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:59:38.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T13:59:38.113+0000] {logging_mixin.py:151} INFO - [2024-07-22T13:59:38.113+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T13:59:38.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-22T14:00:08.559+0000] {processor.py:157} INFO - Started process (PID=97763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:00:08.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:00:08.567+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:00:08.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:00:08.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:00:08.605+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:00:08.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:00:08.618+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:00:08.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:00:08.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-22T14:00:39.014+0000] {processor.py:157} INFO - Started process (PID=97788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:00:39.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:00:39.018+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:00:39.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:00:39.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:00:39.055+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:00:39.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:00:39.071+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:00:39.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:00:39.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-22T14:01:09.470+0000] {processor.py:157} INFO - Started process (PID=97812) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:01:09.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:01:09.476+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:01:09.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:01:09.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:01:09.519+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:01:09.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:01:09.532+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:01:09.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:01:09.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-22T14:01:39.962+0000] {processor.py:157} INFO - Started process (PID=97838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:01:39.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:01:39.968+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:01:39.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:01:39.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:01:40.000+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:01:40.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:01:40.012+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:01:40.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:01:40.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-22T14:02:10.426+0000] {processor.py:157} INFO - Started process (PID=97863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:02:10.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:02:10.431+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:02:10.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:02:10.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:02:10.473+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:02:10.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:02:10.487+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:02:10.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:02:10.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-22T14:02:40.841+0000] {processor.py:157} INFO - Started process (PID=97888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:02:40.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:02:40.846+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:02:40.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:02:40.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:02:40.875+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:02:40.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:02:40.888+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:02:40.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:02:40.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T14:03:11.307+0000] {processor.py:157} INFO - Started process (PID=97913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:03:11.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:03:11.314+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:03:11.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:03:11.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:03:11.358+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:03:11.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:03:11.371+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:03:11.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:03:11.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-22T14:03:41.788+0000] {processor.py:157} INFO - Started process (PID=97938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:03:41.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:03:41.792+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:03:41.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:03:41.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:03:41.822+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:03:41.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:03:41.832+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:03:41.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:03:41.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T14:04:12.208+0000] {processor.py:157} INFO - Started process (PID=97963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:04:12.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:04:12.211+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:04:12.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:04:12.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:04:12.239+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:04:12.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:04:12.248+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:04:12.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:04:12.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T14:04:42.689+0000] {processor.py:157} INFO - Started process (PID=97988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:04:42.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:04:42.694+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:04:42.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:04:42.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:04:42.730+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:04:42.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:04:42.742+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:04:42.742+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:04:42.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-22T14:05:13.155+0000] {processor.py:157} INFO - Started process (PID=98013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:05:13.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:05:13.158+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:05:13.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:05:13.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:05:13.189+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:05:13.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:05:13.201+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:05:13.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:05:13.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T14:05:43.592+0000] {processor.py:157} INFO - Started process (PID=98038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:05:43.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:05:43.595+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:05:43.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:05:43.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:05:43.624+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:05:43.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:05:43.637+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:05:43.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:05:43.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T14:06:14.071+0000] {processor.py:157} INFO - Started process (PID=98063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:06:14.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:06:14.077+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:06:14.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:06:14.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:06:14.106+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:06:14.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:06:14.117+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:06:14.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:06:14.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T14:06:44.463+0000] {processor.py:157} INFO - Started process (PID=98088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:06:44.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:06:44.467+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:06:44.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:06:44.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:06:44.504+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:06:44.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:06:44.515+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:06:44.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:06:44.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-22T14:07:14.926+0000] {processor.py:157} INFO - Started process (PID=98113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:07:14.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:07:14.930+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:07:14.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:07:14.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:07:14.956+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:07:14.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:07:14.966+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:07:14.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:07:14.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T14:07:45.287+0000] {processor.py:157} INFO - Started process (PID=98138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:07:45.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:07:45.290+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:07:45.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:07:45.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:07:45.319+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:07:45.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:07:45.330+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:07:45.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:07:45.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T14:08:15.756+0000] {processor.py:157} INFO - Started process (PID=98163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:08:15.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:08:15.758+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:08:15.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:08:15.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:08:15.786+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:08:15.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:08:15.799+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:08:15.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:08:15.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T14:08:46.161+0000] {processor.py:157} INFO - Started process (PID=98188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:08:46.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:08:46.164+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:08:46.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:08:46.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:08:46.193+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:08:46.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:08:46.205+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:08:46.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:08:46.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T14:09:16.553+0000] {processor.py:157} INFO - Started process (PID=98213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:09:16.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:09:16.557+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:09:16.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:09:16.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:09:16.592+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:09:16.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:09:16.603+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:09:16.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:09:16.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-22T14:09:47.027+0000] {processor.py:157} INFO - Started process (PID=98238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:09:47.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:09:47.033+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:09:47.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:09:47.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:09:47.062+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:09:47.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:09:47.075+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:09:47.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:09:47.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T14:10:17.453+0000] {processor.py:157} INFO - Started process (PID=98263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:10:17.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:10:17.457+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:10:17.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:10:17.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:10:17.484+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:10:17.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:10:17.494+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:10:17.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:10:17.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T14:10:47.929+0000] {processor.py:157} INFO - Started process (PID=98288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:10:47.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:10:47.935+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:10:47.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:10:47.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:10:47.971+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:10:47.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:10:47.984+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:10:47.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:10:47.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T14:11:18.436+0000] {processor.py:157} INFO - Started process (PID=98313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:11:18.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:11:18.439+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:11:18.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:11:18.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:11:18.472+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:11:18.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:11:18.483+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:11:18.483+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:11:18.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T14:11:48.895+0000] {processor.py:157} INFO - Started process (PID=98338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:11:48.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:11:48.898+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:11:48.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:11:48.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:11:48.931+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:11:48.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:11:48.943+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:11:48.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:11:48.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-22T14:12:19.379+0000] {processor.py:157} INFO - Started process (PID=98363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:12:19.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:12:19.383+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:12:19.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:12:19.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:12:19.418+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:12:19.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:12:19.429+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:12:19.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:12:19.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T14:12:49.773+0000] {processor.py:157} INFO - Started process (PID=98388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:12:49.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:12:49.778+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:12:49.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:12:49.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:12:49.807+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:12:49.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:12:49.819+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:12:49.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:12:49.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T14:13:20.250+0000] {processor.py:157} INFO - Started process (PID=98413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:13:20.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:13:20.255+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:13:20.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:13:20.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:13:20.285+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:13:20.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:13:20.296+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:13:20.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:13:20.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T14:13:50.669+0000] {processor.py:157} INFO - Started process (PID=98438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:13:50.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:13:50.675+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:13:50.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:13:50.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:13:50.712+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:13:50.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:13:50.725+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:13:50.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:13:50.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T14:14:21.165+0000] {processor.py:157} INFO - Started process (PID=98463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:14:21.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:14:21.168+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:14:21.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:14:21.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:14:21.202+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:14:21.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:14:21.213+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:14:21.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:14:21.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-22T14:14:51.624+0000] {processor.py:157} INFO - Started process (PID=98488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:14:51.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:14:51.627+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:14:51.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:14:51.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:14:51.655+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:14:51.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:14:51.669+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:14:51.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:14:51.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T14:15:22.076+0000] {processor.py:157} INFO - Started process (PID=98513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:15:22.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:15:22.080+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:15:22.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:15:22.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:15:22.116+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:15:22.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:15:22.130+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:15:22.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:15:22.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-22T14:15:52.543+0000] {processor.py:157} INFO - Started process (PID=98538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:15:52.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:15:52.548+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:15:52.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:15:52.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:15:52.578+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:15:52.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:15:52.592+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:15:52.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:15:52.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-22T14:16:23.016+0000] {processor.py:157} INFO - Started process (PID=98563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:16:23.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:16:23.028+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:16:23.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:16:23.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:16:23.069+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:16:23.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:16:23.083+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:16:23.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:16:23.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-22T14:16:53.511+0000] {processor.py:157} INFO - Started process (PID=98588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:16:53.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:16:53.514+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:16:53.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:16:53.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:16:53.541+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:16:53.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:16:53.552+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:16:53.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:16:53.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T14:17:23.992+0000] {processor.py:157} INFO - Started process (PID=98613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:17:23.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:17:23.998+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:17:23.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:17:24.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:17:24.076+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:17:24.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:17:24.092+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:17:24.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:17:24.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-22T14:17:54.503+0000] {processor.py:157} INFO - Started process (PID=98638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:17:54.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:17:54.507+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:17:54.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:17:54.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:17:54.534+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:17:54.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:17:54.545+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:17:54.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:17:54.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T14:18:24.898+0000] {processor.py:157} INFO - Started process (PID=98662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:18:24.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:18:24.905+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:18:24.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:18:24.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:18:24.965+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:18:24.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:18:24.979+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:18:24.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:18:24.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-22T14:18:55.398+0000] {processor.py:157} INFO - Started process (PID=98688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:18:55.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:18:55.402+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:18:55.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:18:55.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:18:55.428+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:18:55.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:18:55.439+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:18:55.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:18:55.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T14:19:25.831+0000] {processor.py:157} INFO - Started process (PID=98713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:19:25.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:19:25.835+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:19:25.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:19:25.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:19:25.870+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:19:25.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:19:25.883+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:19:25.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:19:25.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-22T14:19:56.295+0000] {processor.py:157} INFO - Started process (PID=98738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:19:56.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:19:56.299+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:19:56.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:19:56.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:19:56.326+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:19:56.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:19:56.337+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:19:56.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:19:56.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T14:20:26.724+0000] {processor.py:157} INFO - Started process (PID=98763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:20:26.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:20:26.726+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:20:26.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:20:26.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:20:26.753+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:20:26.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:20:26.764+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:20:26.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:20:26.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T14:20:57.053+0000] {processor.py:157} INFO - Started process (PID=98788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:20:57.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:20:57.055+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:20:57.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:20:57.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:20:57.086+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:20:57.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:20:57.097+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:20:57.097+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:20:57.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T14:21:27.524+0000] {processor.py:157} INFO - Started process (PID=98813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:21:27.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:21:27.530+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:21:27.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:21:27.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:21:27.570+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:21:27.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:21:27.583+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:21:27.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:21:27.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-22T14:21:57.963+0000] {processor.py:157} INFO - Started process (PID=98838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:21:57.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:21:57.967+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:21:57.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:21:57.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:21:57.996+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:21:57.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:21:58.007+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:21:58.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:21:58.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T14:22:28.395+0000] {processor.py:157} INFO - Started process (PID=98863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:22:28.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:22:28.397+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:22:28.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:22:28.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:22:28.422+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:22:28.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:22:28.433+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:22:28.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:22:28.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-22T14:22:58.856+0000] {processor.py:157} INFO - Started process (PID=98888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:22:58.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:22:58.861+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:22:58.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:22:58.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:22:58.891+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:22:58.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:22:58.900+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:22:58.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:22:58.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T14:23:29.186+0000] {processor.py:157} INFO - Started process (PID=98913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:23:29.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:23:29.193+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:23:29.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:23:29.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:23:29.233+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:23:29.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:23:29.248+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:23:29.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:23:29.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-22T14:23:59.647+0000] {processor.py:157} INFO - Started process (PID=98938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:23:59.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:23:59.651+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:23:59.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:23:59.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:23:59.679+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:23:59.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:23:59.692+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:23:59.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:23:59.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T14:24:30.044+0000] {processor.py:157} INFO - Started process (PID=98963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:24:30.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:24:30.049+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:24:30.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:24:30.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:24:30.087+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:24:30.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:24:30.100+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:24:30.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:24:30.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T14:25:00.504+0000] {processor.py:157} INFO - Started process (PID=98988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:25:00.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:25:00.508+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:25:00.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:25:00.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:25:00.534+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:25:00.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:25:00.545+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:25:00.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:25:00.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T14:25:31.100+0000] {processor.py:157} INFO - Started process (PID=99012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:25:31.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:25:31.112+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:25:31.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:25:31.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:25:31.185+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:25:31.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:25:31.201+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:25:31.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:25:31.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-22T14:26:01.856+0000] {processor.py:157} INFO - Started process (PID=99038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:26:01.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:26:01.863+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:26:01.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:26:01.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:26:01.912+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:26:01.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:26:01.925+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:26:01.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:26:01.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-22T14:26:32.356+0000] {processor.py:157} INFO - Started process (PID=99063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:26:32.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:26:32.364+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:26:32.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:26:32.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:26:32.423+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:26:32.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:26:32.437+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:26:32.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:26:32.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-22T14:27:02.986+0000] {processor.py:157} INFO - Started process (PID=99088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:27:02.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:27:03.005+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:27:03.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:27:03.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:27:03.086+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:27:03.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:27:03.102+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:27:03.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:27:03.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-07-22T14:27:33.587+0000] {processor.py:157} INFO - Started process (PID=99113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:27:33.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:27:33.608+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:27:33.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:27:33.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:27:33.674+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:27:33.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:27:33.711+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:27:33.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:27:33.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-07-22T14:28:04.146+0000] {processor.py:157} INFO - Started process (PID=99138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:28:04.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:28:04.154+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:28:04.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:28:04.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:28:04.199+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:28:04.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:28:04.215+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:28:04.215+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:28:04.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-22T14:28:34.629+0000] {processor.py:157} INFO - Started process (PID=99163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:28:34.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:28:34.633+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:28:34.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:28:34.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:28:34.667+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:28:34.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:28:34.683+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:28:34.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:28:34.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-22T14:29:05.040+0000] {processor.py:157} INFO - Started process (PID=99188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:29:05.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:29:05.045+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:29:05.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:29:05.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:29:05.087+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:29:05.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:29:05.101+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:29:05.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:29:05.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-22T14:29:35.453+0000] {processor.py:157} INFO - Started process (PID=99213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:29:35.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:29:35.456+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:29:35.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:29:35.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:29:35.489+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:29:35.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:29:35.501+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:29:35.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:29:35.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-22T14:30:05.936+0000] {processor.py:157} INFO - Started process (PID=99237) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:30:05.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:30:05.941+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:30:05.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:30:05.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:30:05.989+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:30:05.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:30:06.002+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:30:06.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:30:06.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-22T14:30:36.404+0000] {processor.py:157} INFO - Started process (PID=99263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:30:36.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:30:36.410+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:30:36.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:30:36.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:30:36.457+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:30:36.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:30:36.475+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:30:36.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:30:36.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-22T14:31:06.891+0000] {processor.py:157} INFO - Started process (PID=99288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:31:06.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:31:06.893+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:31:06.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:31:06.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:31:06.921+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:31:06.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:31:06.933+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:31:06.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:31:06.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T14:31:37.349+0000] {processor.py:157} INFO - Started process (PID=99313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:31:37.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:31:37.355+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:31:37.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:31:37.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:31:37.396+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:31:37.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:31:37.409+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:31:37.409+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:31:37.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-22T14:32:07.837+0000] {processor.py:157} INFO - Started process (PID=99338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:32:07.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:32:07.841+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:32:07.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:32:07.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:32:07.871+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:32:07.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:32:07.884+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:32:07.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:32:07.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T14:32:38.268+0000] {processor.py:157} INFO - Started process (PID=99363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:32:38.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:32:38.270+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:32:38.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:32:38.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:32:38.292+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:32:38.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:32:38.300+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:32:38.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:32:38.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-22T14:33:08.708+0000] {processor.py:157} INFO - Started process (PID=99388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:33:08.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:33:08.710+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:33:08.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:33:08.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:33:08.735+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:33:08.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:33:08.746+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:33:08.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:33:08.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T14:33:39.079+0000] {processor.py:157} INFO - Started process (PID=99413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:33:39.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:33:39.084+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:33:39.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:33:39.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:33:39.120+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:33:39.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:33:39.133+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:33:39.133+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:33:39.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-22T14:34:09.506+0000] {processor.py:157} INFO - Started process (PID=99438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:34:09.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:34:09.510+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:34:09.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:34:09.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:34:09.553+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:34:09.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:34:09.570+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:34:09.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:34:09.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-22T14:34:39.995+0000] {processor.py:157} INFO - Started process (PID=99463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:34:40.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:34:40.005+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:34:40.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:34:40.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:34:40.052+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:34:40.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:34:40.070+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:34:40.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:34:40.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-22T14:35:10.466+0000] {processor.py:157} INFO - Started process (PID=99488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:35:10.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:35:10.473+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:35:10.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:35:10.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:35:10.513+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:35:10.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:35:10.525+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:35:10.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:35:10.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-22T14:35:40.943+0000] {processor.py:157} INFO - Started process (PID=99513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:35:40.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:35:40.946+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:35:40.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:35:40.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:35:40.973+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:35:40.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:35:40.985+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:35:40.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:35:40.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T14:36:11.377+0000] {processor.py:157} INFO - Started process (PID=99537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:36:11.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:36:11.382+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:36:11.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:36:11.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:36:11.445+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:36:11.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:36:11.457+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:36:11.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:36:11.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-22T14:36:41.874+0000] {processor.py:157} INFO - Started process (PID=99563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:36:41.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:36:41.877+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:36:41.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:36:41.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:36:41.905+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:36:41.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:36:41.916+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:36:41.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:36:41.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T14:37:12.318+0000] {processor.py:157} INFO - Started process (PID=99588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:37:12.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:37:12.321+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:37:12.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:37:12.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:37:12.353+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:37:12.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:37:12.364+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:37:12.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:37:12.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T14:37:42.806+0000] {processor.py:157} INFO - Started process (PID=99613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:37:42.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:37:42.814+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:37:42.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:37:42.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:37:42.876+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:37:42.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:37:42.895+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:37:42.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:37:42.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-22T14:38:13.319+0000] {processor.py:157} INFO - Started process (PID=99638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:38:13.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:38:13.324+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:38:13.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:38:13.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:38:13.355+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:38:13.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:38:13.369+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:38:13.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:38:13.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-22T14:38:43.746+0000] {processor.py:157} INFO - Started process (PID=99663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:38:43.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:38:43.766+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:38:43.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:38:43.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:38:43.815+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:38:43.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:38:43.839+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:38:43.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:38:43.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-22T14:39:14.239+0000] {processor.py:157} INFO - Started process (PID=99688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:39:14.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:39:14.243+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:39:14.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:39:14.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:39:14.272+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:39:14.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:39:14.285+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:39:14.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:39:14.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T14:39:44.623+0000] {processor.py:157} INFO - Started process (PID=99713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:39:44.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:39:44.630+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:39:44.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:39:44.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:39:44.671+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:39:44.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:39:44.692+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:39:44.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:39:44.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-22T14:40:15.108+0000] {processor.py:157} INFO - Started process (PID=99738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:40:15.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:40:15.114+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:40:15.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:40:15.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:40:15.142+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:40:15.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:40:15.153+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:40:15.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:40:15.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T14:40:45.551+0000] {processor.py:157} INFO - Started process (PID=99763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:40:45.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:40:45.556+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:40:45.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:40:45.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:40:45.611+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:40:45.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:40:45.623+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:40:45.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:40:45.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-22T14:41:16.036+0000] {processor.py:157} INFO - Started process (PID=99788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:41:16.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:41:16.040+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:41:16.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:41:16.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:41:16.075+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:41:16.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:41:16.087+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:41:16.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:41:16.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-22T14:41:46.525+0000] {processor.py:157} INFO - Started process (PID=99813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:41:46.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:41:46.537+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:41:46.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:41:46.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:41:46.579+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:41:46.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:41:46.592+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:41:46.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:41:46.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-22T14:42:17.022+0000] {processor.py:157} INFO - Started process (PID=99838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:42:17.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:42:17.026+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:42:17.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:42:17.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:42:17.054+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:42:17.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:42:17.064+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:42:17.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:42:17.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T14:42:47.478+0000] {processor.py:157} INFO - Started process (PID=99863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:42:47.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:42:47.485+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:42:47.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:42:47.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:42:47.508+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:42:47.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:42:47.518+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:42:47.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:42:47.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T14:43:17.873+0000] {processor.py:157} INFO - Started process (PID=99888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:43:17.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:43:17.881+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:43:17.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:43:17.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:43:17.935+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:43:17.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:43:17.960+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:43:17.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:43:17.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-22T14:43:48.403+0000] {processor.py:157} INFO - Started process (PID=99913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:43:48.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:43:48.408+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:43:48.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:43:48.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:43:48.463+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:43:48.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:43:48.475+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:43:48.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:43:48.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-22T14:44:18.858+0000] {processor.py:157} INFO - Started process (PID=99938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:44:18.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:44:18.861+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:44:18.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:44:18.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:44:18.892+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:44:18.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:44:18.901+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:44:18.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:44:18.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T14:44:49.326+0000] {processor.py:157} INFO - Started process (PID=99963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:44:49.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:44:49.330+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:44:49.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:44:49.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:44:49.359+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:44:49.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:44:49.369+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:44:49.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:44:49.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T14:45:19.786+0000] {processor.py:157} INFO - Started process (PID=99988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:45:19.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:45:19.792+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:45:19.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:45:19.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:45:19.830+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:45:19.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:45:19.843+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:45:19.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:45:19.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-22T14:45:50.290+0000] {processor.py:157} INFO - Started process (PID=314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:45:50.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:45:50.298+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:45:50.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:45:50.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:45:50.353+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:45:50.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:45:50.366+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:45:50.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:45:50.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-22T14:46:20.775+0000] {processor.py:157} INFO - Started process (PID=339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:46:20.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:46:20.777+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:46:20.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:46:20.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:46:20.800+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:46:20.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:46:20.810+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:46:20.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:46:20.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-22T14:46:51.232+0000] {processor.py:157} INFO - Started process (PID=364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:46:51.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:46:51.238+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:46:51.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:46:51.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:46:51.285+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:46:51.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:46:51.300+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:46:51.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:46:51.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-22T14:47:21.734+0000] {processor.py:157} INFO - Started process (PID=389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:47:21.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:47:21.741+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:47:21.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:47:21.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:47:21.775+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:47:21.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:47:21.788+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:47:21.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:47:21.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-22T14:47:52.173+0000] {processor.py:157} INFO - Started process (PID=414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:47:52.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:47:52.177+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:47:52.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:47:52.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:47:52.207+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:47:52.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:47:52.218+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:47:52.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:47:52.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T14:48:22.637+0000] {processor.py:157} INFO - Started process (PID=439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:48:22.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:48:22.642+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:48:22.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:48:22.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:48:22.675+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:48:22.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:48:22.688+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:48:22.688+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:48:22.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-22T14:48:53.089+0000] {processor.py:157} INFO - Started process (PID=464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:48:53.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:48:53.093+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:48:53.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:48:53.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:48:53.125+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:48:53.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:48:53.139+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:48:53.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:48:53.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-22T14:49:23.573+0000] {processor.py:157} INFO - Started process (PID=489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:49:23.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:49:23.577+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:49:23.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:49:23.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:49:23.605+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:49:23.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:49:23.616+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:49:23.616+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:49:23.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T14:49:53.929+0000] {processor.py:157} INFO - Started process (PID=514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:49:53.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:49:53.933+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:49:53.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:49:53.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:49:53.966+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:49:53.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:49:53.977+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:49:53.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:49:53.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-22T14:50:24.413+0000] {processor.py:157} INFO - Started process (PID=539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:50:24.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:50:24.417+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:50:24.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:50:24.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:50:24.461+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:50:24.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:50:24.475+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:50:24.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:50:24.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-22T14:50:54.907+0000] {processor.py:157} INFO - Started process (PID=564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:50:54.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:50:54.913+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:50:54.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:50:54.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:50:54.951+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:50:54.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:50:54.966+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:50:54.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:50:54.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-22T14:51:25.360+0000] {processor.py:157} INFO - Started process (PID=589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:51:25.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:51:25.369+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:51:25.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:51:25.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:51:25.416+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:51:25.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:51:25.433+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:51:25.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:51:25.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-22T14:51:55.836+0000] {processor.py:157} INFO - Started process (PID=614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:51:55.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:51:55.840+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:51:55.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:51:55.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:51:55.872+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:51:55.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:51:55.885+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:51:55.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:51:55.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T14:52:26.261+0000] {processor.py:157} INFO - Started process (PID=639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:52:26.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:52:26.266+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:52:26.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:52:26.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:52:26.303+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:52:26.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:52:26.315+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:52:26.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:52:26.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-22T14:52:56.724+0000] {processor.py:157} INFO - Started process (PID=663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:52:56.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:52:56.729+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:52:56.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:52:56.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:52:56.755+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:52:56.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:52:56.768+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:52:56.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:52:56.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T14:53:27.146+0000] {processor.py:157} INFO - Started process (PID=689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:53:27.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:53:27.151+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:53:27.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:53:27.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:53:27.193+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:53:27.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:53:27.209+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:53:27.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:53:27.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-22T14:53:57.595+0000] {processor.py:157} INFO - Started process (PID=714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:53:57.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:53:57.599+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:53:57.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:53:57.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:53:57.634+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:53:57.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:53:57.664+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:53:57.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:53:57.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-22T14:54:28.059+0000] {processor.py:157} INFO - Started process (PID=739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:54:28.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:54:28.061+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:54:28.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:54:28.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:54:28.089+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:54:28.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:54:28.099+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:54:28.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:54:28.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-22T14:54:58.511+0000] {processor.py:157} INFO - Started process (PID=764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:54:58.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:54:58.517+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:54:58.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:54:58.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:54:58.556+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:54:58.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:54:58.569+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:54:58.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:54:58.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-22T14:55:28.999+0000] {processor.py:157} INFO - Started process (PID=789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:55:29.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:55:29.005+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:55:29.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:55:29.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:55:29.037+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:55:29.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:55:29.050+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:55:29.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:55:29.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-22T14:55:59.497+0000] {processor.py:157} INFO - Started process (PID=814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:55:59.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:55:59.502+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:55:59.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:55:59.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:55:59.531+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:55:59.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:55:59.542+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:55:59.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:55:59.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T14:56:29.943+0000] {processor.py:157} INFO - Started process (PID=839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:56:29.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:56:29.948+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:56:29.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:56:29.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:56:30.002+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:56:30.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:56:30.019+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:56:30.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:56:30.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-22T14:57:00.360+0000] {processor.py:157} INFO - Started process (PID=864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:57:00.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:57:00.366+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:57:00.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:57:00.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:57:00.401+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:57:00.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:57:00.420+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:57:00.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:57:00.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-22T14:57:30.804+0000] {processor.py:157} INFO - Started process (PID=889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:57:30.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:57:30.811+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:57:30.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:57:30.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:57:30.848+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:57:30.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:57:30.860+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:57:30.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:57:30.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T14:58:01.246+0000] {processor.py:157} INFO - Started process (PID=914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:58:01.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:58:01.252+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:58:01.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:58:01.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:58:01.303+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:58:01.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:58:01.316+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:58:01.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:58:01.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-22T14:58:31.814+0000] {processor.py:157} INFO - Started process (PID=939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:58:31.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:58:31.820+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:58:31.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:58:31.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:58:31.866+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:58:31.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:58:31.879+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:58:31.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:58:31.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-22T14:59:02.268+0000] {processor.py:157} INFO - Started process (PID=964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:59:02.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:59:02.272+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:59:02.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:59:02.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:59:02.316+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:59:02.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:59:02.337+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:59:02.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:59:02.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-22T14:59:32.683+0000] {processor.py:157} INFO - Started process (PID=989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:59:32.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T14:59:32.689+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:59:32.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:59:32.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T14:59:32.729+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:59:32.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T14:59:32.758+0000] {logging_mixin.py:151} INFO - [2024-07-22T14:59:32.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T14:59:32.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-22T15:00:03.161+0000] {processor.py:157} INFO - Started process (PID=1014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:00:03.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:00:03.168+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:00:03.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:00:03.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:00:03.224+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:00:03.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:00:03.240+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:00:03.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:00:03.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-22T15:00:33.693+0000] {processor.py:157} INFO - Started process (PID=1039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:00:33.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:00:33.701+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:00:33.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:00:33.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:00:33.746+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:00:33.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:00:33.760+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:00:33.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:00:33.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-22T15:01:04.181+0000] {processor.py:157} INFO - Started process (PID=1064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:01:04.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:01:04.184+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:01:04.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:01:04.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:01:04.214+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:01:04.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:01:04.224+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:01:04.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:01:04.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T15:01:34.548+0000] {processor.py:157} INFO - Started process (PID=1089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:01:34.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:01:34.550+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:01:34.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:01:34.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:01:34.577+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:01:34.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:01:34.588+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:01:34.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:01:34.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T15:02:05.002+0000] {processor.py:157} INFO - Started process (PID=1114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:02:05.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:02:05.007+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:02:05.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:02:05.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:02:05.036+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:02:05.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:02:05.046+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:02:05.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:02:05.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T15:02:35.445+0000] {processor.py:157} INFO - Started process (PID=1139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:02:35.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:02:35.448+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:02:35.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:02:35.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:02:35.485+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:02:35.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:02:35.500+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:02:35.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:02:35.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T15:03:05.901+0000] {processor.py:157} INFO - Started process (PID=1164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:03:05.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:03:05.906+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:03:05.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:03:05.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:03:05.938+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:03:05.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:03:05.952+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:03:05.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:03:05.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-22T15:03:36.408+0000] {processor.py:157} INFO - Started process (PID=1189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:03:36.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:03:36.419+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:03:36.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:03:36.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:03:36.477+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:03:36.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:03:36.493+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:03:36.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:03:36.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-22T15:04:06.882+0000] {processor.py:157} INFO - Started process (PID=1214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:04:06.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:04:06.887+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:04:06.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:04:06.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:04:06.916+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:04:06.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:04:06.927+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:04:06.927+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:04:06.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T15:04:37.396+0000] {processor.py:157} INFO - Started process (PID=1239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:04:37.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:04:37.402+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:04:37.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:04:37.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:04:37.458+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:04:37.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:04:37.474+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:04:37.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:04:37.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-22T15:05:07.975+0000] {processor.py:157} INFO - Started process (PID=1264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:05:07.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:05:07.982+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:05:07.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:05:07.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:05:08.021+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:05:08.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:05:08.034+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:05:08.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:05:08.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-22T15:05:38.416+0000] {processor.py:157} INFO - Started process (PID=1289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:05:38.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:05:38.420+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:05:38.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:05:38.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:05:38.447+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:05:38.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:05:38.459+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:05:38.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:05:38.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T15:06:08.878+0000] {processor.py:157} INFO - Started process (PID=1314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:06:08.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:06:08.881+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:06:08.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:06:08.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:06:08.909+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:06:08.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:06:08.921+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:06:08.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:06:08.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T15:06:39.268+0000] {processor.py:157} INFO - Started process (PID=1338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:06:39.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:06:39.272+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:06:39.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:06:39.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:06:39.299+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:06:39.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:06:39.310+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:06:39.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:06:39.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T15:07:09.676+0000] {processor.py:157} INFO - Started process (PID=1364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:07:09.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:07:09.680+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:07:09.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:07:09.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:07:09.731+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:07:09.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:07:09.748+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:07:09.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:07:09.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-22T15:07:40.162+0000] {processor.py:157} INFO - Started process (PID=1389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:07:40.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:07:40.167+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:07:40.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:07:40.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:07:40.199+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:07:40.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:07:40.213+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:07:40.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:07:40.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-22T15:08:10.616+0000] {processor.py:157} INFO - Started process (PID=1414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:08:10.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:08:10.621+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:08:10.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:08:10.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:08:10.651+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:08:10.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:08:10.662+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:08:10.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:08:10.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T15:08:41.054+0000] {processor.py:157} INFO - Started process (PID=1439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:08:41.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:08:41.060+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:08:41.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:08:41.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:08:41.090+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:08:41.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:08:41.102+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:08:41.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:08:41.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T15:09:11.473+0000] {processor.py:157} INFO - Started process (PID=1463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:09:11.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:09:11.491+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:09:11.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:09:11.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:09:11.533+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:09:11.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:09:11.550+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:09:11.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:09:11.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-22T15:09:41.950+0000] {processor.py:157} INFO - Started process (PID=1489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:09:41.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:09:41.954+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:09:41.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:09:41.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:09:41.983+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:09:41.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:09:41.993+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:09:41.993+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:09:42.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T15:10:12.430+0000] {processor.py:157} INFO - Started process (PID=1513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:10:12.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:10:12.437+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:10:12.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:10:12.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:10:12.481+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:10:12.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:10:12.493+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:10:12.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:10:12.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-22T15:10:42.918+0000] {processor.py:157} INFO - Started process (PID=1539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:10:42.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:10:42.923+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:10:42.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:10:42.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:10:42.955+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:10:42.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:10:42.965+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:10:42.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:10:42.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T15:11:13.357+0000] {processor.py:157} INFO - Started process (PID=1564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:11:13.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:11:13.363+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:11:13.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:11:13.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:11:13.423+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:11:13.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:11:13.437+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:11:13.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:11:13.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-22T15:11:43.806+0000] {processor.py:157} INFO - Started process (PID=1589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:11:43.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:11:43.811+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:11:43.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:11:43.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:11:43.843+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:11:43.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:11:43.856+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:11:43.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:11:43.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-22T15:12:14.214+0000] {processor.py:157} INFO - Started process (PID=1614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:12:14.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:12:14.221+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:12:14.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:12:14.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:12:14.256+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:12:14.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:12:14.267+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:12:14.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:12:14.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-22T15:12:44.672+0000] {processor.py:157} INFO - Started process (PID=1639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:12:44.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:12:44.675+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:12:44.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:12:44.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:12:44.710+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:12:44.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:12:44.724+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:12:44.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:12:44.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-22T15:13:15.119+0000] {processor.py:157} INFO - Started process (PID=1664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:13:15.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:13:15.123+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:13:15.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:13:15.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:13:15.156+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:13:15.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:13:15.165+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:13:15.165+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:13:15.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T15:13:45.582+0000] {processor.py:157} INFO - Started process (PID=1689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:13:45.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:13:45.586+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:13:45.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:13:45.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:13:45.622+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:13:45.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:13:45.634+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:13:45.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:13:45.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-22T15:14:16.009+0000] {processor.py:157} INFO - Started process (PID=1714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:14:16.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:14:16.012+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:14:16.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:14:16.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:14:16.050+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:14:16.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:14:16.071+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:14:16.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:14:16.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-22T15:14:46.510+0000] {processor.py:157} INFO - Started process (PID=1739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:14:46.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:14:46.513+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:14:46.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:14:46.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:14:46.547+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:14:46.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:14:46.558+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:14:46.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:14:46.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T15:15:16.939+0000] {processor.py:157} INFO - Started process (PID=1764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:15:16.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:15:16.943+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:15:16.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:15:16.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:15:16.978+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:15:16.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:15:16.991+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:15:16.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:15:17.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-22T15:15:47.353+0000] {processor.py:157} INFO - Started process (PID=1789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:15:47.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:15:47.357+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:15:47.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:15:47.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:15:47.388+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:15:47.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:15:47.400+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:15:47.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:15:47.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T15:16:17.811+0000] {processor.py:157} INFO - Started process (PID=1814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:16:17.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:16:17.826+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:16:17.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:16:17.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:16:17.865+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:16:17.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:16:17.876+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:16:17.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:16:17.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-22T15:16:48.263+0000] {processor.py:157} INFO - Started process (PID=1839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:16:48.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:16:48.266+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:16:48.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:16:48.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:16:48.301+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:16:48.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:16:48.313+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:16:48.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:16:48.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-22T15:17:18.725+0000] {processor.py:157} INFO - Started process (PID=1864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:17:18.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:17:18.729+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:17:18.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:17:18.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:17:18.759+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:17:18.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:17:18.770+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:17:18.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:17:18.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T15:17:49.130+0000] {processor.py:157} INFO - Started process (PID=1889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:17:49.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:17:49.134+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:17:49.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:17:49.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:17:49.169+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:17:49.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:17:49.180+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:17:49.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:17:49.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-22T15:18:19.529+0000] {processor.py:157} INFO - Started process (PID=1914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:18:19.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:18:19.534+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:18:19.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:18:19.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:18:19.562+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:18:19.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:18:19.571+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:18:19.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:18:19.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T15:18:49.965+0000] {processor.py:157} INFO - Started process (PID=1939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:18:49.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:18:49.969+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:18:49.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:18:49.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:18:50.003+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:18:50.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:18:50.016+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:18:50.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:18:50.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-22T15:19:20.433+0000] {processor.py:157} INFO - Started process (PID=1964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:19:20.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:19:20.438+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:19:20.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:19:20.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:19:20.466+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:19:20.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:19:20.479+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:19:20.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:19:20.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T15:19:50.816+0000] {processor.py:157} INFO - Started process (PID=1989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:19:50.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:19:50.824+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:19:50.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:19:50.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:19:50.853+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:19:50.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:19:50.864+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:19:50.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:19:50.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T15:20:21.269+0000] {processor.py:157} INFO - Started process (PID=2014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:20:21.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:20:21.271+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:20:21.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:20:21.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:20:21.300+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:20:21.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:20:21.310+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:20:21.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:20:21.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T15:20:51.707+0000] {processor.py:157} INFO - Started process (PID=2039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:20:51.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:20:51.709+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:20:51.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:20:51.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:20:51.745+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:20:51.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:20:51.756+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:20:51.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:20:51.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T15:21:22.149+0000] {processor.py:157} INFO - Started process (PID=2064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:21:22.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:21:22.152+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:21:22.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:21:22.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:21:22.178+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:21:22.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:21:22.190+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:21:22.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:21:22.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T15:21:52.620+0000] {processor.py:157} INFO - Started process (PID=2089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:21:52.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:21:52.624+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:21:52.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:21:52.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:21:52.653+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:21:52.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:21:52.665+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:21:52.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:21:52.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T15:22:22.973+0000] {processor.py:157} INFO - Started process (PID=2114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:22:22.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:22:22.976+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:22:22.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:22:22.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:22:23.006+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:22:23.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:22:23.017+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:22:23.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:22:23.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T15:22:53.388+0000] {processor.py:157} INFO - Started process (PID=2139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:22:53.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:22:53.393+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:22:53.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:22:53.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:22:53.420+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:22:53.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:22:53.433+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:22:53.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:22:53.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T15:23:23.814+0000] {processor.py:157} INFO - Started process (PID=2164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:23:23.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:23:23.821+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:23:23.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:23:23.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:23:23.876+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:23:23.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:23:23.889+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:23:23.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:23:23.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-22T15:23:54.264+0000] {processor.py:157} INFO - Started process (PID=2189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:23:54.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:23:54.268+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:23:54.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:23:54.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:23:54.295+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:23:54.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:23:54.306+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:23:54.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:23:54.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T15:24:24.741+0000] {processor.py:157} INFO - Started process (PID=2214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:24:24.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:24:24.751+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:24:24.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:24:24.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:24:24.805+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:24:24.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:24:24.821+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:24:24.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:24:24.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-22T15:24:55.261+0000] {processor.py:157} INFO - Started process (PID=2239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:24:55.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:24:55.271+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:24:55.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:24:55.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:24:55.376+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:24:55.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:24:55.396+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:24:55.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:24:55.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-07-22T15:25:25.856+0000] {processor.py:157} INFO - Started process (PID=2264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:25:25.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:25:25.864+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:25:25.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:25:25.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:25:25.906+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:25:25.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:25:25.923+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:25:25.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:25:25.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-22T15:25:56.306+0000] {processor.py:157} INFO - Started process (PID=2289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:25:56.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:25:56.312+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:25:56.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:25:56.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:25:56.350+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:25:56.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:25:56.364+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:25:56.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:25:56.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-22T15:26:26.774+0000] {processor.py:157} INFO - Started process (PID=2313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:26:26.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:26:26.781+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:26:26.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:26:26.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:26:26.806+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:26:26.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:26:26.816+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:26:26.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:26:26.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T15:26:57.150+0000] {processor.py:157} INFO - Started process (PID=2338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:26:57.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:26:57.156+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:26:57.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:26:57.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:26:57.202+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:26:57.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:26:57.222+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:26:57.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:26:57.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-22T15:27:27.622+0000] {processor.py:157} INFO - Started process (PID=2364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:27:27.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:27:27.625+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:27:27.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:27:27.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:27:27.656+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:27:27.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:27:27.666+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:27:27.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:27:27.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T15:27:58.089+0000] {processor.py:157} INFO - Started process (PID=2388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:27:58.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:27:58.097+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:27:58.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:27:58.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:27:58.148+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:27:58.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:27:58.171+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:27:58.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:27:58.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-22T15:28:28.615+0000] {processor.py:157} INFO - Started process (PID=2414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:28:28.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:28:28.620+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:28:28.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:28:28.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:28:28.660+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:28:28.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:28:28.677+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:28:28.677+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:28:28.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-22T15:28:59.081+0000] {processor.py:157} INFO - Started process (PID=2439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:28:59.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:28:59.085+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:28:59.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:28:59.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:28:59.112+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:28:59.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:28:59.122+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:28:59.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:28:59.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T15:29:29.554+0000] {processor.py:157} INFO - Started process (PID=2464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:29:29.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:29:29.560+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:29:29.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:29:29.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:29:29.595+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:29:29.595+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:29:29.607+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:29:29.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:29:29.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T15:30:00.029+0000] {processor.py:157} INFO - Started process (PID=2489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:30:00.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:30:00.039+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:30:00.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:30:00.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:30:00.067+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:30:00.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:30:00.077+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:30:00.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:30:00.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T15:30:30.484+0000] {processor.py:157} INFO - Started process (PID=2514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:30:30.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:30:30.505+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:30:30.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:30:30.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:30:30.556+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:30:30.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:30:30.571+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:30:30.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:30:30.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-22T15:31:01.042+0000] {processor.py:157} INFO - Started process (PID=2539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:31:01.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:31:01.048+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:31:01.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:31:01.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:31:01.088+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:31:01.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:31:01.102+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:31:01.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:31:01.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-22T15:31:31.490+0000] {processor.py:157} INFO - Started process (PID=2564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:31:31.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:31:31.494+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:31:31.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:31:31.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:31:31.525+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:31:31.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:31:31.536+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:31:31.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:31:31.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T15:32:01.964+0000] {processor.py:157} INFO - Started process (PID=2589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:32:01.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:32:01.971+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:32:01.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:32:01.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:32:02.012+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:32:02.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:32:02.027+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:32:02.027+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:32:02.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-22T15:32:32.386+0000] {processor.py:157} INFO - Started process (PID=2614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:32:32.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:32:32.391+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:32:32.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:32:32.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:32:32.421+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:32:32.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:32:32.433+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:32:32.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:32:32.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T15:33:02.855+0000] {processor.py:157} INFO - Started process (PID=2639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:33:02.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:33:02.859+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:33:02.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:33:02.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:33:02.892+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:33:02.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:33:02.902+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:33:02.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:33:02.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T15:33:33.228+0000] {processor.py:157} INFO - Started process (PID=2664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:33:33.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:33:33.232+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:33:33.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:33:33.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:33:33.271+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:33:33.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:33:33.284+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:33:33.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:33:33.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T15:34:03.691+0000] {processor.py:157} INFO - Started process (PID=2689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:34:03.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:34:03.693+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:34:03.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:34:03.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:34:03.725+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:34:03.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:34:03.738+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:34:03.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:34:03.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-22T15:34:34.205+0000] {processor.py:157} INFO - Started process (PID=2712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:34:34.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:34:34.217+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:34:34.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:34:34.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:34:34.266+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:34:34.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:34:34.289+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:34:34.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:34:34.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-22T15:35:04.743+0000] {processor.py:157} INFO - Started process (PID=2739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:35:04.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:35:04.748+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:35:04.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:35:04.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:35:04.815+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:35:04.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:35:04.829+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:35:04.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:35:04.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-22T15:35:35.206+0000] {processor.py:157} INFO - Started process (PID=2764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:35:35.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:35:35.209+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:35:35.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:35:35.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:35:35.237+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:35:35.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:35:35.247+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:35:35.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:35:35.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T15:36:05.675+0000] {processor.py:157} INFO - Started process (PID=2789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:36:05.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:36:05.681+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:36:05.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:36:05.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:36:05.708+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:36:05.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:36:05.719+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:36:05.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:36:05.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T15:36:36.155+0000] {processor.py:157} INFO - Started process (PID=2814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:36:36.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:36:36.161+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:36:36.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:36:36.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:36:36.197+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:36:36.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:36:36.213+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:36:36.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:36:36.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-22T15:37:06.542+0000] {processor.py:157} INFO - Started process (PID=2839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:37:06.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:37:06.545+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:37:06.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:37:06.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:37:06.572+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:37:06.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:37:06.581+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:37:06.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:37:06.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T15:37:36.950+0000] {processor.py:157} INFO - Started process (PID=2864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:37:36.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:37:36.953+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:37:36.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:37:36.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:37:36.984+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:37:36.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:37:36.994+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:37:36.994+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:37:37.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T15:38:07.398+0000] {processor.py:157} INFO - Started process (PID=2889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:38:07.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:38:07.401+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:38:07.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:38:07.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:38:07.431+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:38:07.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:38:07.442+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:38:07.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:38:07.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T15:38:37.884+0000] {processor.py:157} INFO - Started process (PID=2914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:38:37.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:38:37.890+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:38:37.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:38:37.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:38:37.929+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:38:37.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:38:37.941+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:38:37.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:38:37.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-22T15:39:08.348+0000] {processor.py:157} INFO - Started process (PID=2939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:39:08.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:39:08.352+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:39:08.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:39:08.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:39:08.379+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:39:08.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:39:08.390+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:39:08.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:39:08.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T15:39:38.772+0000] {processor.py:157} INFO - Started process (PID=2964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:39:38.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:39:38.775+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:39:38.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:39:38.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:39:38.807+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:39:38.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:39:38.818+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:39:38.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:39:38.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T15:40:09.270+0000] {processor.py:157} INFO - Started process (PID=2989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:40:09.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:40:09.278+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:40:09.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:40:09.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:40:09.317+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:40:09.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:40:09.336+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:40:09.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:40:09.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-22T15:40:39.694+0000] {processor.py:157} INFO - Started process (PID=3014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:40:39.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:40:39.698+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:40:39.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:40:39.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:40:39.728+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:40:39.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:40:39.740+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:40:39.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:40:39.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T15:41:10.226+0000] {processor.py:157} INFO - Started process (PID=3039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:41:10.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:41:10.229+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:41:10.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:41:10.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:41:10.260+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:41:10.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:41:10.270+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:41:10.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:41:10.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T15:41:40.672+0000] {processor.py:157} INFO - Started process (PID=3063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:41:40.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:41:40.680+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:41:40.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:41:40.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:41:40.723+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:41:40.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:41:40.738+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:41:40.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:41:40.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-22T15:42:11.169+0000] {processor.py:157} INFO - Started process (PID=3089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:42:11.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:42:11.171+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:42:11.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:42:11.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:42:11.205+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:42:11.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:42:11.218+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:42:11.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:42:11.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-22T15:42:41.667+0000] {processor.py:157} INFO - Started process (PID=3114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:42:41.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:42:41.680+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:42:41.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:42:41.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:42:41.746+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:42:41.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:42:41.761+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:42:41.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:42:41.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-22T15:43:12.215+0000] {processor.py:157} INFO - Started process (PID=3139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:43:12.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:43:12.222+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:43:12.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:43:12.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:43:12.268+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:43:12.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:43:12.290+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:43:12.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:43:12.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-22T15:43:42.661+0000] {processor.py:157} INFO - Started process (PID=3164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:43:42.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:43:42.665+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:43:42.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:43:42.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:43:42.691+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:43:42.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:43:42.701+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:43:42.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:43:42.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T15:44:13.124+0000] {processor.py:157} INFO - Started process (PID=3189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:44:13.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:44:13.129+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:44:13.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:44:13.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:44:13.167+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:44:13.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:44:13.180+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:44:13.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:44:13.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-22T15:44:43.542+0000] {processor.py:157} INFO - Started process (PID=3214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:44:43.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:44:43.545+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:44:43.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:44:43.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:44:43.571+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:44:43.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:44:43.581+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:44:43.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:44:43.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-22T15:45:13.928+0000] {processor.py:157} INFO - Started process (PID=3239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:45:13.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:45:13.935+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:45:13.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:45:13.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:45:13.974+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:45:13.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:45:13.990+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:45:13.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:45:14.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-22T15:45:44.401+0000] {processor.py:157} INFO - Started process (PID=3264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:45:44.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:45:44.405+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:45:44.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:45:44.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:45:44.434+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:45:44.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:45:44.443+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:45:44.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:45:44.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T15:46:14.821+0000] {processor.py:157} INFO - Started process (PID=3289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:46:14.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:46:14.825+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:46:14.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:46:14.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:46:14.858+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:46:14.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:46:14.869+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:46:14.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:46:14.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T15:46:45.292+0000] {processor.py:157} INFO - Started process (PID=3313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:46:45.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:46:45.317+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:46:45.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:46:45.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:46:45.363+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:46:45.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:46:45.376+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:46:45.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:46:45.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-22T15:47:15.791+0000] {processor.py:157} INFO - Started process (PID=3339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:47:15.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:47:15.796+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:47:15.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:47:15.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:47:15.833+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:47:15.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:47:15.844+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:47:15.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:47:15.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-22T15:47:46.224+0000] {processor.py:157} INFO - Started process (PID=3364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:47:46.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:47:46.227+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:47:46.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:47:46.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:47:46.267+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:47:46.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:47:46.282+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:47:46.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:47:46.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-22T15:48:16.743+0000] {processor.py:157} INFO - Started process (PID=3389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:48:16.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:48:16.752+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:48:16.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:48:16.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:48:16.785+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:48:16.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:48:16.796+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:48:16.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:48:16.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-22T15:48:47.179+0000] {processor.py:157} INFO - Started process (PID=3414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:48:47.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:48:47.184+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:48:47.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:48:47.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:48:47.223+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:48:47.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:48:47.238+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:48:47.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:48:47.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T15:49:17.614+0000] {processor.py:157} INFO - Started process (PID=3439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:49:17.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:49:17.620+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:49:17.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:49:17.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:49:17.654+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:49:17.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:49:17.664+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:49:17.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:49:17.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-22T15:49:48.016+0000] {processor.py:157} INFO - Started process (PID=3464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:49:48.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:49:48.019+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:49:48.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:49:48.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:49:48.059+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:49:48.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:49:48.072+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:49:48.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:49:48.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T15:50:18.507+0000] {processor.py:157} INFO - Started process (PID=3489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:50:18.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:50:18.529+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:50:18.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:50:18.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:50:18.576+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:50:18.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:50:18.590+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:50:18.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:50:18.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-22T15:50:48.977+0000] {processor.py:157} INFO - Started process (PID=3514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:50:48.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:50:48.982+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:50:48.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:50:48.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:50:49.015+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:50:49.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:50:49.029+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:50:49.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:50:49.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-22T15:51:19.661+0000] {processor.py:157} INFO - Started process (PID=3539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:51:19.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:51:19.666+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:51:19.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:51:19.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:51:19.727+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:51:19.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:51:19.740+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:51:19.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:51:19.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-22T15:51:49.934+0000] {processor.py:157} INFO - Started process (PID=3564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:51:49.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:51:49.937+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:51:49.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:51:49.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:51:49.965+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:51:49.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:51:49.977+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:51:49.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:51:49.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T15:52:20.605+0000] {processor.py:157} INFO - Started process (PID=3589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:52:20.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:52:20.612+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:52:20.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:52:20.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:52:20.679+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:52:20.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:52:20.694+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:52:20.694+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:52:20.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-22T15:52:52.398+0000] {processor.py:157} INFO - Started process (PID=3614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:52:52.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:52:52.401+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:52:52.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:52:52.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:52:52.426+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:52:52.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:52:52.441+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:52:52.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:52:52.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T15:56:31.484+0000] {processor.py:157} INFO - Started process (PID=3641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:56:31.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:56:31.497+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:56:31.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:56:31.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:56:31.591+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:56:31.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:56:31.631+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:56:31.631+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:56:31.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.177 seconds
[2024-07-22T15:57:02.066+0000] {processor.py:157} INFO - Started process (PID=3666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:57:02.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:57:02.073+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:57:02.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:57:02.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:57:02.133+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:57:02.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:57:02.147+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:57:02.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:57:02.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-22T15:57:32.535+0000] {processor.py:157} INFO - Started process (PID=3691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:57:32.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:57:32.538+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:57:32.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:57:32.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:57:32.561+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:57:32.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:57:32.570+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:57:32.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:57:32.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-22T15:58:02.944+0000] {processor.py:157} INFO - Started process (PID=3716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:58:02.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:58:02.947+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:58:02.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:58:02.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:58:02.976+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:58:02.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:58:02.988+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:58:02.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:58:02.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T15:58:33.402+0000] {processor.py:157} INFO - Started process (PID=3741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:58:33.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:58:33.405+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:58:33.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:58:33.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:58:33.435+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:58:33.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:58:33.447+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:58:33.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:58:33.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T15:59:03.763+0000] {processor.py:157} INFO - Started process (PID=3766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:59:03.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:59:03.769+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:59:03.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:59:03.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:59:03.808+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:59:03.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:59:03.822+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:59:03.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:59:03.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-22T15:59:34.270+0000] {processor.py:157} INFO - Started process (PID=3789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:59:34.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T15:59:34.274+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:59:34.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:59:34.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T15:59:34.301+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:59:34.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T15:59:34.312+0000] {logging_mixin.py:151} INFO - [2024-07-22T15:59:34.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T15:59:34.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T16:00:04.760+0000] {processor.py:157} INFO - Started process (PID=3816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:00:04.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:00:04.768+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:00:04.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:00:04.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:00:04.834+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:00:04.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:00:04.849+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:00:04.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:00:04.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-22T16:00:35.465+0000] {processor.py:157} INFO - Started process (PID=3841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:00:35.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:00:35.473+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:00:35.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:00:35.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:00:35.526+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:00:35.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:00:35.540+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:00:35.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:00:35.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-22T16:01:06.044+0000] {processor.py:157} INFO - Started process (PID=3865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:01:06.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:01:06.051+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:01:06.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:01:06.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:01:06.102+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:01:06.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:01:06.115+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:01:06.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:01:06.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-22T16:01:36.567+0000] {processor.py:157} INFO - Started process (PID=3891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:01:36.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:01:36.574+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:01:36.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:01:36.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:01:36.629+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:01:36.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:01:36.649+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:01:36.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:01:36.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-22T16:02:07.090+0000] {processor.py:157} INFO - Started process (PID=3916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:02:07.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:02:07.093+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:02:07.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:02:07.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:02:07.122+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:02:07.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:02:07.133+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:02:07.133+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:02:07.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T16:02:37.574+0000] {processor.py:157} INFO - Started process (PID=3941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:02:37.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:02:37.579+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:02:37.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:02:37.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:02:37.647+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:02:37.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:02:37.661+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:02:37.660+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:02:37.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-22T16:03:08.134+0000] {processor.py:157} INFO - Started process (PID=3966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:03:08.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:03:08.137+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:03:08.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:03:08.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:03:08.167+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:03:08.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:03:08.177+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:03:08.177+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:03:08.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T16:03:38.615+0000] {processor.py:157} INFO - Started process (PID=3991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:03:38.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:03:38.622+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:03:38.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:03:38.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:03:38.659+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:03:38.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:03:38.671+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:03:38.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:03:38.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T16:04:09.072+0000] {processor.py:157} INFO - Started process (PID=4016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:04:09.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:04:09.077+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:04:09.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:04:09.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:04:09.106+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:04:09.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:04:09.115+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:04:09.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:04:09.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T16:04:39.482+0000] {processor.py:157} INFO - Started process (PID=4041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:04:39.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:04:39.488+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:04:39.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:04:39.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:04:39.517+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:04:39.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:04:39.528+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:04:39.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:04:39.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T16:05:09.888+0000] {processor.py:157} INFO - Started process (PID=4066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:05:09.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:05:09.892+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:05:09.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:05:09.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:05:09.927+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:05:09.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:05:09.941+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:05:09.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:05:09.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-22T16:05:40.342+0000] {processor.py:157} INFO - Started process (PID=4091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:05:40.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:05:40.345+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:05:40.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:05:40.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:05:40.376+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:05:40.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:05:40.387+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:05:40.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:05:40.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T16:06:10.801+0000] {processor.py:157} INFO - Started process (PID=4116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:06:10.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:06:10.805+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:06:10.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:06:10.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:06:10.830+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:06:10.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:06:10.839+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:06:10.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:06:10.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-22T16:06:41.276+0000] {processor.py:157} INFO - Started process (PID=4141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:06:41.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:06:41.280+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:06:41.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:06:41.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:06:41.322+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:06:41.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:06:41.335+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:06:41.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:06:41.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-22T16:07:11.748+0000] {processor.py:157} INFO - Started process (PID=4166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:07:11.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:07:11.751+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:07:11.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:07:11.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:07:11.776+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:07:11.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:07:11.786+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:07:11.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:07:11.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-22T16:07:42.222+0000] {processor.py:157} INFO - Started process (PID=4191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:07:42.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:07:42.227+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:07:42.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:07:42.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:07:42.256+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:07:42.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:07:42.268+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:07:42.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:07:42.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T16:08:12.663+0000] {processor.py:157} INFO - Started process (PID=4216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:08:12.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:08:12.668+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:08:12.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:08:12.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:08:12.698+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:08:12.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:08:12.709+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:08:12.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:08:12.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T16:08:43.100+0000] {processor.py:157} INFO - Started process (PID=4241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:08:43.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:08:43.102+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:08:43.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:08:43.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:08:43.134+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:08:43.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:08:43.144+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:08:43.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:08:43.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T16:09:13.526+0000] {processor.py:157} INFO - Started process (PID=4266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:09:13.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:09:13.529+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:09:13.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:09:13.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:09:13.560+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:09:13.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:09:13.573+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:09:13.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:09:13.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T16:09:43.931+0000] {processor.py:157} INFO - Started process (PID=4291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:09:43.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:09:43.935+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:09:43.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:09:43.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:09:43.961+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:09:43.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:09:43.970+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:09:43.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:09:43.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T16:10:14.355+0000] {processor.py:157} INFO - Started process (PID=4316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:10:14.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:10:14.357+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:10:14.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:10:14.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:10:14.385+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:10:14.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:10:14.395+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:10:14.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:10:14.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T16:10:44.779+0000] {processor.py:157} INFO - Started process (PID=4341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:10:44.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:10:44.784+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:10:44.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:10:44.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:10:44.823+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:10:44.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:10:44.835+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:10:44.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:10:44.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-22T16:11:15.279+0000] {processor.py:157} INFO - Started process (PID=4366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:11:15.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:11:15.283+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:11:15.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:11:15.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:11:15.310+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:11:15.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:11:15.320+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:11:15.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:11:15.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T16:11:45.769+0000] {processor.py:157} INFO - Started process (PID=4391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:11:45.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:11:45.775+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:11:45.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:11:45.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:11:45.810+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:11:45.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:11:45.820+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:11:45.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:11:45.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-22T16:12:16.190+0000] {processor.py:157} INFO - Started process (PID=4416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:12:16.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:12:16.193+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:12:16.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:12:16.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:12:16.222+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:12:16.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:12:16.232+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:12:16.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:12:16.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T16:12:46.685+0000] {processor.py:157} INFO - Started process (PID=4441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:12:46.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:12:46.688+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:12:46.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:12:46.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:12:46.717+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:12:46.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:12:46.726+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:12:46.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:12:46.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T16:13:17.082+0000] {processor.py:157} INFO - Started process (PID=4466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:13:17.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:13:17.086+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:13:17.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:13:17.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:13:17.113+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:13:17.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:13:17.123+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:13:17.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:13:17.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T16:13:47.558+0000] {processor.py:157} INFO - Started process (PID=4491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:13:47.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:13:47.561+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:13:47.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:13:47.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:13:47.587+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:13:47.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:13:47.600+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:13:47.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:13:47.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T16:14:18.071+0000] {processor.py:157} INFO - Started process (PID=4516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:14:18.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:14:18.074+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:14:18.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:14:18.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:14:18.096+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:14:18.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:14:18.108+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:14:18.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:14:18.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-22T16:14:48.511+0000] {processor.py:157} INFO - Started process (PID=4541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:14:48.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:14:48.513+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:14:48.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:14:48.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:14:48.538+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:14:48.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:14:48.547+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:14:48.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:14:48.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-22T16:15:19.041+0000] {processor.py:157} INFO - Started process (PID=4566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:15:19.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:15:19.047+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:15:19.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:15:19.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:15:19.084+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:15:19.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:15:19.097+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:15:19.097+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:15:19.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-22T16:15:49.545+0000] {processor.py:157} INFO - Started process (PID=4591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:15:49.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:15:49.549+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:15:49.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:15:49.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:15:49.576+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:15:49.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:15:49.586+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:15:49.586+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:15:49.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T16:16:20.002+0000] {processor.py:157} INFO - Started process (PID=4616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:16:20.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:16:20.007+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:16:20.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:16:20.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:16:20.037+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:16:20.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:16:20.050+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:16:20.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:16:20.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-22T16:16:50.395+0000] {processor.py:157} INFO - Started process (PID=4641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:16:50.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:16:50.398+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:16:50.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:16:50.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:16:50.427+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:16:50.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:16:50.437+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:16:50.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:16:50.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T16:17:20.911+0000] {processor.py:157} INFO - Started process (PID=4666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:17:20.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:17:20.914+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:17:20.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:17:20.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:17:20.945+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:17:20.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:17:20.955+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:17:20.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:17:20.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T16:17:51.322+0000] {processor.py:157} INFO - Started process (PID=4691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:17:51.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:17:51.326+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:17:51.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:17:51.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:17:51.354+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:17:51.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:17:51.367+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:17:51.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:17:51.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T16:18:21.740+0000] {processor.py:157} INFO - Started process (PID=4716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:18:21.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:18:21.745+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:18:21.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:18:21.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:18:21.771+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:18:21.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:18:21.780+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:18:21.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:18:21.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T16:18:52.167+0000] {processor.py:157} INFO - Started process (PID=4741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:18:52.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:18:52.171+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:18:52.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:18:52.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:18:52.199+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:18:52.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:18:52.209+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:18:52.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:18:52.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T16:19:22.583+0000] {processor.py:157} INFO - Started process (PID=4766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:19:22.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:19:22.589+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:19:22.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:19:22.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:19:22.620+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:19:22.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:19:22.630+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:19:22.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:19:22.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T16:19:53.066+0000] {processor.py:157} INFO - Started process (PID=4791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:19:53.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:19:53.070+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:19:53.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:19:53.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:19:53.104+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:19:53.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:19:53.117+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:19:53.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:19:53.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-22T16:20:23.480+0000] {processor.py:157} INFO - Started process (PID=4816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:20:23.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:20:23.484+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:20:23.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:20:23.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:20:23.511+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:20:23.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:20:23.523+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:20:23.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:20:23.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T16:20:53.963+0000] {processor.py:157} INFO - Started process (PID=4841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:20:53.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:20:53.966+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:20:53.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:20:53.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:20:53.994+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:20:53.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:20:54.003+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:20:54.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:20:54.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T16:21:24.395+0000] {processor.py:157} INFO - Started process (PID=4866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:21:24.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:21:24.399+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:21:24.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:21:24.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:21:24.424+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:21:24.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:21:24.433+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:21:24.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:21:24.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-22T16:21:54.846+0000] {processor.py:157} INFO - Started process (PID=4891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:21:54.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:21:54.852+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:21:54.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:21:54.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:21:54.882+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:21:54.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:21:54.893+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:21:54.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:21:54.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T16:22:25.267+0000] {processor.py:157} INFO - Started process (PID=4916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:22:25.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:22:25.274+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:22:25.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:22:25.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:22:25.309+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:22:25.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:22:25.321+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:22:25.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:22:25.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-22T16:22:55.658+0000] {processor.py:157} INFO - Started process (PID=4941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:22:55.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:22:55.661+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:22:55.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:22:55.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:22:55.690+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:22:55.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:22:55.700+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:22:55.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:22:55.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T16:23:26.069+0000] {processor.py:157} INFO - Started process (PID=4966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:23:26.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:23:26.072+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:23:26.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:23:26.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:23:26.103+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:23:26.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:23:26.113+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:23:26.113+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:23:26.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T16:23:56.511+0000] {processor.py:157} INFO - Started process (PID=4991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:23:56.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:23:56.515+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:23:56.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:23:56.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:23:56.547+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:23:56.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:23:56.558+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:23:56.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:23:56.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T16:24:26.954+0000] {processor.py:157} INFO - Started process (PID=5016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:24:26.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:24:26.958+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:24:26.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:24:26.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:24:26.987+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:24:26.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:24:26.997+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:24:26.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:24:27.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T16:24:57.418+0000] {processor.py:157} INFO - Started process (PID=5041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:24:57.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:24:57.420+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:24:57.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:24:57.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:24:57.449+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:24:57.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:24:57.459+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:24:57.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:24:57.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T16:25:27.833+0000] {processor.py:157} INFO - Started process (PID=5066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:25:27.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:25:27.836+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:25:27.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:25:27.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:25:27.874+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:25:27.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:25:27.888+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:25:27.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:25:27.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T16:25:58.340+0000] {processor.py:157} INFO - Started process (PID=5091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:25:58.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:25:58.342+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:25:58.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:25:58.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:25:58.371+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:25:58.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:25:58.382+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:25:58.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:25:58.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T16:26:28.794+0000] {processor.py:157} INFO - Started process (PID=5116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:26:28.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:26:28.801+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:26:28.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:26:28.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:26:28.838+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:26:28.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:26:28.850+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:26:28.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:26:28.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T16:26:59.269+0000] {processor.py:157} INFO - Started process (PID=5141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:26:59.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:26:59.272+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:26:59.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:26:59.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:26:59.302+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:26:59.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:26:59.313+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:26:59.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:26:59.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T16:27:29.709+0000] {processor.py:157} INFO - Started process (PID=5166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:27:29.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:27:29.713+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:27:29.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:27:29.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:27:29.738+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:27:29.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:27:29.748+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:27:29.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:27:29.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T16:28:00.093+0000] {processor.py:157} INFO - Started process (PID=5191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:28:00.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:28:00.096+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:28:00.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:28:00.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:28:00.126+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:28:00.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:28:00.138+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:28:00.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:28:00.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T16:28:30.524+0000] {processor.py:157} INFO - Started process (PID=5216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:28:30.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:28:30.527+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:28:30.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:28:30.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:28:30.555+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:28:30.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:28:30.564+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:28:30.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:28:30.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T16:29:00.988+0000] {processor.py:157} INFO - Started process (PID=5241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:29:00.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:29:00.991+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:29:00.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:29:01.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:29:01.022+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:29:01.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:29:01.032+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:29:01.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:29:01.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T16:29:31.482+0000] {processor.py:157} INFO - Started process (PID=5266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:29:31.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:29:31.488+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:29:31.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:29:31.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:29:31.523+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:29:31.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:29:31.536+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:29:31.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:29:31.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-22T16:30:01.984+0000] {processor.py:157} INFO - Started process (PID=5291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:30:01.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:30:01.988+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:30:01.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:30:01.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:30:02.014+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:30:02.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:30:02.025+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:30:02.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:30:02.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T16:30:32.431+0000] {processor.py:157} INFO - Started process (PID=5316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:30:32.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:30:32.435+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:30:32.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:30:32.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:30:32.466+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:30:32.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:30:32.477+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:30:32.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:30:32.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T16:31:02.859+0000] {processor.py:157} INFO - Started process (PID=5341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:31:02.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:31:02.865+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:31:02.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:31:02.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:31:02.893+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:31:02.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:31:02.903+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:31:02.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:31:02.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T16:31:33.351+0000] {processor.py:157} INFO - Started process (PID=5366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:31:33.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:31:33.354+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:31:33.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:31:33.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:31:33.384+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:31:33.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:31:33.398+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:31:33.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:31:33.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T16:32:03.812+0000] {processor.py:157} INFO - Started process (PID=5391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:32:03.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:32:03.815+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:32:03.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:32:03.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:32:03.849+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:32:03.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:32:03.859+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:32:03.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:32:03.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T16:32:34.246+0000] {processor.py:157} INFO - Started process (PID=5416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:32:34.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:32:34.250+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:32:34.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:32:34.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:32:34.275+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:32:34.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:32:34.284+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:32:34.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:32:34.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T16:33:04.692+0000] {processor.py:157} INFO - Started process (PID=5441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:33:04.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:33:04.697+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:33:04.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:33:04.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:33:04.752+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:33:04.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:33:04.765+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:33:04.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:33:04.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-22T16:33:35.138+0000] {processor.py:157} INFO - Started process (PID=5466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:33:35.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:33:35.143+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:33:35.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:33:35.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:33:35.171+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:33:35.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:33:35.181+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:33:35.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:33:35.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T16:34:05.651+0000] {processor.py:157} INFO - Started process (PID=5491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:34:05.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:34:05.659+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:34:05.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:34:05.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:34:05.692+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:34:05.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:34:05.703+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:34:05.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:34:05.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-22T16:34:36.113+0000] {processor.py:157} INFO - Started process (PID=5516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:34:36.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:34:36.117+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:34:36.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:34:36.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:34:36.153+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:34:36.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:34:36.166+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:34:36.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:34:36.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-22T16:35:06.655+0000] {processor.py:157} INFO - Started process (PID=5541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:35:06.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:35:06.661+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:35:06.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:35:06.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:35:06.705+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:35:06.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:35:06.717+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:35:06.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:35:06.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-22T16:35:37.102+0000] {processor.py:157} INFO - Started process (PID=5566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:35:37.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:35:37.105+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:35:37.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:35:37.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:35:37.129+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:35:37.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:35:37.140+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:35:37.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:35:37.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T16:36:07.521+0000] {processor.py:157} INFO - Started process (PID=5591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:36:07.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:36:07.526+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:36:07.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:36:07.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:36:07.553+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:36:07.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:36:07.562+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:36:07.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:36:07.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T16:36:37.982+0000] {processor.py:157} INFO - Started process (PID=5616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:36:37.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:36:37.987+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:36:37.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:36:38.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:36:38.015+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:36:38.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:36:38.027+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:36:38.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:36:38.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T16:37:08.477+0000] {processor.py:157} INFO - Started process (PID=5641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:37:08.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:37:08.483+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:37:08.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:37:08.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:37:08.518+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:37:08.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:37:08.531+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:37:08.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:37:08.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-22T16:37:39.107+0000] {processor.py:157} INFO - Started process (PID=5666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:37:39.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:37:39.111+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:37:39.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:37:39.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:37:39.144+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:37:39.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:37:39.155+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:37:39.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:37:39.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T16:38:09.656+0000] {processor.py:157} INFO - Started process (PID=5690) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:38:09.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:38:09.664+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:38:09.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:38:09.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:38:09.724+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:38:09.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:38:09.738+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:38:09.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:38:09.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-22T16:38:40.153+0000] {processor.py:157} INFO - Started process (PID=5716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:38:40.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:38:40.160+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:38:40.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:38:40.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:38:40.195+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:38:40.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:38:40.208+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:38:40.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:38:40.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T16:39:10.579+0000] {processor.py:157} INFO - Started process (PID=5741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:39:10.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:39:10.583+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:39:10.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:39:10.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:39:10.612+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:39:10.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:39:10.622+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:39:10.622+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:39:10.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T16:39:41.061+0000] {processor.py:157} INFO - Started process (PID=5765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:39:41.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:39:41.066+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:39:41.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:39:41.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:39:41.131+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:39:41.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:39:41.145+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:39:41.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:39:41.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-22T16:40:11.568+0000] {processor.py:157} INFO - Started process (PID=5791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:40:11.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:40:11.572+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:40:11.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:40:11.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:40:11.601+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:40:11.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:40:11.610+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:40:11.610+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:40:11.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T16:40:41.999+0000] {processor.py:157} INFO - Started process (PID=5816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:40:42.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:40:42.006+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:40:42.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:40:42.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:40:42.049+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:40:42.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:40:42.066+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:40:42.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:40:42.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-22T16:41:12.494+0000] {processor.py:157} INFO - Started process (PID=5841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:41:12.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:41:12.497+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:41:12.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:41:12.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:41:12.527+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:41:12.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:41:12.536+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:41:12.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:41:12.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T16:41:42.945+0000] {processor.py:157} INFO - Started process (PID=5866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:41:42.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:41:42.951+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:41:42.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:41:42.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:41:42.987+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:41:42.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:41:42.999+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:41:42.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:41:43.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T16:42:13.405+0000] {processor.py:157} INFO - Started process (PID=5891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:42:13.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:42:13.408+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:42:13.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:42:13.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:42:13.435+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:42:13.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:42:13.446+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:42:13.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:42:13.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T16:42:43.875+0000] {processor.py:157} INFO - Started process (PID=5915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:42:43.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:42:43.880+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:42:43.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:42:43.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:42:43.918+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:42:43.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:42:43.934+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:42:43.934+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:42:43.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-22T16:43:14.332+0000] {processor.py:157} INFO - Started process (PID=5941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:43:14.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:43:14.336+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:43:14.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:43:14.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:43:14.367+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:43:14.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:43:14.378+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:43:14.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:43:14.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T16:43:44.739+0000] {processor.py:157} INFO - Started process (PID=5965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:43:44.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:43:44.765+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:43:44.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:43:44.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:43:44.810+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:43:44.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:43:44.825+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:43:44.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:43:44.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-22T16:44:15.291+0000] {processor.py:157} INFO - Started process (PID=5991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:44:15.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:44:15.295+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:44:15.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:44:15.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:44:15.326+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:44:15.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:44:15.337+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:44:15.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:44:15.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T16:44:45.623+0000] {processor.py:157} INFO - Started process (PID=6015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:44:45.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:44:45.628+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:44:45.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:44:45.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:44:45.686+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:44:45.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:44:45.698+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:44:45.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:44:45.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-22T16:45:16.178+0000] {processor.py:157} INFO - Started process (PID=6041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:45:16.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:45:16.182+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:45:16.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:45:16.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:45:16.208+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:45:16.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:45:16.220+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:45:16.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:45:16.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T16:45:46.659+0000] {processor.py:157} INFO - Started process (PID=6065) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:45:46.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:45:46.665+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:45:46.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:45:46.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:45:46.712+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:45:46.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:45:46.727+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:45:46.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:45:46.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-22T16:46:17.164+0000] {processor.py:157} INFO - Started process (PID=6091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:46:17.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:46:17.168+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:46:17.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:46:17.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:46:17.196+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:46:17.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:46:17.207+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:46:17.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:46:17.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T16:46:47.647+0000] {processor.py:157} INFO - Started process (PID=6116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:46:47.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:46:47.652+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:46:47.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:46:47.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:46:47.712+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:46:47.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:46:47.724+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:46:47.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:46:47.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-22T16:47:18.105+0000] {processor.py:157} INFO - Started process (PID=6141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:47:18.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:47:18.111+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:47:18.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:47:18.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:47:18.141+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:47:18.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:47:18.153+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:47:18.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:47:18.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T16:47:48.587+0000] {processor.py:157} INFO - Started process (PID=6165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:47:48.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:47:48.592+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:47:48.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:47:48.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:47:48.649+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:47:48.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:47:48.664+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:47:48.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:47:48.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-22T16:48:19.091+0000] {processor.py:157} INFO - Started process (PID=6191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:48:19.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:48:19.095+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:48:19.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:48:19.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:48:19.125+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:48:19.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:48:19.138+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:48:19.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:48:19.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T16:48:49.575+0000] {processor.py:157} INFO - Started process (PID=6216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:48:49.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:48:49.581+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:48:49.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:48:49.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:48:49.642+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:48:49.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:48:49.656+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:48:49.656+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:48:49.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-22T16:49:20.110+0000] {processor.py:157} INFO - Started process (PID=6241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:49:20.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:49:20.113+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:49:20.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:49:20.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:49:20.139+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:49:20.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:49:20.149+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:49:20.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:49:20.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T16:49:50.571+0000] {processor.py:157} INFO - Started process (PID=6266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:49:50.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:49:50.576+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:49:50.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:49:50.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:49:50.638+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:49:50.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:49:50.652+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:49:50.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:49:50.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-22T16:50:21.124+0000] {processor.py:157} INFO - Started process (PID=6291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:50:21.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:50:21.128+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:50:21.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:50:21.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:50:21.158+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:50:21.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:50:21.169+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:50:21.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:50:21.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T16:50:51.561+0000] {processor.py:157} INFO - Started process (PID=6315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:50:51.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:50:51.567+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:50:51.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:50:51.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:50:51.633+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:50:51.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:50:51.649+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:50:51.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:50:51.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-22T16:51:22.095+0000] {processor.py:157} INFO - Started process (PID=6341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:51:22.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:51:22.098+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:51:22.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:51:22.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:51:22.127+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:51:22.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:51:22.140+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:51:22.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:51:22.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T16:51:52.635+0000] {processor.py:157} INFO - Started process (PID=6366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:51:52.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:51:52.643+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:51:52.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:51:52.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:51:52.689+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:51:52.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:51:52.704+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:51:52.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:51:52.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-22T16:52:23.137+0000] {processor.py:157} INFO - Started process (PID=6391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:52:23.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:52:23.140+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:52:23.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:52:23.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:52:23.171+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:52:23.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:52:23.181+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:52:23.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:52:23.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T16:52:53.600+0000] {processor.py:157} INFO - Started process (PID=6416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:52:53.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:52:53.604+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:52:53.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:52:53.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:52:53.643+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:52:53.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:52:53.655+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:52:53.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:52:53.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-22T16:53:24.043+0000] {processor.py:157} INFO - Started process (PID=6441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:53:24.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:53:24.048+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:53:24.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:53:24.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:53:24.078+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:53:24.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:53:24.088+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:53:24.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:53:24.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T16:53:54.457+0000] {processor.py:157} INFO - Started process (PID=6466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:53:54.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:53:54.463+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:53:54.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:53:54.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:53:54.522+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:53:54.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:53:54.535+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:53:54.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:53:54.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-22T16:54:24.878+0000] {processor.py:157} INFO - Started process (PID=6491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:54:24.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:54:24.881+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:54:24.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:54:24.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:54:24.916+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:54:24.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:54:24.927+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:54:24.927+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:54:24.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T16:54:55.385+0000] {processor.py:157} INFO - Started process (PID=6515) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:54:55.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:54:55.392+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:54:55.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:54:55.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:54:55.455+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:54:55.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:54:55.470+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:54:55.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:54:55.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-22T16:55:25.893+0000] {processor.py:157} INFO - Started process (PID=6541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:55:25.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:55:25.899+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:55:25.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:55:25.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:55:25.934+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:55:25.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:55:25.947+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:55:25.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:55:25.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-22T16:55:56.445+0000] {processor.py:157} INFO - Started process (PID=6565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:55:56.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:55:56.451+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:55:56.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:55:56.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:55:56.503+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:55:56.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:55:56.518+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:55:56.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:55:56.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-22T16:56:26.909+0000] {processor.py:157} INFO - Started process (PID=6589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:56:26.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:56:26.918+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:56:26.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:56:26.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:56:26.993+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:56:26.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:56:27.013+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:56:27.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:56:27.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-22T16:56:57.435+0000] {processor.py:157} INFO - Started process (PID=6616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:56:57.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:56:57.441+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:56:57.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:56:57.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:56:57.466+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:56:57.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:56:57.476+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:56:57.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:56:57.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T16:57:27.839+0000] {processor.py:157} INFO - Started process (PID=6641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:57:27.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:57:27.853+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:57:27.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:57:27.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:57:27.899+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:57:27.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:57:27.919+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:57:27.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:57:27.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-22T16:57:58.376+0000] {processor.py:157} INFO - Started process (PID=6666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:57:58.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:57:58.381+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:57:58.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:57:58.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:57:58.410+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:57:58.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:57:58.420+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:57:58.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:57:58.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T16:58:28.785+0000] {processor.py:157} INFO - Started process (PID=6691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:58:28.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:58:28.793+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:58:28.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:58:28.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:58:28.838+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:58:28.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:58:28.867+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:58:28.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:58:28.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-22T16:58:59.290+0000] {processor.py:157} INFO - Started process (PID=6716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:58:59.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:58:59.295+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:58:59.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:58:59.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:58:59.326+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:58:59.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:58:59.340+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:58:59.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:58:59.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T16:59:29.775+0000] {processor.py:157} INFO - Started process (PID=6741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:59:29.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T16:59:29.781+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:59:29.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:59:29.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T16:59:29.819+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:59:29.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T16:59:29.844+0000] {logging_mixin.py:151} INFO - [2024-07-22T16:59:29.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T16:59:29.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-22T17:00:00.293+0000] {processor.py:157} INFO - Started process (PID=6765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:00:00.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:00:00.300+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:00:00.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:00:00.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:00:00.331+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:00:00.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:00:00.343+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:00:00.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:00:00.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-22T17:00:30.766+0000] {processor.py:157} INFO - Started process (PID=6791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:00:30.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:00:30.773+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:00:30.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:00:30.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:00:30.815+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:00:30.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:00:30.827+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:00:30.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:00:30.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-22T17:01:01.202+0000] {processor.py:157} INFO - Started process (PID=6816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:01:01.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:01:01.207+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:01:01.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:01:01.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:01:01.237+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:01:01.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:01:01.248+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:01:01.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:01:01.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T17:01:31.676+0000] {processor.py:157} INFO - Started process (PID=6841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:01:31.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:01:31.680+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:01:31.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:01:31.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:01:31.723+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:01:31.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:01:31.738+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:01:31.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:01:31.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-22T17:02:02.118+0000] {processor.py:157} INFO - Started process (PID=6866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:02:02.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:02:02.124+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:02:02.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:02:02.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:02:02.175+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:02:02.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:02:02.192+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:02:02.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:02:02.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-22T17:02:32.629+0000] {processor.py:157} INFO - Started process (PID=6891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:02:32.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:02:32.633+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:02:32.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:02:32.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:02:32.663+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:02:32.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:02:32.677+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:02:32.677+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:02:32.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T17:03:03.080+0000] {processor.py:157} INFO - Started process (PID=6916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:03:03.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:03:03.088+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:03:03.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:03:03.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:03:03.120+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:03:03.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:03:03.132+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:03:03.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:03:03.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-22T17:03:33.557+0000] {processor.py:157} INFO - Started process (PID=6941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:03:33.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:03:33.566+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:03:33.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:03:33.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:03:33.635+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:03:33.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:03:33.655+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:03:33.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:03:33.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-22T17:04:04.115+0000] {processor.py:157} INFO - Started process (PID=6966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:04:04.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:04:04.131+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:04:04.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:04:04.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:04:04.186+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:04:04.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:04:04.199+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:04:04.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:04:04.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-22T17:04:34.727+0000] {processor.py:157} INFO - Started process (PID=6991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:04:34.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:04:34.734+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:04:34.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:04:34.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:04:34.792+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:04:34.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:04:34.804+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:04:34.804+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:04:34.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-22T17:05:05.240+0000] {processor.py:157} INFO - Started process (PID=7016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:05:05.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:05:05.252+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:05:05.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:05:05.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:05:05.304+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:05:05.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:05:05.319+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:05:05.319+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:05:05.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-22T17:05:35.772+0000] {processor.py:157} INFO - Started process (PID=7041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:05:35.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:05:35.776+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:05:35.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:05:35.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:05:35.827+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:05:35.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:05:35.838+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:05:35.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:05:35.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-22T17:06:06.265+0000] {processor.py:157} INFO - Started process (PID=7066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:06:06.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:06:06.282+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:06:06.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:06:06.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:06:06.335+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:06:06.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:06:06.348+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:06:06.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:06:06.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-22T17:06:36.741+0000] {processor.py:157} INFO - Started process (PID=7091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:06:36.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:06:36.747+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:06:36.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:06:36.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:06:36.776+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:06:36.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:06:36.786+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:06:36.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:06:36.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T17:07:07.255+0000] {processor.py:157} INFO - Started process (PID=7116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:07:07.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:07:07.263+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:07:07.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:07:07.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:07:07.320+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:07:07.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:07:07.336+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:07:07.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:07:07.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-22T17:07:37.813+0000] {processor.py:157} INFO - Started process (PID=7141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:07:37.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:07:37.825+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:07:37.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:07:37.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:07:37.887+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:07:37.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:07:37.903+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:07:37.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:07:37.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-22T17:08:08.381+0000] {processor.py:157} INFO - Started process (PID=7166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:08:08.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:08:08.390+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:08:08.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:08:08.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:08:08.480+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:08:08.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:08:08.500+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:08:08.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:08:08.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-07-22T17:08:38.986+0000] {processor.py:157} INFO - Started process (PID=7191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:08:38.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:08:38.992+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:08:38.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:08:39.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:08:39.048+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:08:39.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:08:39.062+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:08:39.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:08:39.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-22T17:09:09.439+0000] {processor.py:157} INFO - Started process (PID=7216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:09:09.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:09:09.448+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:09:09.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:09:09.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:09:09.487+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:09:09.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:09:09.504+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:09:09.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:09:09.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-22T17:09:39.973+0000] {processor.py:157} INFO - Started process (PID=7241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:09:39.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:09:39.981+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:09:39.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:09:39.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:09:40.037+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:09:40.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:09:40.051+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:09:40.051+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:09:40.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-22T17:10:10.516+0000] {processor.py:157} INFO - Started process (PID=7266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:10:10.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:10:10.523+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:10:10.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:10:10.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:10:10.578+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:10:10.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:10:10.591+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:10:10.591+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:10:10.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-22T17:10:41.083+0000] {processor.py:157} INFO - Started process (PID=7291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:10:41.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:10:41.102+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:10:41.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:10:41.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:10:41.151+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:10:41.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:10:41.164+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:10:41.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:10:41.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-22T17:11:11.559+0000] {processor.py:157} INFO - Started process (PID=7316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:11:11.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:11:11.564+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:11:11.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:11:11.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:11:11.602+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:11:11.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:11:11.615+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:11:11.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:11:11.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-22T17:11:42.138+0000] {processor.py:157} INFO - Started process (PID=7341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:11:42.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:11:42.145+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:11:42.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:11:42.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:11:42.193+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:11:42.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:11:42.207+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:11:42.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:11:42.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-22T17:12:12.573+0000] {processor.py:157} INFO - Started process (PID=7366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:12:12.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:12:12.576+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:12:12.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:12:12.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:12:12.604+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:12:12.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:12:12.613+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:12:12.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:12:12.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T17:12:43.240+0000] {processor.py:157} INFO - Started process (PID=7391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:12:43.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:12:43.251+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:12:43.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:12:43.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:12:43.294+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:12:43.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:12:43.307+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:12:43.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:12:43.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-22T17:13:13.764+0000] {processor.py:157} INFO - Started process (PID=7416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:13:13.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:13:13.769+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:13:13.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:13:13.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:13:13.796+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:13:13.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:13:13.807+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:13:13.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:13:13.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T17:13:44.301+0000] {processor.py:157} INFO - Started process (PID=7441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:13:44.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:13:44.306+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:13:44.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:13:44.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:13:44.344+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:13:44.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:13:44.357+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:13:44.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:13:44.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-22T17:14:14.819+0000] {processor.py:157} INFO - Started process (PID=7466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:14:14.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:14:14.823+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:14:14.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:14:14.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:14:14.848+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:14:14.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:14:14.861+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:14:14.861+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:14:14.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T17:14:45.251+0000] {processor.py:157} INFO - Started process (PID=7491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:14:45.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:14:45.258+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:14:45.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:14:45.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:14:45.308+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:14:45.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:14:45.326+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:14:45.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:14:45.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-22T17:15:15.820+0000] {processor.py:157} INFO - Started process (PID=7516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:15:15.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:15:15.824+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:15:15.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:15:15.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:15:15.863+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:15:15.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:15:15.876+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:15:15.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:15:15.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T17:15:46.365+0000] {processor.py:157} INFO - Started process (PID=7541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:15:46.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:15:46.368+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:15:46.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:15:46.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:15:46.393+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:15:46.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:15:46.403+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:15:46.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:15:46.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T17:16:16.768+0000] {processor.py:157} INFO - Started process (PID=7566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:16:16.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:16:16.771+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:16:16.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:16:16.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:16:16.795+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:16:16.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:16:16.808+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:16:16.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:16:16.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T17:16:47.276+0000] {processor.py:157} INFO - Started process (PID=7591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:16:47.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:16:47.282+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:16:47.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:16:47.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:16:47.319+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:16:47.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:16:47.331+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:16:47.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:16:47.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T17:17:17.730+0000] {processor.py:157} INFO - Started process (PID=7616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:17:17.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:17:17.735+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:17:17.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:17:17.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:17:17.765+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:17:17.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:17:17.775+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:17:17.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:17:17.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T17:17:48.223+0000] {processor.py:157} INFO - Started process (PID=7641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:17:48.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:17:48.228+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:17:48.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:17:48.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:17:48.255+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:17:48.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:17:48.267+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:17:48.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:17:48.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T17:18:18.781+0000] {processor.py:157} INFO - Started process (PID=7666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:18:18.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:18:18.788+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:18:18.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:18:18.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:18:18.851+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:18:18.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:18:18.874+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:18:18.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:18:18.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-22T17:18:49.294+0000] {processor.py:157} INFO - Started process (PID=7691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:18:49.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:18:49.305+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:18:49.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:18:49.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:18:49.359+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:18:49.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:18:49.375+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:18:49.374+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:18:49.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-22T17:19:19.761+0000] {processor.py:157} INFO - Started process (PID=7716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:19:19.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:19:19.766+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:19:19.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:19:19.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:19:19.810+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:19:19.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:19:19.824+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:19:19.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:19:19.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-22T17:19:50.247+0000] {processor.py:157} INFO - Started process (PID=7741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:19:50.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:19:50.253+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:19:50.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:19:50.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:19:50.297+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:19:50.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:19:50.310+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:19:50.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:19:50.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-22T17:20:20.760+0000] {processor.py:157} INFO - Started process (PID=7766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:20:20.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:20:20.767+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:20:20.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:20:20.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:20:20.817+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:20:20.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:20:20.830+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:20:20.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:20:20.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-22T17:20:51.244+0000] {processor.py:157} INFO - Started process (PID=7791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:20:51.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:20:51.253+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:20:51.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:20:51.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:20:51.305+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:20:51.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:20:51.321+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:20:51.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:20:51.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-22T17:21:21.735+0000] {processor.py:157} INFO - Started process (PID=7816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:21:21.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:21:21.748+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:21:21.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:21:21.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:21:21.793+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:21:21.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:21:21.807+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:21:21.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:21:21.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-22T17:21:52.319+0000] {processor.py:157} INFO - Started process (PID=7841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:21:52.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:21:52.332+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:21:52.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:21:52.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:21:52.400+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:21:52.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:21:52.413+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:21:52.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:21:52.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-22T17:22:23.250+0000] {processor.py:157} INFO - Started process (PID=7865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:22:23.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:22:23.256+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:22:23.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:22:23.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:22:23.302+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:22:23.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:22:23.318+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:22:23.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:22:23.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-22T17:22:53.764+0000] {processor.py:157} INFO - Started process (PID=7891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:22:53.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:22:53.771+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:22:53.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:22:53.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:22:53.833+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:22:53.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:22:53.848+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:22:53.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:22:53.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-22T17:23:24.258+0000] {processor.py:157} INFO - Started process (PID=7916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:23:24.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:23:24.265+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:23:24.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:23:24.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:23:24.349+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:23:24.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:23:24.365+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:23:24.365+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:23:24.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-07-22T17:23:54.847+0000] {processor.py:157} INFO - Started process (PID=7941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:23:54.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:23:54.850+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:23:54.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:23:54.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:23:54.877+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:23:54.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:23:54.887+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:23:54.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:23:54.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T17:24:25.537+0000] {processor.py:157} INFO - Started process (PID=7966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:24:25.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:24:25.543+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:24:25.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:24:25.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:24:25.594+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:24:25.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:24:25.607+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:24:25.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:24:25.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-22T17:24:55.975+0000] {processor.py:157} INFO - Started process (PID=7991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:24:55.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:24:55.980+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:24:55.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:24:55.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:24:56.013+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:24:56.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:24:56.025+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:24:56.025+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:24:56.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-22T17:25:26.464+0000] {processor.py:157} INFO - Started process (PID=8016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:25:26.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:25:26.467+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:25:26.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:25:26.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:25:26.496+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:25:26.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:25:26.506+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:25:26.506+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:25:26.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T17:25:56.864+0000] {processor.py:157} INFO - Started process (PID=8041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:25:56.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:25:56.869+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:25:56.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:25:56.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:25:56.906+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:25:56.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:25:56.921+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:25:56.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:25:56.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T17:26:27.340+0000] {processor.py:157} INFO - Started process (PID=8066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:26:27.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:26:27.343+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:26:27.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:26:27.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:26:27.372+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:26:27.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:26:27.382+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:26:27.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:26:27.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T17:26:57.822+0000] {processor.py:157} INFO - Started process (PID=8091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:26:57.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:26:57.825+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:26:57.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:26:57.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:26:57.856+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:26:57.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:26:57.865+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:26:57.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:26:57.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T17:27:28.291+0000] {processor.py:157} INFO - Started process (PID=8116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:27:28.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:27:28.296+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:27:28.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:27:28.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:27:28.335+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:27:28.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:27:28.350+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:27:28.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:27:28.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-22T17:27:58.772+0000] {processor.py:157} INFO - Started process (PID=8141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:27:58.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:27:58.774+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:27:58.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:27:58.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:27:58.795+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:27:58.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:27:58.804+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:27:58.804+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:27:58.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-22T17:28:29.144+0000] {processor.py:157} INFO - Started process (PID=8166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:28:29.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:28:29.147+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:28:29.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:28:29.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:28:29.174+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:28:29.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:28:29.183+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:28:29.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:28:29.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-22T17:28:59.591+0000] {processor.py:157} INFO - Started process (PID=8191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:28:59.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:28:59.594+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:28:59.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:28:59.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:28:59.624+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:28:59.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:28:59.635+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:28:59.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:28:59.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T17:29:30.030+0000] {processor.py:157} INFO - Started process (PID=8216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:29:30.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:29:30.034+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:29:30.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:29:30.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:29:30.064+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:29:30.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:29:30.074+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:29:30.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:29:30.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T17:30:00.497+0000] {processor.py:157} INFO - Started process (PID=8241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:30:00.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:30:00.502+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:30:00.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:30:00.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:30:00.541+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:30:00.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:30:00.556+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:30:00.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:30:00.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-22T17:30:30.935+0000] {processor.py:157} INFO - Started process (PID=8266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:30:30.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:30:30.939+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:30:30.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:30:30.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:30:30.971+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:30:30.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:30:30.980+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:30:30.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:30:30.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T17:31:01.390+0000] {processor.py:157} INFO - Started process (PID=8291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:31:01.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:31:01.391+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:31:01.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:31:01.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:31:01.421+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:31:01.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:31:01.431+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:31:01.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:31:01.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T17:31:31.857+0000] {processor.py:157} INFO - Started process (PID=8316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:31:31.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:31:31.860+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:31:31.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:31:31.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:31:31.892+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:31:31.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:31:31.902+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:31:31.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:31:31.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T17:32:02.304+0000] {processor.py:157} INFO - Started process (PID=8341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:32:02.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:32:02.311+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:32:02.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:32:02.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:32:02.355+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:32:02.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:32:02.369+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:32:02.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:32:02.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-22T17:32:32.785+0000] {processor.py:157} INFO - Started process (PID=8366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:32:32.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:32:32.788+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:32:32.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:32:32.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:32:32.816+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:32:32.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:32:32.829+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:32:32.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:32:32.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T17:33:03.169+0000] {processor.py:157} INFO - Started process (PID=8391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:33:03.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:33:03.173+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:33:03.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:33:03.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:33:03.199+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:33:03.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:33:03.209+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:33:03.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:33:03.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T17:33:33.570+0000] {processor.py:157} INFO - Started process (PID=8416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:33:33.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:33:33.572+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:33:33.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:33:33.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:33:33.603+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:33:33.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:33:33.613+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:33:33.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:33:33.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T17:34:03.982+0000] {processor.py:157} INFO - Started process (PID=8441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:34:03.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:34:03.987+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:34:03.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:34:04.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:34:04.024+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:34:04.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:34:04.036+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:34:04.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:34:04.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T17:34:34.483+0000] {processor.py:157} INFO - Started process (PID=8465) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:34:34.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:34:34.493+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:34:34.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:34:34.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:34:34.560+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:34:34.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:34:34.574+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:34:34.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:34:34.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-22T17:35:04.975+0000] {processor.py:157} INFO - Started process (PID=8491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:35:04.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:35:04.980+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:35:04.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:35:04.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:35:05.042+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:35:05.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:35:05.057+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:35:05.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:35:05.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-22T17:35:35.532+0000] {processor.py:157} INFO - Started process (PID=8516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:35:35.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:35:35.537+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:35:35.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:35:35.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:35:35.571+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:35:35.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:35:35.581+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:35:35.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:35:35.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T17:36:05.942+0000] {processor.py:157} INFO - Started process (PID=8541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:36:05.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:36:05.948+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:36:05.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:36:05.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:36:05.977+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:36:05.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:36:05.987+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:36:05.987+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:36:05.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T17:36:36.299+0000] {processor.py:157} INFO - Started process (PID=8566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:36:36.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:36:36.307+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:36:36.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:36:36.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:36:36.368+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:36:36.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:36:36.383+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:36:36.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:36:36.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-22T17:37:06.843+0000] {processor.py:157} INFO - Started process (PID=8591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:37:06.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:37:06.847+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:37:06.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:37:06.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:37:06.878+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:37:06.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:37:06.891+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:37:06.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:37:06.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T17:37:37.315+0000] {processor.py:157} INFO - Started process (PID=8616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:37:37.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:37:37.319+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:37:37.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:37:37.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:37:37.356+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:37:37.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:37:37.369+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:37:37.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:37:37.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-22T17:38:07.775+0000] {processor.py:157} INFO - Started process (PID=8641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:38:07.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:38:07.778+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:38:07.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:38:07.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:38:07.805+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:38:07.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:38:07.814+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:38:07.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:38:07.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T17:38:38.186+0000] {processor.py:157} INFO - Started process (PID=8666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:38:38.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:38:38.191+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:38:38.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:38:38.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:38:38.223+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:38:38.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:38:38.233+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:38:38.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:38:38.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T17:39:08.588+0000] {processor.py:157} INFO - Started process (PID=8691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:39:08.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:39:08.594+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:39:08.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:39:08.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:39:08.634+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:39:08.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:39:08.647+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:39:08.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:39:08.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-22T17:39:39.079+0000] {processor.py:157} INFO - Started process (PID=8716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:39:39.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:39:39.083+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:39:39.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:39:39.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:39:39.113+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:39:39.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:39:39.123+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:39:39.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:39:39.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T17:40:09.509+0000] {processor.py:157} INFO - Started process (PID=8741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:40:09.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:40:09.516+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:40:09.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:40:09.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:40:09.557+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:40:09.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:40:09.569+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:40:09.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:40:09.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T17:40:39.973+0000] {processor.py:157} INFO - Started process (PID=8766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:40:39.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:40:39.976+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:40:39.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:40:39.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:40:40.010+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:40:40.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:40:40.025+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:40:40.025+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:40:40.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-22T17:41:10.440+0000] {processor.py:157} INFO - Started process (PID=8791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:41:10.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:41:10.447+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:41:10.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:41:10.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:41:10.485+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:41:10.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:41:10.496+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:41:10.496+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:41:10.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T17:41:40.889+0000] {processor.py:157} INFO - Started process (PID=8816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:41:40.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:41:40.893+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:41:40.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:41:40.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:41:40.921+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:41:40.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:41:40.931+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:41:40.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:41:40.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T17:42:11.330+0000] {processor.py:157} INFO - Started process (PID=8841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:42:11.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:42:11.335+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:42:11.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:42:11.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:42:11.364+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:42:11.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:42:11.378+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:42:11.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:42:11.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T17:42:41.785+0000] {processor.py:157} INFO - Started process (PID=8866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:42:41.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:42:41.788+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:42:41.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:42:41.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:42:41.820+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:42:41.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:42:41.832+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:42:41.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:42:41.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T17:43:12.241+0000] {processor.py:157} INFO - Started process (PID=8891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:43:12.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:43:12.247+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:43:12.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:43:12.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:43:12.286+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:43:12.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:43:12.298+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:43:12.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:43:12.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T17:43:42.675+0000] {processor.py:157} INFO - Started process (PID=8916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:43:42.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:43:42.681+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:43:42.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:43:42.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:43:42.711+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:43:42.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:43:42.721+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:43:42.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:43:42.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T17:44:13.037+0000] {processor.py:157} INFO - Started process (PID=8941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:44:13.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:44:13.039+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:44:13.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:44:13.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:44:13.066+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:44:13.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:44:13.079+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:44:13.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:44:13.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T17:44:43.495+0000] {processor.py:157} INFO - Started process (PID=8966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:44:43.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:44:43.500+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:44:43.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:44:43.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:44:43.539+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:44:43.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:44:43.552+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:44:43.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:44:43.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T17:45:13.961+0000] {processor.py:157} INFO - Started process (PID=8991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:45:13.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:45:13.963+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:45:13.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:45:13.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:45:13.994+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:45:13.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:45:14.008+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:45:14.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:45:14.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T17:45:44.406+0000] {processor.py:157} INFO - Started process (PID=9016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:45:44.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:45:44.410+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:45:44.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:45:44.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:45:44.438+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:45:44.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:45:44.448+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:45:44.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:45:44.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T17:46:14.834+0000] {processor.py:157} INFO - Started process (PID=9041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:46:14.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:46:14.838+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:46:14.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:46:14.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:46:14.866+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:46:14.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:46:14.879+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:46:14.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:46:14.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T17:46:45.277+0000] {processor.py:157} INFO - Started process (PID=9066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:46:45.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:46:45.284+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:46:45.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:46:45.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:46:45.320+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:46:45.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:46:45.332+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:46:45.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:46:45.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-22T17:47:15.697+0000] {processor.py:157} INFO - Started process (PID=9091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:47:15.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:47:15.701+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:47:15.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:47:15.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:47:15.729+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:47:15.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:47:15.740+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:47:15.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:47:15.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T17:47:46.117+0000] {processor.py:157} INFO - Started process (PID=9116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:47:46.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:47:46.121+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:47:46.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:47:46.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:47:46.151+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:47:46.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:47:46.164+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:47:46.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:47:46.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T17:48:16.564+0000] {processor.py:157} INFO - Started process (PID=9141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:48:16.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:48:16.567+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:48:16.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:48:16.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:48:16.598+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:48:16.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:48:16.609+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:48:16.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:48:16.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T17:48:46.998+0000] {processor.py:157} INFO - Started process (PID=9166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:48:47.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:48:47.002+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:48:47.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:48:47.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:48:47.028+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:48:47.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:48:47.039+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:48:47.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:48:47.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T17:49:17.383+0000] {processor.py:157} INFO - Started process (PID=9191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:49:17.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:49:17.385+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:49:17.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:49:17.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:49:17.417+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:49:17.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:49:17.428+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:49:17.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:49:17.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T17:49:47.774+0000] {processor.py:157} INFO - Started process (PID=9216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:49:47.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:49:47.777+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:49:47.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:49:47.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:49:47.813+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:49:47.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:49:47.828+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:49:47.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:49:47.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T17:50:18.187+0000] {processor.py:157} INFO - Started process (PID=9241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:50:18.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:50:18.193+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:50:18.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:50:18.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:50:18.225+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:50:18.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:50:18.235+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:50:18.235+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:50:18.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T17:50:48.588+0000] {processor.py:157} INFO - Started process (PID=9266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:50:48.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:50:48.591+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:50:48.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:50:48.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:50:48.619+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:50:48.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:50:48.628+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:50:48.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:50:48.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T17:51:19.078+0000] {processor.py:157} INFO - Started process (PID=9291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:51:19.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:51:19.083+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:51:19.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:51:19.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:51:19.113+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:51:19.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:51:19.126+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:51:19.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:51:19.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T17:51:49.533+0000] {processor.py:157} INFO - Started process (PID=9316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:51:49.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:51:49.538+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:51:49.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:51:49.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:51:49.576+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:51:49.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:51:49.587+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:51:49.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:51:49.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-22T17:52:19.969+0000] {processor.py:157} INFO - Started process (PID=9341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:52:19.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:52:19.972+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:52:19.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:52:19.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:52:20.006+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:52:20.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:52:20.020+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:52:20.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:52:20.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-22T17:52:50.437+0000] {processor.py:157} INFO - Started process (PID=9366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:52:50.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:52:50.440+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:52:50.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:52:50.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:52:50.471+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:52:50.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:52:50.481+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:52:50.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:52:50.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T17:53:20.901+0000] {processor.py:157} INFO - Started process (PID=9391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:53:20.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:53:20.906+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:53:20.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:53:20.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:53:20.939+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:53:20.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:53:20.950+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:53:20.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:53:20.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T17:53:51.349+0000] {processor.py:157} INFO - Started process (PID=9416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:53:51.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:53:51.354+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:53:51.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:53:51.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:53:51.393+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:53:51.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:53:51.407+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:53:51.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:53:51.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-22T17:54:21.861+0000] {processor.py:157} INFO - Started process (PID=9441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:54:21.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:54:21.865+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:54:21.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:54:21.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:54:21.901+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:54:21.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:54:21.913+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:54:21.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:54:21.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-22T17:54:52.306+0000] {processor.py:157} INFO - Started process (PID=9466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:54:52.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:54:52.310+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:54:52.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:54:52.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:54:52.341+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:54:52.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:54:52.354+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:54:52.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:54:52.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T17:55:22.810+0000] {processor.py:157} INFO - Started process (PID=9491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:55:22.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:55:22.814+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:55:22.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:55:22.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:55:22.846+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:55:22.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:55:22.857+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:55:22.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:55:22.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-22T17:55:53.226+0000] {processor.py:157} INFO - Started process (PID=9516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:55:53.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:55:53.230+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:55:53.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:55:53.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:55:53.265+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:55:53.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:55:53.275+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:55:53.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:55:53.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-22T17:56:23.643+0000] {processor.py:157} INFO - Started process (PID=9541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:56:23.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:56:23.649+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:56:23.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:56:23.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:56:23.680+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:56:23.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:56:23.690+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:56:23.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:56:23.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T17:56:54.121+0000] {processor.py:157} INFO - Started process (PID=9566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:56:54.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:56:54.124+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:56:54.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:56:54.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:56:54.163+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:56:54.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:56:54.178+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:56:54.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:56:54.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-22T17:57:24.645+0000] {processor.py:157} INFO - Started process (PID=9591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:57:24.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:57:24.652+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:57:24.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:57:24.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:57:24.685+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:57:24.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:57:24.694+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:57:24.694+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:57:24.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T17:57:55.068+0000] {processor.py:157} INFO - Started process (PID=9616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:57:55.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:57:55.073+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:57:55.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:57:55.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:57:55.104+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:57:55.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:57:55.114+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:57:55.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:57:55.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T17:58:25.547+0000] {processor.py:157} INFO - Started process (PID=9641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:58:25.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:58:25.551+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:58:25.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:58:25.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:58:25.581+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:58:25.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:58:25.593+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:58:25.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:58:25.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T17:58:55.956+0000] {processor.py:157} INFO - Started process (PID=9666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:58:55.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:58:55.963+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:58:55.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:58:55.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:58:56.004+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:58:56.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:58:56.020+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:58:56.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:58:56.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-22T17:59:26.395+0000] {processor.py:157} INFO - Started process (PID=9691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:59:26.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:59:26.398+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:59:26.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:59:26.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:59:26.431+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:59:26.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:59:26.444+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:59:26.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:59:26.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T17:59:56.836+0000] {processor.py:157} INFO - Started process (PID=9716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:59:56.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T17:59:56.842+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:59:56.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:59:56.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T17:59:56.875+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:59:56.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T17:59:56.885+0000] {logging_mixin.py:151} INFO - [2024-07-22T17:59:56.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T17:59:56.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-22T18:00:27.314+0000] {processor.py:157} INFO - Started process (PID=9741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:00:27.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:00:27.318+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:00:27.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:00:27.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:00:27.359+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:00:27.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:00:27.377+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:00:27.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:00:27.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-22T18:00:57.732+0000] {processor.py:157} INFO - Started process (PID=9766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:00:57.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:00:57.735+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:00:57.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:00:57.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:00:57.769+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:00:57.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:00:57.780+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:00:57.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:00:57.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-22T18:01:28.182+0000] {processor.py:157} INFO - Started process (PID=9791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:01:28.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:01:28.187+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:01:28.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:01:28.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:01:28.226+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:01:28.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:01:28.237+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:01:28.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:01:28.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-22T18:01:58.658+0000] {processor.py:157} INFO - Started process (PID=9816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:01:58.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:01:58.663+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:01:58.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:01:58.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:01:58.691+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:01:58.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:01:58.705+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:01:58.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:01:58.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T18:02:29.040+0000] {processor.py:157} INFO - Started process (PID=9841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:02:29.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:02:29.047+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:02:29.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:02:29.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:02:29.081+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:02:29.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:02:29.094+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:02:29.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:02:29.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-22T18:02:59.517+0000] {processor.py:157} INFO - Started process (PID=9866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:02:59.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:02:59.521+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:02:59.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:02:59.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:02:59.559+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:02:59.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:02:59.570+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:02:59.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:02:59.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-22T18:03:29.999+0000] {processor.py:157} INFO - Started process (PID=9891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:03:30.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:03:30.001+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:03:30.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:03:30.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:03:30.029+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:03:30.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:03:30.040+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:03:30.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:03:30.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T18:04:00.448+0000] {processor.py:157} INFO - Started process (PID=9916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:04:00.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:04:00.451+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:04:00.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:04:00.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:04:00.481+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:04:00.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:04:00.494+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:04:00.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:04:00.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T18:04:30.945+0000] {processor.py:157} INFO - Started process (PID=9941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:04:30.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:04:30.948+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:04:30.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:04:30.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:04:30.984+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:04:30.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:04:30.997+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:04:30.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:04:31.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-22T18:05:01.430+0000] {processor.py:157} INFO - Started process (PID=9966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:05:01.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:05:01.436+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:05:01.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:05:01.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:05:01.472+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:05:01.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:05:01.485+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:05:01.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:05:01.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-22T18:05:31.843+0000] {processor.py:157} INFO - Started process (PID=9991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:05:31.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:05:31.848+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:05:31.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:05:31.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:05:31.880+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:05:31.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:05:31.894+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:05:31.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:05:31.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-22T18:06:02.283+0000] {processor.py:157} INFO - Started process (PID=10016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:06:02.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:06:02.286+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:06:02.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:06:02.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:06:02.316+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:06:02.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:06:02.326+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:06:02.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:06:02.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T18:06:32.755+0000] {processor.py:157} INFO - Started process (PID=10041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:06:32.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:06:32.761+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:06:32.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:06:32.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:06:32.797+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:06:32.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:06:32.811+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:06:32.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:06:32.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T18:07:03.218+0000] {processor.py:157} INFO - Started process (PID=10066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:07:03.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:07:03.222+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:07:03.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:07:03.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:07:03.262+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:07:03.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:07:03.274+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:07:03.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:07:03.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T18:07:33.653+0000] {processor.py:157} INFO - Started process (PID=10091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:07:33.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:07:33.655+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:07:33.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:07:33.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:07:33.691+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:07:33.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:07:33.704+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:07:33.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:07:33.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T18:08:04.150+0000] {processor.py:157} INFO - Started process (PID=10116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:08:04.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:08:04.157+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:08:04.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:08:04.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:08:04.194+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:08:04.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:08:04.205+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:08:04.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:08:04.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-22T18:08:34.631+0000] {processor.py:157} INFO - Started process (PID=10141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:08:34.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:08:34.635+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:08:34.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:08:34.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:08:34.671+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:08:34.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:08:34.683+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:08:34.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:08:34.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-22T18:09:05.063+0000] {processor.py:157} INFO - Started process (PID=10166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:09:05.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:09:05.067+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:09:05.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:09:05.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:09:05.099+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:09:05.099+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:09:05.109+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:09:05.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:09:05.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T18:09:35.421+0000] {processor.py:157} INFO - Started process (PID=10191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:09:35.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:09:35.427+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:09:35.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:09:35.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:09:35.457+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:09:35.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:09:35.467+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:09:35.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:09:35.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T18:10:05.889+0000] {processor.py:157} INFO - Started process (PID=10216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:10:05.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:10:05.893+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:10:05.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:10:05.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:10:05.932+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:10:05.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:10:05.948+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:10:05.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:10:05.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-22T18:10:36.331+0000] {processor.py:157} INFO - Started process (PID=10241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:10:36.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:10:36.333+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:10:36.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:10:36.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:10:36.358+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:10:36.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:10:36.392+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:10:36.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:10:36.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-22T18:11:06.818+0000] {processor.py:157} INFO - Started process (PID=10266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:11:06.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:11:06.822+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:11:06.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:11:06.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:11:06.856+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:11:06.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:11:06.866+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:11:06.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:11:06.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T18:11:37.275+0000] {processor.py:157} INFO - Started process (PID=10291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:11:37.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:11:37.278+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:11:37.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:11:37.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:11:37.315+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:11:37.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:11:37.328+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:11:37.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:11:37.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-22T18:12:07.745+0000] {processor.py:157} INFO - Started process (PID=10316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:12:07.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:12:07.749+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:12:07.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:12:07.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:12:07.780+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:12:07.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:12:07.791+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:12:07.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:12:07.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T18:12:38.209+0000] {processor.py:157} INFO - Started process (PID=10341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:12:38.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:12:38.214+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:12:38.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:12:38.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:12:38.240+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:12:38.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:12:38.250+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:12:38.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:12:38.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T18:13:08.668+0000] {processor.py:157} INFO - Started process (PID=10366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:13:08.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:13:08.670+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:13:08.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:13:08.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:13:08.704+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:13:08.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:13:08.716+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:13:08.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:13:08.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T18:13:39.106+0000] {processor.py:157} INFO - Started process (PID=10391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:13:39.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:13:39.111+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:13:39.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:13:39.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:13:39.146+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:13:39.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:13:39.159+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:13:39.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:13:39.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-22T18:14:09.483+0000] {processor.py:157} INFO - Started process (PID=10416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:14:09.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:14:09.486+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:14:09.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:14:09.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:14:09.515+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:14:09.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:14:09.525+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:14:09.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:14:09.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T18:14:39.979+0000] {processor.py:157} INFO - Started process (PID=10441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:14:39.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:14:39.983+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:14:39.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:14:39.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:14:40.012+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:14:40.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:14:40.021+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:14:40.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:14:40.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T18:15:10.456+0000] {processor.py:157} INFO - Started process (PID=10466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:15:10.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:15:10.460+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:15:10.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:15:10.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:15:10.497+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:15:10.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:15:10.511+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:15:10.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:15:10.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-22T18:15:40.960+0000] {processor.py:157} INFO - Started process (PID=10491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:15:40.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:15:40.966+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:15:40.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:15:40.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:15:41.011+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:15:41.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:15:41.026+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:15:41.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:15:41.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-22T18:16:11.436+0000] {processor.py:157} INFO - Started process (PID=10516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:16:11.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:16:11.439+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:16:11.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:16:11.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:16:11.469+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:16:11.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:16:11.481+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:16:11.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:16:11.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T18:16:41.880+0000] {processor.py:157} INFO - Started process (PID=10541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:16:41.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:16:41.886+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:16:41.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:16:41.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:16:41.917+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:16:41.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:16:41.926+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:16:41.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:16:41.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T18:17:12.302+0000] {processor.py:157} INFO - Started process (PID=10566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:17:12.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:17:12.305+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:17:12.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:17:12.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:17:12.346+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:17:12.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:17:12.359+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:17:12.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:17:12.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-22T18:17:42.802+0000] {processor.py:157} INFO - Started process (PID=10591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:17:42.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:17:42.805+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:17:42.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:17:42.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:17:42.835+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:17:42.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:17:42.846+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:17:42.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:17:42.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T18:18:13.289+0000] {processor.py:157} INFO - Started process (PID=10616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:18:13.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:18:13.294+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:18:13.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:18:13.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:18:13.325+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:18:13.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:18:13.334+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:18:13.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:18:13.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T18:18:43.644+0000] {processor.py:157} INFO - Started process (PID=10641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:18:43.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:18:43.648+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:18:43.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:18:43.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:18:43.682+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:18:43.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:18:43.691+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:18:43.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:18:43.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T18:19:14.097+0000] {processor.py:157} INFO - Started process (PID=10666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:19:14.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:19:14.102+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:19:14.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:19:14.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:19:14.137+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:19:14.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:19:14.150+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:19:14.150+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:19:14.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-22T18:19:44.576+0000] {processor.py:157} INFO - Started process (PID=10691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:19:44.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:19:44.580+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:19:44.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:19:44.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:19:44.607+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:19:44.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:19:44.617+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:19:44.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:19:44.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T18:20:14.986+0000] {processor.py:157} INFO - Started process (PID=10716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:20:14.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:20:14.993+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:20:14.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:20:15.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:20:15.020+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:20:15.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:20:15.029+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:20:15.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:20:15.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T18:20:45.414+0000] {processor.py:157} INFO - Started process (PID=10741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:20:45.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:20:45.416+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:20:45.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:20:45.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:20:45.445+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:20:45.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:20:45.458+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:20:45.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:20:45.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T18:21:15.798+0000] {processor.py:157} INFO - Started process (PID=10766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:21:15.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:21:15.801+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:21:15.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:21:15.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:21:15.837+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:21:15.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:21:15.849+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:21:15.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:21:15.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-22T18:21:46.271+0000] {processor.py:157} INFO - Started process (PID=10791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:21:46.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:21:46.275+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:21:46.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:21:46.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:21:46.312+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:21:46.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:21:46.326+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:21:46.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:21:46.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T18:22:16.729+0000] {processor.py:157} INFO - Started process (PID=10816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:22:16.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:22:16.734+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:22:16.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:22:16.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:22:16.768+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:22:16.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:22:16.781+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:22:16.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:22:16.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-22T18:22:47.153+0000] {processor.py:157} INFO - Started process (PID=10841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:22:47.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:22:47.157+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:22:47.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:22:47.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:22:47.194+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:22:47.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:22:47.205+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:22:47.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:22:47.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-22T18:23:17.644+0000] {processor.py:157} INFO - Started process (PID=10866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:23:17.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:23:17.650+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:23:17.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:23:17.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:23:17.690+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:23:17.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:23:17.704+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:23:17.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:23:17.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-22T18:23:48.123+0000] {processor.py:157} INFO - Started process (PID=10891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:23:48.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:23:48.127+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:23:48.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:23:48.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:23:48.163+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:23:48.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:23:48.174+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:23:48.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:23:48.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-22T18:24:18.530+0000] {processor.py:157} INFO - Started process (PID=10916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:24:18.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:24:18.533+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:24:18.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:24:18.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:24:18.559+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:24:18.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:24:18.569+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:24:18.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:24:18.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-22T18:24:49.022+0000] {processor.py:157} INFO - Started process (PID=10941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:24:49.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:24:49.026+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:24:49.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:24:49.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:24:49.060+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:24:49.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:24:49.073+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:24:49.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:24:49.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-22T18:25:19.485+0000] {processor.py:157} INFO - Started process (PID=10966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:25:19.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:25:19.489+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:25:19.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:25:19.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:25:19.520+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:25:19.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:25:19.532+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:25:19.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:25:19.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T18:25:49.894+0000] {processor.py:157} INFO - Started process (PID=10991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:25:49.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:25:49.900+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:25:49.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:25:49.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:25:49.934+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:25:49.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:25:49.944+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:25:49.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:25:49.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T18:26:20.344+0000] {processor.py:157} INFO - Started process (PID=11016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:26:20.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:26:20.349+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:26:20.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:26:20.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:26:20.384+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:26:20.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:26:20.395+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:26:20.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:26:20.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-22T18:26:50.793+0000] {processor.py:157} INFO - Started process (PID=11041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:26:50.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:26:50.801+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:26:50.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:26:50.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:26:50.853+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:26:50.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:26:50.866+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:26:50.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:26:50.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-22T18:27:21.227+0000] {processor.py:157} INFO - Started process (PID=11066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:27:21.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:27:21.231+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:27:21.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:27:21.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:27:21.265+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:27:21.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:27:21.278+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:27:21.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:27:21.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-22T18:27:51.706+0000] {processor.py:157} INFO - Started process (PID=11091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:27:51.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:27:51.710+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:27:51.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:27:51.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:27:51.748+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:27:51.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:27:51.760+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:27:51.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:27:51.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T18:28:22.185+0000] {processor.py:157} INFO - Started process (PID=11116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:28:22.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:28:22.189+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:28:22.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:28:22.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:28:22.217+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:28:22.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:28:22.229+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:28:22.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:28:22.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T18:28:52.627+0000] {processor.py:157} INFO - Started process (PID=11141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:28:52.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:28:52.631+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:28:52.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:28:52.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:28:52.669+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:28:52.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:28:52.679+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:28:52.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:28:52.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-22T18:29:23.121+0000] {processor.py:157} INFO - Started process (PID=11166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:29:23.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:29:23.128+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:29:23.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:29:23.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:29:23.166+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:29:23.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:29:23.178+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:29:23.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:29:23.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T18:29:53.611+0000] {processor.py:157} INFO - Started process (PID=11191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:29:53.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:29:53.615+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:29:53.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:29:53.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:29:53.642+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:29:53.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:29:53.654+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:29:53.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:29:53.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T18:30:24.043+0000] {processor.py:157} INFO - Started process (PID=11216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:30:24.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:30:24.048+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:30:24.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:30:24.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:30:24.078+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:30:24.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:30:24.088+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:30:24.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:30:24.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T18:30:54.514+0000] {processor.py:157} INFO - Started process (PID=11241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:30:54.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:30:54.524+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:30:54.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:30:54.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:30:54.564+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:30:54.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:30:54.578+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:30:54.578+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:30:54.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-22T18:31:24.967+0000] {processor.py:157} INFO - Started process (PID=11266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:31:24.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:31:24.970+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:31:24.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:31:24.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:31:25.001+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:31:25.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:31:25.010+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:31:25.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:31:25.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T18:31:55.390+0000] {processor.py:157} INFO - Started process (PID=11291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:31:55.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:31:55.395+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:31:55.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:31:55.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:31:55.425+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:31:55.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:31:55.437+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:31:55.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:31:55.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T18:32:25.830+0000] {processor.py:157} INFO - Started process (PID=11316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:32:25.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:32:25.838+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:32:25.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:32:25.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:32:25.875+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:32:25.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:32:25.887+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:32:25.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:32:25.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T18:32:56.329+0000] {processor.py:157} INFO - Started process (PID=11341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:32:56.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:32:56.333+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:32:56.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:32:56.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:32:56.365+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:32:56.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:32:56.377+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:32:56.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:32:56.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T18:33:26.722+0000] {processor.py:157} INFO - Started process (PID=11366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:33:26.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:33:26.730+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:33:26.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:33:26.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:33:26.773+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:33:26.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:33:26.788+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:33:26.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:33:26.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-22T18:33:57.239+0000] {processor.py:157} INFO - Started process (PID=11391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:33:57.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:33:57.244+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:33:57.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:33:57.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:33:57.275+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:33:57.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:33:57.285+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:33:57.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:33:57.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T18:34:27.625+0000] {processor.py:157} INFO - Started process (PID=11416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:34:27.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:34:27.630+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:34:27.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:34:27.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:34:27.681+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:34:27.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:34:27.695+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:34:27.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:34:27.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-22T18:34:58.147+0000] {processor.py:157} INFO - Started process (PID=11441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:34:58.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:34:58.153+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:34:58.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:34:58.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:34:58.194+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:34:58.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:34:58.205+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:34:58.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:34:58.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-22T18:35:28.569+0000] {processor.py:157} INFO - Started process (PID=11466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:35:28.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:35:28.573+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:35:28.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:35:28.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:35:28.600+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:35:28.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:35:28.611+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:35:28.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:35:28.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T18:35:58.998+0000] {processor.py:157} INFO - Started process (PID=11491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:35:59.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:35:59.004+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:35:59.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:35:59.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:35:59.044+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:35:59.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:35:59.057+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:35:59.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:35:59.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-22T18:36:29.412+0000] {processor.py:157} INFO - Started process (PID=11516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:36:29.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:36:29.416+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:36:29.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:36:29.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:36:29.447+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:36:29.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:36:29.457+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:36:29.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:36:29.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T18:36:59.893+0000] {processor.py:157} INFO - Started process (PID=11540) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:36:59.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:36:59.909+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:36:59.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:36:59.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:36:59.971+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:36:59.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:36:59.985+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:36:59.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:36:59.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-07-22T18:37:30.427+0000] {processor.py:157} INFO - Started process (PID=11566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:37:30.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:37:30.434+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:37:30.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:37:30.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:37:30.467+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:37:30.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:37:30.476+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:37:30.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:37:30.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-22T18:38:00.901+0000] {processor.py:157} INFO - Started process (PID=11591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:38:00.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:38:00.907+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:38:00.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:38:00.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:38:00.952+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:38:00.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:38:00.967+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:38:00.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:38:00.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-22T18:38:31.381+0000] {processor.py:157} INFO - Started process (PID=11616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:38:31.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:38:31.385+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:38:31.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:38:31.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:38:31.412+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:38:31.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:38:31.422+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:38:31.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:38:31.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T18:39:01.821+0000] {processor.py:157} INFO - Started process (PID=11641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:39:01.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:39:01.830+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:39:01.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:39:01.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:39:01.878+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:39:01.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:39:01.892+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:39:01.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:39:01.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-22T18:39:32.325+0000] {processor.py:157} INFO - Started process (PID=11666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:39:32.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:39:32.328+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:39:32.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:39:32.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:39:32.357+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:39:32.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:39:32.370+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:39:32.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:39:32.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T18:40:02.811+0000] {processor.py:157} INFO - Started process (PID=11691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:40:02.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:40:02.815+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:40:02.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:40:02.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:40:02.847+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:40:02.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:40:02.858+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:40:02.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:40:02.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T18:40:33.285+0000] {processor.py:157} INFO - Started process (PID=11716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:40:33.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:40:33.289+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:40:33.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:40:33.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:40:33.334+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:40:33.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:40:33.354+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:40:33.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:40:33.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-22T18:41:03.799+0000] {processor.py:157} INFO - Started process (PID=11741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:41:03.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:41:03.803+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:41:03.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:41:03.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:41:03.834+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:41:03.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:41:03.846+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:41:03.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:41:03.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T18:41:34.222+0000] {processor.py:157} INFO - Started process (PID=11766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:41:34.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:41:34.227+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:41:34.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:41:34.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:41:34.284+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:41:34.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:41:34.296+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:41:34.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:41:34.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-22T18:42:04.763+0000] {processor.py:157} INFO - Started process (PID=11791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:42:04.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:42:04.768+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:42:04.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:42:04.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:42:04.800+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:42:04.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:42:04.812+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:42:04.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:42:04.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-22T18:42:35.279+0000] {processor.py:157} INFO - Started process (PID=11816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:42:35.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:42:35.283+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:42:35.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:42:35.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:42:35.360+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:42:35.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:42:35.378+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:42:35.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:42:35.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-22T18:43:05.794+0000] {processor.py:157} INFO - Started process (PID=11841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:43:05.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:43:05.807+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:43:05.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:43:05.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:43:05.845+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:43:05.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:43:05.857+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:43:05.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:43:05.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-22T18:43:36.314+0000] {processor.py:157} INFO - Started process (PID=11866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:43:36.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:43:36.319+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:43:36.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:43:36.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:43:36.357+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:43:36.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:43:36.370+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:43:36.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:43:36.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-22T18:44:06.780+0000] {processor.py:157} INFO - Started process (PID=11891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:44:06.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:44:06.783+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:44:06.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:44:06.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:44:06.813+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:44:06.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:44:06.824+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:44:06.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:44:06.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T18:44:37.246+0000] {processor.py:157} INFO - Started process (PID=11915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:44:37.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:44:37.251+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:44:37.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:44:37.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:44:37.281+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:44:37.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:44:37.294+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:44:37.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:44:37.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T18:45:07.752+0000] {processor.py:157} INFO - Started process (PID=11941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:45:07.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:45:07.761+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:45:07.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:45:07.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:45:07.836+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:45:07.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:45:07.851+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:45:07.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:45:07.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-07-22T18:45:38.279+0000] {processor.py:157} INFO - Started process (PID=11966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:45:38.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:45:38.284+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:45:38.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:45:38.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:45:38.311+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:45:38.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:45:38.320+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:45:38.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:45:38.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T18:46:08.685+0000] {processor.py:157} INFO - Started process (PID=11991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:46:08.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:46:08.689+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:46:08.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:46:08.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:46:08.729+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:46:08.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:46:08.742+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:46:08.742+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:46:08.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-22T18:46:39.170+0000] {processor.py:157} INFO - Started process (PID=12016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:46:39.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:46:39.177+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:46:39.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:46:39.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:46:39.209+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:46:39.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:46:39.222+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:46:39.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:46:39.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-22T18:47:09.594+0000] {processor.py:157} INFO - Started process (PID=12041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:47:09.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:47:09.600+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:47:09.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:47:09.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:47:09.653+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:47:09.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:47:09.667+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:47:09.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:47:09.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-22T18:47:40.088+0000] {processor.py:157} INFO - Started process (PID=12066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:47:40.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:47:40.093+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:47:40.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:47:40.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:47:40.120+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:47:40.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:47:40.130+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:47:40.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:47:40.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T18:48:10.581+0000] {processor.py:157} INFO - Started process (PID=12091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:48:10.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:48:10.599+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:48:10.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:48:10.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:48:10.643+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:48:10.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:48:10.655+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:48:10.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:48:10.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-22T18:48:41.028+0000] {processor.py:157} INFO - Started process (PID=12116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:48:41.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:48:41.037+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:48:41.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:48:41.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:48:41.061+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:48:41.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:48:41.071+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:48:41.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:48:41.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T18:49:11.509+0000] {processor.py:157} INFO - Started process (PID=12141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:49:11.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:49:11.514+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:49:11.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:49:11.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:49:11.552+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:49:11.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:49:11.570+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:49:11.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:49:11.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-22T18:49:41.932+0000] {processor.py:157} INFO - Started process (PID=12166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:49:41.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:49:41.936+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:49:41.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:49:41.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:49:41.965+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:49:41.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:49:41.975+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:49:41.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:49:41.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T18:50:12.379+0000] {processor.py:157} INFO - Started process (PID=12191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:50:12.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:50:12.388+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:50:12.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:50:12.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:50:12.434+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:50:12.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:50:12.458+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:50:12.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:50:12.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-22T18:50:42.882+0000] {processor.py:157} INFO - Started process (PID=12216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:50:42.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:50:42.885+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:50:42.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:50:42.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:50:42.918+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:50:42.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:50:42.928+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:50:42.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:50:42.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T18:51:13.399+0000] {processor.py:157} INFO - Started process (PID=12241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:51:13.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:51:13.404+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:51:13.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:51:13.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:51:13.452+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:51:13.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:51:13.465+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:51:13.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:51:13.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-22T18:51:43.842+0000] {processor.py:157} INFO - Started process (PID=12266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:51:43.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:51:43.848+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:51:43.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:51:43.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:51:43.889+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:51:43.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:51:43.902+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:51:43.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:51:43.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-22T18:52:14.507+0000] {processor.py:157} INFO - Started process (PID=12291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:52:14.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:52:14.511+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:52:14.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:52:14.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:52:14.539+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:52:14.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:52:14.549+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:52:14.549+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:52:14.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T18:52:44.920+0000] {processor.py:157} INFO - Started process (PID=12316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:52:44.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:52:44.927+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:52:44.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:52:44.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:52:44.965+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:52:44.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:52:44.978+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:52:44.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:52:44.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-22T18:53:15.413+0000] {processor.py:157} INFO - Started process (PID=12341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:53:15.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:53:15.417+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:53:15.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:53:15.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:53:15.444+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:53:15.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:53:15.454+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:53:15.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:53:15.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T18:53:45.868+0000] {processor.py:157} INFO - Started process (PID=12366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:53:45.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:53:45.874+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:53:45.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:53:45.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:53:45.913+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:53:45.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:53:45.927+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:53:45.927+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:53:45.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-22T18:54:16.286+0000] {processor.py:157} INFO - Started process (PID=12391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:54:16.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:54:16.288+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:54:16.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:54:16.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:54:16.318+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:54:16.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:54:16.328+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:54:16.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:54:16.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T18:54:46.757+0000] {processor.py:157} INFO - Started process (PID=12415) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:54:46.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:54:46.762+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:54:46.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:54:46.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:54:46.800+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:54:46.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:54:46.814+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:54:46.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:54:46.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T18:55:17.173+0000] {processor.py:157} INFO - Started process (PID=12441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:55:17.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:55:17.176+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:55:17.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:55:17.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:55:17.209+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:55:17.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:55:17.221+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:55:17.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:55:17.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T18:55:47.679+0000] {processor.py:157} INFO - Started process (PID=12466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:55:47.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:55:47.691+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:55:47.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:55:47.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:55:47.762+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:55:47.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:55:47.777+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:55:47.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:55:47.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-07-22T18:56:18.213+0000] {processor.py:157} INFO - Started process (PID=12491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:56:18.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:56:18.222+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:56:18.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:56:18.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:56:18.278+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:56:18.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:56:18.295+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:56:18.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:56:18.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-22T18:56:48.711+0000] {processor.py:157} INFO - Started process (PID=12516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:56:48.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:56:48.714+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:56:48.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:56:48.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:56:48.742+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:56:48.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:56:48.754+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:56:48.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:56:48.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T18:57:19.067+0000] {processor.py:157} INFO - Started process (PID=12541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:57:19.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:57:19.072+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:57:19.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:57:19.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:57:19.100+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:57:19.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:57:19.111+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:57:19.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:57:19.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T18:57:49.524+0000] {processor.py:157} INFO - Started process (PID=12566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:57:49.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:57:49.528+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:57:49.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:57:49.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:57:49.575+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:57:49.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:57:49.590+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:57:49.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:57:49.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-22T18:58:20.004+0000] {processor.py:157} INFO - Started process (PID=12591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:58:20.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:58:20.006+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:58:20.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:58:20.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:58:20.028+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:58:20.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:58:20.037+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:58:20.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:58:20.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-22T18:58:50.416+0000] {processor.py:157} INFO - Started process (PID=12616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:58:50.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:58:50.420+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:58:50.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:58:50.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:58:50.448+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:58:50.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:58:50.461+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:58:50.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:58:50.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T18:59:20.822+0000] {processor.py:157} INFO - Started process (PID=12641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:59:20.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:59:20.825+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:59:20.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:59:20.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:59:20.857+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:59:20.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:59:20.872+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:59:20.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:59:20.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T18:59:51.298+0000] {processor.py:157} INFO - Started process (PID=12666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:59:51.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T18:59:51.303+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:59:51.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:59:51.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T18:59:51.333+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:59:51.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T18:59:51.342+0000] {logging_mixin.py:151} INFO - [2024-07-22T18:59:51.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T18:59:51.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T19:00:21.684+0000] {processor.py:157} INFO - Started process (PID=12691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:00:21.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:00:21.688+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:00:21.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:00:21.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:00:21.719+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:00:21.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:00:21.732+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:00:21.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:00:21.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T19:00:52.142+0000] {processor.py:157} INFO - Started process (PID=12716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:00:52.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:00:52.147+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:00:52.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:00:52.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:00:52.186+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:00:52.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:00:52.198+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:00:52.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:00:52.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-22T19:01:22.595+0000] {processor.py:157} INFO - Started process (PID=12741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:01:22.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:01:22.598+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:01:22.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:01:22.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:01:22.630+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:01:22.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:01:22.640+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:01:22.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:01:22.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T19:01:52.999+0000] {processor.py:157} INFO - Started process (PID=12766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:01:52.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:01:53.001+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:01:53.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:01:53.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:01:53.025+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:01:53.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:01:53.035+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:01:53.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:01:53.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-22T19:02:23.439+0000] {processor.py:157} INFO - Started process (PID=12791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:02:23.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:02:23.441+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:02:23.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:02:23.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:02:23.475+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:02:23.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:02:23.489+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:02:23.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:02:23.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-22T19:02:53.925+0000] {processor.py:157} INFO - Started process (PID=12816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:02:53.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:02:53.928+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:02:53.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:02:53.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:02:53.958+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:02:53.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:02:53.968+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:02:53.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:02:53.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T19:03:24.393+0000] {processor.py:157} INFO - Started process (PID=12841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:03:24.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:03:24.401+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:03:24.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:03:24.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:03:24.441+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:03:24.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:03:24.454+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:03:24.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:03:24.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-22T19:03:54.918+0000] {processor.py:157} INFO - Started process (PID=12866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:03:54.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:03:54.924+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:03:54.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:03:54.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:03:54.953+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:03:54.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:03:54.963+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:03:54.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:03:54.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T19:04:25.318+0000] {processor.py:157} INFO - Started process (PID=12891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:04:25.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:04:25.322+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:04:25.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:04:25.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:04:25.350+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:04:25.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:04:25.359+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:04:25.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:04:25.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T19:04:55.806+0000] {processor.py:157} INFO - Started process (PID=12916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:04:55.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:04:55.809+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:04:55.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:04:55.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:04:55.841+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:04:55.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:04:55.853+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:04:55.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:04:55.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T19:05:26.236+0000] {processor.py:157} INFO - Started process (PID=12941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:05:26.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:05:26.240+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:05:26.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:05:26.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:05:26.277+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:05:26.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:05:26.290+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:05:26.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:05:26.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-22T19:05:56.701+0000] {processor.py:157} INFO - Started process (PID=12966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:05:56.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:05:56.704+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:05:56.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:05:56.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:05:56.734+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:05:56.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:05:56.745+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:05:56.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:05:56.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T19:06:27.127+0000] {processor.py:157} INFO - Started process (PID=12991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:06:27.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:06:27.130+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:06:27.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:06:27.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:06:27.161+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:06:27.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:06:27.172+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:06:27.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:06:27.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T19:06:57.608+0000] {processor.py:157} INFO - Started process (PID=13016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:06:57.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:06:57.614+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:06:57.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:06:57.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:06:57.655+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:06:57.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:06:57.668+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:06:57.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:06:57.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-22T19:07:28.084+0000] {processor.py:157} INFO - Started process (PID=13041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:07:28.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:07:28.089+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:07:28.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:07:28.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:07:28.119+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:07:28.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:07:28.130+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:07:28.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:07:28.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T19:07:58.475+0000] {processor.py:157} INFO - Started process (PID=13066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:07:58.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:07:58.478+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:07:58.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:07:58.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:07:58.510+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:07:58.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:07:58.522+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:07:58.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:07:58.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T19:08:28.887+0000] {processor.py:157} INFO - Started process (PID=13091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:08:28.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:08:28.892+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:08:28.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:08:28.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:08:28.930+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:08:28.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:08:28.941+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:08:28.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:08:28.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-22T19:08:59.327+0000] {processor.py:157} INFO - Started process (PID=13116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:08:59.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:08:59.331+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:08:59.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:08:59.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:08:59.359+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:08:59.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:08:59.370+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:08:59.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:08:59.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T19:09:29.726+0000] {processor.py:157} INFO - Started process (PID=13141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:09:29.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:09:29.729+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:09:29.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:09:29.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:09:29.765+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:09:29.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:09:29.778+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:09:29.778+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:09:29.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-22T19:10:00.182+0000] {processor.py:157} INFO - Started process (PID=13166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:10:00.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:10:00.186+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:10:00.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:10:00.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:10:00.218+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:10:00.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:10:00.227+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:10:00.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:10:00.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T19:10:30.629+0000] {processor.py:157} INFO - Started process (PID=13191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:10:30.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:10:30.635+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:10:30.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:10:30.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:10:30.670+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:10:30.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:10:30.684+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:10:30.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:10:30.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-22T19:11:01.104+0000] {processor.py:157} INFO - Started process (PID=13216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:11:01.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:11:01.108+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:11:01.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:11:01.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:11:01.140+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:11:01.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:11:01.151+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:11:01.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:11:01.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T19:11:31.532+0000] {processor.py:157} INFO - Started process (PID=13241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:11:31.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:11:31.536+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:11:31.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:11:31.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:11:31.568+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:11:31.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:11:31.580+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:11:31.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:11:31.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T19:12:02.002+0000] {processor.py:157} INFO - Started process (PID=13266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:12:02.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:12:02.004+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:12:02.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:12:02.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:12:02.035+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:12:02.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:12:02.045+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:12:02.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:12:02.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T19:12:32.415+0000] {processor.py:157} INFO - Started process (PID=13291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:12:32.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:12:32.420+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:12:32.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:12:32.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:12:32.452+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:12:32.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:12:32.462+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:12:32.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:12:32.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T19:13:02.907+0000] {processor.py:157} INFO - Started process (PID=13316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:13:02.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:13:02.912+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:13:02.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:13:02.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:13:02.941+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:13:02.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:13:02.956+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:13:02.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:13:02.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-22T19:13:33.351+0000] {processor.py:157} INFO - Started process (PID=13341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:13:33.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:13:33.354+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:13:33.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:13:33.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:13:33.409+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:13:33.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:13:33.425+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:13:33.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:13:33.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-22T19:14:03.792+0000] {processor.py:157} INFO - Started process (PID=13366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:14:03.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:14:03.799+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:14:03.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:14:03.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:14:03.834+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:14:03.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:14:03.844+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:14:03.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:14:03.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-22T19:14:34.259+0000] {processor.py:157} INFO - Started process (PID=13391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:14:34.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:14:34.264+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:14:34.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:14:34.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:14:34.299+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:14:34.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:14:34.310+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:14:34.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:14:34.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-22T19:15:04.640+0000] {processor.py:157} INFO - Started process (PID=13416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:15:04.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:15:04.645+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:15:04.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:15:04.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:15:04.675+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:15:04.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:15:04.687+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:15:04.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:15:04.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T19:15:35.107+0000] {processor.py:157} INFO - Started process (PID=13441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:15:35.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:15:35.112+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:15:35.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:15:35.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:15:35.140+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:15:35.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:15:35.150+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:15:35.150+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:15:35.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T19:16:05.540+0000] {processor.py:157} INFO - Started process (PID=13466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:16:05.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:16:05.545+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:16:05.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:16:05.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:16:05.573+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:16:05.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:16:05.586+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:16:05.586+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:16:05.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T19:16:36.012+0000] {processor.py:157} INFO - Started process (PID=13491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:16:36.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:16:36.016+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:16:36.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:16:36.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:16:36.055+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:16:36.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:16:36.069+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:16:36.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:16:36.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T19:17:06.453+0000] {processor.py:157} INFO - Started process (PID=13516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:17:06.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:17:06.457+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:17:06.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:17:06.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:17:06.489+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:17:06.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:17:06.502+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:17:06.502+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:17:06.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T19:17:36.822+0000] {processor.py:157} INFO - Started process (PID=13541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:17:36.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:17:36.829+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:17:36.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:17:36.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:17:36.861+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:17:36.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:17:36.874+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:17:36.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:17:36.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-22T19:18:07.313+0000] {processor.py:157} INFO - Started process (PID=13566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:18:07.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:18:07.316+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:18:07.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:18:07.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:18:07.352+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:18:07.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:18:07.364+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:18:07.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:18:07.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-22T19:18:37.768+0000] {processor.py:157} INFO - Started process (PID=13591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:18:37.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:18:37.771+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:18:37.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:18:37.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:18:37.801+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:18:37.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:18:37.811+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:18:37.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:18:37.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T19:19:08.234+0000] {processor.py:157} INFO - Started process (PID=13616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:19:08.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:19:08.237+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:19:08.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:19:08.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:19:08.268+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:19:08.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:19:08.280+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:19:08.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:19:08.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T19:19:38.754+0000] {processor.py:157} INFO - Started process (PID=13641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:19:38.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:19:38.766+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:19:38.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:19:38.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:19:38.825+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:19:38.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:19:38.842+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:19:38.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:19:38.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-22T19:20:09.376+0000] {processor.py:157} INFO - Started process (PID=13665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:20:09.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:20:09.383+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:20:09.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:20:09.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:20:09.446+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:20:09.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:20:09.460+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:20:09.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:20:09.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-22T19:20:39.989+0000] {processor.py:157} INFO - Started process (PID=13690) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:20:39.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:20:39.997+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:20:39.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:20:40.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:20:40.057+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:20:40.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:20:40.072+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:20:40.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:20:40.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-22T19:21:10.543+0000] {processor.py:157} INFO - Started process (PID=13716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:21:10.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:21:10.551+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:21:10.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:21:10.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:21:10.596+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:21:10.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:21:10.609+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:21:10.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:21:10.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-22T19:21:41.048+0000] {processor.py:157} INFO - Started process (PID=13741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:21:41.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:21:41.057+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:21:41.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:21:41.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:21:41.100+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:21:41.099+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:21:41.114+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:21:41.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:21:41.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-22T19:22:11.611+0000] {processor.py:157} INFO - Started process (PID=13766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:22:11.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:22:11.620+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:22:11.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:22:11.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:22:11.675+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:22:11.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:22:11.689+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:22:11.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:22:11.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-22T19:22:42.138+0000] {processor.py:157} INFO - Started process (PID=13791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:22:42.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:22:42.143+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:22:42.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:22:42.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:22:42.185+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:22:42.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:22:42.199+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:22:42.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:22:42.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-22T19:23:12.663+0000] {processor.py:157} INFO - Started process (PID=13816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:23:12.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:23:12.671+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:23:12.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:23:12.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:23:12.729+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:23:12.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:23:12.750+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:23:12.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:23:12.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-22T19:23:43.296+0000] {processor.py:157} INFO - Started process (PID=13839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:23:43.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:23:43.302+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:23:43.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:23:43.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:23:43.346+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:23:43.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:23:43.361+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:23:43.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:23:43.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-22T19:24:13.786+0000] {processor.py:157} INFO - Started process (PID=13866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:24:13.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:24:13.789+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:24:13.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:24:13.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:24:13.820+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:24:13.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:24:13.831+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:24:13.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:24:13.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T19:24:44.216+0000] {processor.py:157} INFO - Started process (PID=13891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:24:44.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:24:44.221+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:24:44.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:24:44.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:24:44.272+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:24:44.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:24:44.290+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:24:44.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:24:44.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-22T19:25:14.716+0000] {processor.py:157} INFO - Started process (PID=13916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:25:14.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:25:14.719+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:25:14.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:25:14.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:25:14.746+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:25:14.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:25:14.756+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:25:14.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:25:14.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T19:25:45.267+0000] {processor.py:157} INFO - Started process (PID=13941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:25:45.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:25:45.273+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:25:45.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:25:45.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:25:45.314+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:25:45.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:25:45.328+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:25:45.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:25:45.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-22T19:26:15.731+0000] {processor.py:157} INFO - Started process (PID=13966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:26:15.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:26:15.734+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:26:15.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:26:15.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:26:15.763+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:26:15.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:26:15.774+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:26:15.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:26:15.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T19:26:46.195+0000] {processor.py:157} INFO - Started process (PID=13990) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:26:46.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:26:46.200+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:26:46.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:26:46.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:26:46.255+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:26:46.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:26:46.269+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:26:46.269+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:26:46.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-22T19:27:16.796+0000] {processor.py:157} INFO - Started process (PID=14016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:27:16.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:27:16.802+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:27:16.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:27:16.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:27:16.851+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:27:16.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:27:16.866+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:27:16.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:27:16.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-22T19:27:47.297+0000] {processor.py:157} INFO - Started process (PID=14041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:27:47.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:27:47.300+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:27:47.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:27:47.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:27:47.329+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:27:47.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:27:47.341+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:27:47.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:27:47.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T19:28:17.768+0000] {processor.py:157} INFO - Started process (PID=14066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:28:17.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:28:17.772+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:28:17.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:28:17.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:28:17.801+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:28:17.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:28:17.810+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:28:17.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:28:17.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T19:28:48.282+0000] {processor.py:157} INFO - Started process (PID=14091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:28:48.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:28:48.299+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:28:48.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:28:48.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:28:48.344+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:28:48.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:28:48.357+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:28:48.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:28:48.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-22T19:29:18.778+0000] {processor.py:157} INFO - Started process (PID=14116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:29:18.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:29:18.784+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:29:18.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:29:18.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:29:18.819+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:29:18.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:29:18.831+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:29:18.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:29:18.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-22T19:29:49.158+0000] {processor.py:157} INFO - Started process (PID=14141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:29:49.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:29:49.163+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:29:49.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:29:49.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:29:49.190+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:29:49.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:29:49.201+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:29:49.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:29:49.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T19:30:19.632+0000] {processor.py:157} INFO - Started process (PID=14166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:30:19.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:30:19.635+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:30:19.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:30:19.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:30:19.663+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:30:19.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:30:19.674+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:30:19.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:30:19.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T19:30:50.070+0000] {processor.py:157} INFO - Started process (PID=14191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:30:50.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:30:50.077+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:30:50.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:30:50.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:30:50.116+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:30:50.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:30:50.129+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:30:50.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:30:50.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-22T19:31:20.594+0000] {processor.py:157} INFO - Started process (PID=14216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:31:20.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:31:20.599+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:31:20.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:31:20.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:31:20.639+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:31:20.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:31:20.652+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:31:20.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:31:20.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T19:31:50.959+0000] {processor.py:157} INFO - Started process (PID=14241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:31:50.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:31:50.960+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:31:50.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:31:50.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:31:50.982+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:31:50.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:31:50.992+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:31:50.992+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:31:51.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-22T19:32:21.419+0000] {processor.py:157} INFO - Started process (PID=14266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:32:21.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:32:21.424+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:32:21.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:32:21.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:32:21.452+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:32:21.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:32:21.462+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:32:21.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:32:21.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T19:32:51.802+0000] {processor.py:157} INFO - Started process (PID=14291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:32:51.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:32:51.806+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:32:51.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:32:51.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:32:51.830+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:32:51.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:32:51.840+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:32:51.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:32:51.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-22T19:33:22.206+0000] {processor.py:157} INFO - Started process (PID=14316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:33:22.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:33:22.208+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:33:22.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:33:22.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:33:22.238+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:33:22.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:33:22.249+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:33:22.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:33:22.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T19:33:52.643+0000] {processor.py:157} INFO - Started process (PID=14341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:33:52.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:33:52.656+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:33:52.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:33:52.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:33:52.720+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:33:52.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:33:52.739+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:33:52.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:33:52.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-22T19:34:23.107+0000] {processor.py:157} INFO - Started process (PID=14366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:34:23.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:34:23.111+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:34:23.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:34:23.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:34:23.139+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:34:23.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:34:23.149+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:34:23.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:34:23.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T19:34:53.549+0000] {processor.py:157} INFO - Started process (PID=14391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:34:53.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:34:53.552+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:34:53.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:34:53.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:34:53.579+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:34:53.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:34:53.588+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:34:53.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:34:53.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T19:35:23.931+0000] {processor.py:157} INFO - Started process (PID=14416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:35:23.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:35:23.935+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:35:23.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:35:23.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:35:23.962+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:35:23.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:35:23.972+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:35:23.972+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:35:23.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T19:35:54.317+0000] {processor.py:157} INFO - Started process (PID=14441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:35:54.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:35:54.325+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:35:54.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:35:54.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:35:54.359+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:35:54.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:35:54.370+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:35:54.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:35:54.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-22T19:36:24.746+0000] {processor.py:157} INFO - Started process (PID=14466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:36:24.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:36:24.749+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:36:24.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:36:24.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:36:24.777+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:36:24.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:36:24.787+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:36:24.787+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:36:24.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T19:36:55.193+0000] {processor.py:157} INFO - Started process (PID=14491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:36:55.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:36:55.199+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:36:55.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:36:55.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:36:55.236+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:36:55.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:36:55.249+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:36:55.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:36:55.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T19:37:25.629+0000] {processor.py:157} INFO - Started process (PID=14516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:37:25.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:37:25.636+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:37:25.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:37:25.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:37:25.669+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:37:25.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:37:25.682+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:37:25.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:37:25.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-22T19:37:55.989+0000] {processor.py:157} INFO - Started process (PID=14541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:37:55.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:37:55.991+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:37:55.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:37:56.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:37:56.018+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:37:56.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:37:56.028+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:37:56.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:37:56.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-22T19:38:26.422+0000] {processor.py:157} INFO - Started process (PID=14566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:38:26.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:38:26.425+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:38:26.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:38:26.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:38:26.453+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:38:26.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:38:26.464+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:38:26.464+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:38:26.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T19:38:56.832+0000] {processor.py:157} INFO - Started process (PID=14591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:38:56.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:38:56.835+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:38:56.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:38:56.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:38:56.863+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:38:56.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:38:56.874+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:38:56.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:38:56.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T19:39:27.208+0000] {processor.py:157} INFO - Started process (PID=14616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:39:27.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:39:27.210+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:39:27.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:39:27.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:39:27.230+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:39:27.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:39:27.239+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:39:27.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:39:27.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-22T19:39:57.644+0000] {processor.py:157} INFO - Started process (PID=14641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:39:57.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:39:57.648+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:39:57.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:39:57.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:39:57.678+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:39:57.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:39:57.691+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:39:57.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:39:57.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T19:40:28.055+0000] {processor.py:157} INFO - Started process (PID=14666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:40:28.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:40:28.059+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:40:28.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:40:28.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:40:28.087+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:40:28.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:40:28.097+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:40:28.097+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:40:28.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T19:40:58.464+0000] {processor.py:157} INFO - Started process (PID=14691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:40:58.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:40:58.467+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:40:58.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:40:58.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:40:58.490+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:40:58.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:40:58.501+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:40:58.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:40:58.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-22T19:41:28.847+0000] {processor.py:157} INFO - Started process (PID=14716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:41:28.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:41:28.851+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:41:28.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:41:28.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:41:28.878+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:41:28.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:41:28.888+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:41:28.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:41:28.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T19:41:59.338+0000] {processor.py:157} INFO - Started process (PID=14741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:41:59.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:41:59.343+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:41:59.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:41:59.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:41:59.380+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:41:59.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:41:59.393+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:41:59.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:41:59.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T19:42:29.793+0000] {processor.py:157} INFO - Started process (PID=14766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:42:29.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:42:29.796+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:42:29.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:42:29.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:42:29.826+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:42:29.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:42:29.838+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:42:29.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:42:29.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T19:43:00.228+0000] {processor.py:157} INFO - Started process (PID=14791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:43:00.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:43:00.232+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:43:00.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:43:00.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:43:00.259+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:43:00.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:43:00.268+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:43:00.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:43:00.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T19:43:30.609+0000] {processor.py:157} INFO - Started process (PID=14816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:43:30.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:43:30.613+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:43:30.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:43:30.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:43:30.638+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:43:30.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:43:30.648+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:43:30.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:43:30.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T19:44:00.992+0000] {processor.py:157} INFO - Started process (PID=14841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:44:00.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:44:00.995+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:44:00.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:44:01.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:44:01.022+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:44:01.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:44:01.032+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:44:01.032+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:44:01.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T19:44:31.399+0000] {processor.py:157} INFO - Started process (PID=14866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:44:31.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:44:31.403+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:44:31.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:44:31.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:44:31.434+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:44:31.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:44:31.445+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:44:31.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:44:31.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T19:45:01.843+0000] {processor.py:157} INFO - Started process (PID=14891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:45:01.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:45:01.846+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:45:01.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:45:01.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:45:01.875+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:45:01.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:45:01.886+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:45:01.886+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:45:01.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T19:45:32.289+0000] {processor.py:157} INFO - Started process (PID=14916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:45:32.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:45:32.291+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:45:32.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:45:32.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:45:32.320+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:45:32.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:45:32.330+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:45:32.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:45:32.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T19:46:02.699+0000] {processor.py:157} INFO - Started process (PID=14941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:46:02.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:46:02.702+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:46:02.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:46:02.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:46:02.734+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:46:02.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:46:02.747+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:46:02.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:46:02.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T19:46:33.113+0000] {processor.py:157} INFO - Started process (PID=14966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:46:33.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:46:33.116+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:46:33.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:46:33.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:46:33.143+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:46:33.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:46:33.152+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:46:33.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:46:33.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T19:47:03.526+0000] {processor.py:157} INFO - Started process (PID=14991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:47:03.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:47:03.529+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:47:03.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:47:03.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:47:03.553+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:47:03.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:47:03.564+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:47:03.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:47:03.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T19:47:33.936+0000] {processor.py:157} INFO - Started process (PID=15016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:47:33.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:47:33.939+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:47:33.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:47:33.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:47:33.970+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:47:33.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:47:33.981+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:47:33.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:47:33.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T19:48:04.330+0000] {processor.py:157} INFO - Started process (PID=15041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:48:04.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:48:04.334+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:48:04.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:48:04.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:48:04.361+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:48:04.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:48:04.371+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:48:04.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:48:04.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T19:48:34.794+0000] {processor.py:157} INFO - Started process (PID=15066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:48:34.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:48:34.800+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:48:34.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:48:34.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:48:34.840+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:48:34.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:48:34.852+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:48:34.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:48:34.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T19:49:05.319+0000] {processor.py:157} INFO - Started process (PID=15091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:49:05.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:49:05.323+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:49:05.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:49:05.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:49:05.376+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:49:05.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:49:05.390+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:49:05.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:49:05.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-22T19:49:35.783+0000] {processor.py:157} INFO - Started process (PID=15116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:49:35.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:49:35.786+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:49:35.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:49:35.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:49:35.815+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:49:35.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:49:35.826+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:49:35.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:49:35.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T19:50:06.222+0000] {processor.py:157} INFO - Started process (PID=15141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:50:06.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:50:06.224+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:50:06.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:50:06.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:50:06.252+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:50:06.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:50:06.263+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:50:06.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:50:06.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T19:50:36.668+0000] {processor.py:157} INFO - Started process (PID=15166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:50:36.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:50:36.674+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:50:36.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:50:36.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:50:36.714+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:50:36.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:50:36.731+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:50:36.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:50:36.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-22T19:51:07.184+0000] {processor.py:157} INFO - Started process (PID=15191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:51:07.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:51:07.189+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:51:07.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:51:07.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:51:07.218+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:51:07.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:51:07.229+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:51:07.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:51:07.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T19:51:37.609+0000] {processor.py:157} INFO - Started process (PID=15216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:51:37.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:51:37.617+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:51:37.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:51:37.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:51:37.643+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:51:37.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:51:37.654+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:51:37.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:51:37.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T19:52:08.094+0000] {processor.py:157} INFO - Started process (PID=15241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:52:08.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:52:08.098+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:52:08.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:52:08.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:52:08.129+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:52:08.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:52:08.140+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:52:08.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:52:08.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T19:52:38.587+0000] {processor.py:157} INFO - Started process (PID=15266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:52:38.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:52:38.592+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:52:38.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:52:38.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:52:38.631+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:52:38.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:52:38.645+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:52:38.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:52:38.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-22T19:53:09.061+0000] {processor.py:157} INFO - Started process (PID=15291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:53:09.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:53:09.064+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:53:09.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:53:09.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:53:09.091+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:53:09.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:53:09.102+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:53:09.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:53:09.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T19:53:39.509+0000] {processor.py:157} INFO - Started process (PID=15316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:53:39.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:53:39.513+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:53:39.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:53:39.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:53:39.542+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:53:39.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:53:39.552+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:53:39.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:53:39.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T19:54:09.963+0000] {processor.py:157} INFO - Started process (PID=15341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:54:09.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:54:09.967+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:54:09.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:54:09.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:54:09.992+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:54:09.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:54:10.002+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:54:10.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:54:10.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-22T19:54:40.409+0000] {processor.py:157} INFO - Started process (PID=15366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:54:40.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:54:40.412+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:54:40.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:54:40.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:54:40.442+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:54:40.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:54:40.453+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:54:40.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:54:40.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T19:55:10.828+0000] {processor.py:157} INFO - Started process (PID=15391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:55:10.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:55:10.834+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:55:10.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:55:10.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:55:10.877+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:55:10.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:55:10.891+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:55:10.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:55:10.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-22T19:55:41.266+0000] {processor.py:157} INFO - Started process (PID=15416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:55:41.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:55:41.269+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:55:41.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:55:41.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:55:41.298+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:55:41.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:55:41.310+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:55:41.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:55:41.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T19:56:11.669+0000] {processor.py:157} INFO - Started process (PID=15441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:56:11.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:56:11.672+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:56:11.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:56:11.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:56:11.706+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:56:11.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:56:11.720+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:56:11.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:56:11.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-22T19:56:42.081+0000] {processor.py:157} INFO - Started process (PID=15466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:56:42.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:56:42.084+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:56:42.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:56:42.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:56:42.111+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:56:42.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:56:42.122+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:56:42.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:56:42.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T19:57:12.557+0000] {processor.py:157} INFO - Started process (PID=15491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:57:12.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:57:12.560+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:57:12.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:57:12.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:57:12.587+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:57:12.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:57:12.598+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:57:12.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:57:12.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T19:57:42.904+0000] {processor.py:157} INFO - Started process (PID=15516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:57:42.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:57:42.909+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:57:42.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:57:42.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:57:42.938+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:57:42.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:57:42.948+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:57:42.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:57:42.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T19:58:13.324+0000] {processor.py:157} INFO - Started process (PID=15541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:58:13.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:58:13.328+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:58:13.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:58:13.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:58:13.364+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:58:13.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:58:13.377+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:58:13.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:58:13.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-22T19:58:43.780+0000] {processor.py:157} INFO - Started process (PID=15566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:58:43.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:58:43.782+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:58:43.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:58:43.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:58:43.811+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:58:43.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:58:43.821+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:58:43.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:58:43.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T19:59:14.224+0000] {processor.py:157} INFO - Started process (PID=15591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:59:14.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:59:14.227+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:59:14.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:59:14.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:59:14.253+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:59:14.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:59:14.263+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:59:14.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:59:14.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T19:59:44.636+0000] {processor.py:157} INFO - Started process (PID=15616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:59:44.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T19:59:44.640+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:59:44.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:59:44.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T19:59:44.677+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:59:44.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T19:59:44.689+0000] {logging_mixin.py:151} INFO - [2024-07-22T19:59:44.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T19:59:44.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-22T20:00:15.084+0000] {processor.py:157} INFO - Started process (PID=15641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:00:15.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:00:15.087+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:00:15.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:00:15.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:00:15.114+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:00:15.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:00:15.125+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:00:15.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:00:15.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T20:00:45.543+0000] {processor.py:157} INFO - Started process (PID=15666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:00:45.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:00:45.548+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:00:45.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:00:45.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:00:45.580+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:00:45.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:00:45.590+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:00:45.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:00:45.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T20:01:15.919+0000] {processor.py:157} INFO - Started process (PID=15691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:01:15.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:01:15.920+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:01:15.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:01:15.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:01:15.941+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:01:15.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:01:15.950+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:01:15.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:01:15.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-22T20:01:46.344+0000] {processor.py:157} INFO - Started process (PID=15716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:01:46.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:01:46.347+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:01:46.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:01:46.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:01:46.376+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:01:46.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:01:46.388+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:01:46.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:01:46.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T20:02:16.753+0000] {processor.py:157} INFO - Started process (PID=15741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:02:16.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:02:16.758+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:02:16.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:02:16.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:02:16.788+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:02:16.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:02:16.797+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:02:16.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:02:16.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T20:02:47.082+0000] {processor.py:157} INFO - Started process (PID=15766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:02:47.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:02:47.085+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:02:47.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:02:47.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:02:47.114+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:02:47.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:02:47.123+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:02:47.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:02:47.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T20:03:17.475+0000] {processor.py:157} INFO - Started process (PID=15791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:03:17.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:03:17.478+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:03:17.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:03:17.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:03:17.507+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:03:17.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:03:17.519+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:03:17.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:03:17.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T20:03:47.868+0000] {processor.py:157} INFO - Started process (PID=15816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:03:47.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:03:47.871+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:03:47.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:03:47.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:03:47.898+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:03:47.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:03:47.908+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:03:47.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:03:47.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T20:04:18.301+0000] {processor.py:157} INFO - Started process (PID=15841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:04:18.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:04:18.312+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:04:18.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:04:18.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:04:18.367+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:04:18.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:04:18.382+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:04:18.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:04:18.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-22T20:04:48.740+0000] {processor.py:157} INFO - Started process (PID=15866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:04:48.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:04:48.744+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:04:48.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:04:48.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:04:48.776+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:04:48.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:04:48.786+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:04:48.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:04:48.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T20:05:19.103+0000] {processor.py:157} INFO - Started process (PID=15891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:05:19.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:05:19.108+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:05:19.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:05:19.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:05:19.136+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:05:19.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:05:19.147+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:05:19.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:05:19.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T20:05:49.541+0000] {processor.py:157} INFO - Started process (PID=15916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:05:49.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:05:49.545+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:05:49.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:05:49.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:05:49.572+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:05:49.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:05:49.584+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:05:49.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:05:49.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T20:06:19.992+0000] {processor.py:157} INFO - Started process (PID=15941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:06:19.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:06:19.995+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:06:19.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:06:20.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:06:20.026+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:06:20.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:06:20.036+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:06:20.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:06:20.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T20:06:50.436+0000] {processor.py:157} INFO - Started process (PID=15966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:06:50.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:06:50.441+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:06:50.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:06:50.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:06:50.473+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:06:50.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:06:50.484+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:06:50.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:06:50.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T20:07:20.917+0000] {processor.py:157} INFO - Started process (PID=15991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:07:20.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:07:20.923+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:07:20.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:07:20.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:07:20.960+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:07:20.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:07:20.973+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:07:20.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:07:20.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-22T20:07:51.371+0000] {processor.py:157} INFO - Started process (PID=16016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:07:51.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:07:51.374+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:07:51.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:07:51.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:07:51.404+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:07:51.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:07:51.415+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:07:51.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:07:51.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T20:08:21.760+0000] {processor.py:157} INFO - Started process (PID=16041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:08:21.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:08:21.762+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:08:21.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:08:21.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:08:21.788+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:08:21.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:08:21.801+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:08:21.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:08:21.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T20:08:52.149+0000] {processor.py:157} INFO - Started process (PID=16066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:08:52.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:08:52.151+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:08:52.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:08:52.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:08:52.173+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:08:52.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:08:52.183+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:08:52.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:08:52.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-22T20:09:22.542+0000] {processor.py:157} INFO - Started process (PID=16091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:09:22.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:09:22.547+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:09:22.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:09:22.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:09:22.576+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:09:22.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:09:22.587+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:09:22.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:09:22.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T20:09:53.026+0000] {processor.py:157} INFO - Started process (PID=16116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:09:53.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:09:53.029+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:09:53.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:09:53.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:09:53.057+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:09:53.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:09:53.069+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:09:53.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:09:53.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T20:10:23.407+0000] {processor.py:157} INFO - Started process (PID=16141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:10:23.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:10:23.413+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:10:23.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:10:23.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:10:23.438+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:10:23.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:10:23.448+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:10:23.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:10:23.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T20:10:53.852+0000] {processor.py:157} INFO - Started process (PID=16166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:10:53.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:10:53.854+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:10:53.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:10:53.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:10:53.881+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:10:53.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:10:53.892+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:10:53.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:10:53.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T20:11:24.234+0000] {processor.py:157} INFO - Started process (PID=16191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:11:24.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:11:24.236+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:11:24.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:11:24.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:11:24.263+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:11:24.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:11:24.276+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:11:24.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:11:24.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T20:11:54.792+0000] {processor.py:157} INFO - Started process (PID=16216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:11:54.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:11:54.805+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:11:54.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:11:54.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:11:54.851+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:11:54.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:11:54.863+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:11:54.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:11:54.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-22T20:12:25.234+0000] {processor.py:157} INFO - Started process (PID=16241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:12:25.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:12:25.236+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:12:25.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:12:25.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:12:25.264+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:12:25.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:12:25.273+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:12:25.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:12:25.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-22T20:12:55.687+0000] {processor.py:157} INFO - Started process (PID=16266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:12:55.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:12:55.692+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:12:55.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:12:55.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:12:55.718+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:12:55.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:12:55.729+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:12:55.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:12:55.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T20:13:26.145+0000] {processor.py:157} INFO - Started process (PID=16291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:13:26.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:13:26.148+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:13:26.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:13:26.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:13:26.177+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:13:26.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:13:26.188+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:13:26.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:13:26.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T20:13:56.528+0000] {processor.py:157} INFO - Started process (PID=16316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:13:56.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:13:56.533+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:13:56.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:13:56.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:13:56.559+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:13:56.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:13:56.571+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:13:56.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:13:56.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T20:14:26.943+0000] {processor.py:157} INFO - Started process (PID=16341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:14:26.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:14:26.950+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:14:26.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:14:26.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:14:26.987+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:14:26.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:14:26.998+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:14:26.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:14:27.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-22T20:14:57.390+0000] {processor.py:157} INFO - Started process (PID=16366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:14:57.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:14:57.394+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:14:57.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:14:57.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:14:57.428+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:14:57.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:14:57.438+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:14:57.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:14:57.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T20:15:27.839+0000] {processor.py:157} INFO - Started process (PID=16391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:15:27.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:15:27.841+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:15:27.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:15:27.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:15:27.872+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:15:27.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:15:27.882+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:15:27.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:15:27.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T20:15:58.262+0000] {processor.py:157} INFO - Started process (PID=16416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:15:58.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:15:58.265+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:15:58.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:15:58.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:15:58.288+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:15:58.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:15:58.297+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:15:58.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:15:58.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-22T20:16:28.658+0000] {processor.py:157} INFO - Started process (PID=16441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:16:28.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:16:28.663+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:16:28.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:16:28.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:16:28.690+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:16:28.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:16:28.700+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:16:28.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:16:28.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T20:16:59.121+0000] {processor.py:157} INFO - Started process (PID=16466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:16:59.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:16:59.124+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:16:59.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:16:59.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:16:59.156+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:16:59.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:16:59.168+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:16:59.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:16:59.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T20:17:29.608+0000] {processor.py:157} INFO - Started process (PID=16491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:17:29.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:17:29.616+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:17:29.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:17:29.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:17:29.652+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:17:29.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:17:29.664+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:17:29.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:17:29.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T20:18:00.071+0000] {processor.py:157} INFO - Started process (PID=16516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:18:00.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:18:00.074+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:18:00.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:18:00.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:18:00.100+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:18:00.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:18:00.109+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:18:00.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:18:00.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T20:18:30.443+0000] {processor.py:157} INFO - Started process (PID=16541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:18:30.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:18:30.447+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:18:30.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:18:30.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:18:30.475+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:18:30.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:18:30.486+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:18:30.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:18:30.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T20:19:00.902+0000] {processor.py:157} INFO - Started process (PID=16566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:19:00.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:19:00.905+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:19:00.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:19:00.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:19:00.933+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:19:00.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:19:00.943+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:19:00.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:19:00.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T20:19:31.283+0000] {processor.py:157} INFO - Started process (PID=16591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:19:31.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:19:31.288+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:19:31.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:19:31.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:19:31.321+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:19:31.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:19:31.331+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:19:31.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:19:31.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T20:20:01.740+0000] {processor.py:157} INFO - Started process (PID=16616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:20:01.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:20:01.744+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:20:01.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:20:01.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:20:01.778+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:20:01.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:20:01.791+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:20:01.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:20:01.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-22T20:20:32.266+0000] {processor.py:157} INFO - Started process (PID=16641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:20:32.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:20:32.271+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:20:32.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:20:32.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:20:32.301+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:20:32.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:20:32.310+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:20:32.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:20:32.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T20:21:02.690+0000] {processor.py:157} INFO - Started process (PID=16666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:21:02.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:21:02.695+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:21:02.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:21:02.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:21:02.723+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:21:02.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:21:02.733+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:21:02.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:21:02.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T20:21:33.195+0000] {processor.py:157} INFO - Started process (PID=16691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:21:33.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:21:33.203+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:21:33.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:21:33.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:21:33.243+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:21:33.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:21:33.256+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:21:33.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:21:33.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-22T20:22:03.648+0000] {processor.py:157} INFO - Started process (PID=16716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:22:03.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:22:03.654+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:22:03.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:22:03.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:22:03.701+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:22:03.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:22:03.714+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:22:03.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:22:03.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-22T20:22:34.135+0000] {processor.py:157} INFO - Started process (PID=16741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:22:34.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:22:34.139+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:22:34.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:22:34.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:22:34.174+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:22:34.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:22:34.190+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:22:34.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:22:34.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-22T20:23:04.653+0000] {processor.py:157} INFO - Started process (PID=16766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:23:04.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:23:04.659+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:23:04.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:23:04.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:23:04.707+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:23:04.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:23:04.722+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:23:04.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:23:04.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-22T20:23:35.130+0000] {processor.py:157} INFO - Started process (PID=16791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:23:35.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:23:35.137+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:23:35.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:23:35.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:23:35.167+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:23:35.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:23:35.179+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:23:35.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:23:35.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-22T20:24:05.613+0000] {processor.py:157} INFO - Started process (PID=16816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:24:05.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:24:05.623+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:24:05.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:24:05.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:24:05.668+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:24:05.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:24:05.688+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:24:05.688+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:24:05.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-22T20:24:36.173+0000] {processor.py:157} INFO - Started process (PID=16840) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:24:36.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:24:36.180+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:24:36.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:24:36.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:24:36.228+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:24:36.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:24:36.241+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:24:36.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:24:36.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-22T20:25:06.680+0000] {processor.py:157} INFO - Started process (PID=16866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:25:06.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:25:06.683+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:25:06.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:25:06.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:25:06.711+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:25:06.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:25:06.721+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:25:06.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:25:06.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T20:25:37.179+0000] {processor.py:157} INFO - Started process (PID=16891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:25:37.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:25:37.184+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:25:37.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:25:37.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:25:37.224+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:25:37.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:25:37.236+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:25:37.236+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:25:37.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T20:26:07.650+0000] {processor.py:157} INFO - Started process (PID=16916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:26:07.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:26:07.656+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:26:07.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:26:07.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:26:07.719+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:26:07.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:26:07.741+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:26:07.741+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:26:07.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-07-22T20:26:38.192+0000] {processor.py:157} INFO - Started process (PID=16941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:26:38.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:26:38.202+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:26:38.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:26:38.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:26:38.248+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:26:38.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:26:38.264+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:26:38.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:26:38.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-22T20:27:08.881+0000] {processor.py:157} INFO - Started process (PID=16966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:27:08.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:27:08.888+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:27:08.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:27:08.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:27:08.931+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:27:08.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:27:08.946+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:27:08.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:27:08.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-22T20:27:39.328+0000] {processor.py:157} INFO - Started process (PID=16991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:27:39.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:27:39.333+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:27:39.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:27:39.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:27:39.364+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:27:39.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:27:39.374+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:27:39.374+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:27:39.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T20:28:09.726+0000] {processor.py:157} INFO - Started process (PID=17016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:28:09.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:28:09.734+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:28:09.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:28:09.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:28:09.794+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:28:09.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:28:09.809+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:28:09.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:28:09.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-22T20:28:40.327+0000] {processor.py:157} INFO - Started process (PID=17041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:28:40.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:28:40.334+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:28:40.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:28:40.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:28:40.383+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:28:40.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:28:40.406+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:28:40.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:28:40.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-22T20:29:17.977+0000] {processor.py:157} INFO - Started process (PID=17066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:29:17.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:29:17.984+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:29:17.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:29:17.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:29:18.027+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:29:18.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:29:18.041+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:29:18.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:29:18.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-22T20:38:43.944+0000] {processor.py:157} INFO - Started process (PID=17093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:38:43.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:38:43.950+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:38:43.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:38:43.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:38:44.029+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:38:44.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:38:44.053+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:38:44.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:38:44.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-07-22T20:39:14.659+0000] {processor.py:157} INFO - Started process (PID=17118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:39:14.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:39:14.665+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:39:14.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:39:14.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:39:14.704+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:39:14.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:39:14.718+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:39:14.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:39:14.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-22T20:39:45.260+0000] {processor.py:157} INFO - Started process (PID=17143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:39:45.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:39:45.262+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:39:45.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:39:45.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:39:45.290+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:39:45.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:39:45.302+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:39:45.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:39:45.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T20:40:15.689+0000] {processor.py:157} INFO - Started process (PID=17168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:40:15.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:40:15.696+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:40:15.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:40:15.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:40:15.733+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:40:15.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:40:15.745+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:40:15.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:40:15.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T20:40:46.203+0000] {processor.py:157} INFO - Started process (PID=17193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:40:46.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:40:46.206+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:40:46.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:40:46.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:40:46.232+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:40:46.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:40:46.242+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:40:46.242+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:40:46.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T20:41:16.688+0000] {processor.py:157} INFO - Started process (PID=17218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:41:16.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:41:16.692+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:41:16.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:41:16.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:41:16.722+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:41:16.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:41:16.736+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:41:16.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:41:16.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-22T20:45:10.610+0000] {processor.py:157} INFO - Started process (PID=17243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:45:10.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:45:10.617+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:45:10.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:45:10.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:45:10.697+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:45:10.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:45:10.725+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:45:10.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:45:10.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-07-22T20:45:41.172+0000] {processor.py:157} INFO - Started process (PID=17269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:45:41.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:45:41.176+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:45:41.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:45:41.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:45:41.218+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:45:41.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:45:41.233+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:45:41.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:45:41.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-22T20:46:11.700+0000] {processor.py:157} INFO - Started process (PID=17294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:46:11.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:46:11.706+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:46:11.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:46:11.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:46:11.727+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:46:11.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:46:11.738+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:46:11.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:46:11.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T20:46:42.113+0000] {processor.py:157} INFO - Started process (PID=17318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:46:42.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:46:42.118+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:46:42.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:46:42.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:46:42.158+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:46:42.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:46:42.171+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:46:42.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:46:42.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-22T20:47:12.643+0000] {processor.py:157} INFO - Started process (PID=17344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:47:12.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:47:12.645+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:47:12.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:47:12.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:47:12.674+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:47:12.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:47:12.686+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:47:12.686+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:47:12.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T20:47:43.193+0000] {processor.py:157} INFO - Started process (PID=17369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:47:43.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:47:43.197+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:47:43.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:47:43.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:47:43.224+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:47:43.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:47:43.234+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:47:43.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:47:43.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T20:48:13.708+0000] {processor.py:157} INFO - Started process (PID=17394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:48:13.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:48:13.711+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:48:13.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:48:13.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:48:13.737+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:48:13.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:48:13.747+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:48:13.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:48:13.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T20:48:44.189+0000] {processor.py:157} INFO - Started process (PID=17419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:48:44.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:48:44.192+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:48:44.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:48:44.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:48:44.220+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:48:44.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:48:44.229+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:48:44.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:48:44.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T20:49:14.703+0000] {processor.py:157} INFO - Started process (PID=17444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:49:14.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:49:14.707+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:49:14.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:49:14.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:49:14.730+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:49:14.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:49:14.742+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:49:14.742+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:49:14.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-22T20:49:45.201+0000] {processor.py:157} INFO - Started process (PID=17469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:49:45.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:49:45.203+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:49:45.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:49:45.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:49:45.231+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:49:45.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:49:45.244+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:49:45.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:49:45.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T20:50:15.691+0000] {processor.py:157} INFO - Started process (PID=17493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:50:15.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:50:15.694+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:50:15.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:50:15.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:50:15.723+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:50:15.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:50:15.733+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:50:15.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:50:15.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T20:50:46.137+0000] {processor.py:157} INFO - Started process (PID=17519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:50:46.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:50:46.140+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:50:46.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:50:46.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:50:46.171+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:50:46.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:50:46.183+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:50:46.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:50:46.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T20:51:16.683+0000] {processor.py:157} INFO - Started process (PID=17544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:51:16.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:51:16.690+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:51:16.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:51:16.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:51:16.710+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:51:16.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:51:16.721+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:51:16.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:51:16.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-22T20:51:47.192+0000] {processor.py:157} INFO - Started process (PID=17569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:51:47.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:51:47.195+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:51:47.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:51:47.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:51:47.223+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:51:47.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:51:47.236+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:51:47.236+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:51:47.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T20:52:17.592+0000] {processor.py:157} INFO - Started process (PID=17594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:52:17.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:52:17.595+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:52:17.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:52:17.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:52:17.620+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:52:17.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:52:17.629+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:52:17.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:52:17.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-22T20:52:48.127+0000] {processor.py:157} INFO - Started process (PID=17619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:52:48.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:52:48.129+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:52:48.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:52:48.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:52:48.155+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:52:48.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:52:48.166+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:52:48.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:52:48.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T20:53:18.590+0000] {processor.py:157} INFO - Started process (PID=17644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:53:18.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:53:18.592+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:53:18.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:53:18.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:53:18.618+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:53:18.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:53:18.627+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:53:18.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:53:18.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T20:53:49.006+0000] {processor.py:157} INFO - Started process (PID=17669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:53:49.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:53:49.008+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:53:49.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:53:49.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:53:49.034+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:53:49.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:53:49.044+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:53:49.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:53:49.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T20:54:19.589+0000] {processor.py:157} INFO - Started process (PID=17694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:54:19.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:54:19.595+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:54:19.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:54:19.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:54:19.617+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:54:19.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:54:19.626+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:54:19.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:54:19.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-22T20:54:50.162+0000] {processor.py:157} INFO - Started process (PID=17719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:54:50.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:54:50.167+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:54:50.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:54:50.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:54:50.192+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:54:50.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:54:50.202+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:54:50.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:54:50.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T20:55:20.600+0000] {processor.py:157} INFO - Started process (PID=17744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:55:20.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:55:20.606+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:55:20.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:55:20.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:55:20.631+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:55:20.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:55:20.641+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:55:20.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:55:20.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T20:55:51.033+0000] {processor.py:157} INFO - Started process (PID=17769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:55:51.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:55:51.035+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:55:51.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:55:51.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:55:51.064+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:55:51.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:55:51.075+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:55:51.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:55:51.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T20:56:21.547+0000] {processor.py:157} INFO - Started process (PID=17794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:56:21.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:56:21.551+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:56:21.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:56:21.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:56:21.583+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:56:21.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:56:21.594+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:56:21.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:56:21.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T20:56:51.987+0000] {processor.py:157} INFO - Started process (PID=17819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:56:51.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:56:51.992+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:56:51.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:56:52.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:56:52.030+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:56:52.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:56:52.043+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:56:52.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:56:52.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-22T20:57:22.562+0000] {processor.py:157} INFO - Started process (PID=17844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:57:22.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:57:22.563+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:57:22.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:57:22.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:57:22.584+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:57:22.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:57:22.594+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:57:22.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:57:22.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-22T20:57:53.102+0000] {processor.py:157} INFO - Started process (PID=17869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:57:53.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:57:53.105+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:57:53.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:57:53.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:57:53.135+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:57:53.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:57:53.145+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:57:53.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:57:53.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T20:58:23.634+0000] {processor.py:157} INFO - Started process (PID=17894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:58:23.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:58:23.641+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:58:23.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:58:23.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:58:23.661+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:58:23.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:58:23.673+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:58:23.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:58:23.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-22T20:58:54.186+0000] {processor.py:157} INFO - Started process (PID=17919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:58:54.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:58:54.188+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:58:54.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:58:54.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:58:54.212+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:58:54.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:58:54.225+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:58:54.225+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:58:54.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-22T20:59:24.659+0000] {processor.py:157} INFO - Started process (PID=17944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:59:24.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:59:24.663+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:59:24.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:59:24.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:59:24.689+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:59:24.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:59:24.699+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:59:24.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:59:24.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T20:59:55.150+0000] {processor.py:157} INFO - Started process (PID=17969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:59:55.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T20:59:55.153+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:59:55.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:59:55.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T20:59:55.180+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:59:55.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T20:59:55.191+0000] {logging_mixin.py:151} INFO - [2024-07-22T20:59:55.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T20:59:55.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T21:00:25.593+0000] {processor.py:157} INFO - Started process (PID=17994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:00:25.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:00:25.595+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:00:25.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:00:25.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:00:25.617+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:00:25.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:00:25.629+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:00:25.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:00:25.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-22T21:00:56.071+0000] {processor.py:157} INFO - Started process (PID=18019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:00:56.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:00:56.074+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:00:56.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:00:56.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:00:56.098+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:00:56.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:00:56.107+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:00:56.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:00:56.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-22T21:01:26.510+0000] {processor.py:157} INFO - Started process (PID=18044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:01:26.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:01:26.513+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:01:26.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:01:26.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:01:26.538+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:01:26.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:01:26.547+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:01:26.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:01:26.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T21:01:56.907+0000] {processor.py:157} INFO - Started process (PID=18069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:01:56.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:01:56.911+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:01:56.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:01:56.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:01:56.937+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:01:56.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:01:56.948+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:01:56.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:01:56.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T21:02:27.413+0000] {processor.py:157} INFO - Started process (PID=18094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:02:27.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:02:27.418+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:02:27.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:02:27.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:02:27.456+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:02:27.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:02:27.470+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:02:27.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:02:27.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-22T21:02:57.877+0000] {processor.py:157} INFO - Started process (PID=18119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:02:57.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:02:57.880+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:02:57.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:02:57.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:02:57.908+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:02:57.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:02:57.920+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:02:57.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:02:57.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T21:03:28.347+0000] {processor.py:157} INFO - Started process (PID=18144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:03:28.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:03:28.356+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:03:28.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:03:28.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:03:28.375+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:03:28.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:03:28.384+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:03:28.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:03:28.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-22T21:03:58.932+0000] {processor.py:157} INFO - Started process (PID=18169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:03:58.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:03:58.934+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:03:58.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:03:58.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:03:58.963+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:03:58.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:03:58.974+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:03:58.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:03:58.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T21:04:29.435+0000] {processor.py:157} INFO - Started process (PID=18194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:04:29.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:04:29.438+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:04:29.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:04:29.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:04:29.465+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:04:29.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:04:29.475+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:04:29.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:04:29.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T21:04:59.867+0000] {processor.py:157} INFO - Started process (PID=18219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:04:59.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:04:59.870+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:04:59.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:04:59.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:04:59.899+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:04:59.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:04:59.910+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:04:59.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:04:59.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T21:05:30.330+0000] {processor.py:157} INFO - Started process (PID=18244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:05:30.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:05:30.336+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:05:30.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:05:30.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:05:30.361+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:05:30.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:05:30.373+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:05:30.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:05:30.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T21:06:00.787+0000] {processor.py:157} INFO - Started process (PID=18269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:06:00.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:06:00.789+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:06:00.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:06:00.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:06:00.817+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:06:00.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:06:00.830+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:06:00.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:06:00.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T21:06:31.299+0000] {processor.py:157} INFO - Started process (PID=18294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:06:31.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:06:31.303+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:06:31.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:06:31.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:06:31.338+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:06:31.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:06:31.351+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:06:31.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:06:31.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-22T21:07:01.773+0000] {processor.py:157} INFO - Started process (PID=18319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:07:01.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:07:01.778+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:07:01.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:07:01.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:07:01.803+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:07:01.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:07:01.814+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:07:01.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:07:01.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T21:07:32.216+0000] {processor.py:157} INFO - Started process (PID=18344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:07:32.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:07:32.218+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:07:32.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:07:32.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:07:32.246+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:07:32.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:07:32.257+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:07:32.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:07:32.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T21:08:02.618+0000] {processor.py:157} INFO - Started process (PID=18369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:08:02.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:08:02.625+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:08:02.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:08:02.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:08:02.645+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:08:02.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:08:02.654+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:08:02.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:08:02.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-22T21:08:33.021+0000] {processor.py:157} INFO - Started process (PID=18394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:08:33.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:08:33.024+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:08:33.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:08:33.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:08:33.054+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:08:33.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:08:33.067+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:08:33.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:08:33.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T21:09:03.513+0000] {processor.py:157} INFO - Started process (PID=18419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:09:03.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:09:03.515+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:09:03.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:09:03.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:09:03.541+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:09:03.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:09:03.552+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:09:03.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:09:03.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T21:09:33.965+0000] {processor.py:157} INFO - Started process (PID=18444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:09:33.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:09:33.970+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:09:33.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:09:33.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:09:33.996+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:09:33.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:09:34.007+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:09:34.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:09:34.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T21:10:04.456+0000] {processor.py:157} INFO - Started process (PID=18469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:10:04.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:10:04.460+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:10:04.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:10:04.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:10:04.495+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:10:04.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:10:04.506+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:10:04.506+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:10:04.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T21:10:34.927+0000] {processor.py:157} INFO - Started process (PID=18494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:10:34.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:10:34.931+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:10:34.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:10:34.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:10:34.956+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:10:34.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:10:34.966+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:10:34.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:10:34.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T21:11:05.434+0000] {processor.py:157} INFO - Started process (PID=18519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:11:05.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:11:05.437+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:11:05.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:11:05.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:11:05.465+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:11:05.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:11:05.477+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:11:05.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:11:05.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T21:11:35.856+0000] {processor.py:157} INFO - Started process (PID=18544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:11:35.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:11:35.858+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:11:35.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:11:35.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:11:35.883+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:11:35.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:11:35.895+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:11:35.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:11:35.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T21:12:06.278+0000] {processor.py:157} INFO - Started process (PID=18569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:12:06.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:12:06.283+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:12:06.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:12:06.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:12:06.311+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:12:06.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:12:06.322+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:12:06.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:12:06.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T21:12:36.723+0000] {processor.py:157} INFO - Started process (PID=18594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:12:36.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:12:36.726+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:12:36.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:12:36.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:12:36.761+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:12:36.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:12:36.773+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:12:36.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:12:36.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T21:13:07.209+0000] {processor.py:157} INFO - Started process (PID=18619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:13:07.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:13:07.212+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:13:07.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:13:07.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:13:07.246+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:13:07.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:13:07.258+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:13:07.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:13:07.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-22T21:13:37.747+0000] {processor.py:157} INFO - Started process (PID=18644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:13:37.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:13:37.754+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:13:37.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:13:37.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:13:37.775+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:13:37.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:13:37.784+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:13:37.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:13:37.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T21:14:08.253+0000] {processor.py:157} INFO - Started process (PID=18668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:14:08.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:14:08.260+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:14:08.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:14:08.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:14:08.279+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:14:08.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:14:08.288+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:14:08.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:14:08.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-22T21:14:38.748+0000] {processor.py:157} INFO - Started process (PID=18694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:14:38.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:14:38.752+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:14:38.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:14:38.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:14:38.778+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:14:38.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:14:38.788+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:14:38.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:14:38.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T21:15:09.207+0000] {processor.py:157} INFO - Started process (PID=18719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:15:09.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:15:09.209+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:15:09.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:15:09.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:15:09.236+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:15:09.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:15:09.247+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:15:09.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:15:09.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T21:15:39.628+0000] {processor.py:157} INFO - Started process (PID=18744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:15:39.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:15:39.631+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:15:39.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:15:39.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:15:39.658+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:15:39.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:15:39.668+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:15:39.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:15:39.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T21:16:10.090+0000] {processor.py:157} INFO - Started process (PID=18769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:16:10.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:16:10.097+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:16:10.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:16:10.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:16:10.118+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:16:10.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:16:10.127+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:16:10.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:16:10.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-22T21:16:40.590+0000] {processor.py:157} INFO - Started process (PID=18794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:16:40.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:16:40.594+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:16:40.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:16:40.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:16:40.631+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:16:40.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:16:40.643+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:16:40.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:16:40.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-22T21:17:11.054+0000] {processor.py:157} INFO - Started process (PID=18819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:17:11.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:17:11.057+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:17:11.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:17:11.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:17:11.088+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:17:11.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:17:11.100+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:17:11.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:17:11.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T21:17:41.563+0000] {processor.py:157} INFO - Started process (PID=18843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:17:41.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:17:41.566+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:17:41.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:17:41.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:17:41.589+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:17:41.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:17:41.598+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:17:41.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:17:41.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-22T21:18:12.125+0000] {processor.py:157} INFO - Started process (PID=18869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:18:12.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:18:12.128+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:18:12.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:18:12.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:18:12.153+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:18:12.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:18:12.163+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:18:12.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:18:12.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-22T21:18:42.530+0000] {processor.py:157} INFO - Started process (PID=18894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:18:42.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:18:42.534+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:18:42.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:18:42.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:18:42.562+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:18:42.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:18:42.572+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:18:42.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:18:42.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T21:19:13.027+0000] {processor.py:157} INFO - Started process (PID=18919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:19:13.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:19:13.030+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:19:13.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:19:13.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:19:13.058+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:19:13.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:19:13.067+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:19:13.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:19:13.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T21:19:43.563+0000] {processor.py:157} INFO - Started process (PID=18944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:19:43.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:19:43.566+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:19:43.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:19:43.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:19:43.594+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:19:43.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:19:43.605+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:19:43.605+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:19:43.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T21:20:14.024+0000] {processor.py:157} INFO - Started process (PID=18969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:20:14.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:20:14.025+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:20:14.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:20:14.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:20:14.046+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:20:14.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:20:14.059+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:20:14.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:20:14.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-22T21:20:44.448+0000] {processor.py:157} INFO - Started process (PID=18994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:20:44.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:20:44.451+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:20:44.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:20:44.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:20:44.479+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:20:44.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:20:44.492+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:20:44.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:20:44.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T21:21:14.881+0000] {processor.py:157} INFO - Started process (PID=19019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:21:14.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:21:14.884+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:21:14.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:21:14.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:21:14.909+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:21:14.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:21:14.919+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:21:14.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:21:14.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T21:21:45.385+0000] {processor.py:157} INFO - Started process (PID=19044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:21:45.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:21:45.388+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:21:45.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:21:45.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:21:45.414+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:21:45.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:21:45.424+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:21:45.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:21:45.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T21:22:15.838+0000] {processor.py:157} INFO - Started process (PID=19069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:22:15.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:22:15.841+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:22:15.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:22:15.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:22:15.878+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:22:15.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:22:15.892+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:22:15.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:22:15.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-22T21:22:46.322+0000] {processor.py:157} INFO - Started process (PID=19094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:22:46.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:22:46.325+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:22:46.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:22:46.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:22:46.353+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:22:46.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:22:46.367+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:22:46.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:22:46.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T21:23:16.808+0000] {processor.py:157} INFO - Started process (PID=19119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:23:16.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:23:16.811+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:23:16.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:23:16.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:23:16.838+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:23:16.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:23:16.849+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:23:16.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:23:16.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T21:23:47.257+0000] {processor.py:157} INFO - Started process (PID=19144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:23:47.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:23:47.260+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:23:47.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:23:47.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:23:47.289+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:23:47.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:23:47.300+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:23:47.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:23:47.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T21:24:17.674+0000] {processor.py:157} INFO - Started process (PID=19169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:24:17.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:24:17.681+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:24:17.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:24:17.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:24:17.705+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:24:17.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:24:17.715+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:24:17.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:24:17.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T21:24:48.174+0000] {processor.py:157} INFO - Started process (PID=19194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:24:48.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:24:48.178+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:24:48.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:24:48.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:24:48.208+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:24:48.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:24:48.218+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:24:48.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:24:48.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T21:25:18.642+0000] {processor.py:157} INFO - Started process (PID=19219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:25:18.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:25:18.645+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:25:18.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:25:18.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:25:18.671+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:25:18.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:25:18.683+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:25:18.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:25:18.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T21:25:49.035+0000] {processor.py:157} INFO - Started process (PID=19243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:25:49.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:25:49.038+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:25:49.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:25:49.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:25:49.073+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:25:49.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:25:49.088+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:25:49.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:25:49.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-22T21:26:19.463+0000] {processor.py:157} INFO - Started process (PID=19269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:26:19.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:26:19.467+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:26:19.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:26:19.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:26:19.495+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:26:19.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:26:19.505+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:26:19.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:26:19.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T21:26:49.916+0000] {processor.py:157} INFO - Started process (PID=19294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:26:49.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:26:49.918+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:26:49.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:26:49.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:26:49.940+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:26:49.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:26:49.950+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:26:49.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:26:49.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-22T21:27:20.411+0000] {processor.py:157} INFO - Started process (PID=19319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:27:20.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:27:20.414+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:27:20.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:27:20.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:27:20.444+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:27:20.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:27:20.453+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:27:20.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:27:20.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T21:27:50.918+0000] {processor.py:157} INFO - Started process (PID=19344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:27:50.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:27:50.923+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:27:50.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:27:50.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:27:50.957+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:27:50.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:27:50.969+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:27:50.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:27:50.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-22T21:28:21.495+0000] {processor.py:157} INFO - Started process (PID=19369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:28:21.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:28:21.501+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:28:21.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:28:21.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:28:21.520+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:28:21.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:28:21.529+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:28:21.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:28:21.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-22T21:28:51.940+0000] {processor.py:157} INFO - Started process (PID=19394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:28:51.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:28:51.949+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:28:51.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:28:51.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:28:51.971+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:28:51.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:28:51.982+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:28:51.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:28:51.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T21:29:22.419+0000] {processor.py:157} INFO - Started process (PID=19419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:29:22.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:29:22.421+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:29:22.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:29:22.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:29:22.447+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:29:22.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:29:22.456+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:29:22.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:29:22.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T21:29:52.847+0000] {processor.py:157} INFO - Started process (PID=19444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:29:52.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:29:52.850+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:29:52.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:29:52.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:29:52.877+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:29:52.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:29:52.889+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:29:52.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:29:52.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T21:30:23.305+0000] {processor.py:157} INFO - Started process (PID=19469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:30:23.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:30:23.308+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:30:23.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:30:23.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:30:23.336+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:30:23.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:30:23.345+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:30:23.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:30:23.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T21:30:53.817+0000] {processor.py:157} INFO - Started process (PID=19494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:30:53.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:30:53.821+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:30:53.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:30:53.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:30:53.859+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:30:53.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:30:53.872+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:30:53.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:30:53.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T21:31:24.374+0000] {processor.py:157} INFO - Started process (PID=19519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:31:24.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:31:24.377+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:31:24.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:31:24.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:31:24.403+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:31:24.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:31:24.414+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:31:24.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:31:24.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T21:31:54.921+0000] {processor.py:157} INFO - Started process (PID=19544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:31:54.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:31:54.924+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:31:54.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:31:54.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:31:54.953+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:31:54.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:31:54.965+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:31:54.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:31:54.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T21:32:25.458+0000] {processor.py:157} INFO - Started process (PID=19569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:32:25.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:32:25.462+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:32:25.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:32:25.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:32:25.491+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:32:25.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:32:25.504+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:32:25.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:32:25.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T21:32:55.878+0000] {processor.py:157} INFO - Started process (PID=19594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:32:55.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:32:55.880+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:32:55.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:32:55.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:32:55.907+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:32:55.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:32:55.916+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:32:55.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:32:55.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-22T21:33:26.290+0000] {processor.py:157} INFO - Started process (PID=19619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:33:26.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:33:26.292+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:33:26.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:33:26.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:33:26.320+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:33:26.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:33:26.332+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:33:26.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:33:26.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T21:33:56.736+0000] {processor.py:157} INFO - Started process (PID=19644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:33:56.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:33:56.742+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:33:56.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:33:56.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:33:56.797+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:33:56.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:33:56.812+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:33:56.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:33:56.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-22T21:34:27.212+0000] {processor.py:157} INFO - Started process (PID=19669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:34:27.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:34:27.217+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:34:27.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:34:27.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:34:27.239+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:34:27.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:34:27.248+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:34:27.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:34:27.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-22T21:34:57.626+0000] {processor.py:157} INFO - Started process (PID=19694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:34:57.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:34:57.631+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:34:57.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:34:57.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:34:57.656+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:34:57.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:34:57.667+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:34:57.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:34:57.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T21:35:28.124+0000] {processor.py:157} INFO - Started process (PID=19719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:35:28.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:35:28.129+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:35:28.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:35:28.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:35:28.159+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:35:28.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:35:28.170+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:35:28.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:35:28.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-22T21:35:58.550+0000] {processor.py:157} INFO - Started process (PID=19744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:35:58.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:35:58.554+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:35:58.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:35:58.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:35:58.614+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:35:58.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:35:58.628+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:35:58.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:35:58.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-22T21:36:29.114+0000] {processor.py:157} INFO - Started process (PID=19769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:36:29.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:36:29.116+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:36:29.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:36:29.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:36:29.140+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:36:29.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:36:29.152+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:36:29.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:36:29.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T21:36:59.512+0000] {processor.py:157} INFO - Started process (PID=19794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:36:59.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:36:59.514+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:36:59.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:36:59.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:36:59.543+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:36:59.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:36:59.556+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:36:59.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:36:59.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T21:37:30.048+0000] {processor.py:157} INFO - Started process (PID=19819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:37:30.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:37:30.055+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:37:30.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:37:30.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:37:30.078+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:37:30.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:37:30.087+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:37:30.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:37:30.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T21:38:00.527+0000] {processor.py:157} INFO - Started process (PID=19844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:38:00.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:38:00.530+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:38:00.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:38:00.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:38:00.556+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:38:00.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:38:00.564+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:38:00.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:38:00.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-22T21:38:30.947+0000] {processor.py:157} INFO - Started process (PID=19869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:38:30.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:38:30.950+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:38:30.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:38:30.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:38:30.975+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:38:30.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:38:30.985+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:38:30.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:38:30.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-22T21:39:01.382+0000] {processor.py:157} INFO - Started process (PID=19894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:39:01.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:39:01.390+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:39:01.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:39:01.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:39:01.414+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:39:01.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:39:01.425+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:39:01.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:39:01.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T21:39:31.955+0000] {processor.py:157} INFO - Started process (PID=19919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:39:31.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:39:31.960+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:39:31.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:39:31.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:39:31.995+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:39:31.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:39:32.009+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:39:32.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:39:32.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-22T21:40:02.475+0000] {processor.py:157} INFO - Started process (PID=19944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:40:02.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:40:02.478+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:40:02.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:40:02.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:40:02.504+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:40:02.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:40:02.514+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:40:02.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:40:02.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T21:40:32.970+0000] {processor.py:157} INFO - Started process (PID=19969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:40:32.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:40:32.974+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:40:32.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:40:32.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:40:33.000+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:40:33.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:40:33.011+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:40:33.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:40:33.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T21:41:03.411+0000] {processor.py:157} INFO - Started process (PID=19994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:41:03.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:41:03.413+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:41:03.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:41:03.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:41:03.445+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:41:03.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:41:03.456+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:41:03.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:41:03.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T21:41:33.961+0000] {processor.py:157} INFO - Started process (PID=20019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:41:33.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:41:33.965+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:41:33.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:41:33.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:41:33.993+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:41:33.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:41:34.002+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:41:34.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:41:34.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T21:42:04.471+0000] {processor.py:157} INFO - Started process (PID=20044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:42:04.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:42:04.480+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:42:04.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:42:04.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:42:04.500+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:42:04.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:42:04.509+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:42:04.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:42:04.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T21:42:34.923+0000] {processor.py:157} INFO - Started process (PID=20069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:42:34.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:42:34.926+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:42:34.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:42:34.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:42:34.954+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:42:34.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:42:34.967+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:42:34.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:42:34.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T21:43:05.416+0000] {processor.py:157} INFO - Started process (PID=20094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:43:05.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:43:05.419+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:43:05.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:43:05.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:43:05.446+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:43:05.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:43:05.458+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:43:05.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:43:05.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T21:43:35.898+0000] {processor.py:157} INFO - Started process (PID=20119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:43:35.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:43:35.900+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:43:35.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:43:35.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:43:35.925+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:43:35.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:43:35.937+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:43:35.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:43:35.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T21:44:06.381+0000] {processor.py:157} INFO - Started process (PID=20144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:44:06.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:44:06.384+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:44:06.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:44:06.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:44:06.411+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:44:06.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:44:06.421+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:44:06.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:44:06.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T21:44:36.738+0000] {processor.py:157} INFO - Started process (PID=20168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:44:36.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:44:36.742+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:44:36.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:44:36.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:44:36.771+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:44:36.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:44:36.804+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:44:36.804+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:44:36.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-22T21:45:07.334+0000] {processor.py:157} INFO - Started process (PID=20194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:45:07.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:45:07.337+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:45:07.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:45:07.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:45:07.364+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:45:07.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:45:07.373+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:45:07.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:45:07.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T21:45:37.806+0000] {processor.py:157} INFO - Started process (PID=20219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:45:37.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:45:37.810+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:45:37.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:45:37.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:45:37.836+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:45:37.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:45:37.847+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:45:37.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:45:37.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T21:46:08.335+0000] {processor.py:157} INFO - Started process (PID=20244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:46:08.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:46:08.339+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:46:08.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:46:08.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:46:08.363+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:46:08.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:46:08.372+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:46:08.372+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:46:08.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-22T21:46:38.802+0000] {processor.py:157} INFO - Started process (PID=20269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:46:38.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:46:38.809+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:46:38.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:46:38.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:46:38.831+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:46:38.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:46:38.841+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:46:38.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:46:38.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-22T21:47:09.280+0000] {processor.py:157} INFO - Started process (PID=20294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:47:09.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:47:09.283+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:47:09.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:47:09.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:47:09.312+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:47:09.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:47:09.322+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:47:09.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:47:09.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T21:47:39.775+0000] {processor.py:157} INFO - Started process (PID=20319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:47:39.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T21:47:39.778+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:47:39.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:47:39.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T21:47:39.816+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:47:39.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T21:47:39.830+0000] {logging_mixin.py:151} INFO - [2024-07-22T21:47:39.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T21:47:39.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-22T22:03:43.657+0000] {processor.py:157} INFO - Started process (PID=20346) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:03:43.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:03:43.664+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:03:43.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:03:43.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:03:43.714+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:03:43.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:03:43.740+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:03:43.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:03:43.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-07-22T22:04:14.241+0000] {processor.py:157} INFO - Started process (PID=20371) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:04:14.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:04:14.248+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:04:14.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:04:14.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:04:14.281+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:04:14.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:04:14.293+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:04:14.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:04:14.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-22T22:04:44.646+0000] {processor.py:157} INFO - Started process (PID=20396) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:04:44.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:04:44.651+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:04:44.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:04:44.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:04:44.691+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:04:44.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:04:44.703+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:04:44.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:04:44.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T22:05:15.234+0000] {processor.py:157} INFO - Started process (PID=20421) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:05:15.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:05:15.239+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:05:15.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:05:15.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:05:15.264+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:05:15.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:05:15.273+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:05:15.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:05:15.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-22T22:05:45.653+0000] {processor.py:157} INFO - Started process (PID=20446) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:05:45.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:05:45.655+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:05:45.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:05:45.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:05:45.679+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:05:45.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:05:45.688+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:05:45.688+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:05:45.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-22T22:06:16.140+0000] {processor.py:157} INFO - Started process (PID=20471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:06:16.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:06:16.147+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:06:16.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:06:16.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:06:16.168+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:06:16.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:06:16.180+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:06:16.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:06:16.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T22:06:46.506+0000] {processor.py:157} INFO - Started process (PID=20496) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:06:46.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:06:46.510+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:06:46.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:06:46.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:06:46.533+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:06:46.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:06:46.543+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:06:46.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:06:46.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-22T22:07:17.023+0000] {processor.py:157} INFO - Started process (PID=20521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:07:17.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:07:17.026+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:07:17.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:07:17.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:07:17.055+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:07:17.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:07:17.066+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:07:17.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:07:17.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T22:07:47.472+0000] {processor.py:157} INFO - Started process (PID=20546) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:07:47.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:07:47.475+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:07:47.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:07:47.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:07:47.500+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:07:47.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:07:47.510+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:07:47.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:07:47.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T22:08:17.992+0000] {processor.py:157} INFO - Started process (PID=20571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:08:17.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:08:17.995+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:08:17.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:08:18.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:08:18.025+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:08:18.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:08:18.035+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:08:18.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:08:18.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T22:08:48.583+0000] {processor.py:157} INFO - Started process (PID=20596) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:08:48.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:08:48.587+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:08:48.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:08:48.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:08:48.624+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:08:48.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:08:48.636+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:08:48.636+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:08:48.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T22:09:19.027+0000] {processor.py:157} INFO - Started process (PID=20621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:09:19.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:09:19.030+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:09:19.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:09:19.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:09:19.063+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:09:19.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:09:19.072+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:09:19.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:09:19.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T22:09:49.492+0000] {processor.py:157} INFO - Started process (PID=20646) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:09:49.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:09:49.494+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:09:49.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:09:49.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:09:49.523+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:09:49.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:09:49.533+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:09:49.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:09:49.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T22:10:20.020+0000] {processor.py:157} INFO - Started process (PID=20671) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:10:20.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:10:20.023+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:10:20.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:10:20.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:10:20.050+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:10:20.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:10:20.061+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:10:20.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:10:20.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T22:10:50.541+0000] {processor.py:157} INFO - Started process (PID=20696) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:10:50.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:10:50.543+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:10:50.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:10:50.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:10:50.570+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:10:50.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:10:50.582+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:10:50.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:10:50.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T22:11:20.960+0000] {processor.py:157} INFO - Started process (PID=20721) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:11:20.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:11:20.963+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:11:20.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:11:20.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:11:20.990+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:11:20.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:11:21.000+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:11:21.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:11:21.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-22T22:11:51.514+0000] {processor.py:157} INFO - Started process (PID=20746) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:11:51.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:11:51.516+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:11:51.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:11:51.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:11:51.541+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:11:51.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:11:51.551+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:11:51.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:11:51.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-22T22:12:21.972+0000] {processor.py:157} INFO - Started process (PID=20771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:12:21.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:12:21.975+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:12:21.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:12:21.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:12:21.996+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:12:21.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:12:22.005+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:12:22.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:12:22.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-22T22:12:52.467+0000] {processor.py:157} INFO - Started process (PID=20796) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:12:52.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:12:52.469+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:12:52.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:12:52.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:12:52.495+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:12:52.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:12:52.506+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:12:52.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:12:52.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T22:13:23.014+0000] {processor.py:157} INFO - Started process (PID=20821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:13:23.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:13:23.018+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:13:23.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:13:23.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:13:23.048+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:13:23.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:13:23.058+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:13:23.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:13:23.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T22:13:53.528+0000] {processor.py:157} INFO - Started process (PID=20846) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:13:53.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:13:53.532+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:13:53.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:13:53.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:13:53.570+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:13:53.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:13:53.582+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:13:53.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:13:53.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-22T22:14:24.126+0000] {processor.py:157} INFO - Started process (PID=20871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:14:24.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:14:24.131+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:14:24.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:14:24.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:14:24.158+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:14:24.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:14:24.169+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:14:24.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:14:24.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T22:14:54.605+0000] {processor.py:157} INFO - Started process (PID=20896) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:14:54.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:14:54.611+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:14:54.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:14:54.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:14:54.638+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:14:54.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:14:54.648+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:14:54.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:14:54.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T22:15:25.113+0000] {processor.py:157} INFO - Started process (PID=20921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:15:25.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:15:25.118+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:15:25.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:15:25.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:15:25.143+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:15:25.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:15:25.156+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:15:25.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:15:25.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.305 seconds
[2024-07-22T22:15:55.763+0000] {processor.py:157} INFO - Started process (PID=20946) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:15:55.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:15:55.767+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:15:55.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:15:55.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:15:55.798+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:15:55.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:15:55.811+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:15:55.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:15:55.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T22:16:26.209+0000] {processor.py:157} INFO - Started process (PID=20971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:16:26.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:16:26.213+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:16:26.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:16:26.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:16:26.243+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:16:26.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:16:26.254+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:16:26.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:16:26.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T22:16:56.734+0000] {processor.py:157} INFO - Started process (PID=20996) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:16:56.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:16:56.738+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:16:56.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:16:56.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:16:56.777+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:16:56.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:16:56.789+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:16:56.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:16:56.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-22T22:17:27.166+0000] {processor.py:157} INFO - Started process (PID=21021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:17:27.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:17:27.168+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:17:27.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:17:27.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:17:27.193+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:17:27.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:17:27.204+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:17:27.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:17:27.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-22T22:17:57.696+0000] {processor.py:157} INFO - Started process (PID=21046) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:17:57.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:17:57.699+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:17:57.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:17:57.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:17:57.727+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:17:57.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:17:57.739+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:17:57.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:17:57.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T22:18:28.186+0000] {processor.py:157} INFO - Started process (PID=21071) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:18:28.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:18:28.191+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:18:28.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:18:28.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:18:28.220+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:18:28.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:18:28.233+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:18:28.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:18:28.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T22:18:58.707+0000] {processor.py:157} INFO - Started process (PID=21096) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:18:58.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:18:58.711+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:18:58.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:18:58.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:18:58.739+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:18:58.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:18:58.750+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:18:58.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:18:58.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T22:19:29.179+0000] {processor.py:157} INFO - Started process (PID=21121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:19:29.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:19:29.182+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:19:29.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:19:29.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:19:29.210+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:19:29.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:19:29.220+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:19:29.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:19:29.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T22:19:59.627+0000] {processor.py:157} INFO - Started process (PID=21146) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:19:59.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:19:59.637+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:19:59.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:19:59.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:19:59.660+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:19:59.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:19:59.669+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:19:59.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:19:59.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T22:20:30.098+0000] {processor.py:157} INFO - Started process (PID=21170) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:20:30.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:20:30.103+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:20:30.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:20:30.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:20:30.142+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:20:30.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:20:30.154+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:20:30.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:20:30.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T22:21:00.685+0000] {processor.py:157} INFO - Started process (PID=21196) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:21:00.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:21:00.689+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:21:00.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:21:00.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:21:00.716+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:21:00.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:21:00.727+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:21:00.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:21:00.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.186 seconds
[2024-07-22T22:21:31.381+0000] {processor.py:157} INFO - Started process (PID=21221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:21:31.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:21:31.386+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:21:31.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:21:31.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:21:31.419+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:21:31.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:21:31.432+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:21:31.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:21:31.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-22T22:22:01.944+0000] {processor.py:157} INFO - Started process (PID=21246) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:22:01.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:22:01.951+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:22:01.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:22:01.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:22:01.989+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:22:01.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:22:02.001+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:22:02.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:22:02.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T22:22:32.440+0000] {processor.py:157} INFO - Started process (PID=21271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:22:32.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:22:32.445+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:22:32.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:22:32.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:22:32.474+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:22:32.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:22:32.486+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:22:32.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:22:32.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T22:23:02.858+0000] {processor.py:157} INFO - Started process (PID=21296) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:23:02.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:23:02.861+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:23:02.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:23:02.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:23:02.890+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:23:02.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:23:02.900+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:23:02.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:23:02.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T22:23:33.427+0000] {processor.py:157} INFO - Started process (PID=21321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:23:33.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:23:33.431+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:23:33.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:23:33.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:23:33.458+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:23:33.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:23:33.471+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:23:33.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:23:33.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T22:24:03.790+0000] {processor.py:157} INFO - Started process (PID=21346) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:24:03.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:24:03.793+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:24:03.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:24:03.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:24:03.819+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:24:03.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:24:03.829+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:24:03.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:24:03.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.201 seconds
[2024-07-22T22:24:34.562+0000] {processor.py:157} INFO - Started process (PID=21371) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:24:34.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:24:34.565+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:24:34.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:24:34.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:24:34.588+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:24:34.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:24:34.598+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:24:34.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:24:34.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-22T22:25:05.048+0000] {processor.py:157} INFO - Started process (PID=21396) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:25:05.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:25:05.052+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:25:05.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:25:05.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:25:05.079+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:25:05.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:25:05.092+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:25:05.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:25:05.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T22:25:35.603+0000] {processor.py:157} INFO - Started process (PID=21421) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:25:35.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:25:35.608+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:25:35.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:25:35.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:25:35.639+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:25:35.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:25:35.649+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:25:35.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:25:35.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T22:26:06.095+0000] {processor.py:157} INFO - Started process (PID=21446) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:26:06.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:26:06.097+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:26:06.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:26:06.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:26:06.124+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:26:06.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:26:06.133+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:26:06.133+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:26:06.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-22T22:26:36.555+0000] {processor.py:157} INFO - Started process (PID=21471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:26:36.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:26:36.558+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:26:36.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:26:36.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:26:36.592+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:26:36.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:26:36.603+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:26:36.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:26:36.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T22:27:07.056+0000] {processor.py:157} INFO - Started process (PID=21496) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:27:07.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:27:07.060+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:27:07.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:27:07.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:27:07.087+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:27:07.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:27:07.100+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:27:07.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:27:07.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-22T22:27:37.576+0000] {processor.py:157} INFO - Started process (PID=21521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:27:37.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:27:37.579+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:27:37.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:27:37.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:27:37.606+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:27:37.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:27:37.617+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:27:37.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:27:37.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T22:28:08.074+0000] {processor.py:157} INFO - Started process (PID=21546) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:28:08.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:28:08.078+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:28:08.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:28:08.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:28:08.105+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:28:08.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:28:08.117+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:28:08.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:28:08.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T22:28:38.670+0000] {processor.py:157} INFO - Started process (PID=21571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:28:38.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:28:38.674+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:28:38.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:28:38.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:28:38.711+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:28:38.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:28:38.720+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:28:38.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:28:38.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-22T22:29:09.171+0000] {processor.py:157} INFO - Started process (PID=21596) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:29:09.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:29:09.175+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:29:09.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:29:09.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:29:09.210+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:29:09.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:29:09.223+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:29:09.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:29:09.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-22T22:29:39.617+0000] {processor.py:157} INFO - Started process (PID=21621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:29:39.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:29:39.620+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:29:39.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:29:39.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:29:39.655+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:29:39.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:29:39.664+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:29:39.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:29:39.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-07-22T22:30:10.419+0000] {processor.py:157} INFO - Started process (PID=21646) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:30:10.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:30:10.421+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:30:10.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:30:10.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:30:10.453+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:30:10.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:30:10.463+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:30:10.463+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:30:10.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T22:30:40.883+0000] {processor.py:157} INFO - Started process (PID=21671) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:30:40.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:30:40.888+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:30:40.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:30:40.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:30:40.927+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:30:40.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:30:40.937+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:30:40.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:30:40.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-22T22:31:11.466+0000] {processor.py:157} INFO - Started process (PID=21696) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:31:11.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:31:11.469+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:31:11.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:31:11.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:31:11.502+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:31:11.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:31:11.514+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:31:11.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:31:11.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T22:31:42.047+0000] {processor.py:157} INFO - Started process (PID=21721) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:31:42.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:31:42.051+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:31:42.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:31:42.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:31:42.084+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:31:42.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:31:42.094+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:31:42.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:31:42.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-22T22:32:12.498+0000] {processor.py:157} INFO - Started process (PID=21746) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:32:12.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:32:12.501+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:32:12.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:32:12.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:32:12.528+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:32:12.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:32:12.540+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:32:12.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:32:12.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T22:32:42.946+0000] {processor.py:157} INFO - Started process (PID=21771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:32:42.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:32:42.949+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:32:42.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:32:42.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:32:42.978+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:32:42.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:32:43.056+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:32:43.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:32:43.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-22T22:33:13.496+0000] {processor.py:157} INFO - Started process (PID=21796) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:33:13.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:33:13.499+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:33:13.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:33:13.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:33:13.526+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:33:13.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:33:13.539+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:33:13.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:33:13.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T22:33:43.994+0000] {processor.py:157} INFO - Started process (PID=21821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:33:43.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:33:43.999+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:33:43.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:33:44.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:33:44.035+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:33:44.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:33:44.050+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:33:44.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:33:44.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-22T22:34:14.482+0000] {processor.py:157} INFO - Started process (PID=21846) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:34:14.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:34:14.488+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:34:14.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:34:14.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:34:14.527+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:34:14.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:34:14.543+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:34:14.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:34:14.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-22T22:34:45.039+0000] {processor.py:157} INFO - Started process (PID=21871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:34:45.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:34:45.042+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:34:45.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:34:45.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:34:45.070+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:34:45.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:34:45.080+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:34:45.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:34:45.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T22:35:15.555+0000] {processor.py:157} INFO - Started process (PID=21896) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:35:15.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:35:15.558+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:35:15.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:35:15.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:35:15.584+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:35:15.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:35:15.594+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:35:15.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:35:15.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.217 seconds
[2024-07-22T22:35:46.448+0000] {processor.py:157} INFO - Started process (PID=21921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:35:46.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:35:46.450+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:35:46.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:35:46.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:35:46.478+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:35:46.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:35:46.488+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:35:46.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:35:46.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T22:36:17.010+0000] {processor.py:157} INFO - Started process (PID=21946) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:36:17.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:36:17.014+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:36:17.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:36:17.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:36:17.050+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:36:17.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:36:17.060+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:36:17.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:36:17.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T22:36:47.527+0000] {processor.py:157} INFO - Started process (PID=21971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:36:47.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:36:47.530+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:36:47.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:36:47.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:36:47.560+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:36:47.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:36:47.572+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:36:47.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:36:47.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T22:37:18.038+0000] {processor.py:157} INFO - Started process (PID=21996) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:37:18.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:37:18.044+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:37:18.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:37:18.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:37:18.068+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:37:18.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:37:18.078+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:37:18.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:37:18.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T22:37:48.520+0000] {processor.py:157} INFO - Started process (PID=22021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:37:48.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:37:48.522+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:37:48.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:37:48.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:37:48.552+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:37:48.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:37:48.562+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:37:48.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:37:48.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T22:38:19.016+0000] {processor.py:157} INFO - Started process (PID=22046) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:38:19.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:38:19.020+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:38:19.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:38:19.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:38:19.045+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:38:19.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:38:19.058+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:38:19.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:38:19.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-07-22T22:38:49.576+0000] {processor.py:157} INFO - Started process (PID=22071) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:38:49.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:38:49.579+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:38:49.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:38:49.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:38:49.615+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:38:49.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:38:49.625+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:38:49.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:38:49.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T22:39:20.065+0000] {processor.py:157} INFO - Started process (PID=22096) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:39:20.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:39:20.070+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:39:20.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:39:20.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:39:20.097+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:39:20.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:39:20.107+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:39:20.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:39:20.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T22:39:50.532+0000] {processor.py:157} INFO - Started process (PID=22121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:39:50.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:39:50.538+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:39:50.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:39:50.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:39:50.573+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:39:50.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:39:50.584+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:39:50.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:39:50.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-22T22:40:20.962+0000] {processor.py:157} INFO - Started process (PID=22146) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:40:20.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:40:20.968+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:40:20.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:40:20.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:40:20.997+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:40:20.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:40:21.010+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:40:21.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:40:21.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T22:40:51.452+0000] {processor.py:157} INFO - Started process (PID=22171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:40:51.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:40:51.456+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:40:51.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:40:51.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:40:51.480+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:40:51.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:40:51.490+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:40:51.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:40:51.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-22T22:41:21.894+0000] {processor.py:157} INFO - Started process (PID=22196) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:41:21.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:41:21.897+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:41:21.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:41:21.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:41:21.923+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:41:21.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:41:22.034+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:41:22.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:41:22.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-07-22T22:41:52.537+0000] {processor.py:157} INFO - Started process (PID=22221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:41:52.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:41:52.540+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:41:52.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:41:52.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:41:52.570+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:41:52.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:41:52.582+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:41:52.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:41:52.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T22:42:23.009+0000] {processor.py:157} INFO - Started process (PID=22246) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:42:23.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:42:23.012+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:42:23.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:42:23.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:42:23.044+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:42:23.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:42:23.055+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:42:23.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:42:23.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T22:42:53.483+0000] {processor.py:157} INFO - Started process (PID=22271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:42:53.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:42:53.485+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:42:53.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:42:53.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:42:53.506+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:42:53.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:42:53.515+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:42:53.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:42:53.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-22T22:43:24.032+0000] {processor.py:157} INFO - Started process (PID=22296) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:43:24.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:43:24.037+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:43:24.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:43:24.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:43:24.073+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:43:24.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:43:24.086+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:43:24.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:43:24.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-22T22:43:54.560+0000] {processor.py:157} INFO - Started process (PID=22321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:43:54.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:43:54.563+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:43:54.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:43:54.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:43:54.590+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:43:54.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:43:54.605+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:43:54.605+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:43:54.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-22T22:44:25.247+0000] {processor.py:157} INFO - Started process (PID=22346) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:44:25.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:44:25.251+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:44:25.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:44:25.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:44:25.277+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:44:25.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:44:25.357+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:44:25.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:44:25.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-22T22:44:55.833+0000] {processor.py:157} INFO - Started process (PID=22371) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:44:55.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:44:55.836+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:44:55.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:44:55.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:44:55.863+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:44:55.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:44:55.874+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:44:55.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:44:55.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T22:45:26.432+0000] {processor.py:157} INFO - Started process (PID=22396) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:45:26.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:45:26.435+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:45:26.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:45:26.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:45:26.464+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:45:26.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:45:26.477+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:45:26.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:45:26.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T22:45:57.001+0000] {processor.py:157} INFO - Started process (PID=22421) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:45:57.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:45:57.004+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:45:57.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:45:57.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:45:57.035+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:45:57.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:45:57.045+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:45:57.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:45:57.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T22:46:27.456+0000] {processor.py:157} INFO - Started process (PID=22446) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:46:27.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:46:27.458+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:46:27.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:46:27.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:46:27.488+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:46:27.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:46:27.498+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:46:27.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:46:27.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T22:46:58.028+0000] {processor.py:157} INFO - Started process (PID=22471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:46:58.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:46:58.035+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:46:58.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:46:58.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:46:58.058+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:46:58.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:46:58.067+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:46:58.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:46:58.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.218 seconds
[2024-07-22T22:47:28.703+0000] {processor.py:157} INFO - Started process (PID=22496) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:47:28.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:47:28.709+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:47:28.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:47:28.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:47:28.745+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:47:28.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:47:28.757+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:47:28.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:47:28.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-22T22:47:59.167+0000] {processor.py:157} INFO - Started process (PID=22521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:47:59.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:47:59.171+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:47:59.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:47:59.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:47:59.201+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:47:59.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:47:59.216+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:47:59.216+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:47:59.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-22T22:48:29.711+0000] {processor.py:157} INFO - Started process (PID=22546) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:48:29.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:48:29.715+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:48:29.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:48:29.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:48:29.743+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:48:29.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:48:29.752+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:48:29.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:48:29.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T22:49:00.158+0000] {processor.py:157} INFO - Started process (PID=22571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:49:00.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:49:00.163+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:49:00.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:49:00.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:49:00.189+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:49:00.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:49:00.198+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:49:00.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:49:00.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T22:49:30.649+0000] {processor.py:157} INFO - Started process (PID=22596) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:49:30.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:49:30.651+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:49:30.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:49:30.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:49:30.675+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:49:30.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:49:30.684+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:49:30.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:49:30.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-22T22:50:01.310+0000] {processor.py:157} INFO - Started process (PID=22621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:50:01.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:50:01.314+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:50:01.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:50:01.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:50:01.344+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:50:01.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:50:01.462+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:50:01.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:50:01.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-07-22T22:50:31.969+0000] {processor.py:157} INFO - Started process (PID=22646) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:50:31.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:50:31.973+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:50:31.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:50:31.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:50:32.013+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:50:32.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:50:32.026+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:50:32.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:50:32.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-22T22:51:02.510+0000] {processor.py:157} INFO - Started process (PID=22671) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:51:02.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:51:02.513+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:51:02.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:51:02.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:51:02.543+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:51:02.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:51:02.553+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:51:02.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:51:02.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T22:51:33.024+0000] {processor.py:157} INFO - Started process (PID=22696) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:51:33.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:51:33.029+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:51:33.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:51:33.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:51:33.059+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:51:33.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:51:33.070+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:51:33.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:51:33.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T22:52:03.609+0000] {processor.py:157} INFO - Started process (PID=22721) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:52:03.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:52:03.613+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:52:03.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:52:03.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:52:03.640+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:52:03.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:52:03.650+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:52:03.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:52:03.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T22:52:34.195+0000] {processor.py:157} INFO - Started process (PID=22746) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:52:34.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:52:34.197+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:52:34.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:52:34.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:52:34.224+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:52:34.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:52:34.235+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:52:34.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:52:34.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.212 seconds
[2024-07-22T22:53:04.973+0000] {processor.py:157} INFO - Started process (PID=22771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:53:04.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:53:04.976+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:53:04.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:53:04.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:53:05.004+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:53:05.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:53:05.082+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:53:05.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:53:05.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-22T22:53:35.717+0000] {processor.py:157} INFO - Started process (PID=22796) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:53:35.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:53:35.721+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:53:35.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:53:35.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:53:35.746+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:53:35.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:53:35.756+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:53:35.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:53:35.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-22T22:54:06.166+0000] {processor.py:157} INFO - Started process (PID=22821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:54:06.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:54:06.169+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:54:06.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:54:06.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:54:06.193+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:54:06.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:54:06.204+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:54:06.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:54:06.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-22T22:54:36.675+0000] {processor.py:157} INFO - Started process (PID=22846) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:54:36.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:54:36.678+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:54:36.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:54:36.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:54:36.706+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:54:36.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:54:36.715+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:54:36.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:54:36.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T22:55:07.178+0000] {processor.py:157} INFO - Started process (PID=22871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:55:07.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:55:07.182+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:55:07.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:55:07.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:55:07.210+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:55:07.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:55:07.221+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:55:07.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:55:07.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T22:55:37.631+0000] {processor.py:157} INFO - Started process (PID=22896) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:55:37.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:55:37.637+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:55:37.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:55:37.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:55:37.673+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:55:37.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:55:37.812+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:55:37.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:55:37.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.191 seconds
[2024-07-22T22:56:08.266+0000] {processor.py:157} INFO - Started process (PID=22921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:56:08.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:56:08.268+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:56:08.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:56:08.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:56:08.298+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:56:08.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:56:08.311+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:56:08.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:56:08.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-22T22:56:38.793+0000] {processor.py:157} INFO - Started process (PID=22946) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:56:38.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:56:38.796+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:56:38.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:56:38.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:56:38.823+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:56:38.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:56:38.835+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:56:38.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:56:38.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T22:57:09.227+0000] {processor.py:157} INFO - Started process (PID=22971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:57:09.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:57:09.230+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:57:09.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:57:09.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:57:09.253+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:57:09.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:57:09.262+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:57:09.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:57:09.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-22T22:57:39.715+0000] {processor.py:157} INFO - Started process (PID=22996) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:57:39.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:57:39.719+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:57:39.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:57:39.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:57:39.745+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:57:39.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:57:39.755+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:57:39.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:57:39.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T22:58:10.232+0000] {processor.py:157} INFO - Started process (PID=23021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:58:10.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:58:10.234+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:58:10.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:58:10.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:58:10.260+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:58:10.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:58:10.271+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:58:10.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:58:10.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-22T22:58:40.820+0000] {processor.py:157} INFO - Started process (PID=23046) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:58:40.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:58:40.824+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:58:40.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:58:40.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:58:40.850+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:58:40.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:58:40.932+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:58:40.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:58:40.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-22T22:59:11.494+0000] {processor.py:157} INFO - Started process (PID=23071) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:59:11.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:59:11.498+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:59:11.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:59:11.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:59:11.524+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:59:11.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:59:11.537+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:59:11.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:59:11.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T22:59:42.010+0000] {processor.py:157} INFO - Started process (PID=23096) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:59:42.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T22:59:42.014+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:59:42.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:59:42.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T22:59:42.041+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:59:42.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T22:59:42.051+0000] {logging_mixin.py:151} INFO - [2024-07-22T22:59:42.051+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T22:59:42.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T23:00:12.411+0000] {processor.py:157} INFO - Started process (PID=23121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:00:12.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T23:00:12.415+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:00:12.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:00:12.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:00:12.446+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:00:12.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T23:00:12.457+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:00:12.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T23:00:12.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-22T23:00:42.920+0000] {processor.py:157} INFO - Started process (PID=23146) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:00:42.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T23:00:42.924+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:00:42.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:00:42.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:00:42.951+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:00:42.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T23:00:42.961+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:00:42.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T23:00:42.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-22T23:01:13.356+0000] {processor.py:157} INFO - Started process (PID=23171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:01:13.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T23:01:13.360+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:01:13.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:01:13.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:01:13.385+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:01:13.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T23:01:13.395+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:01:13.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T23:01:13.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.217 seconds
[2024-07-22T23:01:44.174+0000] {processor.py:157} INFO - Started process (PID=23196) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:01:44.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T23:01:44.176+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:01:44.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:01:44.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:01:44.208+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:01:44.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T23:01:44.286+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:01:44.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T23:01:44.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-22T23:02:14.758+0000] {processor.py:157} INFO - Started process (PID=23221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:02:14.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T23:02:14.761+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:02:14.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:02:14.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:02:14.788+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:02:14.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T23:02:14.799+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:02:14.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T23:02:14.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-22T23:02:45.254+0000] {processor.py:157} INFO - Started process (PID=23246) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:02:45.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T23:02:45.257+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:02:45.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:02:45.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:02:45.284+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:02:45.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T23:02:45.294+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:02:45.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T23:02:45.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-22T23:03:15.746+0000] {processor.py:157} INFO - Started process (PID=23271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:03:15.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T23:03:15.750+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:03:15.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:03:15.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:03:15.779+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:03:15.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T23:03:15.789+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:03:15.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T23:03:15.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-22T23:03:46.382+0000] {processor.py:157} INFO - Started process (PID=23296) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:03:46.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T23:03:46.388+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:03:46.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:03:46.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:03:46.425+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:03:46.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T23:03:46.438+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:03:46.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T23:03:46.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-22T23:20:02.176+0000] {processor.py:157} INFO - Started process (PID=23321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:20:02.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T23:20:02.180+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:20:02.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:20:02.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:20:02.219+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:20:02.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T23:20:02.499+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:20:02.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T23:20:02.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.347 seconds
[2024-07-22T23:20:32.996+0000] {processor.py:157} INFO - Started process (PID=23348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:20:32.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T23:20:33.000+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:20:33.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:20:33.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:20:33.029+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:20:33.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T23:20:33.106+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:20:33.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T23:20:33.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-22T23:29:59.817+0000] {processor.py:157} INFO - Started process (PID=23375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:29:59.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T23:29:59.822+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:29:59.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:29:59.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:29:59.885+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:29:59.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T23:29:59.916+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:29:59.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T23:29:59.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-22T23:30:30.840+0000] {processor.py:157} INFO - Started process (PID=23400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:30:30.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T23:30:30.862+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:30:30.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:30:30.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:30:30.904+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:30:30.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T23:30:30.916+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:30:30.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T23:30:30.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-22T23:31:01.251+0000] {processor.py:157} INFO - Started process (PID=23425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:31:01.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T23:31:01.256+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:31:01.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:31:01.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:31:01.281+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:31:01.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T23:31:01.293+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:31:01.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T23:31:01.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-22T23:47:05.409+0000] {processor.py:157} INFO - Started process (PID=23451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:47:05.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T23:47:05.420+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:47:05.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:47:05.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:47:05.502+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:47:05.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T23:47:05.533+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:47:05.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T23:47:05.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.331 seconds
[2024-07-22T23:47:36.538+0000] {processor.py:157} INFO - Started process (PID=23477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:47:36.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T23:47:36.542+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:47:36.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:47:36.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:47:36.579+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:47:36.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T23:47:36.672+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:47:36.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T23:47:36.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-07-22T23:48:07.247+0000] {processor.py:157} INFO - Started process (PID=23502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:48:07.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T23:48:07.250+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:48:07.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:48:07.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:48:07.283+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:48:07.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T23:48:07.294+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:48:07.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T23:48:07.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-22T23:48:37.731+0000] {processor.py:157} INFO - Started process (PID=23527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:48:37.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T23:48:37.736+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:48:37.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:48:37.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:48:37.772+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:48:37.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T23:48:37.784+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:48:37.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T23:48:37.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-22T23:49:08.183+0000] {processor.py:157} INFO - Started process (PID=23552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:49:08.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-22T23:49:08.185+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:49:08.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:49:08.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-22T23:49:08.215+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:49:08.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-22T23:49:08.225+0000] {logging_mixin.py:151} INFO - [2024-07-22T23:49:08.225+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-22T01:00:00+00:00, run_after=2024-07-23T01:00:00+00:00
[2024-07-22T23:49:08.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
