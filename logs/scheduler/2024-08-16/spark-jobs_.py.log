[2024-08-16T00:18:06.394+0000] {processor.py:157} INFO - Started process (PID=48313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T00:18:06.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T00:18:06.407+0000] {logging_mixin.py:151} INFO - [2024-08-16T00:18:06.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T00:18:06.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T00:18:06.480+0000] {logging_mixin.py:151} INFO - [2024-08-16T00:18:06.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T00:18:06.510+0000] {logging_mixin.py:151} INFO - [2024-08-16T00:18:06.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-16T00:18:06.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-08-16T00:26:32.024+0000] {processor.py:157} INFO - Started process (PID=48323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T00:26:32.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T00:26:32.028+0000] {logging_mixin.py:151} INFO - [2024-08-16T00:26:32.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T00:26:32.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T00:26:32.075+0000] {logging_mixin.py:151} INFO - [2024-08-16T00:26:32.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T00:26:32.091+0000] {logging_mixin.py:151} INFO - [2024-08-16T00:26:32.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-16T00:26:32.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-16T00:28:58.964+0000] {processor.py:157} INFO - Started process (PID=48333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T00:28:58.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T00:28:58.969+0000] {logging_mixin.py:151} INFO - [2024-08-16T00:28:58.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T00:28:58.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T00:28:59.012+0000] {logging_mixin.py:151} INFO - [2024-08-16T00:28:59.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T00:28:59.027+0000] {logging_mixin.py:151} INFO - [2024-08-16T00:28:59.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-16T00:28:59.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-16T00:29:29.319+0000] {processor.py:157} INFO - Started process (PID=48343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T00:29:29.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T00:29:29.326+0000] {logging_mixin.py:151} INFO - [2024-08-16T00:29:29.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T00:29:29.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T00:29:29.370+0000] {logging_mixin.py:151} INFO - [2024-08-16T00:29:29.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T00:29:29.385+0000] {logging_mixin.py:151} INFO - [2024-08-16T00:29:29.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-16T00:29:29.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-16T00:37:42.667+0000] {processor.py:157} INFO - Started process (PID=48358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T00:37:42.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T00:37:42.671+0000] {logging_mixin.py:151} INFO - [2024-08-16T00:37:42.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T00:37:42.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T00:37:42.725+0000] {logging_mixin.py:151} INFO - [2024-08-16T00:37:42.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T00:37:42.740+0000] {logging_mixin.py:151} INFO - [2024-08-16T00:37:42.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-16T00:37:42.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-16T01:11:52.206+0000] {processor.py:157} INFO - Started process (PID=48957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T01:11:52.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T01:11:52.213+0000] {logging_mixin.py:151} INFO - [2024-08-16T01:11:52.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T01:11:52.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T01:11:52.274+0000] {logging_mixin.py:151} INFO - [2024-08-16T01:11:52.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T01:11:52.289+0000] {logging_mixin.py:151} INFO - [2024-08-16T01:11:52.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T01:11:52.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-16T01:30:08.477+0000] {processor.py:157} INFO - Started process (PID=49135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T01:30:08.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T01:30:08.483+0000] {logging_mixin.py:151} INFO - [2024-08-16T01:30:08.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T01:30:08.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T01:30:08.566+0000] {logging_mixin.py:151} INFO - [2024-08-16T01:30:08.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T01:30:08.595+0000] {logging_mixin.py:151} INFO - [2024-08-16T01:30:08.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T01:30:08.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-08-16T01:46:33.930+0000] {processor.py:157} INFO - Started process (PID=49146) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T01:46:33.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T01:46:33.936+0000] {logging_mixin.py:151} INFO - [2024-08-16T01:46:33.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T01:46:33.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T01:46:33.988+0000] {logging_mixin.py:151} INFO - [2024-08-16T01:46:33.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T01:46:34.002+0000] {logging_mixin.py:151} INFO - [2024-08-16T01:46:34.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T01:46:34.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-16T02:27:47.407+0000] {processor.py:157} INFO - Started process (PID=49155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:27:47.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:27:47.417+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:27:47.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:27:47.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:27:47.486+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:27:47.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:27:47.521+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:27:47.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:27:47.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-08-16T02:29:05.686+0000] {processor.py:157} INFO - Started process (PID=49165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:29:05.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:29:05.692+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:29:05.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:29:05.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:29:05.741+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:29:05.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:29:05.763+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:29:05.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:29:05.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-16T02:29:35.955+0000] {processor.py:157} INFO - Started process (PID=49174) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:29:35.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:29:35.960+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:29:35.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:29:35.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:29:36.005+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:29:36.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:29:36.023+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:29:36.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:29:36.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-16T02:40:52.476+0000] {processor.py:157} INFO - Started process (PID=49187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:40:52.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:40:52.488+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:40:52.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:40:52.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:40:52.573+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:40:52.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:40:52.602+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:40:52.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:40:52.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-08-16T02:41:22.777+0000] {processor.py:157} INFO - Started process (PID=49198) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:41:22.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:41:22.785+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:41:22.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:41:22.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:41:22.850+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:41:22.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:41:22.865+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:41:22.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:41:22.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-16T02:41:53.201+0000] {processor.py:157} INFO - Started process (PID=49208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:41:53.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:41:53.215+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:41:53.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:41:53.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:41:53.280+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:41:53.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:41:53.318+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:41:53.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:41:53.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-08-16T02:42:23.708+0000] {processor.py:157} INFO - Started process (PID=49218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:42:23.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:42:23.714+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:42:23.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:42:23.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:42:23.797+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:42:23.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:42:23.819+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:42:23.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:42:23.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-16T02:42:54.287+0000] {processor.py:157} INFO - Started process (PID=49228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:42:54.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:42:54.305+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:42:54.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:42:54.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:42:54.419+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:42:54.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:42:54.477+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:42:54.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:42:54.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.223 seconds
[2024-08-16T02:43:24.590+0000] {processor.py:157} INFO - Started process (PID=49238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:43:24.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:43:24.598+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:43:24.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:43:24.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:43:24.661+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:43:24.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:43:24.677+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:43:24.677+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:43:24.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-16T02:43:54.918+0000] {processor.py:157} INFO - Started process (PID=49248) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:43:54.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:43:54.924+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:43:54.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:43:54.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:43:55.002+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:43:55.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:43:55.018+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:43:55.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:43:55.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-16T02:44:25.274+0000] {processor.py:157} INFO - Started process (PID=49257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:44:25.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:44:25.282+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:44:25.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:44:25.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:44:25.338+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:44:25.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:44:25.356+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:44:25.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:44:25.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-16T02:44:55.678+0000] {processor.py:157} INFO - Started process (PID=49268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:44:55.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:44:55.701+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:44:55.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:44:55.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:44:55.748+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:44:55.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:44:55.762+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:44:55.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:44:55.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-16T02:45:25.996+0000] {processor.py:157} INFO - Started process (PID=49278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:45:25.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:45:26.009+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:45:26.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:45:26.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:45:26.060+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:45:26.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:45:26.074+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:45:26.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:45:26.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-16T02:45:56.368+0000] {processor.py:157} INFO - Started process (PID=49288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:45:56.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:45:56.377+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:45:56.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:45:56.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:45:56.427+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:45:56.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:45:56.446+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:45:56.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:45:56.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-16T02:46:26.660+0000] {processor.py:157} INFO - Started process (PID=49298) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:46:26.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:46:26.665+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:46:26.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:46:26.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:46:26.708+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:46:26.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:46:26.724+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:46:26.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:46:26.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-16T02:46:56.980+0000] {processor.py:157} INFO - Started process (PID=49308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:46:56.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:46:56.986+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:46:56.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:46:57.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:46:57.027+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:46:57.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:46:57.041+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:46:57.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:46:57.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-16T02:47:27.340+0000] {processor.py:157} INFO - Started process (PID=49318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:47:27.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:47:27.342+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:47:27.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:47:27.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:47:27.398+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:47:27.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:47:27.414+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:47:27.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:47:27.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-16T02:47:57.619+0000] {processor.py:157} INFO - Started process (PID=49328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:47:57.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:47:57.623+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:47:57.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:47:57.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:47:57.655+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:47:57.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:47:57.668+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:47:57.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:47:57.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-16T02:48:27.986+0000] {processor.py:157} INFO - Started process (PID=49338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:48:27.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:48:27.992+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:48:27.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:48:28.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:48:28.035+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:48:28.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:48:28.049+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:48:28.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:48:28.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-16T02:48:58.278+0000] {processor.py:157} INFO - Started process (PID=49348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:48:58.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:48:58.281+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:48:58.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:48:58.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:48:58.313+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:48:58.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:48:58.324+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:48:58.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:48:58.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-16T02:49:28.630+0000] {processor.py:157} INFO - Started process (PID=49358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:49:28.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:49:28.634+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:49:28.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:49:28.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:49:28.698+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:49:28.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:49:28.713+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:49:28.713+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:49:28.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-16T02:49:58.939+0000] {processor.py:157} INFO - Started process (PID=49368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:49:58.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:49:58.941+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:49:58.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:49:58.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:49:58.972+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:49:58.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:49:58.985+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:49:58.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:49:58.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-16T02:50:29.262+0000] {processor.py:157} INFO - Started process (PID=49378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:50:29.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:50:29.265+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:50:29.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:50:29.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:50:29.322+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:50:29.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:50:29.336+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:50:29.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:50:29.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-16T02:50:59.550+0000] {processor.py:157} INFO - Started process (PID=49388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:50:59.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:50:59.555+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:50:59.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:50:59.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:50:59.608+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:50:59.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:50:59.644+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:50:59.644+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:50:59.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-16T02:51:29.959+0000] {processor.py:157} INFO - Started process (PID=49398) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:51:29.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:51:29.963+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:51:29.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:51:29.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:51:29.993+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:51:29.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:51:30.028+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:51:30.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:51:30.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-16T02:52:00.361+0000] {processor.py:157} INFO - Started process (PID=49408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:52:00.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:52:00.367+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:52:00.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:52:00.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:52:00.432+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:52:00.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:52:00.446+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:52:00.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:52:00.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-16T02:52:30.628+0000] {processor.py:157} INFO - Started process (PID=49418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:52:30.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:52:30.631+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:52:30.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:52:30.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:52:30.659+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:52:30.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:52:30.672+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:52:30.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:52:30.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-16T02:53:01.023+0000] {processor.py:157} INFO - Started process (PID=49428) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:53:01.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:53:01.027+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:53:01.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:53:01.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:53:01.087+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:53:01.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:53:01.105+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:53:01.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:53:01.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-16T02:53:31.327+0000] {processor.py:157} INFO - Started process (PID=49438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:53:31.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:53:31.333+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:53:31.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:53:31.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:53:31.379+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:53:31.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:53:31.452+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:53:31.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:53:31.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-08-16T02:54:01.816+0000] {processor.py:157} INFO - Started process (PID=49448) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:54:01.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:54:01.821+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:54:01.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:54:01.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:54:01.889+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:54:01.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:54:01.911+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:54:01.911+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:54:01.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-16T02:54:32.214+0000] {processor.py:157} INFO - Started process (PID=49458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:54:32.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:54:32.219+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:54:32.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:54:32.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:54:32.257+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:54:32.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:54:32.292+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:54:32.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:54:32.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-16T02:55:02.483+0000] {processor.py:157} INFO - Started process (PID=49468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:55:02.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:55:02.487+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:55:02.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:55:02.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:55:02.522+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:55:02.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:55:02.552+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:55:02.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:55:02.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-16T02:55:32.861+0000] {processor.py:157} INFO - Started process (PID=49478) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:55:32.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:55:32.870+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:55:32.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:55:32.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:55:32.922+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:55:32.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:55:32.942+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:55:32.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:55:32.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-16T02:56:03.177+0000] {processor.py:157} INFO - Started process (PID=49488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:56:03.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:56:03.183+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:56:03.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:56:03.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:56:03.210+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:56:03.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:56:03.222+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:56:03.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:56:03.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-16T02:56:33.580+0000] {processor.py:157} INFO - Started process (PID=49498) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:56:33.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:56:33.586+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:56:33.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:56:33.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:56:33.630+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:56:33.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:56:33.647+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:56:33.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:56:33.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-16T02:57:03.840+0000] {processor.py:157} INFO - Started process (PID=49508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:57:03.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:57:03.842+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:57:03.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:57:03.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:57:03.865+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:57:03.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:57:03.876+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:57:03.875+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:57:03.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-16T02:57:34.166+0000] {processor.py:157} INFO - Started process (PID=49518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:57:34.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:57:34.173+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:57:34.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:57:34.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:57:34.226+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:57:34.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:57:34.247+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:57:34.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:57:34.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-16T02:58:04.562+0000] {processor.py:157} INFO - Started process (PID=49528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:58:04.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:58:04.571+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:58:04.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:58:04.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:58:04.606+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:58:04.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:58:04.628+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:58:04.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:58:04.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-16T02:58:34.975+0000] {processor.py:157} INFO - Started process (PID=49538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:58:34.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:58:34.978+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:58:34.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:58:35.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:58:35.045+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:58:35.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:58:35.060+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:58:35.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:58:35.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-16T02:59:05.388+0000] {processor.py:157} INFO - Started process (PID=49548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:59:05.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:59:05.391+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:59:05.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:59:05.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:59:05.423+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:59:05.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:59:05.438+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:59:05.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:59:05.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-16T02:59:35.755+0000] {processor.py:157} INFO - Started process (PID=49557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:59:35.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T02:59:35.761+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:59:35.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:59:35.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T02:59:35.834+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:59:35.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T02:59:35.847+0000] {logging_mixin.py:151} INFO - [2024-08-16T02:59:35.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T02:59:35.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-16T03:00:06.022+0000] {processor.py:157} INFO - Started process (PID=49568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:00:06.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:00:06.025+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:00:06.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:00:06.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:00:06.056+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:00:06.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:00:06.067+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:00:06.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:00:06.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-16T03:00:36.428+0000] {processor.py:157} INFO - Started process (PID=49578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:00:36.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:00:36.431+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:00:36.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:00:36.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:00:36.511+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:00:36.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:00:36.528+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:00:36.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:00:36.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-16T03:01:06.816+0000] {processor.py:157} INFO - Started process (PID=49588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:01:06.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:01:06.823+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:01:06.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:01:06.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:01:06.879+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:01:06.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:01:06.901+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:01:06.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:01:06.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-16T03:01:37.177+0000] {processor.py:157} INFO - Started process (PID=49598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:01:37.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:01:37.184+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:01:37.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:01:37.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:01:37.240+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:01:37.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:01:37.254+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:01:37.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:01:37.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-16T03:02:07.545+0000] {processor.py:157} INFO - Started process (PID=49608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:02:07.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:02:07.550+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:02:07.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:02:07.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:02:07.585+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:02:07.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:02:07.598+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:02:07.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:02:07.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-16T03:02:37.935+0000] {processor.py:157} INFO - Started process (PID=49618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:02:37.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:02:37.942+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:02:37.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:02:37.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:02:37.992+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:02:37.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:02:38.008+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:02:38.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:02:38.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-16T03:03:08.317+0000] {processor.py:157} INFO - Started process (PID=49628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:03:08.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:03:08.324+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:03:08.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:03:08.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:03:08.388+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:03:08.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:03:08.403+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:03:08.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:03:08.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-16T03:03:38.686+0000] {processor.py:157} INFO - Started process (PID=49638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:03:38.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:03:38.695+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:03:38.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:03:38.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:03:38.764+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:03:38.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:03:38.795+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:03:38.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:03:38.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-08-16T03:04:09.096+0000] {processor.py:157} INFO - Started process (PID=49648) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:04:09.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:04:09.103+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:04:09.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:04:09.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:04:09.149+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:04:09.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:04:09.165+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:04:09.165+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:04:09.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-16T03:04:39.443+0000] {processor.py:157} INFO - Started process (PID=49658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:04:39.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:04:39.450+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:04:39.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:04:39.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:04:39.496+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:04:39.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:04:39.513+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:04:39.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:04:39.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-16T03:05:09.731+0000] {processor.py:157} INFO - Started process (PID=49668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:05:09.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:05:09.734+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:05:09.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:05:09.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:05:09.764+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:05:09.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:05:09.777+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:05:09.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:05:09.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-16T03:05:40.087+0000] {processor.py:157} INFO - Started process (PID=49677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:05:40.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:05:40.102+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:05:40.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:05:40.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:05:40.148+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:05:40.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:05:40.177+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:05:40.177+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:05:40.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-16T03:06:10.541+0000] {processor.py:157} INFO - Started process (PID=49688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:06:10.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:06:10.546+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:06:10.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:06:10.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:06:10.585+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:06:10.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:06:10.599+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:06:10.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:06:10.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-16T03:06:40.862+0000] {processor.py:157} INFO - Started process (PID=49698) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:06:40.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:06:40.864+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:06:40.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:06:40.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:06:40.896+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:06:40.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:06:40.908+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:06:40.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:06:40.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-16T03:07:11.257+0000] {processor.py:157} INFO - Started process (PID=49708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:07:11.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:07:11.262+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:07:11.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:07:11.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:07:11.332+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:07:11.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:07:11.348+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:07:11.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:07:11.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-16T03:07:41.737+0000] {processor.py:157} INFO - Started process (PID=49718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:07:41.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:07:41.739+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:07:41.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:07:41.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:07:41.768+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:07:41.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:07:41.782+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:07:41.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:07:41.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-16T03:08:12.139+0000] {processor.py:157} INFO - Started process (PID=49728) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:08:12.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:08:12.149+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:08:12.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:08:12.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:08:12.202+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:08:12.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:08:12.216+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:08:12.216+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:08:12.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-16T03:08:42.431+0000] {processor.py:157} INFO - Started process (PID=49738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:08:42.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:08:42.433+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:08:42.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:08:42.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:08:42.460+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:08:42.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:08:42.473+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:08:42.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:08:42.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-16T03:09:12.804+0000] {processor.py:157} INFO - Started process (PID=49748) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:09:12.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:09:12.809+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:09:12.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:09:12.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:09:12.875+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:09:12.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:09:12.890+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:09:12.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:09:12.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-16T03:09:43.099+0000] {processor.py:157} INFO - Started process (PID=49758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:09:43.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:09:43.102+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:09:43.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:09:43.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:09:43.132+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:09:43.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:09:43.146+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:09:43.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:09:43.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-16T03:10:13.498+0000] {processor.py:157} INFO - Started process (PID=49768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:10:13.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:10:13.503+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:10:13.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:10:13.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:10:13.566+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:10:13.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:10:13.580+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:10:13.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:10:13.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-16T03:10:43.884+0000] {processor.py:157} INFO - Started process (PID=49778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:10:43.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:10:43.887+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:10:43.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:10:43.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:10:43.918+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:10:43.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:10:43.933+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:10:43.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:10:43.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-16T03:11:14.323+0000] {processor.py:157} INFO - Started process (PID=49788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:11:14.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:11:14.332+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:11:14.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:11:14.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:11:14.385+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:11:14.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:11:14.400+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:11:14.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:11:14.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-16T03:11:44.637+0000] {processor.py:157} INFO - Started process (PID=49798) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:11:44.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:11:44.642+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:11:44.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:11:44.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:11:44.672+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:11:44.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:11:44.683+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:11:44.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:11:44.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-16T03:12:15.085+0000] {processor.py:157} INFO - Started process (PID=49808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:12:15.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:12:15.090+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:12:15.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:12:15.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:12:15.129+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:12:15.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:12:15.157+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:12:15.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:12:15.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-16T03:12:45.439+0000] {processor.py:157} INFO - Started process (PID=49818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:12:45.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:12:45.444+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:12:45.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:12:45.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:12:45.470+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:12:45.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:12:45.480+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:12:45.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:12:45.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-16T03:13:15.838+0000] {processor.py:157} INFO - Started process (PID=49828) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:13:15.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:13:15.843+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:13:15.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:13:15.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:13:15.885+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:13:15.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:13:15.914+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:13:15.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:13:15.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-16T03:13:46.134+0000] {processor.py:157} INFO - Started process (PID=49838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:13:46.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:13:46.138+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:13:46.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:13:46.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:13:46.166+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:13:46.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:13:46.178+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:13:46.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:13:46.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-16T03:14:16.455+0000] {processor.py:157} INFO - Started process (PID=49848) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:14:16.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:14:16.460+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:14:16.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:14:16.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:14:16.502+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:14:16.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:14:16.517+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:14:16.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:14:16.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-16T03:14:46.723+0000] {processor.py:157} INFO - Started process (PID=49858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:14:46.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:14:46.731+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:14:46.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:14:46.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:14:46.754+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:14:46.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:14:46.765+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:14:46.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:14:46.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-16T03:15:17.071+0000] {processor.py:157} INFO - Started process (PID=49868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:15:17.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:15:17.078+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:15:17.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:15:17.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:15:17.118+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:15:17.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:15:17.134+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:15:17.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:15:17.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-16T03:15:47.448+0000] {processor.py:157} INFO - Started process (PID=49878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:15:47.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:15:47.451+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:15:47.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:15:47.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:15:47.479+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:15:47.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:15:47.489+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:15:47.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:15:47.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-16T03:16:17.827+0000] {processor.py:157} INFO - Started process (PID=49888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:16:17.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:16:17.832+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:16:17.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:16:17.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:16:17.879+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:16:17.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:16:17.894+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:16:17.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:16:17.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-16T03:16:48.136+0000] {processor.py:157} INFO - Started process (PID=49898) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:16:48.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:16:48.138+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:16:48.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:16:48.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:16:48.171+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:16:48.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:16:48.185+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:16:48.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:16:48.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-16T03:17:18.602+0000] {processor.py:157} INFO - Started process (PID=49907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:17:18.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:17:18.607+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:17:18.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:17:18.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:17:18.649+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:17:18.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:17:18.663+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:17:18.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:17:18.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-16T03:17:48.997+0000] {processor.py:157} INFO - Started process (PID=49918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:17:48.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:17:49.000+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:17:49.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:17:49.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:17:49.030+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:17:49.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:17:49.053+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:17:49.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:17:49.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-16T03:18:19.401+0000] {processor.py:157} INFO - Started process (PID=49928) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:18:19.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:18:19.405+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:18:19.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:18:19.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:18:19.445+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:18:19.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:18:19.457+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:18:19.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:18:19.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-16T03:18:49.731+0000] {processor.py:157} INFO - Started process (PID=49938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:18:49.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:18:49.734+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:18:49.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:18:49.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:18:49.763+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:18:49.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:18:49.774+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:18:49.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:18:49.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-16T03:19:20.084+0000] {processor.py:157} INFO - Started process (PID=49948) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:19:20.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:19:20.089+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:19:20.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:19:20.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:19:20.133+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:19:20.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:19:20.153+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:19:20.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:19:20.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-16T03:19:50.384+0000] {processor.py:157} INFO - Started process (PID=49958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:19:50.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:19:50.397+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:19:50.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:19:50.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:19:50.465+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:19:50.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:19:50.483+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:19:50.483+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:19:50.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-16T03:20:20.684+0000] {processor.py:157} INFO - Started process (PID=49968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:20:20.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:20:20.686+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:20:20.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:20:20.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:20:20.715+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:20:20.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:20:20.726+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:20:20.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:20:20.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-16T03:20:51.070+0000] {processor.py:157} INFO - Started process (PID=49978) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:20:51.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:20:51.074+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:20:51.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:20:51.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:20:51.136+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:20:51.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:20:51.151+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:20:51.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:20:51.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-16T03:21:21.414+0000] {processor.py:157} INFO - Started process (PID=49988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:21:21.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:21:21.419+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:21:21.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:21:21.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:21:21.469+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:21:21.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:21:21.485+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:21:21.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:21:21.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-16T03:21:51.776+0000] {processor.py:157} INFO - Started process (PID=49998) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:21:51.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:21:51.779+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:21:51.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:21:51.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:21:51.820+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:21:51.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:21:51.836+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:21:51.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:21:51.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-16T03:22:22.080+0000] {processor.py:157} INFO - Started process (PID=50008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:22:22.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:22:22.084+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:22:22.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:22:22.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:22:22.108+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:22:22.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:22:22.118+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:22:22.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:22:22.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-16T03:22:52.510+0000] {processor.py:157} INFO - Started process (PID=50018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:22:52.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:22:52.518+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:22:52.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:22:52.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:22:52.569+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:22:52.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:22:52.585+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:22:52.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:22:52.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-16T03:23:22.849+0000] {processor.py:157} INFO - Started process (PID=50028) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:23:22.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:23:22.852+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:23:22.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:23:22.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:23:22.879+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:23:22.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:23:22.889+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:23:22.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:23:22.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-16T03:23:53.263+0000] {processor.py:157} INFO - Started process (PID=50038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:23:53.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:23:53.270+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:23:53.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:23:53.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:23:53.351+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:23:53.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:23:53.366+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:23:53.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:23:53.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-16T03:24:23.572+0000] {processor.py:157} INFO - Started process (PID=50048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:24:23.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:24:23.577+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:24:23.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:24:23.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:24:23.606+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:24:23.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:24:23.620+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:24:23.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:24:23.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-16T03:24:53.976+0000] {processor.py:157} INFO - Started process (PID=50058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:24:53.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:24:53.984+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:24:53.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:24:54.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:24:54.029+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:24:54.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:24:54.043+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:24:54.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:24:54.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-16T03:25:24.347+0000] {processor.py:157} INFO - Started process (PID=50068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:25:24.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:25:24.350+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:25:24.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:25:24.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:25:24.376+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:25:24.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:25:24.387+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:25:24.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:25:24.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-16T03:25:54.761+0000] {processor.py:157} INFO - Started process (PID=50078) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:25:54.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:25:54.767+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:25:54.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:25:54.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:25:54.825+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:25:54.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:25:54.840+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:25:54.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:25:54.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-16T03:26:25.174+0000] {processor.py:157} INFO - Started process (PID=50088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:26:25.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:26:25.177+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:26:25.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:26:25.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:26:25.210+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:26:25.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:26:25.220+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:26:25.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:26:25.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-16T03:26:55.571+0000] {processor.py:157} INFO - Started process (PID=50098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:26:55.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:26:55.576+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:26:55.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:26:55.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:26:55.621+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:26:55.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:26:55.634+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:26:55.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:26:55.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-16T03:27:25.884+0000] {processor.py:157} INFO - Started process (PID=50108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:27:25.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:27:25.887+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:27:25.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:27:25.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:27:25.915+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:27:25.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:27:25.926+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:27:25.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:27:25.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-16T03:27:56.293+0000] {processor.py:157} INFO - Started process (PID=50118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:27:56.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:27:56.298+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:27:56.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:27:56.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:27:56.341+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:27:56.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:27:56.360+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:27:56.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:27:56.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-16T03:28:26.585+0000] {processor.py:157} INFO - Started process (PID=50128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:28:26.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:28:26.589+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:28:26.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:28:26.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:28:26.618+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:28:26.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:28:26.632+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:28:26.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:28:26.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-16T03:28:56.980+0000] {processor.py:157} INFO - Started process (PID=50138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:28:56.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:28:56.991+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:28:56.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:28:57.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:28:57.036+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:28:57.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:28:57.052+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:28:57.051+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:28:57.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-16T03:29:27.296+0000] {processor.py:157} INFO - Started process (PID=50148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:29:27.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:29:27.298+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:29:27.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:29:27.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:29:27.324+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:29:27.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:29:27.336+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:29:27.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:29:27.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-16T03:29:57.713+0000] {processor.py:157} INFO - Started process (PID=50158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:29:57.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:29:57.720+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:29:57.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:29:57.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:29:57.780+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:29:57.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:29:57.797+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:29:57.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:29:57.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-16T03:30:28.120+0000] {processor.py:157} INFO - Started process (PID=50168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:30:28.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:30:28.123+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:30:28.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:30:28.133+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:30:28.151+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:30:28.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:30:28.160+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:30:28.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:30:28.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-16T03:30:58.521+0000] {processor.py:157} INFO - Started process (PID=50178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:30:58.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:30:58.534+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:30:58.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:30:58.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:30:58.575+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:30:58.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:30:58.597+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:30:58.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:30:58.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-16T03:31:28.816+0000] {processor.py:157} INFO - Started process (PID=50188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:31:28.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:31:28.819+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:31:28.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:31:28.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:31:28.846+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:31:28.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:31:28.858+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:31:28.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:31:28.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-16T03:31:59.224+0000] {processor.py:157} INFO - Started process (PID=50198) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:31:59.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:31:59.229+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:31:59.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:31:59.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:31:59.275+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:31:59.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:31:59.288+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:31:59.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:31:59.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-16T03:32:29.519+0000] {processor.py:157} INFO - Started process (PID=50208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:32:29.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:32:29.523+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:32:29.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:32:29.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:32:29.545+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:32:29.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:32:29.554+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:32:29.554+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:32:29.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-16T03:32:59.952+0000] {processor.py:157} INFO - Started process (PID=50218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:32:59.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:32:59.962+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:32:59.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:32:59.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:33:00.024+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:33:00.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:33:00.042+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:33:00.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:33:00.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-16T03:33:30.317+0000] {processor.py:157} INFO - Started process (PID=50228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:33:30.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:33:30.324+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:33:30.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:33:30.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:33:30.366+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:33:30.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:33:30.379+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:33:30.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:33:30.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-16T03:34:00.618+0000] {processor.py:157} INFO - Started process (PID=50238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:34:00.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:34:00.624+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:34:00.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:34:00.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:34:00.678+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:34:00.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:34:00.693+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:34:00.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:34:00.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-16T03:34:30.937+0000] {processor.py:157} INFO - Started process (PID=50248) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:34:30.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:34:30.942+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:34:30.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:34:30.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:34:30.970+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:34:30.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:34:30.982+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:34:30.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:34:30.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-16T03:35:01.311+0000] {processor.py:157} INFO - Started process (PID=50256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:35:01.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:35:01.316+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:35:01.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:35:01.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:35:01.361+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:35:01.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:35:01.374+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:35:01.374+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:35:01.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-16T03:35:31.575+0000] {processor.py:157} INFO - Started process (PID=50268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:35:31.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:35:31.580+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:35:31.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:35:31.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:35:31.616+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:35:31.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:35:31.629+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:35:31.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:35:31.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-16T03:36:01.920+0000] {processor.py:157} INFO - Started process (PID=50278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:36:01.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:36:01.924+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:36:01.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:36:01.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:36:01.951+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:36:01.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:36:01.962+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:36:01.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:36:01.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-16T03:36:32.265+0000] {processor.py:157} INFO - Started process (PID=50288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:36:32.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:36:32.269+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:36:32.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:36:32.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:36:32.309+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:36:32.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:36:32.323+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:36:32.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:36:32.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-16T03:37:02.594+0000] {processor.py:157} INFO - Started process (PID=50298) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:37:02.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:37:02.599+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:37:02.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:37:02.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:37:02.648+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:37:02.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:37:02.662+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:37:02.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:37:02.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-16T03:37:32.883+0000] {processor.py:157} INFO - Started process (PID=50308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:37:32.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:37:32.885+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:37:32.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:37:32.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:37:32.914+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:37:32.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:37:32.924+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:37:32.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:37:32.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-16T03:38:03.262+0000] {processor.py:157} INFO - Started process (PID=50318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:38:03.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:38:03.267+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:38:03.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:38:03.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:38:03.317+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:38:03.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:38:03.331+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:38:03.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:38:03.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-16T03:38:33.533+0000] {processor.py:157} INFO - Started process (PID=50328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:38:33.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:38:33.536+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:38:33.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:38:33.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:38:33.567+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:38:33.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:38:33.576+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:38:33.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:38:33.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-16T03:39:03.841+0000] {processor.py:157} INFO - Started process (PID=50337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:39:03.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:39:03.845+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:39:03.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:39:03.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:39:03.916+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:39:03.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:39:03.939+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:39:03.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:39:03.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-16T03:39:34.190+0000] {processor.py:157} INFO - Started process (PID=50348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:39:34.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:39:34.193+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:39:34.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:39:34.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:39:34.222+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:39:34.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:39:34.232+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:39:34.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:39:34.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-16T03:40:04.592+0000] {processor.py:157} INFO - Started process (PID=50357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:40:04.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:40:04.606+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:40:04.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:40:04.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:40:04.661+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:40:04.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:40:04.676+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:40:04.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:40:04.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-16T03:40:34.888+0000] {processor.py:157} INFO - Started process (PID=50368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:40:34.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:40:34.894+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:40:34.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:40:34.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:40:34.921+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:40:34.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:40:34.931+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:40:34.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:40:34.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-16T03:41:05.305+0000] {processor.py:157} INFO - Started process (PID=50378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:41:05.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:41:05.312+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:41:05.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:41:05.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:41:05.383+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:41:05.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:41:05.403+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:41:05.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:41:05.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-16T03:41:35.744+0000] {processor.py:157} INFO - Started process (PID=50388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:41:35.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:41:35.746+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:41:35.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:41:35.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:41:35.773+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:41:35.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:41:35.787+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:41:35.787+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:41:35.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-16T03:42:06.169+0000] {processor.py:157} INFO - Started process (PID=50396) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:42:06.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:42:06.174+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:42:06.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:42:06.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:42:06.229+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:42:06.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:42:06.243+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:42:06.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:42:06.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-16T03:42:36.449+0000] {processor.py:157} INFO - Started process (PID=50408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:42:36.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:42:36.451+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:42:36.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:42:36.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:42:36.475+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:42:36.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:42:36.486+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:42:36.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:42:36.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-16T03:43:06.759+0000] {processor.py:157} INFO - Started process (PID=50417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:43:06.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:43:06.764+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:43:06.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:43:06.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:43:06.830+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:43:06.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:43:06.846+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:43:06.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:43:06.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-16T03:43:37.021+0000] {processor.py:157} INFO - Started process (PID=50428) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:43:37.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:43:37.024+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:43:37.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:43:37.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:43:37.053+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:43:37.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:43:37.064+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:43:37.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:43:37.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-16T03:44:07.380+0000] {processor.py:157} INFO - Started process (PID=50437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:44:07.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:44:07.386+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:44:07.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:44:07.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:44:07.445+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:44:07.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:44:07.459+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:44:07.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:44:07.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-16T03:44:37.711+0000] {processor.py:157} INFO - Started process (PID=50448) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:44:37.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:44:37.715+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:44:37.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:44:37.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:44:37.742+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:44:37.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:44:37.752+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:44:37.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:44:37.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-16T03:45:08.066+0000] {processor.py:157} INFO - Started process (PID=50457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:45:08.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:45:08.072+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:45:08.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:45:08.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:45:08.119+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:45:08.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:45:08.133+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:45:08.133+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:45:08.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-16T03:45:38.353+0000] {processor.py:157} INFO - Started process (PID=50468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:45:38.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:45:38.356+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:45:38.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:45:38.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:45:38.382+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:45:38.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:45:38.392+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:45:38.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:45:38.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-16T03:46:08.804+0000] {processor.py:157} INFO - Started process (PID=50478) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:46:08.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:46:08.809+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:46:08.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:46:08.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:46:08.862+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:46:08.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:46:08.880+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:46:08.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:46:08.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-16T03:46:39.140+0000] {processor.py:157} INFO - Started process (PID=50488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:46:39.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:46:39.142+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:46:39.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:46:39.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:46:39.168+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:46:39.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:46:39.181+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:46:39.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:46:39.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-16T03:47:09.558+0000] {processor.py:157} INFO - Started process (PID=50498) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:47:09.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:47:09.563+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:47:09.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:47:09.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:47:09.629+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:47:09.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:47:09.643+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:47:09.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:47:09.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-16T03:47:39.993+0000] {processor.py:157} INFO - Started process (PID=50508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:47:39.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:47:39.994+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:47:39.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:47:40.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:47:40.020+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:47:40.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:47:40.030+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:47:40.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:47:40.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-16T03:48:10.323+0000] {processor.py:157} INFO - Started process (PID=50518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:48:10.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:48:10.327+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:48:10.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:48:10.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:48:10.394+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:48:10.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:48:10.409+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:48:10.409+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:48:10.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-16T03:48:40.605+0000] {processor.py:157} INFO - Started process (PID=50528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:48:40.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:48:40.608+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:48:40.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:48:40.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:48:40.640+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:48:40.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:48:40.650+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:48:40.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:48:40.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-16T03:49:11.023+0000] {processor.py:157} INFO - Started process (PID=50537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:49:11.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T03:49:11.027+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:49:11.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:49:11.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T03:49:11.085+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:49:11.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T03:49:11.100+0000] {logging_mixin.py:151} INFO - [2024-08-16T03:49:11.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T03:49:11.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-16T04:05:02.039+0000] {processor.py:157} INFO - Started process (PID=50548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T04:05:02.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T04:05:02.051+0000] {logging_mixin.py:151} INFO - [2024-08-16T04:05:02.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T04:05:02.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T04:05:02.138+0000] {logging_mixin.py:151} INFO - [2024-08-16T04:05:02.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T04:05:02.171+0000] {logging_mixin.py:151} INFO - [2024-08-16T04:05:02.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T04:05:02.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-08-16T04:07:30.465+0000] {processor.py:157} INFO - Started process (PID=50560) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T04:07:30.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T04:07:30.476+0000] {logging_mixin.py:151} INFO - [2024-08-16T04:07:30.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T04:07:30.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T04:07:30.552+0000] {logging_mixin.py:151} INFO - [2024-08-16T04:07:30.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T04:07:30.582+0000] {logging_mixin.py:151} INFO - [2024-08-16T04:07:30.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T04:07:30.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-08-16T04:08:07.280+0000] {processor.py:157} INFO - Started process (PID=50572) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T04:08:07.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T04:08:07.285+0000] {logging_mixin.py:151} INFO - [2024-08-16T04:08:07.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T04:08:07.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T04:08:07.330+0000] {logging_mixin.py:151} INFO - [2024-08-16T04:08:07.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T04:08:07.357+0000] {logging_mixin.py:151} INFO - [2024-08-16T04:08:07.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T04:08:07.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-16T04:08:37.599+0000] {processor.py:157} INFO - Started process (PID=50582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T04:08:37.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T04:08:37.602+0000] {logging_mixin.py:151} INFO - [2024-08-16T04:08:37.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T04:08:37.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T04:08:37.629+0000] {logging_mixin.py:151} INFO - [2024-08-16T04:08:37.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T04:08:37.639+0000] {logging_mixin.py:151} INFO - [2024-08-16T04:08:37.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T04:08:37.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-16T04:31:50.762+0000] {processor.py:157} INFO - Started process (PID=50592) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T04:31:50.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T04:31:50.767+0000] {logging_mixin.py:151} INFO - [2024-08-16T04:31:50.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T04:31:50.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T04:31:50.814+0000] {logging_mixin.py:151} INFO - [2024-08-16T04:31:50.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T04:31:50.832+0000] {logging_mixin.py:151} INFO - [2024-08-16T04:31:50.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T04:31:50.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-16T04:32:21.175+0000] {processor.py:157} INFO - Started process (PID=50602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T04:32:21.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T04:32:21.189+0000] {logging_mixin.py:151} INFO - [2024-08-16T04:32:21.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T04:32:21.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T04:32:21.250+0000] {logging_mixin.py:151} INFO - [2024-08-16T04:32:21.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T04:32:21.265+0000] {logging_mixin.py:151} INFO - [2024-08-16T04:32:21.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T04:32:21.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-16T04:44:12.114+0000] {processor.py:157} INFO - Started process (PID=50614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T04:44:12.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T04:44:12.133+0000] {logging_mixin.py:151} INFO - [2024-08-16T04:44:12.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T04:44:12.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T04:44:12.195+0000] {logging_mixin.py:151} INFO - [2024-08-16T04:44:12.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T04:44:12.213+0000] {logging_mixin.py:151} INFO - [2024-08-16T04:44:12.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T04:44:12.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-16T05:32:42.123+0000] {processor.py:157} INFO - Started process (PID=50624) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T05:32:42.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T05:32:42.144+0000] {logging_mixin.py:151} INFO - [2024-08-16T05:32:42.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T05:32:42.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T05:32:42.222+0000] {logging_mixin.py:151} INFO - [2024-08-16T05:32:42.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T05:32:42.260+0000] {logging_mixin.py:151} INFO - [2024-08-16T05:32:42.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T05:32:42.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-08-16T05:50:37.083+0000] {processor.py:157} INFO - Started process (PID=50634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T05:50:37.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T05:50:37.088+0000] {logging_mixin.py:151} INFO - [2024-08-16T05:50:37.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T05:50:37.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T05:50:37.143+0000] {logging_mixin.py:151} INFO - [2024-08-16T05:50:37.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T05:50:37.165+0000] {logging_mixin.py:151} INFO - [2024-08-16T05:50:37.165+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T05:50:37.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-16T06:07:14.360+0000] {processor.py:157} INFO - Started process (PID=50644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T06:07:14.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T06:07:14.371+0000] {logging_mixin.py:151} INFO - [2024-08-16T06:07:14.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T06:07:14.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T06:07:14.448+0000] {logging_mixin.py:151} INFO - [2024-08-16T06:07:14.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T06:07:14.476+0000] {logging_mixin.py:151} INFO - [2024-08-16T06:07:14.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T06:07:14.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-08-16T07:44:12.192+0000] {processor.py:157} INFO - Started process (PID=50654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T07:44:12.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T07:44:12.205+0000] {logging_mixin.py:151} INFO - [2024-08-16T07:44:12.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T07:44:12.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T07:44:12.269+0000] {logging_mixin.py:151} INFO - [2024-08-16T07:44:12.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T07:44:12.288+0000] {logging_mixin.py:151} INFO - [2024-08-16T07:44:12.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T07:44:12.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-16T09:04:33.457+0000] {processor.py:157} INFO - Started process (PID=50665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T09:04:33.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T09:04:33.462+0000] {logging_mixin.py:151} INFO - [2024-08-16T09:04:33.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T09:04:33.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T09:04:33.522+0000] {logging_mixin.py:151} INFO - [2024-08-16T09:04:33.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T09:04:33.541+0000] {logging_mixin.py:151} INFO - [2024-08-16T09:04:33.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T09:04:33.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-16T10:01:14.510+0000] {processor.py:157} INFO - Started process (PID=50676) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T10:01:14.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T10:01:14.514+0000] {logging_mixin.py:151} INFO - [2024-08-16T10:01:14.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T10:01:14.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T10:01:14.557+0000] {logging_mixin.py:151} INFO - [2024-08-16T10:01:14.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T10:01:14.572+0000] {logging_mixin.py:151} INFO - [2024-08-16T10:01:14.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T10:01:14.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-16T10:01:44.845+0000] {processor.py:157} INFO - Started process (PID=50686) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T10:01:44.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T10:01:44.851+0000] {logging_mixin.py:151} INFO - [2024-08-16T10:01:44.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T10:01:44.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T10:01:44.907+0000] {logging_mixin.py:151} INFO - [2024-08-16T10:01:44.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T10:01:44.920+0000] {logging_mixin.py:151} INFO - [2024-08-16T10:01:44.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T10:01:44.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-16T11:26:28.564+0000] {processor.py:157} INFO - Started process (PID=50696) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T11:26:28.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T11:26:28.569+0000] {logging_mixin.py:151} INFO - [2024-08-16T11:26:28.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T11:26:28.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T11:26:28.615+0000] {logging_mixin.py:151} INFO - [2024-08-16T11:26:28.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T11:26:28.630+0000] {logging_mixin.py:151} INFO - [2024-08-16T11:26:28.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T11:26:28.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-16T12:44:44.115+0000] {processor.py:157} INFO - Started process (PID=50705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T12:44:44.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T12:44:44.120+0000] {logging_mixin.py:151} INFO - [2024-08-16T12:44:44.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T12:44:44.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T12:44:44.178+0000] {logging_mixin.py:151} INFO - [2024-08-16T12:44:44.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T12:44:44.198+0000] {logging_mixin.py:151} INFO - [2024-08-16T12:44:44.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T12:44:44.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-16T12:45:14.373+0000] {processor.py:157} INFO - Started process (PID=50716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T12:45:14.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T12:45:14.379+0000] {logging_mixin.py:151} INFO - [2024-08-16T12:45:14.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T12:45:14.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T12:45:14.428+0000] {logging_mixin.py:151} INFO - [2024-08-16T12:45:14.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T12:45:14.444+0000] {logging_mixin.py:151} INFO - [2024-08-16T12:45:14.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T12:45:14.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-16T12:52:55.506+0000] {processor.py:157} INFO - Started process (PID=50726) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T12:52:55.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T12:52:55.512+0000] {logging_mixin.py:151} INFO - [2024-08-16T12:52:55.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T12:52:55.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T12:52:55.563+0000] {logging_mixin.py:151} INFO - [2024-08-16T12:52:55.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T12:52:55.577+0000] {logging_mixin.py:151} INFO - [2024-08-16T12:52:55.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T12:52:55.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-16T13:02:19.056+0000] {processor.py:157} INFO - Started process (PID=50737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T13:02:19.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T13:02:19.061+0000] {logging_mixin.py:151} INFO - [2024-08-16T13:02:19.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T13:02:19.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T13:02:19.125+0000] {logging_mixin.py:151} INFO - [2024-08-16T13:02:19.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T13:02:19.147+0000] {logging_mixin.py:151} INFO - [2024-08-16T13:02:19.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T13:02:19.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-16T13:02:49.378+0000] {processor.py:157} INFO - Started process (PID=50747) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T13:02:49.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T13:02:49.398+0000] {logging_mixin.py:151} INFO - [2024-08-16T13:02:49.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T13:02:49.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T13:02:49.444+0000] {logging_mixin.py:151} INFO - [2024-08-16T13:02:49.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T13:02:49.458+0000] {logging_mixin.py:151} INFO - [2024-08-16T13:02:49.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T13:02:49.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-16T13:53:44.666+0000] {processor.py:157} INFO - Started process (PID=50758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T13:53:44.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T13:53:44.672+0000] {logging_mixin.py:151} INFO - [2024-08-16T13:53:44.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T13:53:44.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T13:53:44.725+0000] {logging_mixin.py:151} INFO - [2024-08-16T13:53:44.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T13:53:44.761+0000] {logging_mixin.py:151} INFO - [2024-08-16T13:53:44.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T13:53:44.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-16T13:54:14.986+0000] {processor.py:157} INFO - Started process (PID=50769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T13:54:14.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T13:54:14.997+0000] {logging_mixin.py:151} INFO - [2024-08-16T13:54:14.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T13:54:15.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T13:54:15.054+0000] {logging_mixin.py:151} INFO - [2024-08-16T13:54:15.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T13:54:15.069+0000] {logging_mixin.py:151} INFO - [2024-08-16T13:54:15.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T13:54:15.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-16T13:55:01.937+0000] {processor.py:157} INFO - Started process (PID=50779) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T13:55:01.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T13:55:01.939+0000] {logging_mixin.py:151} INFO - [2024-08-16T13:55:01.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T13:55:01.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T13:55:01.966+0000] {logging_mixin.py:151} INFO - [2024-08-16T13:55:01.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T13:55:01.979+0000] {logging_mixin.py:151} INFO - [2024-08-16T13:55:01.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T13:55:01.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-16T14:03:21.109+0000] {processor.py:157} INFO - Started process (PID=50789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T14:03:21.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T14:03:21.119+0000] {logging_mixin.py:151} INFO - [2024-08-16T14:03:21.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T14:03:21.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T14:03:21.159+0000] {logging_mixin.py:151} INFO - [2024-08-16T14:03:21.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T14:03:21.175+0000] {logging_mixin.py:151} INFO - [2024-08-16T14:03:21.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T14:03:21.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-16T14:03:51.452+0000] {processor.py:157} INFO - Started process (PID=50798) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T14:03:51.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T14:03:51.468+0000] {logging_mixin.py:151} INFO - [2024-08-16T14:03:51.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T14:03:51.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T14:03:51.535+0000] {logging_mixin.py:151} INFO - [2024-08-16T14:03:51.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T14:03:51.550+0000] {logging_mixin.py:151} INFO - [2024-08-16T14:03:51.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T14:03:51.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-16T14:51:30.692+0000] {processor.py:157} INFO - Started process (PID=50810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T14:51:30.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T14:51:30.703+0000] {logging_mixin.py:151} INFO - [2024-08-16T14:51:30.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T14:51:30.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T14:51:30.794+0000] {logging_mixin.py:151} INFO - [2024-08-16T14:51:30.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T14:51:30.829+0000] {logging_mixin.py:151} INFO - [2024-08-16T14:51:30.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T14:51:30.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-08-16T14:52:01.002+0000] {processor.py:157} INFO - Started process (PID=50821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T14:52:01.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T14:52:01.019+0000] {logging_mixin.py:151} INFO - [2024-08-16T14:52:01.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T14:52:01.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T14:52:01.066+0000] {logging_mixin.py:151} INFO - [2024-08-16T14:52:01.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T14:52:01.085+0000] {logging_mixin.py:151} INFO - [2024-08-16T14:52:01.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T14:52:01.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-16T15:01:13.611+0000] {processor.py:157} INFO - Started process (PID=50831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T15:01:13.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T15:01:13.617+0000] {logging_mixin.py:151} INFO - [2024-08-16T15:01:13.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T15:01:13.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T15:01:13.664+0000] {logging_mixin.py:151} INFO - [2024-08-16T15:01:13.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T15:01:13.680+0000] {logging_mixin.py:151} INFO - [2024-08-16T15:01:13.680+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T15:01:13.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-16T15:01:43.969+0000] {processor.py:157} INFO - Started process (PID=50841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T15:01:43.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T15:01:43.980+0000] {logging_mixin.py:151} INFO - [2024-08-16T15:01:43.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T15:01:44.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T15:01:44.053+0000] {logging_mixin.py:151} INFO - [2024-08-16T15:01:44.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T15:01:44.083+0000] {logging_mixin.py:151} INFO - [2024-08-16T15:01:44.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T15:01:44.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-08-16T15:02:14.300+0000] {processor.py:157} INFO - Started process (PID=50851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T15:02:14.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T15:02:14.305+0000] {logging_mixin.py:151} INFO - [2024-08-16T15:02:14.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T15:02:14.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T15:02:14.354+0000] {logging_mixin.py:151} INFO - [2024-08-16T15:02:14.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T15:02:14.368+0000] {logging_mixin.py:151} INFO - [2024-08-16T15:02:14.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T15:02:14.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-16T15:02:44.630+0000] {processor.py:157} INFO - Started process (PID=50861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T15:02:44.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T15:02:44.636+0000] {logging_mixin.py:151} INFO - [2024-08-16T15:02:44.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T15:02:44.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T15:02:44.688+0000] {logging_mixin.py:151} INFO - [2024-08-16T15:02:44.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T15:02:44.701+0000] {logging_mixin.py:151} INFO - [2024-08-16T15:02:44.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T15:02:44.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-16T15:03:14.961+0000] {processor.py:157} INFO - Started process (PID=50871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T15:03:14.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T15:03:14.967+0000] {logging_mixin.py:151} INFO - [2024-08-16T15:03:14.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T15:03:14.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T15:03:15.013+0000] {logging_mixin.py:151} INFO - [2024-08-16T15:03:15.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T15:03:15.033+0000] {logging_mixin.py:151} INFO - [2024-08-16T15:03:15.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T15:03:15.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-16T15:03:45.241+0000] {processor.py:157} INFO - Started process (PID=50881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T15:03:45.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T15:03:45.245+0000] {logging_mixin.py:151} INFO - [2024-08-16T15:03:45.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T15:03:45.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T15:03:45.283+0000] {logging_mixin.py:151} INFO - [2024-08-16T15:03:45.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T15:03:45.297+0000] {logging_mixin.py:151} INFO - [2024-08-16T15:03:45.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T15:03:45.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-16T15:15:04.010+0000] {processor.py:157} INFO - Started process (PID=50893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T15:15:04.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T15:15:04.016+0000] {logging_mixin.py:151} INFO - [2024-08-16T15:15:04.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T15:15:04.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T15:15:04.084+0000] {logging_mixin.py:151} INFO - [2024-08-16T15:15:04.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T15:15:04.121+0000] {logging_mixin.py:151} INFO - [2024-08-16T15:15:04.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T15:15:04.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-08-16T15:15:34.389+0000] {processor.py:157} INFO - Started process (PID=50902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T15:15:34.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T15:15:34.394+0000] {logging_mixin.py:151} INFO - [2024-08-16T15:15:34.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T15:15:34.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T15:15:34.439+0000] {logging_mixin.py:151} INFO - [2024-08-16T15:15:34.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T15:15:34.454+0000] {logging_mixin.py:151} INFO - [2024-08-16T15:15:34.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T15:15:34.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-16T15:51:58.559+0000] {processor.py:157} INFO - Started process (PID=50911) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T15:51:58.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T15:51:58.570+0000] {logging_mixin.py:151} INFO - [2024-08-16T15:51:58.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T15:51:58.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T15:51:58.648+0000] {logging_mixin.py:151} INFO - [2024-08-16T15:51:58.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T15:51:58.679+0000] {logging_mixin.py:151} INFO - [2024-08-16T15:51:58.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T15:51:58.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-08-16T15:52:28.884+0000] {processor.py:157} INFO - Started process (PID=50923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T15:52:28.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T15:52:28.889+0000] {logging_mixin.py:151} INFO - [2024-08-16T15:52:28.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T15:52:28.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T15:52:28.951+0000] {logging_mixin.py:151} INFO - [2024-08-16T15:52:28.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T15:52:28.965+0000] {logging_mixin.py:151} INFO - [2024-08-16T15:52:28.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T15:52:28.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-16T16:29:21.247+0000] {processor.py:157} INFO - Started process (PID=50934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T16:29:21.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T16:29:21.258+0000] {logging_mixin.py:151} INFO - [2024-08-16T16:29:21.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T16:29:21.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T16:29:21.325+0000] {logging_mixin.py:151} INFO - [2024-08-16T16:29:21.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T16:29:21.352+0000] {logging_mixin.py:151} INFO - [2024-08-16T16:29:21.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T16:29:21.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-08-16T16:29:51.542+0000] {processor.py:157} INFO - Started process (PID=50944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T16:29:51.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T16:29:51.547+0000] {logging_mixin.py:151} INFO - [2024-08-16T16:29:51.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T16:29:51.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T16:29:51.606+0000] {logging_mixin.py:151} INFO - [2024-08-16T16:29:51.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T16:29:51.622+0000] {logging_mixin.py:151} INFO - [2024-08-16T16:29:51.622+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T16:29:51.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-16T16:37:57.845+0000] {processor.py:157} INFO - Started process (PID=50955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T16:37:57.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T16:37:57.849+0000] {logging_mixin.py:151} INFO - [2024-08-16T16:37:57.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T16:37:57.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T16:37:57.913+0000] {logging_mixin.py:151} INFO - [2024-08-16T16:37:57.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T16:37:57.927+0000] {logging_mixin.py:151} INFO - [2024-08-16T16:37:57.927+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T16:37:57.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-16T16:38:31.856+0000] {processor.py:157} INFO - Started process (PID=50964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T16:38:31.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T16:38:31.863+0000] {logging_mixin.py:151} INFO - [2024-08-16T16:38:31.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T16:38:31.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T16:38:31.915+0000] {logging_mixin.py:151} INFO - [2024-08-16T16:38:31.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T16:38:31.932+0000] {logging_mixin.py:151} INFO - [2024-08-16T16:38:31.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T16:38:31.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-16T16:39:02.209+0000] {processor.py:157} INFO - Started process (PID=50975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T16:39:02.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T16:39:02.211+0000] {logging_mixin.py:151} INFO - [2024-08-16T16:39:02.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T16:39:02.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T16:39:02.242+0000] {logging_mixin.py:151} INFO - [2024-08-16T16:39:02.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T16:39:02.250+0000] {logging_mixin.py:151} INFO - [2024-08-16T16:39:02.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T16:39:02.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-16T16:43:36.910+0000] {processor.py:157} INFO - Started process (PID=50985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T16:43:36.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T16:43:36.922+0000] {logging_mixin.py:151} INFO - [2024-08-16T16:43:36.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T16:43:36.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T16:43:36.988+0000] {logging_mixin.py:151} INFO - [2024-08-16T16:43:36.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T16:43:37.008+0000] {logging_mixin.py:151} INFO - [2024-08-16T16:43:37.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T16:43:37.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-16T16:44:07.212+0000] {processor.py:157} INFO - Started process (PID=50997) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T16:44:07.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T16:44:07.224+0000] {logging_mixin.py:151} INFO - [2024-08-16T16:44:07.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T16:44:07.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T16:44:07.294+0000] {logging_mixin.py:151} INFO - [2024-08-16T16:44:07.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T16:44:07.317+0000] {logging_mixin.py:151} INFO - [2024-08-16T16:44:07.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T16:44:07.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-16T16:44:37.574+0000] {processor.py:157} INFO - Started process (PID=51007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T16:44:37.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T16:44:37.581+0000] {logging_mixin.py:151} INFO - [2024-08-16T16:44:37.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T16:44:37.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T16:44:37.627+0000] {logging_mixin.py:151} INFO - [2024-08-16T16:44:37.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T16:44:37.645+0000] {logging_mixin.py:151} INFO - [2024-08-16T16:44:37.644+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T16:44:37.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-16T17:17:57.148+0000] {processor.py:157} INFO - Started process (PID=51018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T17:17:57.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T17:17:57.164+0000] {logging_mixin.py:151} INFO - [2024-08-16T17:17:57.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T17:17:57.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T17:17:57.247+0000] {logging_mixin.py:151} INFO - [2024-08-16T17:17:57.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T17:17:57.268+0000] {logging_mixin.py:151} INFO - [2024-08-16T17:17:57.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T17:17:57.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-08-16T17:31:52.033+0000] {processor.py:157} INFO - Started process (PID=51029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T17:31:52.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T17:31:52.038+0000] {logging_mixin.py:151} INFO - [2024-08-16T17:31:52.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T17:31:52.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T17:31:52.095+0000] {logging_mixin.py:151} INFO - [2024-08-16T17:31:52.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T17:31:52.117+0000] {logging_mixin.py:151} INFO - [2024-08-16T17:31:52.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T17:31:52.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-16T17:33:07.531+0000] {processor.py:157} INFO - Started process (PID=51039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T17:33:07.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T17:33:07.538+0000] {logging_mixin.py:151} INFO - [2024-08-16T17:33:07.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T17:33:07.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T17:33:07.596+0000] {logging_mixin.py:151} INFO - [2024-08-16T17:33:07.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T17:33:07.613+0000] {logging_mixin.py:151} INFO - [2024-08-16T17:33:07.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T17:33:07.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-16T17:33:37.838+0000] {processor.py:157} INFO - Started process (PID=51049) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T17:33:37.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T17:33:37.841+0000] {logging_mixin.py:151} INFO - [2024-08-16T17:33:37.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T17:33:37.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T17:33:37.868+0000] {logging_mixin.py:151} INFO - [2024-08-16T17:33:37.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T17:33:37.879+0000] {logging_mixin.py:151} INFO - [2024-08-16T17:33:37.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T17:33:37.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-16T18:45:56.458+0000] {processor.py:157} INFO - Started process (PID=51059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T18:45:56.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T18:45:56.463+0000] {logging_mixin.py:151} INFO - [2024-08-16T18:45:56.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T18:45:56.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T18:45:56.527+0000] {logging_mixin.py:151} INFO - [2024-08-16T18:45:56.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T18:45:56.548+0000] {logging_mixin.py:151} INFO - [2024-08-16T18:45:56.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T18:45:56.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-16T18:46:26.897+0000] {processor.py:157} INFO - Started process (PID=51069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T18:46:26.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T18:46:26.899+0000] {logging_mixin.py:151} INFO - [2024-08-16T18:46:26.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T18:46:26.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T18:46:26.928+0000] {logging_mixin.py:151} INFO - [2024-08-16T18:46:26.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T18:46:26.939+0000] {logging_mixin.py:151} INFO - [2024-08-16T18:46:26.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T18:46:26.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-16T19:35:21.901+0000] {processor.py:157} INFO - Started process (PID=51081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T19:35:21.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T19:35:21.908+0000] {logging_mixin.py:151} INFO - [2024-08-16T19:35:21.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T19:35:21.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T19:35:21.983+0000] {logging_mixin.py:151} INFO - [2024-08-16T19:35:21.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T19:35:22.011+0000] {logging_mixin.py:151} INFO - [2024-08-16T19:35:22.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T19:35:22.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-16T19:47:24.992+0000] {processor.py:157} INFO - Started process (PID=51091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T19:47:24.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T19:47:24.997+0000] {logging_mixin.py:151} INFO - [2024-08-16T19:47:24.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T19:47:25.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T19:47:25.032+0000] {logging_mixin.py:151} INFO - [2024-08-16T19:47:25.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T19:47:25.054+0000] {logging_mixin.py:151} INFO - [2024-08-16T19:47:25.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T19:47:25.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-16T20:37:12.122+0000] {processor.py:157} INFO - Started process (PID=51101) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:37:12.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:37:12.127+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:37:12.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:37:12.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:37:12.171+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:37:12.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:37:12.196+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:37:12.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:37:12.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-16T20:43:50.955+0000] {processor.py:157} INFO - Started process (PID=51111) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:43:50.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:43:50.964+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:43:50.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:43:50.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:43:51.022+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:43:51.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:43:51.038+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:43:51.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:43:51.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-16T20:44:21.423+0000] {processor.py:157} INFO - Started process (PID=51121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:44:21.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:44:21.431+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:44:21.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:44:21.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:44:21.505+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:44:21.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:44:21.526+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:44:21.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:44:21.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-16T20:44:51.724+0000] {processor.py:157} INFO - Started process (PID=51131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:44:51.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:44:51.733+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:44:51.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:44:51.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:44:51.784+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:44:51.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:44:51.809+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:44:51.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:44:51.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-16T20:45:22.004+0000] {processor.py:157} INFO - Started process (PID=51141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:45:22.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:45:22.008+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:45:22.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:45:22.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:45:22.049+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:45:22.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:45:22.064+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:45:22.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:45:22.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-16T20:45:52.388+0000] {processor.py:157} INFO - Started process (PID=51151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:45:52.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:45:52.391+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:45:52.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:45:52.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:45:52.419+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:45:52.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:45:52.434+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:45:52.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:45:52.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-16T20:46:22.674+0000] {processor.py:157} INFO - Started process (PID=51160) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:46:22.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:46:22.679+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:46:22.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:46:22.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:46:22.751+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:46:22.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:46:22.768+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:46:22.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:46:22.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-16T20:46:52.948+0000] {processor.py:157} INFO - Started process (PID=51171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:46:52.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:46:52.951+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:46:52.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:46:52.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:46:52.974+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:46:52.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:46:52.983+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:46:52.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:46:52.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-08-16T20:47:23.267+0000] {processor.py:157} INFO - Started process (PID=51181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:47:23.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:47:23.273+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:47:23.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:47:23.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:47:23.345+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:47:23.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:47:23.364+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:47:23.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:47:23.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-16T20:47:53.889+0000] {processor.py:157} INFO - Started process (PID=51191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:47:53.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:47:53.894+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:47:53.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:47:53.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:47:53.969+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:47:53.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:47:53.989+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:47:53.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:47:54.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-16T20:48:24.138+0000] {processor.py:157} INFO - Started process (PID=51201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:48:24.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:48:24.141+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:48:24.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:48:24.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:48:24.171+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:48:24.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:48:24.182+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:48:24.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:48:24.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-16T20:48:54.495+0000] {processor.py:157} INFO - Started process (PID=51211) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:48:54.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:48:54.499+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:48:54.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:48:54.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:48:54.558+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:48:54.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:48:54.574+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:48:54.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:48:54.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-16T20:49:24.802+0000] {processor.py:157} INFO - Started process (PID=51221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:49:24.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:49:24.803+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:49:24.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:49:24.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:49:24.831+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:49:24.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:49:24.843+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:49:24.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:49:24.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-16T20:49:55.113+0000] {processor.py:157} INFO - Started process (PID=51231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:49:55.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:49:55.116+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:49:55.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:49:55.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:49:55.151+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:49:55.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:49:55.164+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:49:55.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:49:55.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-16T20:50:25.328+0000] {processor.py:157} INFO - Started process (PID=51241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:50:25.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:50:25.329+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:50:25.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:50:25.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:50:25.359+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:50:25.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:50:25.372+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:50:25.372+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:50:25.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-16T20:50:55.575+0000] {processor.py:157} INFO - Started process (PID=51251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:50:55.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:50:55.578+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:50:55.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:50:55.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:50:55.630+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:50:55.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:50:55.643+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:50:55.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:50:55.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-16T20:51:25.891+0000] {processor.py:157} INFO - Started process (PID=51261) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:51:25.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:51:25.893+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:51:25.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:51:25.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:51:25.917+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:51:25.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:51:25.929+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:51:25.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:51:25.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-16T20:51:56.181+0000] {processor.py:157} INFO - Started process (PID=51271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:51:56.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:51:56.183+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:51:56.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:51:56.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:51:56.205+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:51:56.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:51:56.214+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:51:56.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:51:56.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-08-16T20:52:26.525+0000] {processor.py:157} INFO - Started process (PID=51281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:52:26.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:52:26.532+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:52:26.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:52:26.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:52:26.593+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:52:26.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:52:26.610+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:52:26.610+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:52:26.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-16T20:52:56.719+0000] {processor.py:157} INFO - Started process (PID=51291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:52:56.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:52:56.722+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:52:56.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:52:56.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:52:56.750+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:52:56.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:52:56.760+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:52:56.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:52:56.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-16T20:53:27.056+0000] {processor.py:157} INFO - Started process (PID=51300) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:53:27.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:53:27.064+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:53:27.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:53:27.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:53:27.159+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:53:27.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:53:27.186+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:53:27.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:53:27.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-08-16T20:53:57.286+0000] {processor.py:157} INFO - Started process (PID=51311) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:53:57.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:53:57.293+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:53:57.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:53:57.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:53:57.319+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:53:57.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:53:57.331+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:53:57.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:53:57.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-16T20:54:27.590+0000] {processor.py:157} INFO - Started process (PID=51321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:54:27.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:54:27.595+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:54:27.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:54:27.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:54:27.630+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:54:27.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:54:27.644+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:54:27.644+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:54:27.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-16T20:54:57.834+0000] {processor.py:157} INFO - Started process (PID=51331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:54:57.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:54:57.836+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:54:57.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:54:57.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:54:57.869+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:54:57.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:54:57.887+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:54:57.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:54:57.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-16T20:55:28.093+0000] {processor.py:157} INFO - Started process (PID=51341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:55:28.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:55:28.097+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:55:28.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:55:28.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:55:28.131+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:55:28.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:55:28.144+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:55:28.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:55:28.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-16T20:55:58.428+0000] {processor.py:157} INFO - Started process (PID=51351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:55:58.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:55:58.430+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:55:58.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:55:58.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:55:58.466+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:55:58.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:55:58.482+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:55:58.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:55:58.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-16T20:56:28.754+0000] {processor.py:157} INFO - Started process (PID=51360) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:56:28.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:56:28.758+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:56:28.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:56:28.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:56:28.783+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:56:28.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:56:28.794+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:56:28.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:56:28.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-16T20:56:59.086+0000] {processor.py:157} INFO - Started process (PID=51371) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:56:59.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:56:59.087+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:56:59.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:56:59.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:56:59.111+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:56:59.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:56:59.121+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:56:59.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:56:59.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-16T20:57:29.406+0000] {processor.py:157} INFO - Started process (PID=51381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:57:29.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:57:29.409+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:57:29.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:57:29.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:57:29.462+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:57:29.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:57:29.477+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:57:29.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:57:29.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-16T20:57:59.676+0000] {processor.py:157} INFO - Started process (PID=51390) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:57:59.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:57:59.682+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:57:59.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:57:59.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:57:59.702+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:57:59.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:57:59.712+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:57:59.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:57:59.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-08-16T20:58:29.994+0000] {processor.py:157} INFO - Started process (PID=51401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:58:29.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:58:29.996+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:58:29.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:58:30.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:58:30.030+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:58:30.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:58:30.043+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:58:30.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:58:30.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-16T20:59:00.301+0000] {processor.py:157} INFO - Started process (PID=51411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:59:00.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:59:00.303+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:59:00.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:59:00.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:59:00.332+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:59:00.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:59:00.347+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:59:00.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:59:00.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-16T20:59:30.610+0000] {processor.py:157} INFO - Started process (PID=51421) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:59:30.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T20:59:30.613+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:59:30.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:59:30.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T20:59:30.641+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:59:30.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T20:59:30.653+0000] {logging_mixin.py:151} INFO - [2024-08-16T20:59:30.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T20:59:30.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-16T21:00:00.999+0000] {processor.py:157} INFO - Started process (PID=51431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:00:01.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:00:01.003+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:00:01.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:00:01.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:00:01.050+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:00:01.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:00:01.068+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:00:01.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:00:01.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-16T21:00:31.329+0000] {processor.py:157} INFO - Started process (PID=51441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:00:31.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:00:31.331+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:00:31.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:00:31.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:00:31.358+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:00:31.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:00:31.374+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:00:31.374+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:00:31.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-16T21:01:01.649+0000] {processor.py:157} INFO - Started process (PID=51451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:01:01.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:01:01.651+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:01:01.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:01:01.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:01:01.686+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:01:01.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:01:01.700+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:01:01.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:01:01.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-16T21:01:31.897+0000] {processor.py:157} INFO - Started process (PID=51461) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:01:31.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:01:31.899+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:01:31.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:01:31.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:01:31.924+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:01:31.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:01:31.934+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:01:31.934+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:01:31.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-16T21:02:02.216+0000] {processor.py:157} INFO - Started process (PID=51470) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:02:02.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:02:02.220+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:02:02.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:02:02.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:02:02.249+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:02:02.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:02:02.264+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:02:02.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:02:02.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-16T21:02:32.498+0000] {processor.py:157} INFO - Started process (PID=51481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:02:32.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:02:32.500+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:02:32.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:02:32.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:02:32.531+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:02:32.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:02:32.543+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:02:32.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:02:32.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-16T21:03:02.823+0000] {processor.py:157} INFO - Started process (PID=51491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:03:02.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:03:02.827+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:03:02.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:03:02.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:03:02.857+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:03:02.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:03:02.868+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:03:02.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:03:02.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-16T21:03:33.129+0000] {processor.py:157} INFO - Started process (PID=51501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:03:33.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:03:33.132+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:03:33.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:03:33.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:03:33.155+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:03:33.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:03:33.166+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:03:33.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:03:33.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-16T21:04:03.493+0000] {processor.py:157} INFO - Started process (PID=51511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:04:03.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:04:03.496+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:04:03.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:04:03.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:04:03.542+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:04:03.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:04:03.558+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:04:03.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:04:03.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-16T21:04:33.734+0000] {processor.py:157} INFO - Started process (PID=51521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:04:33.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:04:33.736+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:04:33.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:04:33.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:04:33.763+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:04:33.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:04:33.774+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:04:33.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:04:33.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-16T21:05:04.072+0000] {processor.py:157} INFO - Started process (PID=51530) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:05:04.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:05:04.080+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:05:04.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:05:04.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:05:04.127+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:05:04.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:05:04.143+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:05:04.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:05:04.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-16T21:05:34.310+0000] {processor.py:157} INFO - Started process (PID=51541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:05:34.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:05:34.313+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:05:34.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:05:34.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:05:34.336+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:05:34.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:05:34.346+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:05:34.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:05:34.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-16T21:06:04.737+0000] {processor.py:157} INFO - Started process (PID=51550) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:06:04.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:06:04.741+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:06:04.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:06:04.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:06:04.795+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:06:04.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:06:04.811+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:06:04.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:06:04.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-16T21:06:35.080+0000] {processor.py:157} INFO - Started process (PID=51561) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:06:35.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:06:35.081+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:06:35.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:06:35.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:06:35.106+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:06:35.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:06:35.115+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:06:35.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:06:35.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-16T21:07:05.482+0000] {processor.py:157} INFO - Started process (PID=51571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:07:05.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:07:05.487+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:07:05.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:07:05.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:07:05.529+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:07:05.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:07:05.543+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:07:05.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:07:05.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-16T21:07:35.771+0000] {processor.py:157} INFO - Started process (PID=51581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:07:35.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:07:35.777+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:07:35.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:07:35.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:07:35.799+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:07:35.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:07:35.814+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:07:35.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:07:35.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-16T21:08:06.043+0000] {processor.py:157} INFO - Started process (PID=51591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:08:06.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:08:06.057+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:08:06.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:08:06.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:08:06.102+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:08:06.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:08:06.116+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:08:06.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:08:06.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-16T21:08:36.319+0000] {processor.py:157} INFO - Started process (PID=51601) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:08:36.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:08:36.325+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:08:36.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:08:36.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:08:36.355+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:08:36.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:08:36.367+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:08:36.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:08:36.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-16T21:09:06.606+0000] {processor.py:157} INFO - Started process (PID=51611) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:09:06.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:09:06.610+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:09:06.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:09:06.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:09:06.644+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:09:06.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:09:06.658+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:09:06.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:09:06.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-16T21:09:36.864+0000] {processor.py:157} INFO - Started process (PID=51621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:09:36.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:09:36.866+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:09:36.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:09:36.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:09:36.898+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:09:36.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:09:36.911+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:09:36.911+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:09:36.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-16T21:10:07.125+0000] {processor.py:157} INFO - Started process (PID=51631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:10:07.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:10:07.129+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:10:07.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:10:07.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:10:07.155+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:10:07.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:10:07.168+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:10:07.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:10:07.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-16T21:10:37.477+0000] {processor.py:157} INFO - Started process (PID=51641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:10:37.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:10:37.482+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:10:37.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:10:37.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:10:37.525+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:10:37.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:10:37.538+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:10:37.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:10:37.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-16T21:11:07.803+0000] {processor.py:157} INFO - Started process (PID=51651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:11:07.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:11:07.808+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:11:07.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:11:07.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:11:07.844+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:11:07.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:11:07.857+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:11:07.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:11:07.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-16T21:11:38.115+0000] {processor.py:157} INFO - Started process (PID=51661) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:11:38.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:11:38.123+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:11:38.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:11:38.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:11:38.142+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:11:38.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:11:38.158+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:11:38.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:11:38.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-16T21:12:08.460+0000] {processor.py:157} INFO - Started process (PID=51671) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:12:08.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:12:08.463+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:12:08.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:12:08.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:12:08.497+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:12:08.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:12:08.510+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:12:08.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:12:08.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-16T21:12:38.836+0000] {processor.py:157} INFO - Started process (PID=51681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:12:38.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:12:38.840+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:12:38.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:12:38.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:12:38.870+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:12:38.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:12:38.882+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:12:38.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:12:38.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-16T21:13:09.133+0000] {processor.py:157} INFO - Started process (PID=51691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:13:09.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:13:09.141+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:13:09.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:13:09.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:13:09.166+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:13:09.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:13:09.176+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:13:09.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:13:09.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-16T21:13:39.465+0000] {processor.py:157} INFO - Started process (PID=51701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:13:39.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:13:39.469+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:13:39.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:13:39.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:13:39.492+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:13:39.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:13:39.502+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:13:39.502+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:13:39.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-16T21:14:09.824+0000] {processor.py:157} INFO - Started process (PID=51711) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:14:09.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:14:09.829+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:14:09.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:14:09.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:14:09.868+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:14:09.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:14:09.883+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:14:09.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:14:09.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-16T21:14:40.215+0000] {processor.py:157} INFO - Started process (PID=51721) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:14:40.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:14:40.217+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:14:40.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:14:40.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:14:40.240+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:14:40.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:14:40.251+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:14:40.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:14:40.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-16T21:15:10.513+0000] {processor.py:157} INFO - Started process (PID=51731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:15:10.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:15:10.517+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:15:10.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:15:10.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:15:10.563+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:15:10.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:15:10.578+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:15:10.578+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:15:10.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-16T21:15:40.770+0000] {processor.py:157} INFO - Started process (PID=51740) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:15:40.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:15:40.775+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:15:40.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:15:40.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:15:40.832+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:15:40.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:15:40.850+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:15:40.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:15:40.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-16T21:16:11.193+0000] {processor.py:157} INFO - Started process (PID=51751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:16:11.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:16:11.202+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:16:11.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:16:11.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:16:11.248+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:16:11.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:16:11.262+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:16:11.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:16:11.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-16T21:16:41.604+0000] {processor.py:157} INFO - Started process (PID=51761) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:16:41.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:16:41.615+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:16:41.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:16:41.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:16:41.666+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:16:41.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:16:41.683+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:16:41.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:16:41.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-16T21:17:11.968+0000] {processor.py:157} INFO - Started process (PID=51771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:17:11.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:17:11.969+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:17:11.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:17:11.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:17:11.994+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:17:11.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:17:12.004+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:17:12.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:17:12.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-16T21:17:42.340+0000] {processor.py:157} INFO - Started process (PID=51781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:17:42.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:17:42.343+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:17:42.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:17:42.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:17:42.376+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:17:42.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:17:42.390+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:17:42.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:17:42.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-16T21:18:12.617+0000] {processor.py:157} INFO - Started process (PID=51791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:18:12.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:18:12.620+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:18:12.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:18:12.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:18:12.644+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:18:12.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:18:12.654+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:18:12.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:18:12.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-16T21:18:42.837+0000] {processor.py:157} INFO - Started process (PID=51801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:18:42.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:18:42.841+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:18:42.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:18:42.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:18:42.877+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:18:42.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:18:42.890+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:18:42.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:18:42.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-16T21:19:13.068+0000] {processor.py:157} INFO - Started process (PID=51811) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:19:13.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:19:13.072+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:19:13.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:19:13.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:19:13.096+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:19:13.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:19:13.108+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:19:13.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:19:13.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-16T21:19:43.334+0000] {processor.py:157} INFO - Started process (PID=51821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:19:43.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:19:43.336+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:19:43.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:19:43.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:19:43.358+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:19:43.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:19:43.368+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:19:43.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:19:43.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-08-16T21:20:13.629+0000] {processor.py:157} INFO - Started process (PID=51831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:20:13.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:20:13.633+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:20:13.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:20:13.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:20:13.667+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:20:13.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:20:13.681+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:20:13.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:20:13.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-16T21:20:43.867+0000] {processor.py:157} INFO - Started process (PID=51841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:20:43.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:20:43.870+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:20:43.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:20:43.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:20:43.901+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:20:43.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:20:43.915+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:20:43.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:20:43.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-16T21:21:14.110+0000] {processor.py:157} INFO - Started process (PID=51851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:21:14.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:21:14.113+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:21:14.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:21:14.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:21:14.174+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:21:14.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:21:14.189+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:21:14.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:21:14.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-16T21:21:44.364+0000] {processor.py:157} INFO - Started process (PID=51861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:21:44.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:21:44.368+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:21:44.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:21:44.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:21:44.395+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:21:44.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:21:44.411+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:21:44.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:21:44.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-16T21:22:14.705+0000] {processor.py:157} INFO - Started process (PID=51871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:22:14.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:22:14.708+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:22:14.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:22:14.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:22:14.740+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:22:14.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:22:14.753+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:22:14.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:22:14.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-16T21:22:45.017+0000] {processor.py:157} INFO - Started process (PID=51881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:22:45.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:22:45.020+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:22:45.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:22:45.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:22:45.059+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:22:45.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:22:45.075+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:22:45.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:22:45.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-16T21:23:15.378+0000] {processor.py:157} INFO - Started process (PID=51891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:23:15.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:23:15.381+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:23:15.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:23:15.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:23:15.406+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:23:15.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:23:15.416+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:23:15.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:23:15.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-16T21:23:45.625+0000] {processor.py:157} INFO - Started process (PID=51901) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:23:45.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:23:45.627+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:23:45.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:23:45.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:23:45.664+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:23:45.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:23:45.679+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:23:45.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:23:45.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-16T21:24:16.006+0000] {processor.py:157} INFO - Started process (PID=51911) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:24:16.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:24:16.008+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:24:16.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:24:16.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:24:16.036+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:24:16.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:24:16.048+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:24:16.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:24:16.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-16T21:24:46.309+0000] {processor.py:157} INFO - Started process (PID=51921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:24:46.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:24:46.310+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:24:46.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:24:46.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:24:46.333+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:24:46.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:24:46.343+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:24:46.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:24:46.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-08-16T21:25:16.584+0000] {processor.py:157} INFO - Started process (PID=51931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:25:16.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:25:16.588+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:25:16.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:25:16.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:25:16.623+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:25:16.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:25:16.638+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:25:16.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:25:16.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-16T21:25:46.894+0000] {processor.py:157} INFO - Started process (PID=51941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:25:46.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:25:46.902+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:25:46.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:25:46.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:25:46.925+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:25:46.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:25:46.936+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:25:46.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:25:46.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-16T21:26:17.217+0000] {processor.py:157} INFO - Started process (PID=51950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:26:17.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:26:17.220+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:26:17.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:26:17.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:26:17.259+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:26:17.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:26:17.273+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:26:17.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:26:17.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-16T21:26:47.465+0000] {processor.py:157} INFO - Started process (PID=51961) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:26:47.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:26:47.467+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:26:47.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:26:47.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:26:47.490+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:26:47.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:26:47.504+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:26:47.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:26:47.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-16T21:27:17.755+0000] {processor.py:157} INFO - Started process (PID=51971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:27:17.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:27:17.757+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:27:17.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:27:17.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:27:17.793+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:27:17.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:27:17.808+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:27:17.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:27:17.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-16T21:27:47.970+0000] {processor.py:157} INFO - Started process (PID=51981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:27:47.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:27:47.975+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:27:47.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:27:47.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:27:47.998+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:27:47.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:27:48.010+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:27:48.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:27:48.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-16T21:28:18.255+0000] {processor.py:157} INFO - Started process (PID=51991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:28:18.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:28:18.261+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:28:18.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:28:18.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:28:18.297+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:28:18.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:28:18.312+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:28:18.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:28:18.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-16T21:28:48.603+0000] {processor.py:157} INFO - Started process (PID=52001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:28:48.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:28:48.608+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:28:48.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:28:48.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:28:48.658+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:28:48.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:28:48.673+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:28:48.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:28:48.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-16T21:29:19.021+0000] {processor.py:157} INFO - Started process (PID=52011) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:29:19.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:29:19.026+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:29:19.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:29:19.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:29:19.079+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:29:19.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:29:19.096+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:29:19.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:29:19.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-16T21:29:49.296+0000] {processor.py:157} INFO - Started process (PID=52021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:29:49.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:29:49.307+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:29:49.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:29:49.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:29:49.358+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:29:49.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:29:49.374+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:29:49.374+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:29:49.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-16T21:30:19.605+0000] {processor.py:157} INFO - Started process (PID=52031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:30:19.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:30:19.611+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:30:19.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:30:19.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:30:19.661+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:30:19.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:30:19.679+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:30:19.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:30:19.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-16T21:30:49.808+0000] {processor.py:157} INFO - Started process (PID=52041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:30:49.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:30:49.811+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:30:49.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:30:49.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:30:49.841+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:30:49.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:30:49.854+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:30:49.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:30:49.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-16T21:31:20.111+0000] {processor.py:157} INFO - Started process (PID=52051) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:31:20.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:31:20.116+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:31:20.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:31:20.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:31:20.173+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:31:20.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:31:20.188+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:31:20.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:31:20.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-16T21:31:50.427+0000] {processor.py:157} INFO - Started process (PID=52061) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:31:50.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:31:50.431+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:31:50.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:31:50.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:31:50.463+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:31:50.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:31:50.475+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:31:50.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:31:50.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-16T21:32:20.687+0000] {processor.py:157} INFO - Started process (PID=52071) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:32:20.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:32:20.694+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:32:20.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:32:20.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:32:20.755+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:32:20.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:32:20.777+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:32:20.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:32:20.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-16T21:32:51.034+0000] {processor.py:157} INFO - Started process (PID=52081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:32:51.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:32:51.037+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:32:51.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:32:51.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:32:51.074+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:32:51.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:32:51.094+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:32:51.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:32:51.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-16T21:33:21.344+0000] {processor.py:157} INFO - Started process (PID=52091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:33:21.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:33:21.349+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:33:21.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:33:21.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:33:21.439+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:33:21.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:33:21.464+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:33:21.464+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:33:21.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-08-16T21:33:51.637+0000] {processor.py:157} INFO - Started process (PID=52101) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:33:51.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:33:51.641+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:33:51.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:33:51.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:33:51.681+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:33:51.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:33:51.693+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:33:51.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:33:51.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-16T21:34:22.066+0000] {processor.py:157} INFO - Started process (PID=52111) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:34:22.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:34:22.070+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:34:22.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:34:22.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:34:22.113+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:34:22.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:34:22.128+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:34:22.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:34:22.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-16T21:34:52.391+0000] {processor.py:157} INFO - Started process (PID=52121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:34:52.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T21:34:52.394+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:34:52.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:34:52.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T21:34:52.421+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:34:52.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T21:34:52.431+0000] {logging_mixin.py:151} INFO - [2024-08-16T21:34:52.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T21:34:52.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-16T22:06:54.326+0000] {processor.py:157} INFO - Started process (PID=52132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T22:06:54.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T22:06:54.337+0000] {logging_mixin.py:151} INFO - [2024-08-16T22:06:54.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T22:06:54.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T22:06:54.435+0000] {logging_mixin.py:151} INFO - [2024-08-16T22:06:54.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T22:06:54.475+0000] {logging_mixin.py:151} INFO - [2024-08-16T22:06:54.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T22:06:54.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.183 seconds
[2024-08-16T23:36:09.351+0000] {processor.py:157} INFO - Started process (PID=52142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T23:36:09.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T23:36:09.359+0000] {logging_mixin.py:151} INFO - [2024-08-16T23:36:09.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T23:36:09.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T23:36:09.449+0000] {logging_mixin.py:151} INFO - [2024-08-16T23:36:09.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T23:36:09.480+0000] {logging_mixin.py:151} INFO - [2024-08-16T23:36:09.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T23:36:09.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-08-16T23:36:39.922+0000] {processor.py:157} INFO - Started process (PID=52152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-16T23:36:39.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-16T23:36:39.928+0000] {logging_mixin.py:151} INFO - [2024-08-16T23:36:39.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T23:36:39.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-16T23:36:39.998+0000] {logging_mixin.py:151} INFO - [2024-08-16T23:36:39.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-16T23:36:40.011+0000] {logging_mixin.py:151} INFO - [2024-08-16T23:36:40.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-16T23:36:40.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
