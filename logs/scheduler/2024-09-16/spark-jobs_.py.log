[2024-09-16T00:00:00.105+0000] {processor.py:157} INFO - Started process (PID=23128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:00:00.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:00:00.122+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:00:00.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:00:00.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:00:00.180+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:00:00.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:00:00.194+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:00:00.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:00:00.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-16T00:00:30.547+0000] {processor.py:157} INFO - Started process (PID=23139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:00:30.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:00:30.553+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:00:30.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:00:30.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:00:30.586+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:00:30.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:00:30.621+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:00:30.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:00:30.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-16T00:01:00.956+0000] {processor.py:157} INFO - Started process (PID=23149) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:01:00.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:01:00.964+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:01:00.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:01:00.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:01:01.041+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:01:01.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:01:01.060+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:01:01.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:01:01.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-16T00:01:31.294+0000] {processor.py:157} INFO - Started process (PID=23158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:01:31.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:01:31.299+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:01:31.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:01:31.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:01:31.342+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:01:31.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:01:31.543+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:01:31.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:01:31.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.262 seconds
[2024-09-16T00:02:01.670+0000] {processor.py:157} INFO - Started process (PID=23169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:02:01.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:02:01.679+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:02:01.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:02:01.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:02:01.737+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:02:01.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:02:01.878+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:02:01.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:02:01.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.221 seconds
[2024-09-16T00:02:32.175+0000] {processor.py:157} INFO - Started process (PID=23179) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:02:32.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:02:32.184+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:02:32.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:02:32.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:02:32.329+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:02:32.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:02:32.337+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:02:32.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:02:32.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.186 seconds
[2024-09-16T00:03:02.497+0000] {processor.py:157} INFO - Started process (PID=23189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:03:02.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:03:02.504+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:03:02.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:03:02.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:03:02.598+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:03:02.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:03:02.615+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:03:02.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:03:02.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-16T00:03:32.893+0000] {processor.py:157} INFO - Started process (PID=23199) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:03:32.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:03:32.896+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:03:32.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:03:32.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:03:32.932+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:03:32.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:03:32.952+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:03:32.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:03:32.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-16T00:04:03.332+0000] {processor.py:157} INFO - Started process (PID=23209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:04:03.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:04:03.338+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:04:03.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:04:03.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:04:03.385+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:04:03.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:04:03.413+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:04:03.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:04:03.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-16T00:04:33.736+0000] {processor.py:157} INFO - Started process (PID=23219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:04:33.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:04:33.740+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:04:33.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:04:33.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:04:33.775+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:04:33.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:04:33.961+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:04:33.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:04:33.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.236 seconds
[2024-09-16T00:05:04.357+0000] {processor.py:157} INFO - Started process (PID=23229) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:05:04.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:05:04.362+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:05:04.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:05:04.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:05:04.420+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:05:04.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:05:04.628+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:05:04.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:05:04.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.284 seconds
[2024-09-16T00:05:34.934+0000] {processor.py:157} INFO - Started process (PID=23239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:05:34.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:05:34.938+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:05:34.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:05:34.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:05:35.045+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:05:35.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:05:35.052+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:05:35.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:05:35.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-16T00:06:05.467+0000] {processor.py:157} INFO - Started process (PID=23249) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:06:05.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:06:05.480+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:06:05.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:06:05.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:06:05.538+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:06:05.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:06:05.555+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:06:05.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:06:05.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-16T00:06:35.916+0000] {processor.py:157} INFO - Started process (PID=23259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:06:35.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:06:35.921+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:06:35.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:06:35.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:06:35.987+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:06:35.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:06:36.016+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:06:36.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:06:36.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-16T00:07:06.198+0000] {processor.py:157} INFO - Started process (PID=23269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:07:06.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:07:06.201+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:07:06.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:07:06.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:07:06.235+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:07:06.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:07:06.249+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:07:06.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:07:06.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-16T00:07:36.618+0000] {processor.py:157} INFO - Started process (PID=23279) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:07:36.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:07:36.625+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:07:36.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:07:36.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:07:36.694+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:07:36.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:07:36.870+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:07:36.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:07:36.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.269 seconds
[2024-09-16T00:08:07.173+0000] {processor.py:157} INFO - Started process (PID=23289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:08:07.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:08:07.179+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:08:07.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:08:07.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:08:07.234+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:08:07.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:08:07.431+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:08:07.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:08:07.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.271 seconds
[2024-09-16T00:08:37.735+0000] {processor.py:157} INFO - Started process (PID=23298) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:08:37.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:08:37.740+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:08:37.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:08:37.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:08:37.899+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:08:37.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:08:37.907+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:08:37.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:08:37.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.200 seconds
[2024-09-16T00:09:08.201+0000] {processor.py:157} INFO - Started process (PID=23309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:09:08.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:09:08.205+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:09:08.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:09:08.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:09:08.246+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:09:08.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:09:08.261+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:09:08.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:09:08.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-16T00:09:38.470+0000] {processor.py:157} INFO - Started process (PID=23319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:09:38.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:09:38.473+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:09:38.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:09:38.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:09:38.507+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:09:38.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:09:38.523+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:09:38.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:09:38.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-16T00:10:08.866+0000] {processor.py:157} INFO - Started process (PID=23329) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:10:08.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:10:08.872+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:10:08.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:10:08.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:10:08.914+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:10:08.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:10:08.946+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:10:08.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:10:09.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.221 seconds
[2024-09-16T00:10:39.336+0000] {processor.py:157} INFO - Started process (PID=23339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:10:39.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:10:39.352+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:10:39.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:10:39.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:10:39.409+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:10:39.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:10:39.589+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:10:39.589+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:10:39.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.266 seconds
[2024-09-16T00:11:09.941+0000] {processor.py:157} INFO - Started process (PID=23349) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:11:09.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:11:09.947+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:11:09.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:11:09.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:11:10.012+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:11:10.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:11:10.199+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:11:10.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:11:10.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.288 seconds
[2024-09-16T00:11:40.336+0000] {processor.py:157} INFO - Started process (PID=23359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:11:40.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:11:40.347+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:11:40.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:11:40.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:11:40.597+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:11:40.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:11:40.606+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:11:40.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:11:40.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.290 seconds
[2024-09-16T00:12:10.745+0000] {processor.py:157} INFO - Started process (PID=23369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:12:10.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:12:10.751+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:12:10.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:12:10.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:12:10.795+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:12:10.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:12:10.814+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:12:10.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:12:10.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-16T00:12:41.145+0000] {processor.py:157} INFO - Started process (PID=23379) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:12:41.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:12:41.153+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:12:41.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:12:41.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:12:41.198+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:12:41.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:12:41.221+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:12:41.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:12:41.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-16T00:13:11.492+0000] {processor.py:157} INFO - Started process (PID=23388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:13:11.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:13:11.508+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:13:11.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:13:11.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:13:11.577+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:13:11.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:13:11.595+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:13:11.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:13:11.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.307 seconds
[2024-09-16T00:13:42.145+0000] {processor.py:157} INFO - Started process (PID=23399) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:13:42.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:13:42.157+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:13:42.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:13:42.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:13:42.246+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:13:42.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:13:42.471+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:13:42.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:13:42.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.346 seconds
[2024-09-16T00:14:12.748+0000] {processor.py:157} INFO - Started process (PID=23409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:14:12.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:14:12.757+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:14:12.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:14:12.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:14:12.814+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:14:12.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:14:13.010+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:14:13.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:14:13.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.276 seconds
[2024-09-16T00:14:43.309+0000] {processor.py:157} INFO - Started process (PID=23419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:14:43.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:14:43.318+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:14:43.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:14:43.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:14:43.565+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:14:43.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:14:43.574+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:14:43.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:14:43.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.280 seconds
[2024-09-16T00:15:13.663+0000] {processor.py:157} INFO - Started process (PID=23429) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:15:13.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:15:13.670+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:15:13.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:15:13.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:15:13.721+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:15:13.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:15:13.747+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:15:13.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:15:13.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-16T00:15:43.999+0000] {processor.py:157} INFO - Started process (PID=23439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:15:44.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:15:44.009+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:15:44.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:15:44.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:15:44.052+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:15:44.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:15:44.068+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:15:44.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:15:44.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-16T00:16:14.496+0000] {processor.py:157} INFO - Started process (PID=23449) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:16:14.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:16:14.501+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:16:14.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:16:14.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:16:14.565+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:16:14.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:16:14.588+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:16:14.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:16:14.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.272 seconds
[2024-09-16T00:16:44.836+0000] {processor.py:157} INFO - Started process (PID=23459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:16:44.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:16:44.842+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:16:44.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:16:44.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:16:44.896+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:16:44.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:16:45.084+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:16:45.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:16:45.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.264 seconds
[2024-09-16T00:17:15.341+0000] {processor.py:157} INFO - Started process (PID=23469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:17:15.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:17:15.347+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:17:15.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:17:15.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:17:15.405+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:17:15.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:17:15.575+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:17:15.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:17:15.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.247 seconds
[2024-09-16T00:17:45.665+0000] {processor.py:157} INFO - Started process (PID=23479) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:17:45.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:17:45.671+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:17:45.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:17:45.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:17:45.891+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:17:45.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:17:45.900+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:17:45.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:17:45.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.248 seconds
[2024-09-16T00:18:16.160+0000] {processor.py:157} INFO - Started process (PID=23489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:18:16.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:18:16.165+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:18:16.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:18:16.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:18:16.223+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:18:16.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:18:16.251+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:18:16.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:18:16.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-16T00:18:46.551+0000] {processor.py:157} INFO - Started process (PID=23499) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:18:46.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:18:46.558+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:18:46.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:18:46.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:18:46.613+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:18:46.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:18:46.630+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:18:46.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:18:46.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-16T00:19:16.989+0000] {processor.py:157} INFO - Started process (PID=23509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:19:16.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:19:16.995+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:19:16.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:19:17.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:19:17.039+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:19:17.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:19:17.057+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:19:17.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:19:17.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.252 seconds
[2024-09-16T00:19:47.628+0000] {processor.py:157} INFO - Started process (PID=23518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:19:47.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:19:47.633+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:19:47.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:19:47.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:19:47.679+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:19:47.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:19:47.812+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:19:47.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:19:47.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.200 seconds
[2024-09-16T00:20:18.163+0000] {processor.py:157} INFO - Started process (PID=23529) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:20:18.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:20:18.167+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:20:18.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:20:18.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:20:18.211+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:20:18.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:20:18.325+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:20:18.325+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:20:18.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.175 seconds
[2024-09-16T00:20:48.493+0000] {processor.py:157} INFO - Started process (PID=23539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:20:48.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:20:48.498+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:20:48.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:20:48.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:20:48.693+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:20:48.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:20:48.703+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:20:48.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:20:48.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.224 seconds
[2024-09-16T00:21:19.086+0000] {processor.py:157} INFO - Started process (PID=23549) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:21:19.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:21:19.091+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:21:19.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:21:19.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:21:19.127+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:21:19.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:21:19.142+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:21:19.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:21:19.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-16T00:21:49.496+0000] {processor.py:157} INFO - Started process (PID=23559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:21:49.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:21:49.501+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:21:49.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:21:49.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:21:49.567+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:21:49.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:21:49.584+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:21:49.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:21:49.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-16T00:22:19.813+0000] {processor.py:157} INFO - Started process (PID=23569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:22:19.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:22:19.828+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:22:19.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:22:19.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:22:19.876+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:22:19.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:22:19.893+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:22:19.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:22:20.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.229 seconds
[2024-09-16T00:22:50.191+0000] {processor.py:157} INFO - Started process (PID=23579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:22:50.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:22:50.198+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:22:50.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:22:50.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:22:50.250+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:22:50.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:22:50.451+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:22:50.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:22:50.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.275 seconds
[2024-09-16T00:23:20.655+0000] {processor.py:157} INFO - Started process (PID=23589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:23:20.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:23:20.663+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:23:20.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:23:20.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:23:20.922+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:23:20.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:23:20.931+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:23:20.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:23:20.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.311 seconds
[2024-09-16T00:23:51.238+0000] {processor.py:157} INFO - Started process (PID=23599) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:23:51.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:23:51.242+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:23:51.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:23:51.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:23:51.348+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:23:51.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:23:51.355+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:23:51.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:23:51.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-16T00:24:21.703+0000] {processor.py:157} INFO - Started process (PID=23609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:24:21.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:24:21.730+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:24:21.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:24:21.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:24:21.795+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:24:21.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:24:21.813+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:24:21.813+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:24:21.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-16T00:24:52.045+0000] {processor.py:157} INFO - Started process (PID=23619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:24:52.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:24:52.049+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:24:52.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:24:52.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:24:52.086+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:24:52.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:24:52.112+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:24:52.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:24:52.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-16T00:25:22.491+0000] {processor.py:157} INFO - Started process (PID=23629) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:25:22.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:25:22.496+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:25:22.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:25:22.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:25:22.564+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:25:22.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:25:22.723+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:25:22.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:25:22.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.247 seconds
[2024-09-16T00:25:53.094+0000] {processor.py:157} INFO - Started process (PID=23639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:25:53.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:25:53.099+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:25:53.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:25:53.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:25:53.153+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:25:53.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:25:53.348+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:25:53.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:25:53.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.268 seconds
[2024-09-16T00:26:23.639+0000] {processor.py:157} INFO - Started process (PID=23649) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:26:23.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:26:23.648+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:26:23.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:26:23.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:26:23.834+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:26:23.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:26:23.842+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:26:23.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:26:23.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.217 seconds
[2024-09-16T00:26:54.210+0000] {processor.py:157} INFO - Started process (PID=23658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:26:54.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:26:54.216+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:26:54.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:26:54.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:26:54.361+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:26:54.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:26:54.368+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:26:54.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:26:54.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.169 seconds
[2024-09-16T00:27:24.762+0000] {processor.py:157} INFO - Started process (PID=23669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:27:24.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:27:24.773+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:27:24.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:27:24.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:27:24.831+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:27:24.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:27:24.858+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:27:24.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:27:24.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-16T00:27:55.173+0000] {processor.py:157} INFO - Started process (PID=23679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:27:55.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:27:55.185+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:27:55.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:27:55.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:27:55.252+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:27:55.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:27:55.268+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:27:55.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:27:55.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-16T00:28:25.673+0000] {processor.py:157} INFO - Started process (PID=23689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:28:25.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:28:25.679+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:28:25.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:28:25.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:28:25.737+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:28:25.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:28:25.901+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:28:25.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:28:25.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.244 seconds
[2024-09-16T00:28:56.021+0000] {processor.py:157} INFO - Started process (PID=23699) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:28:56.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:28:56.025+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:28:56.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:28:56.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:28:56.067+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:28:56.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:28:56.193+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:28:56.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:28:56.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.189 seconds
[2024-09-16T00:29:26.527+0000] {processor.py:157} INFO - Started process (PID=23709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:29:26.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:29:26.532+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:29:26.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:29:26.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:29:26.739+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:29:26.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:29:26.750+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:29:26.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:29:26.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.236 seconds
[2024-09-16T00:29:57.115+0000] {processor.py:157} INFO - Started process (PID=23719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:29:57.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:29:57.122+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:29:57.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:29:57.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:29:57.297+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:29:57.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:29:57.307+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:29:57.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:29:57.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.205 seconds
[2024-09-16T00:30:27.613+0000] {processor.py:157} INFO - Started process (PID=24322) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:30:27.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:30:27.618+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:30:27.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:30:27.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:30:27.677+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:30:27.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:30:27.694+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:30:27.694+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:30:27.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-16T00:30:57.903+0000] {processor.py:157} INFO - Started process (PID=24424) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:30:57.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:30:57.909+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:30:57.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:30:57.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:30:57.961+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:30:57.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:30:57.986+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:30:57.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:30:58.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.313 seconds
[2024-09-16T00:31:28.564+0000] {processor.py:157} INFO - Started process (PID=24432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:31:28.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:31:28.577+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:31:28.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:31:28.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:31:28.641+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:31:28.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:31:28.897+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:31:28.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:31:28.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.351 seconds
[2024-09-16T00:31:59.200+0000] {processor.py:157} INFO - Started process (PID=24443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:31:59.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:31:59.224+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:31:59.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:31:59.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:31:59.278+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:31:59.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:31:59.485+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:31:59.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:31:59.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.299 seconds
[2024-09-16T00:32:29.793+0000] {processor.py:157} INFO - Started process (PID=24453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:32:29.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:32:29.801+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:32:29.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:32:29.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:32:30.026+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:32:30.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:32:30.034+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:32:30.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:32:30.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.254 seconds
[2024-09-16T00:33:00.366+0000] {processor.py:157} INFO - Started process (PID=24463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:33:00.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:33:00.374+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:33:00.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:33:00.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:33:00.665+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:33:00.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:33:00.673+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:33:00.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:33:00.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.336 seconds
[2024-09-16T00:33:31.007+0000] {processor.py:157} INFO - Started process (PID=24474) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:33:31.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:33:31.015+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:33:31.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:33:31.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:33:31.127+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:33:31.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:33:31.149+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:33:31.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:33:31.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.175 seconds
[2024-09-16T00:34:01.352+0000] {processor.py:157} INFO - Started process (PID=24483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:34:01.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:34:01.359+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:34:01.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:34:01.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:34:01.416+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:34:01.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:34:01.431+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:34:01.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:34:01.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.357 seconds
[2024-09-16T00:34:32.048+0000] {processor.py:157} INFO - Started process (PID=24494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:34:32.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:34:32.056+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:34:32.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:34:32.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:34:32.131+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:34:32.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:34:32.351+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:34:32.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:34:32.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.320 seconds
[2024-09-16T00:35:02.758+0000] {processor.py:157} INFO - Started process (PID=24504) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:35:02.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:35:02.767+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:35:02.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:35:02.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:35:02.868+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:35:02.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:35:03.114+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:35:03.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:35:03.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.382 seconds
[2024-09-16T00:35:33.417+0000] {processor.py:157} INFO - Started process (PID=24514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:35:33.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:35:33.427+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:35:33.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:35:33.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:35:33.699+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:35:33.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:35:33.712+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:35:33.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:35:33.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.307 seconds
[2024-09-16T00:36:04.011+0000] {processor.py:157} INFO - Started process (PID=24523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:36:04.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:36:04.018+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:36:04.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:36:04.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:36:04.279+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:36:04.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:36:04.289+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:36:04.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:36:04.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.305 seconds
[2024-09-16T00:36:34.798+0000] {processor.py:157} INFO - Started process (PID=24534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:36:34.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:36:34.806+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:36:34.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:36:34.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:36:34.868+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:36:34.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:36:34.890+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:36:34.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:36:34.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-16T00:37:05.121+0000] {processor.py:157} INFO - Started process (PID=24543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:37:05.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:37:05.128+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:37:05.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:37:05.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:37:05.182+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:37:05.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:37:05.198+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:37:05.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:37:05.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-16T00:37:35.457+0000] {processor.py:157} INFO - Started process (PID=24554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:37:35.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:37:35.467+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:37:35.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:37:35.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:37:35.523+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:37:35.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:37:35.541+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:37:35.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:37:35.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-16T00:38:05.741+0000] {processor.py:157} INFO - Started process (PID=24564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:38:05.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:38:05.748+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:38:05.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:38:05.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:38:05.796+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:38:05.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:38:05.812+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:38:05.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:38:05.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-16T00:38:36.138+0000] {processor.py:157} INFO - Started process (PID=24574) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:38:36.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:38:36.142+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:38:36.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:38:36.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:38:36.183+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:38:36.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:38:36.198+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:38:36.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:38:36.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-16T00:39:06.575+0000] {processor.py:157} INFO - Started process (PID=24584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:39:06.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:39:06.582+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:39:06.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:39:06.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:39:06.636+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:39:06.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:39:06.654+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:39:06.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:39:06.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-16T00:39:36.966+0000] {processor.py:157} INFO - Started process (PID=24594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:39:36.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:39:36.977+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:39:36.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:39:37.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:39:37.042+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:39:37.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:39:37.058+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:39:37.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:39:37.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-16T00:40:07.324+0000] {processor.py:157} INFO - Started process (PID=24604) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:40:07.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:40:07.333+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:40:07.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:40:07.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:40:07.396+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:40:07.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:40:07.411+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:40:07.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:40:07.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-16T00:40:37.675+0000] {processor.py:157} INFO - Started process (PID=24614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:40:37.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:40:37.683+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:40:37.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:40:37.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:40:37.749+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:40:37.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:40:37.767+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:40:37.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:40:37.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-16T00:41:08.072+0000] {processor.py:157} INFO - Started process (PID=24624) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:41:08.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:41:08.081+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:41:08.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:41:08.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:41:08.161+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:41:08.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:41:08.206+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:41:08.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:41:08.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-09-16T00:41:38.422+0000] {processor.py:157} INFO - Started process (PID=24634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:41:38.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:41:38.430+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:41:38.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:41:38.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:41:38.501+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:41:38.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:41:38.521+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:41:38.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:41:38.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-16T00:42:08.786+0000] {processor.py:157} INFO - Started process (PID=24643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:42:08.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:42:08.798+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:42:08.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:42:08.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:42:08.869+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:42:08.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:42:08.885+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:42:08.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:42:08.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-16T00:42:39.136+0000] {processor.py:157} INFO - Started process (PID=24653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:42:39.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:42:39.149+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:42:39.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:42:39.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:42:39.209+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:42:39.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:42:39.226+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:42:39.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:42:39.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-16T00:43:09.490+0000] {processor.py:157} INFO - Started process (PID=24664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:43:09.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:43:09.496+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:43:09.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:43:09.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:43:09.553+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:43:09.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:43:09.583+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:43:09.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:43:09.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-16T00:43:39.843+0000] {processor.py:157} INFO - Started process (PID=24674) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:43:39.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:43:39.849+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:43:39.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:43:39.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:43:39.882+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:43:39.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:43:39.894+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:43:39.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:43:39.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-16T00:44:10.212+0000] {processor.py:157} INFO - Started process (PID=24684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:44:10.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:44:10.219+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:44:10.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:44:10.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:44:10.272+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:44:10.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:44:10.290+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:44:10.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:44:10.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-16T00:44:40.535+0000] {processor.py:157} INFO - Started process (PID=24694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:44:40.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:44:40.542+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:44:40.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:44:40.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:44:40.607+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:44:40.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:44:40.623+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:44:40.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:44:40.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-16T00:45:10.911+0000] {processor.py:157} INFO - Started process (PID=24704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:45:10.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:45:10.916+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:45:10.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:45:10.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:45:10.965+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:45:10.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:45:10.980+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:45:10.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:45:10.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-16T00:45:41.429+0000] {processor.py:157} INFO - Started process (PID=24712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:45:41.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:45:41.444+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:45:41.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:45:41.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:45:41.520+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:45:41.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:45:41.544+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:45:41.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:45:41.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-09-16T00:46:11.909+0000] {processor.py:157} INFO - Started process (PID=24724) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:46:11.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:46:11.922+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:46:11.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:46:11.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:46:11.988+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:46:11.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:46:12.005+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:46:12.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:46:12.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-16T00:46:42.418+0000] {processor.py:157} INFO - Started process (PID=24734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:46:42.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:46:42.427+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:46:42.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:46:42.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:46:42.489+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:46:42.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:46:42.506+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:46:42.506+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:46:42.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-16T00:47:12.758+0000] {processor.py:157} INFO - Started process (PID=24744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:47:12.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:47:12.773+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:47:12.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:47:12.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:47:12.838+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:47:12.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:47:12.853+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:47:12.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:47:12.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-16T00:47:43.265+0000] {processor.py:157} INFO - Started process (PID=24754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:47:43.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:47:43.272+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:47:43.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:47:43.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:47:43.336+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:47:43.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:47:43.361+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:47:43.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:47:43.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T00:48:13.711+0000] {processor.py:157} INFO - Started process (PID=24764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:48:13.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:48:13.721+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:48:13.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:48:13.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:48:13.782+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:48:13.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:48:13.800+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:48:13.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:48:13.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-16T00:48:44.073+0000] {processor.py:157} INFO - Started process (PID=24774) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:48:44.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:48:44.081+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:48:44.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:48:44.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:48:44.122+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:48:44.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:48:44.135+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:48:44.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:48:44.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-16T00:49:14.579+0000] {processor.py:157} INFO - Started process (PID=24784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:49:14.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:49:14.590+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:49:14.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:49:14.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:49:14.673+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:49:14.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:49:14.689+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:49:14.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:49:14.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-16T00:49:44.906+0000] {processor.py:157} INFO - Started process (PID=24794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:49:44.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:49:44.914+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:49:44.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:49:44.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:49:44.983+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:49:44.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:49:45.002+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:49:45.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:49:45.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-16T00:50:15.294+0000] {processor.py:157} INFO - Started process (PID=24804) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:50:15.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:50:15.300+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:50:15.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:50:15.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:50:15.342+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:50:15.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:50:15.357+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:50:15.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:50:15.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-16T00:50:45.608+0000] {processor.py:157} INFO - Started process (PID=24814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:50:45.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:50:45.614+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:50:45.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:50:45.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:50:45.669+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:50:45.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:50:45.684+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:50:45.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:50:45.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-16T00:51:15.970+0000] {processor.py:157} INFO - Started process (PID=24824) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:51:15.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:51:15.976+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:51:15.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:51:15.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:51:16.025+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:51:16.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:51:16.042+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:51:16.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:51:16.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-16T00:51:46.301+0000] {processor.py:157} INFO - Started process (PID=24834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:51:46.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:51:46.310+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:51:46.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:51:46.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:51:46.370+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:51:46.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:51:46.386+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:51:46.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:51:46.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-16T00:52:16.735+0000] {processor.py:157} INFO - Started process (PID=24844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:52:16.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:52:16.742+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:52:16.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:52:16.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:52:16.785+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:52:16.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:52:16.800+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:52:16.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:52:16.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-16T00:52:47.117+0000] {processor.py:157} INFO - Started process (PID=24854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:52:47.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:52:47.124+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:52:47.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:52:47.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:52:47.193+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:52:47.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:52:47.209+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:52:47.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:52:47.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-16T00:53:17.496+0000] {processor.py:157} INFO - Started process (PID=24864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:53:17.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:53:17.498+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:53:17.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:53:17.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:53:17.529+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:53:17.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:53:17.538+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:53:17.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:53:17.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-16T00:53:47.868+0000] {processor.py:157} INFO - Started process (PID=24874) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:53:47.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:53:47.881+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:53:47.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:53:47.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:53:47.949+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:53:47.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:53:47.969+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:53:47.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:53:47.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-16T00:54:18.134+0000] {processor.py:157} INFO - Started process (PID=24884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:54:18.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:54:18.139+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:54:18.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:54:18.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:54:18.176+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:54:18.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:54:18.188+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:54:18.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:54:18.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-16T00:54:48.518+0000] {processor.py:157} INFO - Started process (PID=24894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:54:48.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:54:48.521+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:54:48.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:54:48.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:54:48.565+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:54:48.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:54:48.579+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:54:48.579+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:54:48.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-16T00:55:18.893+0000] {processor.py:157} INFO - Started process (PID=24903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:55:18.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:55:18.905+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:55:18.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:55:18.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:55:18.962+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:55:18.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:55:18.977+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:55:18.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:55:18.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-16T00:55:49.246+0000] {processor.py:157} INFO - Started process (PID=24914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:55:49.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:55:49.252+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:55:49.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:55:49.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:55:49.288+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:55:49.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:55:49.299+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:55:49.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:55:49.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-16T00:56:19.667+0000] {processor.py:157} INFO - Started process (PID=24924) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:56:19.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:56:19.673+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:56:19.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:56:19.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:56:19.710+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:56:19.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:56:19.724+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:56:19.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:56:19.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-16T00:56:50.008+0000] {processor.py:157} INFO - Started process (PID=24934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:56:50.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:56:50.017+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:56:50.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:56:50.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:56:50.074+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:56:50.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:56:50.102+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:56:50.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:56:50.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-16T00:57:20.352+0000] {processor.py:157} INFO - Started process (PID=24944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:57:20.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:57:20.356+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:57:20.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:57:20.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:57:20.392+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:57:20.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:57:20.403+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:57:20.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:57:20.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-16T00:57:50.746+0000] {processor.py:157} INFO - Started process (PID=24954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:57:50.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:57:50.757+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:57:50.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:57:50.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:57:50.802+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:57:50.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:57:50.817+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:57:50.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:57:50.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-16T00:58:21.095+0000] {processor.py:157} INFO - Started process (PID=24964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:58:21.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:58:21.103+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:58:21.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:58:21.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:58:21.151+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:58:21.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:58:21.164+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:58:21.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:58:21.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-16T00:58:51.367+0000] {processor.py:157} INFO - Started process (PID=24974) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:58:51.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:58:51.374+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:58:51.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:58:51.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:58:51.425+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:58:51.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:58:51.440+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:58:51.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:58:51.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-16T00:59:21.804+0000] {processor.py:157} INFO - Started process (PID=24984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:59:21.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:59:21.809+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:59:21.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:59:21.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:59:21.844+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:59:21.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:59:21.855+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:59:21.855+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:59:21.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-16T00:59:52.198+0000] {processor.py:157} INFO - Started process (PID=24994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:59:52.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T00:59:52.204+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:59:52.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:59:52.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T00:59:52.243+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:59:52.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T00:59:52.261+0000] {logging_mixin.py:151} INFO - [2024-09-16T00:59:52.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-16T00:59:52.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-16T01:00:22.620+0000] {processor.py:157} INFO - Started process (PID=25004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:00:22.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:00:22.625+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:00:22.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:00:22.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:00:22.660+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:00:22.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:00:22.671+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:00:22.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:00:22.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-16T01:00:53.038+0000] {processor.py:157} INFO - Started process (PID=25014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:00:53.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:00:53.051+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:00:53.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:00:53.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:00:53.098+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:00:53.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:00:53.118+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:00:53.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:00:53.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-16T01:01:23.469+0000] {processor.py:157} INFO - Started process (PID=25024) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:01:23.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:01:23.477+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:01:23.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:01:23.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:01:23.514+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:01:23.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:01:23.528+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:01:23.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:01:23.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-16T01:01:53.846+0000] {processor.py:157} INFO - Started process (PID=25034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:01:53.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:01:53.851+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:01:53.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:01:53.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:01:53.899+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:01:53.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:01:53.913+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:01:53.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:01:53.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-16T01:02:24.237+0000] {processor.py:157} INFO - Started process (PID=25044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:02:24.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:02:24.243+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:02:24.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:02:24.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:02:24.310+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:02:24.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:02:24.328+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:02:24.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:02:24.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-16T01:02:54.576+0000] {processor.py:157} INFO - Started process (PID=25053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:02:54.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:02:54.580+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:02:54.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:02:54.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:02:54.652+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:02:54.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:02:54.683+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:02:54.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:02:54.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-16T01:03:24.928+0000] {processor.py:157} INFO - Started process (PID=25064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:03:24.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:03:24.931+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:03:24.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:03:24.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:03:24.958+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:03:24.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:03:24.968+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:03:24.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:03:24.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-16T01:03:55.282+0000] {processor.py:157} INFO - Started process (PID=25074) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:03:55.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:03:55.290+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:03:55.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:03:55.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:03:55.364+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:03:55.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:03:55.383+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:03:55.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:03:55.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-16T01:04:25.668+0000] {processor.py:157} INFO - Started process (PID=25084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:04:25.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:04:25.676+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:04:25.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:04:25.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:04:25.735+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:04:25.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:04:25.765+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:04:25.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:04:25.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-16T01:04:56.048+0000] {processor.py:157} INFO - Started process (PID=25094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:04:56.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:04:56.063+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:04:56.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:04:56.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:04:56.121+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:04:56.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:04:56.142+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:04:56.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:04:56.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-16T01:05:26.427+0000] {processor.py:157} INFO - Started process (PID=25104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:05:26.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:05:26.435+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:05:26.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:05:26.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:05:26.495+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:05:26.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:05:26.525+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:05:26.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:05:26.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-16T01:05:56.759+0000] {processor.py:157} INFO - Started process (PID=25114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:05:56.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:05:56.779+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:05:56.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:05:56.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:05:56.852+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:05:56.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:05:56.869+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:05:56.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:05:56.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-16T01:06:27.182+0000] {processor.py:157} INFO - Started process (PID=25124) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:06:27.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:06:27.194+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:06:27.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:06:27.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:06:27.256+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:06:27.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:06:27.272+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:06:27.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:06:27.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-16T01:06:57.490+0000] {processor.py:157} INFO - Started process (PID=25134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:06:57.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:06:57.502+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:06:57.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:06:57.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:06:57.568+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:06:57.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:06:57.585+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:06:57.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:06:57.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-16T01:07:27.827+0000] {processor.py:157} INFO - Started process (PID=25143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:07:27.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:07:27.834+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:07:27.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:07:27.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:07:27.883+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:07:27.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:07:27.900+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:07:27.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:07:27.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-16T01:07:58.235+0000] {processor.py:157} INFO - Started process (PID=25154) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:07:58.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:07:58.240+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:07:58.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:07:58.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:07:58.276+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:07:58.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:07:58.289+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:07:58.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:07:58.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-16T01:08:28.546+0000] {processor.py:157} INFO - Started process (PID=25164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:08:28.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:08:28.553+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:08:28.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:08:28.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:08:28.629+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:08:28.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:08:28.645+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:08:28.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:08:28.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-16T01:08:58.927+0000] {processor.py:157} INFO - Started process (PID=25174) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:08:58.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:08:58.944+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:08:58.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:08:58.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:08:59.005+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:08:59.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:08:59.022+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:08:59.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:08:59.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-16T01:09:29.398+0000] {processor.py:157} INFO - Started process (PID=25184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:09:29.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:09:29.405+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:09:29.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:09:29.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:09:29.444+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:09:29.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:09:29.455+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:09:29.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:09:29.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-16T01:09:59.823+0000] {processor.py:157} INFO - Started process (PID=25194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:09:59.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:09:59.838+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:09:59.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:09:59.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:09:59.876+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:09:59.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:09:59.894+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:09:59.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:09:59.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-16T01:10:30.212+0000] {processor.py:157} INFO - Started process (PID=25204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:10:30.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:10:30.222+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:10:30.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:10:30.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:10:30.270+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:10:30.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:10:30.285+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:10:30.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:10:30.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-16T01:11:00.553+0000] {processor.py:157} INFO - Started process (PID=25214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:11:00.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:11:00.559+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:11:00.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:11:00.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:11:00.632+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:11:00.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:11:00.648+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:11:00.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:11:00.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-16T01:11:31.028+0000] {processor.py:157} INFO - Started process (PID=25223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:11:31.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:11:31.034+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:11:31.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:11:31.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:11:31.100+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:11:31.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:11:31.128+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:11:31.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:11:31.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-16T01:12:01.399+0000] {processor.py:157} INFO - Started process (PID=25234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:12:01.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:12:01.411+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:12:01.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:12:01.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:12:01.485+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:12:01.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:12:01.503+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:12:01.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:12:01.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-16T01:12:31.928+0000] {processor.py:157} INFO - Started process (PID=25244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:12:31.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:12:31.935+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:12:31.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:12:31.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:12:31.997+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:12:31.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:12:32.013+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:12:32.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:12:32.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-16T01:13:02.276+0000] {processor.py:157} INFO - Started process (PID=25254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:13:02.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:13:02.282+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:13:02.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:13:02.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:13:02.325+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:13:02.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:13:02.340+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:13:02.340+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:13:02.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-16T01:13:32.630+0000] {processor.py:157} INFO - Started process (PID=25264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:13:32.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:13:32.642+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:13:32.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:13:32.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:13:32.695+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:13:32.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:13:32.730+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:13:32.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:13:32.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-16T01:14:03.141+0000] {processor.py:157} INFO - Started process (PID=25274) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:14:03.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:14:03.147+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:14:03.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:14:03.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:14:03.221+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:14:03.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:14:03.236+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:14:03.236+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:14:03.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-16T01:14:33.636+0000] {processor.py:157} INFO - Started process (PID=25284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:14:33.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:14:33.644+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:14:33.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:14:33.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:14:33.711+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:14:33.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:14:33.739+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:14:33.739+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:14:33.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-16T01:15:03.990+0000] {processor.py:157} INFO - Started process (PID=25294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:15:03.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:15:03.995+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:15:03.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:15:04.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:15:04.054+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:15:04.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:15:04.072+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:15:04.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:15:04.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T01:15:34.442+0000] {processor.py:157} INFO - Started process (PID=25304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:15:34.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:15:34.451+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:15:34.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:15:34.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:15:34.476+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:15:34.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:15:34.486+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:15:34.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:15:34.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-16T01:16:04.761+0000] {processor.py:157} INFO - Started process (PID=25314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:16:04.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:16:04.766+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:16:04.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:16:04.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:16:04.820+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:16:04.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:16:04.836+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:16:04.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:16:04.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-16T01:16:35.077+0000] {processor.py:157} INFO - Started process (PID=25324) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:16:35.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:16:35.086+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:16:35.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:16:35.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:16:35.141+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:16:35.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:16:35.157+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:16:35.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:16:35.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-16T01:17:05.399+0000] {processor.py:157} INFO - Started process (PID=25334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:17:05.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:17:05.406+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:17:05.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:17:05.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:17:05.447+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:17:05.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:17:05.461+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:17:05.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:17:05.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-16T01:17:35.813+0000] {processor.py:157} INFO - Started process (PID=25343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:17:35.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:17:35.835+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:17:35.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:17:35.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:17:35.885+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:17:35.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:17:35.901+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:17:35.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:17:35.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-16T01:18:06.105+0000] {processor.py:157} INFO - Started process (PID=25354) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:18:06.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:18:06.110+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:18:06.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:18:06.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:18:06.142+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:18:06.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:18:06.151+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:18:06.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:18:06.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-16T01:18:36.488+0000] {processor.py:157} INFO - Started process (PID=25364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:18:36.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:18:36.494+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:18:36.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:18:36.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:18:36.540+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:18:36.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:18:36.555+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:18:36.554+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:18:36.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-16T01:19:06.797+0000] {processor.py:157} INFO - Started process (PID=25374) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:19:06.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:19:06.802+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:19:06.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:19:06.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:19:06.853+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:19:06.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:19:06.866+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:19:06.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:19:06.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-16T01:19:37.158+0000] {processor.py:157} INFO - Started process (PID=25384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:19:37.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:19:37.163+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:19:37.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:19:37.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:19:37.202+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:19:37.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:19:37.215+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:19:37.215+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:19:37.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-16T01:20:07.581+0000] {processor.py:157} INFO - Started process (PID=25393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:20:07.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:20:07.586+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:20:07.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:20:07.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:20:07.638+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:20:07.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:20:07.653+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:20:07.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:20:07.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-16T01:20:37.989+0000] {processor.py:157} INFO - Started process (PID=25404) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:20:37.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:20:37.994+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:20:37.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:20:38.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:20:38.031+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:20:38.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:20:38.042+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:20:38.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:20:38.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-16T01:21:08.291+0000] {processor.py:157} INFO - Started process (PID=25414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:21:08.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:21:08.295+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:21:08.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:21:08.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:21:08.331+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:21:08.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:21:08.344+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:21:08.344+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:21:08.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-16T01:21:38.615+0000] {processor.py:157} INFO - Started process (PID=25423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:21:38.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:21:38.622+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:21:38.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:21:38.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:21:38.668+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:21:38.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:21:38.688+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:21:38.688+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:21:38.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-16T01:22:08.949+0000] {processor.py:157} INFO - Started process (PID=25434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:22:08.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:22:08.955+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:22:08.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:22:08.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:22:09.020+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:22:09.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:22:09.034+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:22:09.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:22:09.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-16T01:22:39.361+0000] {processor.py:157} INFO - Started process (PID=25444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:22:39.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:22:39.364+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:22:39.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:22:39.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:22:39.393+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:22:39.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:22:39.403+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:22:39.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:22:39.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-16T01:23:09.751+0000] {processor.py:157} INFO - Started process (PID=25454) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:23:09.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:23:09.772+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:23:09.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:23:09.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:23:09.815+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:23:09.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:23:09.830+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:23:09.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:23:09.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-16T01:23:40.100+0000] {processor.py:157} INFO - Started process (PID=25464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:23:40.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:23:40.105+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:23:40.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:23:40.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:23:40.134+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:23:40.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:23:40.145+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:23:40.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:23:40.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-16T01:24:10.496+0000] {processor.py:157} INFO - Started process (PID=25473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:24:10.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:24:10.500+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:24:10.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:24:10.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:24:10.549+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:24:10.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:24:10.572+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:24:10.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:24:10.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-16T01:24:40.948+0000] {processor.py:157} INFO - Started process (PID=25484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:24:40.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:24:40.954+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:24:40.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:24:40.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:24:40.989+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:24:40.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:24:41.002+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:24:41.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:24:41.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-16T01:25:11.368+0000] {processor.py:157} INFO - Started process (PID=25493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:25:11.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:25:11.380+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:25:11.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:25:11.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:25:11.431+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:25:11.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:25:11.448+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:25:11.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:25:11.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-16T01:25:41.689+0000] {processor.py:157} INFO - Started process (PID=25504) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:25:41.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:25:41.694+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:25:41.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:25:41.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:25:41.730+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:25:41.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:25:41.745+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:25:41.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:25:41.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-16T01:26:12.121+0000] {processor.py:157} INFO - Started process (PID=25514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:26:12.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:26:12.136+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:26:12.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:26:12.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:26:12.213+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:26:12.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:26:12.228+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:26:12.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:26:12.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-16T01:26:42.515+0000] {processor.py:157} INFO - Started process (PID=25524) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:26:42.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:26:42.522+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:26:42.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:26:42.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:26:42.583+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:26:42.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:26:42.600+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:26:42.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:26:42.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-16T01:27:12.858+0000] {processor.py:157} INFO - Started process (PID=25534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:27:12.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:27:12.868+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:27:12.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:27:12.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:27:12.925+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:27:12.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:27:12.943+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:27:12.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:27:12.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T01:27:43.191+0000] {processor.py:157} INFO - Started process (PID=25544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:27:43.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:27:43.195+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:27:43.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:27:43.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:27:43.238+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:27:43.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:27:43.253+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:27:43.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:27:43.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-16T01:28:13.633+0000] {processor.py:157} INFO - Started process (PID=25554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:28:13.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:28:13.640+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:28:13.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:28:13.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:28:13.693+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:28:13.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:28:13.716+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:28:13.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:28:13.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-16T01:28:43.975+0000] {processor.py:157} INFO - Started process (PID=25564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:28:43.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:28:43.983+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:28:43.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:28:44.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:28:44.049+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:28:44.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:28:44.066+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:28:44.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:28:44.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-16T01:29:14.323+0000] {processor.py:157} INFO - Started process (PID=25573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:29:14.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:29:14.340+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:29:14.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:29:14.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:29:14.409+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:29:14.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:29:14.440+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:29:14.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:29:14.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-16T01:29:44.688+0000] {processor.py:157} INFO - Started process (PID=25584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:29:44.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:29:44.694+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:29:44.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:29:44.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:29:44.745+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:29:44.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:29:44.760+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:29:44.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:29:44.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-16T01:30:15.115+0000] {processor.py:157} INFO - Started process (PID=25594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:30:15.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:30:15.128+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:30:15.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:30:15.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:30:15.177+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:30:15.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:30:15.192+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:30:15.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:30:15.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-16T01:30:45.493+0000] {processor.py:157} INFO - Started process (PID=25604) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:30:45.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:30:45.507+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:30:45.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:30:45.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:30:45.586+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:30:45.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:30:45.606+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:30:45.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:30:45.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-16T01:31:15.866+0000] {processor.py:157} INFO - Started process (PID=25614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:31:15.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:31:15.872+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:31:15.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:31:15.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:31:15.929+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:31:15.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:31:15.954+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:31:15.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:31:15.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-16T01:31:46.269+0000] {processor.py:157} INFO - Started process (PID=25624) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:31:46.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:31:46.276+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:31:46.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:31:46.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:31:46.343+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:31:46.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:31:46.359+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:31:46.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:31:46.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-16T01:32:16.632+0000] {processor.py:157} INFO - Started process (PID=25634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:32:16.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:32:16.640+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:32:16.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:32:16.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:32:16.708+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:32:16.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:32:16.727+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:32:16.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:32:16.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-16T01:32:46.998+0000] {processor.py:157} INFO - Started process (PID=25643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:32:47.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:32:47.003+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:32:47.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:32:47.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:32:47.068+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:32:47.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:32:47.095+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:32:47.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:32:47.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-16T01:33:17.356+0000] {processor.py:157} INFO - Started process (PID=25654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:33:17.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:33:17.377+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:33:17.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:33:17.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:33:17.437+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:33:17.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:33:17.454+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:33:17.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:33:17.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T01:33:47.693+0000] {processor.py:157} INFO - Started process (PID=25664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:33:47.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:33:47.701+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:33:47.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:33:47.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:33:47.754+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:33:47.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:33:47.772+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:33:47.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:33:47.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-16T01:34:18.176+0000] {processor.py:157} INFO - Started process (PID=25673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:34:18.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:34:18.182+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:34:18.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:34:18.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:34:18.230+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:34:18.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:34:18.255+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:34:18.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:34:18.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-16T01:34:48.609+0000] {processor.py:157} INFO - Started process (PID=25684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:34:48.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:34:48.617+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:34:48.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:34:48.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:34:48.666+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:34:48.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:34:48.691+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:34:48.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:34:48.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-16T01:35:19.131+0000] {processor.py:157} INFO - Started process (PID=25694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:35:19.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:35:19.140+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:35:19.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:35:19.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:35:19.203+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:35:19.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:35:19.222+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:35:19.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:35:19.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-16T01:35:49.499+0000] {processor.py:157} INFO - Started process (PID=25704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:35:49.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:35:49.505+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:35:49.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:35:49.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:35:49.574+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:35:49.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:35:49.592+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:35:49.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:35:49.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-16T01:36:19.975+0000] {processor.py:157} INFO - Started process (PID=25714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:36:19.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:36:19.989+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:36:19.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:36:20.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:36:20.065+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:36:20.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:36:20.103+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:36:20.103+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:36:20.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-09-16T01:36:50.296+0000] {processor.py:157} INFO - Started process (PID=25724) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:36:50.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:36:50.304+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:36:50.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:36:50.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:36:50.373+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:36:50.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:36:50.391+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:36:50.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:36:50.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-16T01:37:20.704+0000] {processor.py:157} INFO - Started process (PID=25734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:37:20.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:37:20.718+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:37:20.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:37:20.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:37:20.798+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:37:20.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:37:20.814+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:37:20.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:37:20.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-16T01:37:51.132+0000] {processor.py:157} INFO - Started process (PID=25744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:37:51.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:37:51.139+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:37:51.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:37:51.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:37:51.198+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:37:51.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:37:51.217+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:37:51.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:37:51.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-16T01:38:21.500+0000] {processor.py:157} INFO - Started process (PID=25753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:38:21.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:38:21.506+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:38:21.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:38:21.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:38:21.562+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:38:21.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:38:21.594+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:38:21.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:38:21.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-16T01:38:51.889+0000] {processor.py:157} INFO - Started process (PID=25763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:38:51.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:38:51.897+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:38:51.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:38:51.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:38:51.972+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:38:51.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:38:51.991+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:38:51.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:38:52.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-16T01:39:22.422+0000] {processor.py:157} INFO - Started process (PID=25774) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:39:22.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:39:22.431+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:39:22.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:39:22.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:39:22.502+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:39:22.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:39:22.520+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:39:22.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:39:22.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-16T01:39:52.774+0000] {processor.py:157} INFO - Started process (PID=25784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:39:52.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:39:52.785+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:39:52.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:39:52.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:39:52.836+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:39:52.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:39:52.867+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:39:52.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:39:52.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-16T01:40:23.279+0000] {processor.py:157} INFO - Started process (PID=25793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:40:23.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:40:23.284+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:40:23.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:40:23.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:40:23.343+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:40:23.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:40:23.369+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:40:23.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:40:23.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-16T01:40:53.621+0000] {processor.py:157} INFO - Started process (PID=25804) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:40:53.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:40:53.626+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:40:53.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:40:53.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:40:53.655+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:40:53.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:40:53.666+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:40:53.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:40:53.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-16T01:41:24.035+0000] {processor.py:157} INFO - Started process (PID=25814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:41:24.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:41:24.045+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:41:24.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:41:24.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:41:24.092+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:41:24.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:41:24.108+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:41:24.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:41:24.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-16T01:41:54.371+0000] {processor.py:157} INFO - Started process (PID=25824) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:41:54.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:41:54.389+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:41:54.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:41:54.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:41:54.438+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:41:54.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:41:54.455+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:41:54.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:41:54.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-16T01:42:24.772+0000] {processor.py:157} INFO - Started process (PID=25834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:42:24.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:42:24.790+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:42:24.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:42:24.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:42:24.858+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:42:24.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:42:24.881+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:42:24.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:42:24.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-16T01:42:55.148+0000] {processor.py:157} INFO - Started process (PID=25844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:42:55.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:42:55.156+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:42:55.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:42:55.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:42:55.223+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:42:55.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:42:55.240+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:42:55.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:42:55.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-16T01:43:25.537+0000] {processor.py:157} INFO - Started process (PID=25854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:43:25.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:43:25.550+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:43:25.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:43:25.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:43:25.627+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:43:25.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:43:25.652+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:43:25.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:43:25.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-16T01:43:55.936+0000] {processor.py:157} INFO - Started process (PID=25864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:43:55.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:43:55.943+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:43:55.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:43:55.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:43:56.022+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:43:56.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:43:56.039+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:43:56.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:43:56.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-16T01:44:26.298+0000] {processor.py:157} INFO - Started process (PID=25873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:44:26.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:44:26.304+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:44:26.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:44:26.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:44:26.379+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:44:26.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:44:26.414+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:44:26.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:44:26.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-16T01:44:56.601+0000] {processor.py:157} INFO - Started process (PID=25884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:44:56.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:44:56.606+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:44:56.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:44:56.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:44:56.640+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:44:56.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:44:56.651+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:44:56.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:44:56.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-16T01:45:27.032+0000] {processor.py:157} INFO - Started process (PID=25894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:45:27.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:45:27.053+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:45:27.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:45:27.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:45:27.106+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:45:27.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:45:27.134+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:45:27.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:45:27.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-16T01:45:57.535+0000] {processor.py:157} INFO - Started process (PID=25904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:45:57.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:45:57.542+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:45:57.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:45:57.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:45:57.603+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:45:57.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:45:57.633+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:45:57.633+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:45:57.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-16T01:46:27.887+0000] {processor.py:157} INFO - Started process (PID=25914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:46:27.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:46:27.893+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:46:27.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:46:27.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:46:27.949+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:46:27.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:46:27.965+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:46:27.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:46:27.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-16T01:46:58.236+0000] {processor.py:157} INFO - Started process (PID=25924) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:46:58.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:46:58.258+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:46:58.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:46:58.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:46:58.311+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:46:58.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:46:58.338+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:46:58.338+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:46:58.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-16T01:47:28.639+0000] {processor.py:157} INFO - Started process (PID=25934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:47:28.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:47:28.645+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:47:28.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:47:28.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:47:28.706+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:47:28.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:47:28.722+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:47:28.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:47:28.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-16T01:47:59.024+0000] {processor.py:157} INFO - Started process (PID=25943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:47:59.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:47:59.030+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:47:59.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:47:59.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:47:59.085+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:47:59.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:47:59.100+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:47:59.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:47:59.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-16T01:48:29.380+0000] {processor.py:157} INFO - Started process (PID=25954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:48:29.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:48:29.387+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:48:29.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:48:29.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:48:29.451+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:48:29.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:48:29.470+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:48:29.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:48:29.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-16T01:48:59.832+0000] {processor.py:157} INFO - Started process (PID=25964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:48:59.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:48:59.841+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:48:59.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:48:59.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:48:59.893+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:48:59.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:48:59.912+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:48:59.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:48:59.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-16T01:49:30.202+0000] {processor.py:157} INFO - Started process (PID=25974) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:49:30.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:49:30.208+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:49:30.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:49:30.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:49:30.260+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:49:30.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:49:30.282+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:49:30.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:49:30.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-16T01:50:00.511+0000] {processor.py:157} INFO - Started process (PID=25984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:50:00.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:50:00.517+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:50:00.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:50:00.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:50:00.564+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:50:00.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:50:00.595+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:50:00.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:50:00.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-16T01:50:30.839+0000] {processor.py:157} INFO - Started process (PID=25994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:50:30.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:50:30.860+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:50:30.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:50:30.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:50:30.928+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:50:30.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:50:30.946+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:50:30.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:50:30.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-16T01:51:01.340+0000] {processor.py:157} INFO - Started process (PID=26004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:51:01.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:51:01.349+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:51:01.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:51:01.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:51:01.411+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:51:01.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:51:01.428+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:51:01.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:51:01.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-16T01:51:31.840+0000] {processor.py:157} INFO - Started process (PID=26014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:51:31.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:51:31.847+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:51:31.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:51:31.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:51:31.902+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:51:31.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:51:31.928+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:51:31.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:51:31.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T01:52:02.263+0000] {processor.py:157} INFO - Started process (PID=26024) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:52:02.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:52:02.280+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:52:02.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:52:02.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:52:02.357+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:52:02.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:52:02.375+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:52:02.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:52:02.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-16T01:52:32.730+0000] {processor.py:157} INFO - Started process (PID=26032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:52:32.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:52:32.739+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:52:32.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:52:32.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:52:32.803+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:52:32.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:52:32.821+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:52:32.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:52:32.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-16T01:53:03.095+0000] {processor.py:157} INFO - Started process (PID=26044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:53:03.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:53:03.101+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:53:03.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:53:03.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:53:03.155+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:53:03.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:53:03.172+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:53:03.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:53:03.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-16T01:53:33.428+0000] {processor.py:157} INFO - Started process (PID=26054) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:53:33.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:53:33.435+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:53:33.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:53:33.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:53:33.486+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:53:33.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:53:33.501+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:53:33.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:53:33.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-16T01:54:03.722+0000] {processor.py:157} INFO - Started process (PID=26064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:54:03.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:54:03.728+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:54:03.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:54:03.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:54:03.777+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:54:03.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:54:03.801+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:54:03.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:54:03.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-16T01:54:34.046+0000] {processor.py:157} INFO - Started process (PID=26074) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:54:34.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:54:34.051+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:54:34.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:54:34.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:54:34.130+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:54:34.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:54:34.147+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:54:34.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:54:34.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-16T01:55:04.359+0000] {processor.py:157} INFO - Started process (PID=26084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:55:04.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:55:04.365+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:55:04.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:55:04.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:55:04.414+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:55:04.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:55:04.439+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:55:04.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:55:04.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-16T01:55:34.664+0000] {processor.py:157} INFO - Started process (PID=26094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:55:34.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:55:34.669+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:55:34.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:55:34.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:55:34.700+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:55:34.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:55:34.711+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:55:34.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:55:34.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-16T01:56:05.103+0000] {processor.py:157} INFO - Started process (PID=26104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:56:05.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:56:05.107+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:56:05.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:56:05.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:56:05.160+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:56:05.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:56:05.186+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:56:05.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:56:05.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-16T01:56:35.558+0000] {processor.py:157} INFO - Started process (PID=26114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:56:35.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:56:35.565+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:56:35.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:56:35.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:56:35.621+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:56:35.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:56:35.638+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:56:35.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:56:35.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-16T01:57:05.922+0000] {processor.py:157} INFO - Started process (PID=26124) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:57:05.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:57:05.929+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:57:05.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:57:05.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:57:05.979+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:57:05.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:57:05.995+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:57:05.995+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:57:06.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-16T01:57:36.279+0000] {processor.py:157} INFO - Started process (PID=26134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:57:36.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:57:36.285+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:57:36.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:57:36.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:57:36.346+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:57:36.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:57:36.378+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:57:36.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:57:36.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-16T01:58:06.661+0000] {processor.py:157} INFO - Started process (PID=26144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:58:06.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:58:06.671+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:58:06.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:58:06.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:58:06.732+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:58:06.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:58:06.752+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:58:06.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:58:06.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-16T01:58:36.968+0000] {processor.py:157} INFO - Started process (PID=26154) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:58:36.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:58:36.976+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:58:36.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:58:37.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:58:37.034+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:58:37.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:58:37.063+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:58:37.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:58:37.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-16T01:59:07.281+0000] {processor.py:157} INFO - Started process (PID=26164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:59:07.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:59:07.287+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:59:07.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:59:07.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:59:07.343+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:59:07.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:59:07.359+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:59:07.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:59:07.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-16T01:59:37.621+0000] {processor.py:157} INFO - Started process (PID=26172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:59:37.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T01:59:37.628+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:59:37.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:59:37.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T01:59:37.686+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:59:37.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T01:59:37.702+0000] {logging_mixin.py:151} INFO - [2024-09-16T01:59:37.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T01:59:37.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-16T02:00:07.958+0000] {processor.py:157} INFO - Started process (PID=26184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:00:07.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:00:07.974+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:00:07.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:00:07.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:00:08.030+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:00:08.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:00:08.051+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:00:08.051+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:00:08.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-16T02:00:38.366+0000] {processor.py:157} INFO - Started process (PID=26193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:00:38.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:00:38.374+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:00:38.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:00:38.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:00:38.463+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:00:38.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:00:38.500+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:00:38.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:00:38.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-09-16T02:01:08.738+0000] {processor.py:157} INFO - Started process (PID=26204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:01:08.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:01:08.745+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:01:08.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:01:08.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:01:08.803+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:01:08.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:01:08.818+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:01:08.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:01:08.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-16T02:01:39.128+0000] {processor.py:157} INFO - Started process (PID=26214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:01:39.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:01:39.134+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:01:39.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:01:39.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:01:39.211+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:01:39.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:01:39.227+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:01:39.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:01:39.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-16T02:02:09.518+0000] {processor.py:157} INFO - Started process (PID=26224) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:02:09.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:02:09.529+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:02:09.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:02:09.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:02:09.582+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:02:09.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:02:09.612+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:02:09.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:02:09.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-16T02:02:39.877+0000] {processor.py:157} INFO - Started process (PID=26234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:02:39.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:02:39.886+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:02:39.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:02:39.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:02:39.939+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:02:39.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:02:39.956+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:02:39.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:02:39.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-16T02:03:10.245+0000] {processor.py:157} INFO - Started process (PID=26244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:03:10.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:03:10.252+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:03:10.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:03:10.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:03:10.304+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:03:10.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:03:10.320+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:03:10.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:03:10.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-16T02:03:40.562+0000] {processor.py:157} INFO - Started process (PID=26254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:03:40.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:03:40.568+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:03:40.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:03:40.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:03:40.614+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:03:40.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:03:40.628+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:03:40.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:03:40.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-16T02:04:11.016+0000] {processor.py:157} INFO - Started process (PID=26263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:04:11.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:04:11.037+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:04:11.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:04:11.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:04:11.113+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:04:11.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:04:11.135+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:04:11.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:04:11.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-16T02:04:41.396+0000] {processor.py:157} INFO - Started process (PID=26273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:04:41.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:04:41.413+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:04:41.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:04:41.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:04:41.480+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:04:41.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:04:41.513+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:04:41.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:04:41.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-16T02:05:11.921+0000] {processor.py:157} INFO - Started process (PID=26284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:05:11.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:05:11.930+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:05:11.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:05:11.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:05:12.001+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:05:12.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:05:12.041+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:05:12.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:05:12.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-16T02:05:42.260+0000] {processor.py:157} INFO - Started process (PID=26294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:05:42.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:05:42.275+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:05:42.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:05:42.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:05:42.363+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:05:42.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:05:42.380+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:05:42.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:05:42.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-16T02:06:12.686+0000] {processor.py:157} INFO - Started process (PID=26302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:06:12.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:06:12.693+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:06:12.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:06:12.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:06:12.749+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:06:12.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:06:12.768+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:06:12.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:06:12.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-16T02:06:43.037+0000] {processor.py:157} INFO - Started process (PID=26314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:06:43.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:06:43.053+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:06:43.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:06:43.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:06:43.120+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:06:43.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:06:43.143+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:06:43.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:06:43.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-16T02:07:13.382+0000] {processor.py:157} INFO - Started process (PID=26324) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:07:13.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:07:13.390+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:07:13.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:07:13.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:07:13.473+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:07:13.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:07:13.489+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:07:13.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:07:13.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-16T02:07:43.763+0000] {processor.py:157} INFO - Started process (PID=26334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:07:43.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:07:43.769+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:07:43.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:07:43.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:07:43.835+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:07:43.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:07:43.854+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:07:43.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:07:43.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-16T02:08:14.117+0000] {processor.py:157} INFO - Started process (PID=26344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:08:14.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:08:14.124+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:08:14.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:08:14.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:08:14.177+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:08:14.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:08:14.194+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:08:14.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:08:14.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-16T02:08:44.474+0000] {processor.py:157} INFO - Started process (PID=26354) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:08:44.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:08:44.490+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:08:44.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:08:44.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:08:44.559+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:08:44.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:08:44.585+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:08:44.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:08:44.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-16T02:09:14.808+0000] {processor.py:157} INFO - Started process (PID=26364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:09:14.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:09:14.811+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:09:14.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:09:14.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:09:14.854+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:09:14.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:09:14.869+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:09:14.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:09:14.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-16T02:09:45.207+0000] {processor.py:157} INFO - Started process (PID=26374) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:09:45.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:09:45.215+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:09:45.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:09:45.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:09:45.259+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:09:45.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:09:45.274+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:09:45.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:09:45.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-16T02:10:15.565+0000] {processor.py:157} INFO - Started process (PID=26383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:10:15.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:10:15.572+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:10:15.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:10:15.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:10:15.630+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:10:15.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:10:15.652+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:10:15.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:10:15.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-16T02:10:45.974+0000] {processor.py:157} INFO - Started process (PID=26394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:10:45.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:10:45.980+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:10:45.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:10:45.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:10:46.041+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:10:46.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:10:46.057+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:10:46.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:10:46.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-16T02:11:16.325+0000] {processor.py:157} INFO - Started process (PID=26403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:11:16.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:11:16.332+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:11:16.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:11:16.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:11:16.382+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:11:16.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:11:16.408+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:11:16.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:11:16.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-16T02:11:46.692+0000] {processor.py:157} INFO - Started process (PID=26413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:11:46.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:11:46.698+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:11:46.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:11:46.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:11:46.761+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:11:46.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:11:46.777+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:11:46.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:11:46.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-16T02:12:17.113+0000] {processor.py:157} INFO - Started process (PID=26424) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:12:17.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:12:17.119+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:12:17.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:12:17.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:12:17.169+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:12:17.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:12:17.186+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:12:17.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:12:17.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-16T02:12:47.659+0000] {processor.py:157} INFO - Started process (PID=26434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:12:47.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:12:47.683+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:12:47.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:12:47.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:12:47.742+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:12:47.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:12:47.763+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:12:47.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:12:47.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-16T02:13:17.924+0000] {processor.py:157} INFO - Started process (PID=26444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:13:17.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:13:17.927+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:13:17.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:13:17.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:13:17.957+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:13:17.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:13:17.969+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:13:17.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:13:17.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-16T02:13:48.275+0000] {processor.py:157} INFO - Started process (PID=26454) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:13:48.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:13:48.282+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:13:48.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:13:48.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:13:48.322+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:13:48.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:13:48.337+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:13:48.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:13:48.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-16T02:14:18.624+0000] {processor.py:157} INFO - Started process (PID=26464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:14:18.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:14:18.627+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:14:18.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:14:18.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:14:18.653+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:14:18.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:14:18.666+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:14:18.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:14:18.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-16T02:14:48.995+0000] {processor.py:157} INFO - Started process (PID=26474) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:14:48.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:14:49.000+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:14:49.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:14:49.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:14:49.033+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:14:49.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:14:49.057+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:14:49.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:14:49.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-16T02:15:19.431+0000] {processor.py:157} INFO - Started process (PID=26484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:15:19.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:15:19.437+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:15:19.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:15:19.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:15:19.480+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:15:19.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:15:19.503+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:15:19.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:15:19.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-16T02:15:49.817+0000] {processor.py:157} INFO - Started process (PID=26494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:15:49.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:15:49.822+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:15:49.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:15:49.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:15:49.853+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:15:49.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:15:49.868+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:15:49.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:15:49.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-16T02:16:20.189+0000] {processor.py:157} INFO - Started process (PID=26504) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:16:20.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:16:20.194+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:16:20.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:16:20.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:16:20.241+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:16:20.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:16:20.258+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:16:20.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:16:20.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-16T02:16:50.541+0000] {processor.py:157} INFO - Started process (PID=26513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:16:50.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:16:50.548+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:16:50.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:16:50.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:16:50.631+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:16:50.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:16:50.649+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:16:50.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:16:50.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-16T02:17:20.949+0000] {processor.py:157} INFO - Started process (PID=26524) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:17:20.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:17:20.952+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:17:20.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:17:20.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:17:20.982+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:17:20.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:17:20.993+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:17:20.993+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:17:21.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-16T02:17:51.365+0000] {processor.py:157} INFO - Started process (PID=26533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:17:51.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:17:51.371+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:17:51.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:17:51.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:17:51.429+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:17:51.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:17:51.445+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:17:51.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:17:51.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-16T02:18:21.745+0000] {processor.py:157} INFO - Started process (PID=26544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:18:21.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:18:21.748+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:18:21.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:18:21.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:18:21.791+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:18:21.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:18:21.805+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:18:21.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:18:21.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-16T02:18:52.077+0000] {processor.py:157} INFO - Started process (PID=26554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:18:52.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:18:52.084+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:18:52.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:18:52.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:18:52.150+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:18:52.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:18:52.178+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:18:52.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:18:52.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-16T02:19:22.419+0000] {processor.py:157} INFO - Started process (PID=26564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:19:22.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:19:22.424+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:19:22.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:19:22.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:19:22.455+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:19:22.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:19:22.467+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:19:22.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:19:22.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-16T02:19:52.791+0000] {processor.py:157} INFO - Started process (PID=26574) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:19:52.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:19:52.796+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:19:52.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:19:52.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:19:52.837+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:19:52.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:19:52.854+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:19:52.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:19:52.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-16T02:20:23.231+0000] {processor.py:157} INFO - Started process (PID=26584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:20:23.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:20:23.236+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:20:23.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:20:23.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:20:23.267+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:20:23.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:20:23.282+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:20:23.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:20:23.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-16T02:20:53.646+0000] {processor.py:157} INFO - Started process (PID=26594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:20:53.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:20:53.654+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:20:53.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:20:53.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:20:53.717+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:20:53.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:20:53.741+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:20:53.741+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:20:53.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-16T02:21:23.921+0000] {processor.py:157} INFO - Started process (PID=26604) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:21:23.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:21:23.928+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:21:23.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:21:23.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:21:23.984+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:21:23.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:21:24.002+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:21:24.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:21:24.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-16T02:21:54.270+0000] {processor.py:157} INFO - Started process (PID=26614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:21:54.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:21:54.272+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:21:54.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:21:54.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:21:54.303+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:21:54.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:21:54.315+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:21:54.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:21:54.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-16T02:22:24.668+0000] {processor.py:157} INFO - Started process (PID=26623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:22:24.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:22:24.678+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:22:24.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:22:24.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:22:24.754+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:22:24.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:22:24.773+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:22:24.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:22:24.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-16T02:22:54.898+0000] {processor.py:157} INFO - Started process (PID=26634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:22:54.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:22:54.902+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:22:54.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:22:54.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:22:54.936+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:22:54.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:22:54.950+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:22:54.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:22:54.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-16T02:23:25.315+0000] {processor.py:157} INFO - Started process (PID=26644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:23:25.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:23:25.321+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:23:25.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:23:25.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:23:25.378+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:23:25.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:23:25.393+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:23:25.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:23:25.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-16T02:23:55.631+0000] {processor.py:157} INFO - Started process (PID=26654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:23:55.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:23:55.635+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:23:55.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:23:55.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:23:55.667+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:23:55.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:23:55.683+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:23:55.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:23:55.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-16T02:24:26.065+0000] {processor.py:157} INFO - Started process (PID=26664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:24:26.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:24:26.071+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:24:26.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:24:26.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:24:26.122+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:24:26.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:24:26.138+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:24:26.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:24:26.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-16T02:24:56.414+0000] {processor.py:157} INFO - Started process (PID=26674) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:24:56.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:24:56.420+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:24:56.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:24:56.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:24:56.466+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:24:56.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:24:56.484+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:24:56.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:24:56.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-16T02:25:26.840+0000] {processor.py:157} INFO - Started process (PID=26684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:25:26.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:25:26.844+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:25:26.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:25:26.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:25:26.893+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:25:26.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:25:26.909+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:25:26.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:25:26.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-16T02:25:57.141+0000] {processor.py:157} INFO - Started process (PID=26694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:25:57.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:25:57.150+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:25:57.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:25:57.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:25:57.177+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:25:57.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:25:57.189+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:25:57.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:25:57.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-16T02:26:27.546+0000] {processor.py:157} INFO - Started process (PID=26704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:26:27.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:26:27.564+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:26:27.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:26:27.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:26:27.615+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:26:27.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:26:27.644+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:26:27.644+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:26:27.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-16T02:26:57.856+0000] {processor.py:157} INFO - Started process (PID=26714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:26:57.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:26:57.861+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:26:57.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:26:57.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:26:57.894+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:26:57.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:26:57.907+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:26:57.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:26:57.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-16T02:27:28.225+0000] {processor.py:157} INFO - Started process (PID=26724) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:27:28.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:27:28.228+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:27:28.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:27:28.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:27:28.273+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:27:28.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:27:28.290+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:27:28.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:27:28.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-16T02:27:58.569+0000] {processor.py:157} INFO - Started process (PID=26734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:27:58.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:27:58.575+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:27:58.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:27:58.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:27:58.610+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:27:58.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:27:58.637+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:27:58.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:27:58.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-16T02:28:28.986+0000] {processor.py:157} INFO - Started process (PID=26744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:28:28.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:28:28.991+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:28:28.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:28:29.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:28:29.049+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:28:29.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:28:29.066+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:28:29.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:28:29.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-16T02:28:59.421+0000] {processor.py:157} INFO - Started process (PID=26754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:28:59.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:28:59.424+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:28:59.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:28:59.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:28:59.454+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:28:59.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:28:59.486+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:28:59.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:28:59.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-16T02:29:29.838+0000] {processor.py:157} INFO - Started process (PID=26764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:29:29.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:29:29.843+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:29:29.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:29:29.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:29:29.909+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:29:29.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:29:29.925+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:29:29.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:29:29.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-16T02:30:00.148+0000] {processor.py:157} INFO - Started process (PID=26774) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:30:00.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:30:00.151+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:30:00.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:30:00.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:30:00.183+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:30:00.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:30:00.202+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:30:00.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:30:00.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-16T02:30:30.593+0000] {processor.py:157} INFO - Started process (PID=26784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:30:30.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:30:30.600+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:30:30.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:30:30.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:30:30.659+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:30:30.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:30:30.677+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:30:30.677+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:30:30.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-16T02:31:00.921+0000] {processor.py:157} INFO - Started process (PID=26794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:31:00.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:31:00.925+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:31:00.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:31:00.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:31:00.955+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:31:00.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:31:00.969+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:31:00.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:31:00.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-16T02:31:31.314+0000] {processor.py:157} INFO - Started process (PID=26804) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:31:31.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:31:31.322+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:31:31.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:31:31.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:31:31.378+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:31:31.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:31:31.394+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:31:31.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:31:31.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-16T02:32:01.735+0000] {processor.py:157} INFO - Started process (PID=26814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:32:01.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:32:01.739+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:32:01.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:32:01.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:32:01.772+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:32:01.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:32:01.798+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:32:01.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:32:01.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-16T02:32:32.163+0000] {processor.py:157} INFO - Started process (PID=26824) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:32:32.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:32:32.171+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:32:32.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:32:32.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:32:32.243+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:32:32.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:32:32.264+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:32:32.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:32:32.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-16T02:33:02.467+0000] {processor.py:157} INFO - Started process (PID=26834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:33:02.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:33:02.471+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:33:02.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:33:02.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:33:02.504+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:33:02.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:33:02.516+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:33:02.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:33:02.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-16T02:33:32.927+0000] {processor.py:157} INFO - Started process (PID=26844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:33:32.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:33:32.957+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:33:32.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:33:33.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:33:33.084+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:33:33.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:33:33.104+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:33:33.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:33:33.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.198 seconds
[2024-09-16T02:34:03.279+0000] {processor.py:157} INFO - Started process (PID=26854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:34:03.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:34:03.294+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:34:03.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:34:03.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:34:03.343+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:34:03.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:34:03.359+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:34:03.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:34:03.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T02:34:33.711+0000] {processor.py:157} INFO - Started process (PID=26864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:34:33.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:34:33.720+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:34:33.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:34:33.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:34:33.785+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:34:33.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:34:33.801+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:34:33.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:34:33.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-16T02:35:04.114+0000] {processor.py:157} INFO - Started process (PID=26874) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:35:04.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:35:04.121+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:35:04.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:35:04.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:35:04.187+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:35:04.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:35:04.216+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:35:04.216+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:35:04.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-16T02:35:34.510+0000] {processor.py:157} INFO - Started process (PID=26884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:35:34.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:35:34.517+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:35:34.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:35:34.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:35:34.587+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:35:34.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:35:34.616+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:35:34.616+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:35:34.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-16T02:36:04.869+0000] {processor.py:157} INFO - Started process (PID=26894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:36:04.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:36:04.875+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:36:04.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:36:04.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:36:04.941+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:36:04.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:36:04.968+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:36:04.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:36:04.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T02:36:35.220+0000] {processor.py:157} INFO - Started process (PID=26904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:36:35.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:36:35.227+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:36:35.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:36:35.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:36:35.289+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:36:35.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:36:35.305+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:36:35.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:36:35.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-16T02:37:05.608+0000] {processor.py:157} INFO - Started process (PID=26914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:37:05.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:37:05.618+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:37:05.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:37:05.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:37:05.680+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:37:05.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:37:05.698+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:37:05.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:37:05.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-16T02:37:36.103+0000] {processor.py:157} INFO - Started process (PID=26923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:37:36.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:37:36.110+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:37:36.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:37:36.133+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:37:36.165+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:37:36.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:37:36.198+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:37:36.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:37:36.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-16T02:38:06.507+0000] {processor.py:157} INFO - Started process (PID=26934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:38:06.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:38:06.516+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:38:06.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:38:06.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:38:06.591+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:38:06.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:38:06.607+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:38:06.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:38:06.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-16T02:38:36.965+0000] {processor.py:157} INFO - Started process (PID=26944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:38:36.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:38:36.988+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:38:36.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:38:37.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:38:37.052+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:38:37.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:38:37.069+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:38:37.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:38:37.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-16T02:39:07.340+0000] {processor.py:157} INFO - Started process (PID=26954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:39:07.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:39:07.359+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:39:07.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:39:07.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:39:07.419+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:39:07.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:39:07.437+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:39:07.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:39:07.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-16T02:39:37.677+0000] {processor.py:157} INFO - Started process (PID=26964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:39:37.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:39:37.684+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:39:37.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:39:37.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:39:37.739+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:39:37.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:39:37.755+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:39:37.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:39:37.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-16T02:40:07.997+0000] {processor.py:157} INFO - Started process (PID=26974) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:40:07.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:40:08.002+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:40:08.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:40:08.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:40:08.042+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:40:08.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:40:08.059+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:40:08.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:40:08.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-16T02:40:38.464+0000] {processor.py:157} INFO - Started process (PID=26984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:40:38.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:40:38.471+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:40:38.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:40:38.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:40:38.526+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:40:38.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:40:38.541+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:40:38.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:40:38.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-16T02:41:08.832+0000] {processor.py:157} INFO - Started process (PID=26994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:41:08.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:41:08.845+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:41:08.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:41:08.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:41:08.925+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:41:08.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:41:08.941+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:41:08.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:41:08.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-16T02:41:39.199+0000] {processor.py:157} INFO - Started process (PID=27004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:41:39.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:41:39.206+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:41:39.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:41:39.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:41:39.277+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:41:39.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:41:39.296+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:41:39.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:41:39.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-16T02:42:09.563+0000] {processor.py:157} INFO - Started process (PID=27013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:42:09.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:42:09.570+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:42:09.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:42:09.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:42:09.641+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:42:09.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:42:09.657+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:42:09.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:42:09.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-16T02:42:39.926+0000] {processor.py:157} INFO - Started process (PID=27024) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:42:39.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:42:39.942+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:42:39.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:42:39.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:42:40.006+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:42:40.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:42:40.023+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:42:40.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:42:40.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-16T02:43:10.303+0000] {processor.py:157} INFO - Started process (PID=27034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:43:10.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:43:10.319+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:43:10.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:43:10.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:43:10.393+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:43:10.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:43:10.412+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:43:10.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:43:10.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-16T02:43:40.678+0000] {processor.py:157} INFO - Started process (PID=27043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:43:40.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:43:40.684+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:43:40.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:43:40.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:43:40.750+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:43:40.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:43:40.765+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:43:40.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:43:40.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T02:44:11.040+0000] {processor.py:157} INFO - Started process (PID=27053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:44:11.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:44:11.046+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:44:11.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:44:11.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:44:11.128+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:44:11.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:44:11.145+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:44:11.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:44:11.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-16T02:44:41.371+0000] {processor.py:157} INFO - Started process (PID=27064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:44:41.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:44:41.380+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:44:41.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:44:41.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:44:41.463+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:44:41.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:44:41.479+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:44:41.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:44:41.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-16T02:45:11.740+0000] {processor.py:157} INFO - Started process (PID=27074) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:45:11.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:45:11.747+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:45:11.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:45:11.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:45:11.818+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:45:11.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:45:11.839+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:45:11.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:45:11.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-16T02:45:42.128+0000] {processor.py:157} INFO - Started process (PID=27084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:45:42.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:45:42.142+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:45:42.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:45:42.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:45:42.205+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:45:42.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:45:42.224+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:45:42.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:45:42.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-16T02:46:12.524+0000] {processor.py:157} INFO - Started process (PID=27094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:46:12.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:46:12.532+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:46:12.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:46:12.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:46:12.594+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:46:12.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:46:12.609+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:46:12.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:46:12.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-16T02:46:42.877+0000] {processor.py:157} INFO - Started process (PID=27104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:46:42.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:46:42.885+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:46:42.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:46:42.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:46:42.927+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:46:42.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:46:42.945+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:46:42.945+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:46:42.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-16T02:47:13.260+0000] {processor.py:157} INFO - Started process (PID=27114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:47:13.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:47:13.268+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:47:13.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:47:13.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:47:13.310+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:47:13.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:47:13.324+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:47:13.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:47:13.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-16T02:47:43.663+0000] {processor.py:157} INFO - Started process (PID=27124) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:47:43.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:47:43.670+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:47:43.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:47:43.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:47:43.717+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:47:43.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:47:43.732+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:47:43.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:47:43.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-16T02:48:14.114+0000] {processor.py:157} INFO - Started process (PID=27134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:48:14.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:48:14.121+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:48:14.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:48:14.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:48:14.203+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:48:14.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:48:14.220+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:48:14.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:48:14.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-16T02:48:44.418+0000] {processor.py:157} INFO - Started process (PID=27144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:48:44.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:48:44.421+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:48:44.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:48:44.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:48:44.450+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:48:44.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:48:44.462+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:48:44.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:48:44.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-16T02:49:14.806+0000] {processor.py:157} INFO - Started process (PID=27153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:49:14.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:49:14.812+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:49:14.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:49:14.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:49:14.869+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:49:14.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:49:14.897+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:49:14.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:49:14.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-16T02:49:45.126+0000] {processor.py:157} INFO - Started process (PID=27164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:49:45.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:49:45.130+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:49:45.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:49:45.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:49:45.163+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:49:45.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:49:45.176+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:49:45.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:49:45.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-16T02:50:15.519+0000] {processor.py:157} INFO - Started process (PID=27174) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:50:15.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:50:15.538+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:50:15.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:50:15.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:50:15.594+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:50:15.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:50:15.621+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:50:15.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:50:15.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-16T02:50:45.901+0000] {processor.py:157} INFO - Started process (PID=27184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:50:45.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:50:45.904+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:50:45.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:50:45.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:50:45.954+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:50:45.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:50:45.968+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:50:45.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:50:45.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-16T02:51:16.260+0000] {processor.py:157} INFO - Started process (PID=27194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:51:16.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:51:16.275+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:51:16.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:51:16.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:51:16.330+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:51:16.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:51:16.347+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:51:16.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:51:16.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-16T02:51:46.623+0000] {processor.py:157} INFO - Started process (PID=27204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:51:46.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:51:46.630+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:51:46.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:51:46.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:51:46.692+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:51:46.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:51:46.722+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:51:46.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:51:46.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-16T02:52:16.960+0000] {processor.py:157} INFO - Started process (PID=27214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:52:16.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:52:16.964+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:52:16.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:52:16.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:52:17.006+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:52:17.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:52:17.020+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:52:17.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:52:17.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-16T02:52:47.295+0000] {processor.py:157} INFO - Started process (PID=27224) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:52:47.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:52:47.302+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:52:47.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:52:47.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:52:47.360+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:52:47.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:52:47.376+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:52:47.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:52:47.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-16T02:53:17.742+0000] {processor.py:157} INFO - Started process (PID=27234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:53:17.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:53:17.749+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:53:17.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:53:17.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:53:17.791+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:53:17.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:53:17.806+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:53:17.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:53:17.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-16T02:53:48.088+0000] {processor.py:157} INFO - Started process (PID=27244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:53:48.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:53:48.096+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:53:48.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:53:48.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:53:48.162+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:53:48.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:53:48.180+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:53:48.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:53:48.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-16T02:54:18.403+0000] {processor.py:157} INFO - Started process (PID=27254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:54:18.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:54:18.409+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:54:18.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:54:18.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:54:18.450+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:54:18.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:54:18.466+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:54:18.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:54:18.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-16T02:54:48.773+0000] {processor.py:157} INFO - Started process (PID=27264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:54:48.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:54:48.781+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:54:48.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:54:48.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:54:48.806+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:54:48.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:54:48.816+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:54:48.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:54:48.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-16T02:55:19.208+0000] {processor.py:157} INFO - Started process (PID=27272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:55:19.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:55:19.214+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:55:19.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:55:19.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:55:19.270+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:55:19.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:55:19.294+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:55:19.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:55:19.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T02:55:49.522+0000] {processor.py:157} INFO - Started process (PID=27284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:55:49.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:55:49.527+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:55:49.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:55:49.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:55:49.561+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:55:49.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:55:49.576+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:55:49.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:55:49.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-16T02:56:19.993+0000] {processor.py:157} INFO - Started process (PID=27293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:56:19.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:56:19.999+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:56:19.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:56:20.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:56:20.058+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:56:20.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:56:20.074+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:56:20.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:56:20.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-16T02:56:50.315+0000] {processor.py:157} INFO - Started process (PID=27304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:56:50.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:56:50.321+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:56:50.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:56:50.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:56:50.378+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:56:50.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:56:50.394+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:56:50.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:56:50.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-16T02:57:20.630+0000] {processor.py:157} INFO - Started process (PID=27314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:57:20.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:57:20.634+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:57:20.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:57:20.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:57:20.663+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:57:20.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:57:20.687+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:57:20.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:57:20.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-16T02:57:51.077+0000] {processor.py:157} INFO - Started process (PID=27323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:57:51.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:57:51.084+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:57:51.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:57:51.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:57:51.142+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:57:51.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:57:51.160+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:57:51.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:57:51.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-16T02:58:21.390+0000] {processor.py:157} INFO - Started process (PID=27334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:58:21.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:58:21.395+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:58:21.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:58:21.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:58:21.431+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:58:21.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:58:21.441+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:58:21.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:58:21.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-16T02:58:51.746+0000] {processor.py:157} INFO - Started process (PID=27344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:58:51.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:58:51.762+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:58:51.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:58:51.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:58:51.820+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:58:51.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:58:51.838+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:58:51.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:58:51.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T02:59:22.012+0000] {processor.py:157} INFO - Started process (PID=27354) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:59:22.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:59:22.015+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:59:22.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:59:22.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:59:22.045+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:59:22.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:59:22.056+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:59:22.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:59:22.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-16T02:59:52.410+0000] {processor.py:157} INFO - Started process (PID=27364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:59:52.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T02:59:52.421+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:59:52.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:59:52.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T02:59:52.486+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:59:52.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T02:59:52.513+0000] {logging_mixin.py:151} INFO - [2024-09-16T02:59:52.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T02:59:52.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-16T03:00:22.695+0000] {processor.py:157} INFO - Started process (PID=27374) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:00:22.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:00:22.698+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:00:22.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:00:22.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:00:22.728+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:00:22.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:00:22.741+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:00:22.741+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:00:22.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-16T03:00:53.089+0000] {processor.py:157} INFO - Started process (PID=27384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:00:53.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:00:53.108+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:00:53.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:00:53.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:00:53.165+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:00:53.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:00:53.194+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:00:53.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:00:53.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-16T03:01:23.460+0000] {processor.py:157} INFO - Started process (PID=27394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:01:23.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:01:23.467+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:01:23.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:01:23.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:01:23.512+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:01:23.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:01:23.530+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:01:23.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:01:23.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-16T03:01:53.844+0000] {processor.py:157} INFO - Started process (PID=27404) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:01:53.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:01:53.847+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:01:53.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:01:53.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:01:53.880+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:01:53.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:01:53.891+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:01:53.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:01:53.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-16T03:02:24.282+0000] {processor.py:157} INFO - Started process (PID=27414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:02:24.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:02:24.293+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:02:24.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:02:24.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:02:24.356+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:02:24.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:02:24.377+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:02:24.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:02:24.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-16T03:02:54.734+0000] {processor.py:157} INFO - Started process (PID=27424) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:02:54.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:02:54.745+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:02:54.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:02:54.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:02:54.786+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:02:54.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:02:54.801+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:02:54.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:02:54.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-16T03:03:25.170+0000] {processor.py:157} INFO - Started process (PID=27434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:03:25.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:03:25.174+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:03:25.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:03:25.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:03:25.209+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:03:25.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:03:25.247+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:03:25.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:03:25.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-16T03:03:55.482+0000] {processor.py:157} INFO - Started process (PID=27444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:03:55.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:03:55.497+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:03:55.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:03:55.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:03:55.538+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:03:55.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:03:55.558+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:03:55.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:03:55.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-16T03:04:25.933+0000] {processor.py:157} INFO - Started process (PID=27454) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:04:25.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:04:25.939+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:04:25.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:04:25.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:04:26.010+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:04:26.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:04:26.026+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:04:26.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:04:26.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-16T03:04:56.268+0000] {processor.py:157} INFO - Started process (PID=27464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:04:56.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:04:56.271+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:04:56.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:04:56.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:04:56.298+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:04:56.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:04:56.308+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:04:56.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:04:56.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-16T03:05:26.710+0000] {processor.py:157} INFO - Started process (PID=27473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:05:26.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:05:26.719+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:05:26.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:05:26.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:05:26.796+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:05:26.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:05:26.813+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:05:26.813+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:05:26.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-16T03:05:56.980+0000] {processor.py:157} INFO - Started process (PID=27484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:05:56.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:05:56.985+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:05:56.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:05:56.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:05:57.017+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:05:57.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:05:57.027+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:05:57.027+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:05:57.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-16T03:06:27.391+0000] {processor.py:157} INFO - Started process (PID=27494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:06:27.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:06:27.397+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:06:27.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:06:27.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:06:27.445+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:06:27.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:06:27.460+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:06:27.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:06:27.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-16T03:06:57.789+0000] {processor.py:157} INFO - Started process (PID=27504) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:06:57.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:06:57.797+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:06:57.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:06:57.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:06:57.854+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:06:57.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:06:57.874+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:06:57.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:06:57.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-16T03:07:28.196+0000] {processor.py:157} INFO - Started process (PID=27514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:07:28.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:07:28.201+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:07:28.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:07:28.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:07:28.229+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:07:28.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:07:28.241+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:07:28.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:07:28.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-16T03:07:58.632+0000] {processor.py:157} INFO - Started process (PID=27523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:07:58.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:07:58.639+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:07:58.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:07:58.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:07:58.702+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:07:58.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:07:58.717+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:07:58.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:07:58.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-16T03:08:29.059+0000] {processor.py:157} INFO - Started process (PID=27534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:08:29.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:08:29.070+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:08:29.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:08:29.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:08:29.139+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:08:29.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:08:29.157+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:08:29.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:08:29.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-16T03:08:59.311+0000] {processor.py:157} INFO - Started process (PID=27544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:08:59.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:08:59.314+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:08:59.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:08:59.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:08:59.344+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:08:59.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:08:59.355+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:08:59.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:08:59.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-16T03:09:29.626+0000] {processor.py:157} INFO - Started process (PID=27554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:09:29.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:09:29.636+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:09:29.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:09:29.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:09:29.685+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:09:29.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:09:29.703+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:09:29.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:09:29.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-16T03:09:59.945+0000] {processor.py:157} INFO - Started process (PID=27564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:09:59.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:09:59.948+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:09:59.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:09:59.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:09:59.981+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:09:59.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:09:59.990+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:09:59.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:09:59.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-16T03:10:30.319+0000] {processor.py:157} INFO - Started process (PID=27574) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:10:30.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:10:30.325+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:10:30.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:10:30.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:10:30.373+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:10:30.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:10:30.389+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:10:30.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:10:30.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-16T03:11:00.723+0000] {processor.py:157} INFO - Started process (PID=27584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:11:00.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:11:00.726+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:11:00.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:11:00.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:11:00.758+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:11:00.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:11:00.769+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:11:00.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:11:00.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-16T03:11:31.097+0000] {processor.py:157} INFO - Started process (PID=27593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:11:31.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:11:31.110+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:11:31.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:11:31.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:11:31.170+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:11:31.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:11:31.186+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:11:31.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:11:31.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-16T03:12:01.535+0000] {processor.py:157} INFO - Started process (PID=27604) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:12:01.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:12:01.542+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:12:01.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:12:01.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:12:01.575+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:12:01.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:12:01.588+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:12:01.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:12:01.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-16T03:12:31.969+0000] {processor.py:157} INFO - Started process (PID=27614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:12:31.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:12:31.975+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:12:31.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:12:31.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:12:32.030+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:12:32.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:12:32.058+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:12:32.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:12:32.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-16T03:13:02.276+0000] {processor.py:157} INFO - Started process (PID=27624) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:13:02.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:13:02.278+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:13:02.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:13:02.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:13:02.308+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:13:02.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:13:02.322+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:13:02.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:13:02.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-16T03:13:32.711+0000] {processor.py:157} INFO - Started process (PID=27634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:13:32.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:13:32.724+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:13:32.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:13:32.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:13:32.768+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:13:32.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:13:32.782+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:13:32.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:13:32.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-16T03:14:02.992+0000] {processor.py:157} INFO - Started process (PID=27644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:14:02.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:14:02.997+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:14:02.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:14:03.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:14:03.026+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:14:03.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:14:03.036+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:14:03.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:14:03.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-16T03:14:33.331+0000] {processor.py:157} INFO - Started process (PID=27653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:14:33.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:14:33.347+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:14:33.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:14:33.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:14:33.416+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:14:33.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:14:33.439+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:14:33.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:14:33.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-16T03:15:03.795+0000] {processor.py:157} INFO - Started process (PID=27664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:15:03.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:15:03.801+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:15:03.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:15:03.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:15:03.849+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:15:03.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:15:03.864+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:15:03.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:15:03.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-16T03:15:34.308+0000] {processor.py:157} INFO - Started process (PID=27674) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:15:34.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:15:34.317+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:15:34.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:15:34.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:15:34.390+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:15:34.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:15:34.425+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:15:34.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:15:34.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-16T03:16:04.608+0000] {processor.py:157} INFO - Started process (PID=27684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:16:04.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:16:04.613+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:16:04.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:16:04.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:16:04.649+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:16:04.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:16:04.661+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:16:04.661+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:16:04.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-16T03:16:35.031+0000] {processor.py:157} INFO - Started process (PID=27694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:16:35.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:16:35.042+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:16:35.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:16:35.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:16:35.116+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:16:35.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:16:35.139+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:16:35.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:16:35.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-16T03:17:05.534+0000] {processor.py:157} INFO - Started process (PID=27703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:17:05.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:17:05.541+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:17:05.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:17:05.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:17:05.604+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:17:05.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:17:05.620+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:17:05.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:17:05.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-16T03:17:35.860+0000] {processor.py:157} INFO - Started process (PID=27714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:17:35.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:17:35.866+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:17:35.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:17:35.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:17:35.911+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:17:35.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:17:35.930+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:17:35.930+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:17:35.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-16T03:18:06.257+0000] {processor.py:157} INFO - Started process (PID=27724) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:18:06.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:18:06.263+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:18:06.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:18:06.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:18:06.298+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:18:06.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:18:06.309+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:18:06.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:18:06.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-16T03:18:36.681+0000] {processor.py:157} INFO - Started process (PID=27734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:18:36.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:18:36.692+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:18:36.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:18:36.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:18:36.756+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:18:36.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:18:36.773+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:18:36.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:18:36.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-16T03:19:06.996+0000] {processor.py:157} INFO - Started process (PID=27744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:19:06.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:19:07.000+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:19:07.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:19:07.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:19:07.031+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:19:07.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:19:07.044+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:19:07.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:19:07.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-16T03:19:37.448+0000] {processor.py:157} INFO - Started process (PID=27753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:19:37.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:19:37.459+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:19:37.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:19:37.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:19:37.523+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:19:37.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:19:37.539+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:19:37.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:19:37.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-16T03:20:07.774+0000] {processor.py:157} INFO - Started process (PID=27764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:20:07.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:20:07.781+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:20:07.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:20:07.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:20:07.841+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:20:07.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:20:07.857+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:20:07.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:20:07.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-16T03:20:38.115+0000] {processor.py:157} INFO - Started process (PID=27774) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:20:38.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:20:38.119+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:20:38.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:20:38.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:20:38.148+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:20:38.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:20:38.163+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:20:38.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:20:38.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-16T03:21:08.516+0000] {processor.py:157} INFO - Started process (PID=27783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:21:08.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:21:08.536+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:21:08.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:21:08.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:21:08.590+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:21:08.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:21:08.613+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:21:08.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:21:08.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-16T03:21:38.822+0000] {processor.py:157} INFO - Started process (PID=27794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:21:38.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:21:38.825+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:21:38.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:21:38.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:21:38.855+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:21:38.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:21:38.868+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:21:38.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:21:38.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-16T03:22:09.238+0000] {processor.py:157} INFO - Started process (PID=27804) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:22:09.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:22:09.244+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:22:09.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:22:09.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:22:09.284+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:22:09.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:22:09.298+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:22:09.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:22:09.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-16T03:22:39.571+0000] {processor.py:157} INFO - Started process (PID=27814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:22:39.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:22:39.573+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:22:39.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:22:39.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:22:39.605+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:22:39.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:22:39.614+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:22:39.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:22:39.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-16T03:23:09.907+0000] {processor.py:157} INFO - Started process (PID=27824) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:23:09.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:23:09.912+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:23:09.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:23:09.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:23:09.955+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:23:09.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:23:09.969+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:23:09.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:23:09.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-16T03:23:40.233+0000] {processor.py:157} INFO - Started process (PID=27834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:23:40.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:23:40.238+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:23:40.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:23:40.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:23:40.265+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:23:40.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:23:40.279+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:23:40.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:23:40.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-16T03:24:10.658+0000] {processor.py:157} INFO - Started process (PID=27844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:24:10.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:24:10.667+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:24:10.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:24:10.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:24:10.721+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:24:10.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:24:10.736+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:24:10.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:24:10.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-16T03:24:40.942+0000] {processor.py:157} INFO - Started process (PID=27854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:24:40.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:24:40.945+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:24:40.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:24:40.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:24:40.974+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:24:40.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:24:40.985+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:24:40.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:24:40.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-16T03:25:11.358+0000] {processor.py:157} INFO - Started process (PID=27864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:25:11.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:25:11.366+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:25:11.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:25:11.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:25:11.408+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:25:11.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:25:11.422+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:25:11.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:25:11.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-16T03:25:41.817+0000] {processor.py:157} INFO - Started process (PID=27874) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:25:41.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:25:41.820+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:25:41.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:25:41.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:25:41.850+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:25:41.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:25:41.861+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:25:41.861+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:25:41.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-16T03:26:12.161+0000] {processor.py:157} INFO - Started process (PID=27883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:26:12.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:26:12.167+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:26:12.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:26:12.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:26:12.203+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:26:12.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:26:12.218+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:26:12.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:26:12.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-16T03:26:42.475+0000] {processor.py:157} INFO - Started process (PID=27894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:26:42.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:26:42.480+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:26:42.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:26:42.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:26:42.508+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:26:42.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:26:42.519+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:26:42.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:26:42.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-16T03:27:12.885+0000] {processor.py:157} INFO - Started process (PID=27903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:27:12.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:27:12.896+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:27:12.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:27:12.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:27:12.951+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:27:12.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:27:12.967+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:27:12.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:27:12.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-16T03:27:43.250+0000] {processor.py:157} INFO - Started process (PID=27914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:27:43.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:27:43.253+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:27:43.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:27:43.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:27:43.297+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:27:43.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:27:43.313+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:27:43.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:27:43.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-16T03:28:13.664+0000] {processor.py:157} INFO - Started process (PID=27924) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:28:13.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:28:13.675+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:28:13.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:28:13.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:28:13.726+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:28:13.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:28:13.740+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:28:13.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:28:13.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-16T03:28:44.049+0000] {processor.py:157} INFO - Started process (PID=27934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:28:44.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:28:44.051+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:28:44.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:28:44.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:28:44.080+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:28:44.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:28:44.090+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:28:44.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:28:44.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-16T03:29:14.447+0000] {processor.py:157} INFO - Started process (PID=27944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:29:14.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:29:14.458+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:29:14.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:29:14.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:29:14.509+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:29:14.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:29:14.529+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:29:14.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:29:14.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-16T03:29:44.778+0000] {processor.py:157} INFO - Started process (PID=27954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:29:44.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:29:44.781+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:29:44.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:29:44.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:29:44.812+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:29:44.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:29:44.824+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:29:44.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:29:44.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-16T03:30:15.206+0000] {processor.py:157} INFO - Started process (PID=27964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:30:15.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:30:15.222+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:30:15.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:30:15.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:30:15.266+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:30:15.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:30:15.280+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:30:15.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:30:15.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-16T03:30:45.551+0000] {processor.py:157} INFO - Started process (PID=27974) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:30:45.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:30:45.554+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:30:45.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:30:45.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:30:45.584+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:30:45.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:30:45.596+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:30:45.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:30:45.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-16T03:31:15.983+0000] {processor.py:157} INFO - Started process (PID=27984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:31:15.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:31:15.988+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:31:15.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:31:16.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:31:16.055+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:31:16.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:31:16.071+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:31:16.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:31:16.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-16T03:31:46.288+0000] {processor.py:157} INFO - Started process (PID=27994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:31:46.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:31:46.292+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:31:46.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:31:46.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:31:46.360+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:31:46.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:31:46.380+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:31:46.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:31:46.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-16T03:32:16.514+0000] {processor.py:157} INFO - Started process (PID=28004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:32:16.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:32:16.520+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:32:16.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:32:16.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:32:16.576+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:32:16.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:32:16.602+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:32:16.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:32:16.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-16T03:32:46.890+0000] {processor.py:157} INFO - Started process (PID=28015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:32:46.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:32:46.893+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:32:46.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:32:46.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:32:46.919+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:32:46.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:32:46.930+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:32:46.930+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:32:46.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-16T03:49:10.605+0000] {processor.py:157} INFO - Started process (PID=28024) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:49:10.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:49:10.621+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:49:10.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:49:10.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:49:10.741+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:49:10.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:49:10.775+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:49:10.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:49:10.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.223 seconds
[2024-09-16T03:49:41.017+0000] {processor.py:157} INFO - Started process (PID=28037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:49:41.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:49:41.026+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:49:41.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:49:41.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:49:41.094+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:49:41.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:49:41.122+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:49:41.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:49:41.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-16T03:50:11.522+0000] {processor.py:157} INFO - Started process (PID=28047) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:50:11.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:50:11.527+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:50:11.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:50:11.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:50:11.573+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:50:11.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:50:11.588+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:50:11.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:50:11.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-16T03:50:41.954+0000] {processor.py:157} INFO - Started process (PID=28057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:50:41.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T03:50:41.958+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:50:41.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:50:41.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T03:50:41.987+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:50:41.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T03:50:42.004+0000] {logging_mixin.py:151} INFO - [2024-09-16T03:50:42.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T03:50:42.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-16T04:08:39.816+0000] {processor.py:157} INFO - Started process (PID=28069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:08:39.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T04:08:39.831+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:08:39.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:08:39.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:08:39.941+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:08:39.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T04:08:39.973+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:08:39.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T04:08:39.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.185 seconds
[2024-09-16T04:09:10.198+0000] {processor.py:157} INFO - Started process (PID=28079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:09:10.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T04:09:10.204+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:09:10.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:09:10.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:09:10.262+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:09:10.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T04:09:10.293+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:09:10.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T04:09:10.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T04:09:40.575+0000] {processor.py:157} INFO - Started process (PID=28089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:09:40.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T04:09:40.579+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:09:40.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:09:40.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:09:40.610+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:09:40.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T04:09:40.624+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:09:40.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T04:09:40.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-16T04:10:11.123+0000] {processor.py:157} INFO - Started process (PID=28099) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:10:11.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T04:10:11.129+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:10:11.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:10:11.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:10:11.189+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:10:11.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T04:10:11.205+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:10:11.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T04:10:11.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-16T04:10:41.474+0000] {processor.py:157} INFO - Started process (PID=28109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:10:41.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T04:10:41.479+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:10:41.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:10:41.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:10:41.512+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:10:41.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T04:10:41.524+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:10:41.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T04:10:41.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-16T04:28:23.912+0000] {processor.py:157} INFO - Started process (PID=28120) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:28:23.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T04:28:23.918+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:28:23.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:28:23.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:28:24.016+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:28:24.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T04:28:24.048+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:28:24.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T04:28:24.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-09-16T04:28:54.320+0000] {processor.py:157} INFO - Started process (PID=28130) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:28:54.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T04:28:54.332+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:28:54.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:28:54.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:28:54.390+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:28:54.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T04:28:54.413+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:28:54.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T04:28:54.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-16T04:29:24.758+0000] {processor.py:157} INFO - Started process (PID=28140) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:29:24.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T04:29:24.770+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:29:24.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:29:24.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:29:24.833+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:29:24.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T04:29:24.850+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:29:24.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T04:29:24.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-16T04:29:55.096+0000] {processor.py:157} INFO - Started process (PID=28150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:29:55.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T04:29:55.104+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:29:55.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:29:55.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:29:55.194+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:29:55.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T04:29:55.211+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:29:55.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T04:29:55.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-16T04:45:34.390+0000] {processor.py:157} INFO - Started process (PID=28160) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:45:34.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T04:45:34.401+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:45:34.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:45:34.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:45:34.472+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:45:34.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T04:45:34.494+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:45:34.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T04:45:34.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-16T04:46:04.816+0000] {processor.py:157} INFO - Started process (PID=28170) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:46:04.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T04:46:04.822+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:46:04.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:46:04.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:46:04.870+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:46:04.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T04:46:04.903+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:46:04.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T04:46:04.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-16T04:46:35.180+0000] {processor.py:157} INFO - Started process (PID=28182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:46:35.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T04:46:35.182+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:46:35.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:46:35.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:46:35.216+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:46:35.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T04:46:35.230+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:46:35.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T04:46:35.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-16T04:47:05.674+0000] {processor.py:157} INFO - Started process (PID=28192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:47:05.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T04:47:05.681+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:47:05.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:47:05.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:47:05.722+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:47:05.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T04:47:05.753+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:47:05.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T04:47:05.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-16T04:47:36.167+0000] {processor.py:157} INFO - Started process (PID=28202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:47:36.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T04:47:36.170+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:47:36.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:47:36.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:47:36.206+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:47:36.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T04:47:36.217+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:47:36.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T04:47:36.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-16T04:48:06.528+0000] {processor.py:157} INFO - Started process (PID=28212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:48:06.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T04:48:06.533+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:48:06.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:48:06.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:48:06.573+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:48:06.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T04:48:06.587+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:48:06.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T04:48:06.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-16T04:48:36.879+0000] {processor.py:157} INFO - Started process (PID=28222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:48:36.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T04:48:36.884+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:48:36.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:48:36.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:48:36.915+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:48:36.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T04:48:36.929+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:48:36.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T04:48:36.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-16T04:49:07.314+0000] {processor.py:157} INFO - Started process (PID=28232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:49:07.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T04:49:07.317+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:49:07.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:49:07.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:49:07.352+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:49:07.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T04:49:07.365+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:49:07.365+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T04:49:07.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-16T04:49:37.759+0000] {processor.py:157} INFO - Started process (PID=28242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:49:37.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T04:49:37.780+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:49:37.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:49:37.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:49:37.832+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:49:37.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T04:49:37.848+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:49:37.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T04:49:37.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-16T04:50:08.219+0000] {processor.py:157} INFO - Started process (PID=28252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:50:08.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T04:50:08.221+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:50:08.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:50:08.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:50:08.254+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:50:08.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T04:50:08.266+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:50:08.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T04:50:08.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-16T04:50:38.601+0000] {processor.py:157} INFO - Started process (PID=28262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:50:38.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T04:50:38.608+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:50:38.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:50:38.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:50:38.646+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:50:38.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T04:50:38.662+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:50:38.661+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T04:50:38.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-16T04:51:09.026+0000] {processor.py:157} INFO - Started process (PID=28272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:51:09.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T04:51:09.032+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:51:09.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:51:09.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:51:09.062+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:51:09.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T04:51:09.077+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:51:09.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T04:51:09.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-16T04:51:39.539+0000] {processor.py:157} INFO - Started process (PID=28282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:51:39.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T04:51:39.546+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:51:39.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:51:39.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:51:39.605+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:51:39.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T04:51:39.621+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:51:39.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T04:51:39.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T04:52:10.024+0000] {processor.py:157} INFO - Started process (PID=28292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:52:10.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T04:52:10.030+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:52:10.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:52:10.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:52:10.073+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:52:10.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T04:52:10.087+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:52:10.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T04:52:10.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-16T04:52:40.387+0000] {processor.py:157} INFO - Started process (PID=28302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:52:40.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T04:52:40.394+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:52:40.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:52:40.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:52:40.450+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:52:40.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T04:52:40.469+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:52:40.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T04:52:40.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T04:53:10.762+0000] {processor.py:157} INFO - Started process (PID=28312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:53:10.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T04:53:10.767+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:53:10.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:53:10.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:53:10.821+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:53:10.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T04:53:10.857+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:53:10.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T04:53:10.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-16T04:53:41.194+0000] {processor.py:157} INFO - Started process (PID=28322) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:53:41.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T04:53:41.210+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:53:41.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:53:41.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:53:41.281+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:53:41.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T04:53:41.303+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:53:41.303+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T04:53:41.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-16T04:54:11.527+0000] {processor.py:157} INFO - Started process (PID=28332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:54:11.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T04:54:11.531+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:54:11.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:54:11.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:54:11.562+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:54:11.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T04:54:11.574+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:54:11.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T04:54:11.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-16T04:54:41.991+0000] {processor.py:157} INFO - Started process (PID=28342) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:54:41.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T04:54:42.001+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:54:42.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:54:42.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T04:54:42.069+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:54:42.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T04:54:42.100+0000] {logging_mixin.py:151} INFO - [2024-09-16T04:54:42.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T04:54:42.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-16T05:00:20.987+0000] {processor.py:157} INFO - Started process (PID=28353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:00:20.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:00:21.004+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:00:21.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:00:21.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:00:21.123+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:00:21.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:00:21.159+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:00:21.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:00:21.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.214 seconds
[2024-09-16T05:00:51.315+0000] {processor.py:157} INFO - Started process (PID=28363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:00:51.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:00:51.323+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:00:51.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:00:51.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:00:51.395+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:00:51.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:00:51.423+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:00:51.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:00:51.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-16T05:01:21.833+0000] {processor.py:157} INFO - Started process (PID=28374) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:01:21.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:01:21.844+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:01:21.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:01:21.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:01:21.909+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:01:21.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:01:21.926+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:01:21.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:01:21.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T05:01:52.143+0000] {processor.py:157} INFO - Started process (PID=28384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:01:52.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:01:52.151+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:01:52.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:01:52.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:01:52.183+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:01:52.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:01:52.197+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:01:52.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:01:52.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-16T05:02:22.552+0000] {processor.py:157} INFO - Started process (PID=28394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:02:22.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:02:22.559+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:02:22.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:02:22.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:02:22.601+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:02:22.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:02:22.617+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:02:22.616+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:02:22.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T05:02:53.019+0000] {processor.py:157} INFO - Started process (PID=28404) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:02:53.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:02:53.025+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:02:53.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:02:53.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:02:53.077+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:02:53.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:02:53.101+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:02:53.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:02:53.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-16T05:03:23.439+0000] {processor.py:157} INFO - Started process (PID=28413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:03:23.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:03:23.449+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:03:23.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:03:23.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:03:23.520+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:03:23.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:03:23.537+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:03:23.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:03:23.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-16T05:03:53.798+0000] {processor.py:157} INFO - Started process (PID=28424) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:03:53.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:03:53.805+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:03:53.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:03:53.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:03:53.861+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:03:53.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:03:53.887+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:03:53.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:03:53.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-16T05:04:24.146+0000] {processor.py:157} INFO - Started process (PID=28434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:04:24.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:04:24.156+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:04:24.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:04:24.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:04:24.239+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:04:24.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:04:24.257+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:04:24.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:04:24.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-16T05:04:54.633+0000] {processor.py:157} INFO - Started process (PID=28444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:04:54.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:04:54.637+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:04:54.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:04:54.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:04:54.682+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:04:54.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:04:54.697+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:04:54.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:04:54.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-16T05:05:25.119+0000] {processor.py:157} INFO - Started process (PID=28454) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:05:25.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:05:25.125+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:05:25.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:05:25.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:05:25.192+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:05:25.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:05:25.208+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:05:25.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:05:25.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-16T05:05:55.492+0000] {processor.py:157} INFO - Started process (PID=28464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:05:55.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:05:55.496+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:05:55.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:05:55.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:05:55.527+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:05:55.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:05:55.538+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:05:55.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:05:55.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-16T05:06:26.153+0000] {processor.py:157} INFO - Started process (PID=28473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:06:26.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:06:26.169+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:06:26.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:06:26.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:06:26.261+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:06:26.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:06:26.287+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:06:26.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:06:26.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-09-16T05:07:19.637+0000] {processor.py:157} INFO - Started process (PID=28485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:07:19.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:07:19.648+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:07:19.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:07:19.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:07:19.732+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:07:19.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:07:19.751+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:07:19.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:07:19.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-16T05:12:47.210+0000] {processor.py:157} INFO - Started process (PID=28495) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:12:47.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:12:47.214+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:12:47.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:12:47.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:12:47.253+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:12:47.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:12:47.267+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:12:47.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:12:47.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-16T05:13:17.613+0000] {processor.py:157} INFO - Started process (PID=28505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:13:17.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:13:17.618+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:13:17.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:13:17.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:13:17.689+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:13:17.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:13:17.719+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:13:17.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:13:17.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-16T05:28:57.970+0000] {processor.py:157} INFO - Started process (PID=28517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:28:57.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:28:57.977+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:28:57.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:28:57.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:28:58.036+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:28:58.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:28:58.060+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:28:58.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:28:58.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-16T05:29:28.367+0000] {processor.py:157} INFO - Started process (PID=28527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:29:28.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:29:28.372+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:29:28.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:29:28.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:29:28.440+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:29:28.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:29:28.464+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:29:28.463+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:29:28.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-16T05:29:58.692+0000] {processor.py:157} INFO - Started process (PID=28538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:29:58.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:29:58.694+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:29:58.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:29:58.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:29:58.726+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:29:58.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:29:58.741+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:29:58.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:29:58.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-16T05:30:29.151+0000] {processor.py:157} INFO - Started process (PID=28547) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:30:29.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:30:29.155+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:30:29.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:30:29.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:30:29.212+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:30:29.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:30:29.229+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:30:29.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:30:29.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-16T05:30:59.557+0000] {processor.py:157} INFO - Started process (PID=28558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:30:59.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:30:59.561+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:30:59.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:30:59.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:30:59.596+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:30:59.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:30:59.621+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:30:59.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:30:59.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-16T05:31:30.023+0000] {processor.py:157} INFO - Started process (PID=28568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:31:30.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:31:30.031+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:31:30.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:31:30.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:31:30.095+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:31:30.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:31:30.119+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:31:30.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:31:30.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-16T05:32:00.363+0000] {processor.py:157} INFO - Started process (PID=28578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:32:00.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:32:00.367+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:32:00.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:32:00.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:32:00.400+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:32:00.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:32:00.411+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:32:00.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:32:00.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-16T05:32:30.806+0000] {processor.py:157} INFO - Started process (PID=28587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:32:30.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:32:30.811+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:32:30.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:32:30.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:32:30.852+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:32:30.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:32:30.866+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:32:30.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:32:30.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-16T05:33:01.306+0000] {processor.py:157} INFO - Started process (PID=28598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:33:01.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:33:01.317+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:33:01.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:33:01.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:33:01.388+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:33:01.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:33:01.410+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:33:01.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:33:01.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-16T05:33:31.642+0000] {processor.py:157} INFO - Started process (PID=28608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:33:31.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:33:31.648+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:33:31.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:33:31.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:33:31.694+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:33:31.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:33:31.710+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:33:31.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:33:31.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-16T05:34:02.064+0000] {processor.py:157} INFO - Started process (PID=28618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:34:02.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:34:02.067+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:34:02.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:34:02.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:34:02.097+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:34:02.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:34:02.112+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:34:02.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:34:02.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-16T05:34:32.429+0000] {processor.py:157} INFO - Started process (PID=28627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:34:32.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:34:32.438+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:34:32.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:34:32.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:34:32.484+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:34:32.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:34:32.498+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:34:32.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:34:32.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-16T05:35:02.888+0000] {processor.py:157} INFO - Started process (PID=28638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:35:02.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:35:02.891+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:35:02.891+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:35:02.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:35:02.918+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:35:02.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:35:02.930+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:35:02.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:35:02.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-16T05:35:33.318+0000] {processor.py:157} INFO - Started process (PID=28647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:35:33.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:35:33.325+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:35:33.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:35:33.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:35:33.390+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:35:33.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:35:33.418+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:35:33.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:35:33.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-16T05:36:03.582+0000] {processor.py:157} INFO - Started process (PID=28658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:36:03.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:36:03.585+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:36:03.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:36:03.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:36:03.618+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:36:03.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:36:03.630+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:36:03.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:36:03.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-16T05:36:33.954+0000] {processor.py:157} INFO - Started process (PID=28667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:36:33.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:36:33.963+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:36:33.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:36:33.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:36:34.033+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:36:34.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:36:34.053+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:36:34.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:36:34.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-16T05:37:04.450+0000] {processor.py:157} INFO - Started process (PID=28678) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:37:04.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:37:04.454+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:37:04.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:37:04.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:37:04.488+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:37:04.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:37:04.500+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:37:04.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:37:04.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-16T05:37:34.858+0000] {processor.py:157} INFO - Started process (PID=28688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:37:34.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:37:34.863+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:37:34.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:37:34.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:37:34.902+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:37:34.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:37:34.917+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:37:34.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:37:34.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-16T05:38:05.200+0000] {processor.py:157} INFO - Started process (PID=28698) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:38:05.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:38:05.204+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:38:05.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:38:05.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:38:05.235+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:38:05.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:38:05.246+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:38:05.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:38:05.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-16T05:38:35.622+0000] {processor.py:157} INFO - Started process (PID=28707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:38:35.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:38:35.650+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:38:35.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:38:35.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:38:35.698+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:38:35.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:38:35.714+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:38:35.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:38:35.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-16T05:39:06.012+0000] {processor.py:157} INFO - Started process (PID=28718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:39:06.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:39:06.017+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:39:06.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:39:06.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:39:06.060+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:39:06.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:39:06.076+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:39:06.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:39:06.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-16T05:39:36.448+0000] {processor.py:157} INFO - Started process (PID=28728) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:39:36.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:39:36.452+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:39:36.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:39:36.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:39:36.480+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:39:36.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:39:36.492+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:39:36.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:39:36.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-16T05:40:06.855+0000] {processor.py:157} INFO - Started process (PID=28738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:40:06.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:40:06.878+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:40:06.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:40:06.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:40:06.937+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:40:06.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:40:06.953+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:40:06.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:40:06.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-16T05:40:37.173+0000] {processor.py:157} INFO - Started process (PID=28748) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:40:37.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:40:37.178+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:40:37.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:40:37.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:40:37.214+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:40:37.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:40:37.226+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:40:37.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:40:37.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-16T05:41:07.482+0000] {processor.py:157} INFO - Started process (PID=28758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:41:07.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:41:07.485+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:41:07.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:41:07.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:41:07.527+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:41:07.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:41:07.541+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:41:07.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:41:07.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-16T05:41:37.830+0000] {processor.py:157} INFO - Started process (PID=28768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:41:37.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:41:37.835+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:41:37.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:41:37.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:41:37.871+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:41:37.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:41:37.888+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:41:37.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:41:37.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-16T05:42:08.251+0000] {processor.py:157} INFO - Started process (PID=28778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:42:08.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:42:08.258+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:42:08.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:42:08.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:42:08.311+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:42:08.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:42:08.326+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:42:08.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:42:08.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-16T05:42:38.746+0000] {processor.py:157} INFO - Started process (PID=28788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:42:38.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:42:38.761+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:42:38.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:42:38.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:42:38.806+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:42:38.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:42:38.820+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:42:38.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:42:38.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-16T05:43:09.223+0000] {processor.py:157} INFO - Started process (PID=28798) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:43:09.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:43:09.227+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:43:09.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:43:09.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:43:09.278+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:43:09.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:43:09.293+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:43:09.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:43:09.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-16T05:43:39.600+0000] {processor.py:157} INFO - Started process (PID=28806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:43:39.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:43:39.609+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:43:39.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:43:39.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:43:39.679+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:43:39.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:43:39.695+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:43:39.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:43:39.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-16T05:44:09.898+0000] {processor.py:157} INFO - Started process (PID=28818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:44:09.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:44:09.903+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:44:09.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:44:09.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:44:09.931+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:44:09.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:44:09.942+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:44:09.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:44:09.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-16T05:44:40.283+0000] {processor.py:157} INFO - Started process (PID=28826) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:44:40.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:44:40.290+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:44:40.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:44:40.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:44:40.359+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:44:40.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:44:40.374+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:44:40.374+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:44:40.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-16T05:45:10.558+0000] {processor.py:157} INFO - Started process (PID=28838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:45:10.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:45:10.562+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:45:10.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:45:10.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:45:10.594+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:45:10.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:45:10.605+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:45:10.605+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:45:10.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-16T05:45:40.998+0000] {processor.py:157} INFO - Started process (PID=28848) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:45:41.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:45:41.020+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:45:41.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:45:41.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:45:41.087+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:45:41.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:45:41.111+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:45:41.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:45:41.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-16T05:46:11.388+0000] {processor.py:157} INFO - Started process (PID=28858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:46:11.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:46:11.392+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:46:11.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:46:11.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:46:11.423+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:46:11.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:46:11.438+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:46:11.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:46:11.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-16T05:46:41.826+0000] {processor.py:157} INFO - Started process (PID=28867) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:46:41.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:46:41.838+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:46:41.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:46:41.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:46:41.896+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:46:41.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:46:41.919+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:46:41.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:46:41.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-16T05:47:12.195+0000] {processor.py:157} INFO - Started process (PID=28878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:47:12.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:47:12.203+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:47:12.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:47:12.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:47:12.255+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:47:12.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:47:12.282+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:47:12.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:47:12.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-16T05:47:42.564+0000] {processor.py:157} INFO - Started process (PID=28888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:47:42.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:47:42.570+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:47:42.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:47:42.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:47:42.631+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:47:42.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:47:42.646+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:47:42.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:47:42.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-16T05:48:13.004+0000] {processor.py:157} INFO - Started process (PID=28898) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:48:13.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:48:13.009+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:48:13.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:48:13.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:48:13.048+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:48:13.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:48:13.063+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:48:13.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:48:13.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-16T05:48:43.466+0000] {processor.py:157} INFO - Started process (PID=28907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:48:43.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:48:43.475+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:48:43.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:48:43.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:48:43.547+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:48:43.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:48:43.576+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:48:43.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:48:43.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-16T05:49:14.028+0000] {processor.py:157} INFO - Started process (PID=28918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:49:14.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:49:14.039+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:49:14.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:49:14.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:49:14.119+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:49:14.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:49:14.136+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:49:14.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:49:14.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-16T05:49:44.388+0000] {processor.py:157} INFO - Started process (PID=28928) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:49:44.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:49:44.394+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:49:44.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:49:44.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:49:44.435+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:49:44.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:49:44.448+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:49:44.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:49:44.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-16T05:50:14.799+0000] {processor.py:157} INFO - Started process (PID=28938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:50:14.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:50:14.803+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:50:14.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:50:14.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:50:14.835+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:50:14.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:50:14.850+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:50:14.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:50:14.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-16T05:50:45.283+0000] {processor.py:157} INFO - Started process (PID=28948) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:50:45.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:50:45.293+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:50:45.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:50:45.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:50:45.347+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:50:45.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:50:45.377+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:50:45.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:50:45.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-16T05:51:15.557+0000] {processor.py:157} INFO - Started process (PID=28958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:51:15.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:51:15.559+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:51:15.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:51:15.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:51:15.587+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:51:15.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:51:15.599+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:51:15.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:51:15.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-16T05:51:45.958+0000] {processor.py:157} INFO - Started process (PID=28968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:51:45.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:51:45.964+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:51:45.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:51:45.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:51:46.013+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:51:46.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:51:46.037+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:51:46.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:51:46.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-16T05:52:16.309+0000] {processor.py:157} INFO - Started process (PID=28978) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:52:16.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:52:16.313+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:52:16.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:52:16.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:52:16.343+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:52:16.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:52:16.354+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:52:16.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:52:16.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-16T05:52:46.675+0000] {processor.py:157} INFO - Started process (PID=28988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:52:46.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:52:46.688+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:52:46.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:52:46.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:52:46.752+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:52:46.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:52:46.768+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:52:46.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:52:46.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-16T05:53:16.976+0000] {processor.py:157} INFO - Started process (PID=28998) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:53:16.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:53:16.979+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:53:16.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:53:16.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:53:17.009+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:53:17.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:53:17.020+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:53:17.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:53:17.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-16T05:53:47.451+0000] {processor.py:157} INFO - Started process (PID=29008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:53:47.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:53:47.464+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:53:47.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:53:47.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:53:47.531+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:53:47.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:53:47.549+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:53:47.549+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:53:47.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-16T05:54:17.789+0000] {processor.py:157} INFO - Started process (PID=29018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:54:17.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:54:17.794+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:54:17.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:54:17.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:54:17.829+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:54:17.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:54:17.840+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:54:17.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:54:17.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-16T05:54:48.245+0000] {processor.py:157} INFO - Started process (PID=29028) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:54:48.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:54:48.261+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:54:48.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:54:48.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:54:48.319+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:54:48.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:54:48.347+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:54:48.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:54:48.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-16T05:55:18.558+0000] {processor.py:157} INFO - Started process (PID=29038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:55:18.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:55:18.562+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:55:18.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:55:18.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:55:18.595+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:55:18.595+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:55:18.606+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:55:18.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:55:18.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-16T05:55:48.961+0000] {processor.py:157} INFO - Started process (PID=29048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:55:48.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:55:48.966+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:55:48.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:55:48.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:55:49.023+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:55:49.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:55:49.041+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:55:49.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:55:49.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-16T05:56:19.354+0000] {processor.py:157} INFO - Started process (PID=29057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:56:19.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:56:19.365+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:56:19.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:56:19.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:56:19.438+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:56:19.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:56:19.463+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:56:19.463+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:56:19.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-16T05:56:49.675+0000] {processor.py:157} INFO - Started process (PID=29068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:56:49.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:56:49.682+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:56:49.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:56:49.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:56:49.705+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:56:49.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:56:49.715+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:56:49.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:56:49.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-16T05:57:20.059+0000] {processor.py:157} INFO - Started process (PID=29078) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:57:20.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:57:20.064+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:57:20.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:57:20.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:57:20.135+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:57:20.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:57:20.153+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:57:20.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:57:20.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-16T05:57:50.397+0000] {processor.py:157} INFO - Started process (PID=29088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:57:50.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:57:50.413+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:57:50.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:57:50.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:57:50.469+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:57:50.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:57:50.488+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:57:50.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:57:50.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-16T05:58:20.719+0000] {processor.py:157} INFO - Started process (PID=29098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:58:20.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:58:20.724+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:58:20.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:58:20.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:58:20.758+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:58:20.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:58:20.770+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:58:20.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:58:20.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-16T05:58:51.131+0000] {processor.py:157} INFO - Started process (PID=29108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:58:51.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:58:51.147+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:58:51.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:58:51.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:58:51.287+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:58:51.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:58:51.306+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:58:51.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:58:51.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.196 seconds
[2024-09-16T05:59:21.655+0000] {processor.py:157} INFO - Started process (PID=29118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:59:21.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:59:21.660+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:59:21.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:59:21.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:59:21.694+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:59:21.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:59:21.706+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:59:21.706+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:59:21.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-16T05:59:52.031+0000] {processor.py:157} INFO - Started process (PID=29128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:59:52.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T05:59:52.035+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:59:52.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:59:52.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T05:59:52.093+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:59:52.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T05:59:52.112+0000] {logging_mixin.py:151} INFO - [2024-09-16T05:59:52.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T05:59:52.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-16T06:00:22.370+0000] {processor.py:157} INFO - Started process (PID=29136) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:00:22.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:00:22.376+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:00:22.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:00:22.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:00:22.442+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:00:22.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:00:22.459+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:00:22.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:00:22.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-16T06:00:52.662+0000] {processor.py:157} INFO - Started process (PID=29148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:00:52.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:00:52.668+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:00:52.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:00:52.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:00:52.723+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:00:52.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:00:52.738+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:00:52.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:00:52.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-16T06:01:23.061+0000] {processor.py:157} INFO - Started process (PID=29158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:01:23.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:01:23.068+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:01:23.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:01:23.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:01:23.108+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:01:23.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:01:23.124+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:01:23.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:01:23.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-16T06:01:53.336+0000] {processor.py:157} INFO - Started process (PID=29168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:01:53.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:01:53.339+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:01:53.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:01:53.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:01:53.367+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:01:53.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:01:53.377+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:01:53.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:01:53.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-16T06:02:23.720+0000] {processor.py:157} INFO - Started process (PID=29178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:02:23.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:02:23.727+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:02:23.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:02:23.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:02:23.764+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:02:23.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:02:23.777+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:02:23.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:02:23.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-16T06:02:54.043+0000] {processor.py:157} INFO - Started process (PID=29188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:02:54.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:02:54.047+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:02:54.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:02:54.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:02:54.079+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:02:54.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:02:54.094+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:02:54.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:02:54.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-16T06:03:24.410+0000] {processor.py:157} INFO - Started process (PID=29198) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:03:24.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:03:24.414+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:03:24.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:03:24.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:03:24.439+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:03:24.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:03:24.451+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:03:24.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:03:24.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-16T06:03:54.775+0000] {processor.py:157} INFO - Started process (PID=29208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:03:54.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:03:54.781+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:03:54.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:03:54.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:03:54.819+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:03:54.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:03:54.833+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:03:54.833+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:03:54.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-16T06:04:25.167+0000] {processor.py:157} INFO - Started process (PID=29218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:04:25.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:04:25.170+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:04:25.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:04:25.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:04:25.198+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:04:25.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:04:25.209+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:04:25.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:04:25.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-16T06:04:55.502+0000] {processor.py:157} INFO - Started process (PID=29228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:04:55.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:04:55.510+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:04:55.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:04:55.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:04:55.548+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:04:55.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:04:55.562+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:04:55.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:04:55.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-16T06:05:25.879+0000] {processor.py:157} INFO - Started process (PID=29238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:05:25.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:05:25.882+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:05:25.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:05:25.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:05:25.910+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:05:25.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:05:25.921+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:05:25.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:05:25.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-16T06:05:56.242+0000] {processor.py:157} INFO - Started process (PID=29248) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:05:56.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:05:56.247+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:05:56.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:05:56.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:05:56.274+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:05:56.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:05:56.285+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:05:56.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:05:56.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-16T06:06:26.593+0000] {processor.py:157} INFO - Started process (PID=29258) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:06:26.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:06:26.601+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:06:26.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:06:26.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:06:26.668+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:06:26.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:06:26.691+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:06:26.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:06:26.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-16T06:06:56.899+0000] {processor.py:157} INFO - Started process (PID=29268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:06:56.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:06:56.903+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:06:56.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:06:56.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:06:56.935+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:06:56.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:06:56.947+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:06:56.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:06:56.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-16T06:07:27.348+0000] {processor.py:157} INFO - Started process (PID=29278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:07:27.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:07:27.376+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:07:27.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:07:27.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:07:27.452+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:07:27.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:07:27.469+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:07:27.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:07:27.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-16T06:07:57.853+0000] {processor.py:157} INFO - Started process (PID=29288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:07:57.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:07:57.858+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:07:57.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:07:57.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:07:57.905+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:07:57.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:07:57.920+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:07:57.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:07:57.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-16T06:08:28.233+0000] {processor.py:157} INFO - Started process (PID=29297) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:08:28.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:08:28.245+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:08:28.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:08:28.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:08:28.295+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:08:28.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:08:28.310+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:08:28.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:08:28.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-16T06:08:58.644+0000] {processor.py:157} INFO - Started process (PID=29308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:08:58.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:08:58.660+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:08:58.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:08:58.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:08:58.746+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:08:58.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:08:58.764+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:08:58.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:08:58.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-16T06:09:29.155+0000] {processor.py:157} INFO - Started process (PID=29318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:09:29.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:09:29.164+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:09:29.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:09:29.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:09:29.209+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:09:29.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:09:29.232+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:09:29.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:09:29.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-16T06:09:59.473+0000] {processor.py:157} INFO - Started process (PID=29327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:09:59.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:09:59.481+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:09:59.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:09:59.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:09:59.547+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:09:59.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:09:59.564+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:09:59.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:09:59.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-16T06:10:29.826+0000] {processor.py:157} INFO - Started process (PID=29338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:10:29.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:10:29.835+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:10:29.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:10:29.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:10:29.916+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:10:29.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:10:29.933+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:10:29.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:10:29.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-09-16T06:11:00.157+0000] {processor.py:157} INFO - Started process (PID=29348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:11:00.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:11:00.167+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:11:00.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:11:00.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:11:00.235+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:11:00.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:11:00.262+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:11:00.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:11:00.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-16T06:11:30.570+0000] {processor.py:157} INFO - Started process (PID=29358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:11:30.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:11:30.574+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:11:30.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:11:30.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:11:30.616+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:11:30.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:11:30.631+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:11:30.631+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:11:30.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-16T06:12:00.888+0000] {processor.py:157} INFO - Started process (PID=29368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:12:00.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:12:00.892+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:12:00.891+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:12:00.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:12:00.931+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:12:00.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:12:00.946+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:12:00.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:12:00.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-16T06:12:31.271+0000] {processor.py:157} INFO - Started process (PID=29377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:12:31.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:12:31.279+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:12:31.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:12:31.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:12:31.338+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:12:31.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:12:31.358+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:12:31.358+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:12:31.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-16T06:13:01.600+0000] {processor.py:157} INFO - Started process (PID=29388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:13:01.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:13:01.611+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:13:01.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:13:01.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:13:01.691+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:13:01.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:13:01.709+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:13:01.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:13:01.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-09-16T06:13:31.887+0000] {processor.py:157} INFO - Started process (PID=29398) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:13:31.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:13:31.898+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:13:31.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:13:31.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:13:31.959+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:13:31.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:13:31.986+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:13:31.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:13:31.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-16T06:14:02.308+0000] {processor.py:157} INFO - Started process (PID=29408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:14:02.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:14:02.322+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:14:02.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:14:02.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:14:02.384+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:14:02.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:14:02.399+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:14:02.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:14:02.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-16T06:14:32.804+0000] {processor.py:157} INFO - Started process (PID=29417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:14:32.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:14:32.811+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:14:32.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:14:32.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:14:32.871+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:14:32.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:14:32.900+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:14:32.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:14:32.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-16T06:15:03.154+0000] {processor.py:157} INFO - Started process (PID=29428) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:15:03.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:15:03.164+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:15:03.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:15:03.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:15:03.248+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:15:03.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:15:03.291+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:15:03.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:15:03.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-16T06:15:33.521+0000] {processor.py:157} INFO - Started process (PID=29436) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:15:33.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:15:33.535+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:15:33.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:15:33.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:15:33.594+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:15:33.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:15:33.611+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:15:33.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:15:33.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-16T06:16:03.857+0000] {processor.py:157} INFO - Started process (PID=29448) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:16:03.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:16:03.862+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:16:03.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:16:03.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:16:03.904+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:16:03.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:16:03.919+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:16:03.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:16:03.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-16T06:16:34.323+0000] {processor.py:157} INFO - Started process (PID=29458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:16:34.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:16:34.331+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:16:34.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:16:34.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:16:34.404+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:16:34.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:16:34.420+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:16:34.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:16:34.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-16T06:17:04.762+0000] {processor.py:157} INFO - Started process (PID=29468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:17:04.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:17:04.770+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:17:04.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:17:04.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:17:04.821+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:17:04.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:17:04.840+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:17:04.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:17:04.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-16T06:17:35.068+0000] {processor.py:157} INFO - Started process (PID=29477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:17:35.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:17:35.076+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:17:35.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:17:35.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:17:35.126+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:17:35.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:17:35.143+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:17:35.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:17:35.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-16T06:18:05.551+0000] {processor.py:157} INFO - Started process (PID=29488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:18:05.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:18:05.556+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:18:05.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:18:05.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:18:05.622+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:18:05.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:18:05.640+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:18:05.640+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:18:05.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-16T06:18:35.879+0000] {processor.py:157} INFO - Started process (PID=29498) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:18:35.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:18:35.888+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:18:35.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:18:35.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:18:35.965+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:18:35.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:18:36.000+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:18:36.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:18:36.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-09-16T06:19:06.415+0000] {processor.py:157} INFO - Started process (PID=29507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:19:06.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:19:06.432+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:19:06.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:19:06.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:19:06.488+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:19:06.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:19:06.504+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:19:06.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:19:06.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-16T06:19:36.723+0000] {processor.py:157} INFO - Started process (PID=29518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:19:36.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:19:36.745+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:19:36.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:19:36.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:19:36.817+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:19:36.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:19:36.837+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:19:36.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:19:36.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-16T06:20:07.177+0000] {processor.py:157} INFO - Started process (PID=29528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:20:07.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:20:07.182+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:20:07.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:20:07.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:20:07.224+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:20:07.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:20:07.245+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:20:07.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:20:07.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-16T06:20:37.646+0000] {processor.py:157} INFO - Started process (PID=29538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:20:37.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:20:37.657+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:20:37.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:20:37.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:20:37.709+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:20:37.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:20:37.734+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:20:37.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:20:37.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-16T06:21:07.944+0000] {processor.py:157} INFO - Started process (PID=29548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:21:07.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:21:07.949+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:21:07.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:21:07.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:21:07.992+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:21:07.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:21:08.008+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:21:08.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:21:08.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-16T06:21:38.408+0000] {processor.py:157} INFO - Started process (PID=29558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:21:38.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:21:38.422+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:21:38.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:21:38.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:21:38.503+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:21:38.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:21:38.521+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:21:38.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:21:38.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-16T06:22:08.710+0000] {processor.py:157} INFO - Started process (PID=29568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:22:08.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:22:08.712+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:22:08.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:22:08.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:22:08.742+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:22:08.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:22:08.757+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:22:08.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:22:08.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-16T06:22:39.082+0000] {processor.py:157} INFO - Started process (PID=29578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:22:39.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:22:39.096+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:22:39.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:22:39.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:22:39.159+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:22:39.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:22:39.174+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:22:39.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:22:39.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-16T06:23:09.436+0000] {processor.py:157} INFO - Started process (PID=29588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:23:09.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:23:09.444+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:23:09.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:23:09.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:23:09.495+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:23:09.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:23:09.528+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:23:09.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:23:09.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-16T06:23:39.803+0000] {processor.py:157} INFO - Started process (PID=29598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:23:39.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:23:39.811+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:23:39.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:23:39.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:23:39.902+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:23:39.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:23:39.925+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:23:39.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:23:39.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-16T06:24:10.163+0000] {processor.py:157} INFO - Started process (PID=29607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:24:10.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:24:10.178+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:24:10.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:24:10.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:24:10.240+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:24:10.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:24:10.256+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:24:10.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:24:10.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-16T06:24:40.593+0000] {processor.py:157} INFO - Started process (PID=29617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:24:40.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:24:40.600+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:24:40.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:24:40.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:24:40.678+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:24:40.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:24:40.696+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:24:40.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:24:40.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-16T06:25:10.901+0000] {processor.py:157} INFO - Started process (PID=29628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:25:10.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:25:10.913+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:25:10.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:25:10.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:25:10.989+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:25:10.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:25:11.004+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:25:11.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:25:11.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-16T06:25:41.347+0000] {processor.py:157} INFO - Started process (PID=29638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:25:41.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:25:41.355+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:25:41.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:25:41.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:25:41.394+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:25:41.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:25:41.409+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:25:41.409+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:25:41.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-16T06:26:11.722+0000] {processor.py:157} INFO - Started process (PID=29647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:26:11.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:26:11.736+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:26:11.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:26:11.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:26:11.799+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:26:11.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:26:11.814+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:26:11.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:26:11.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-16T06:26:42.027+0000] {processor.py:157} INFO - Started process (PID=29658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:26:42.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:26:42.035+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:26:42.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:26:42.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:26:42.074+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:26:42.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:26:42.089+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:26:42.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:26:42.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-16T06:27:12.441+0000] {processor.py:157} INFO - Started process (PID=29668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:27:12.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:27:12.445+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:27:12.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:27:12.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:27:12.504+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:27:12.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:27:12.520+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:27:12.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:27:12.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-16T06:27:42.755+0000] {processor.py:157} INFO - Started process (PID=29678) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:27:42.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:27:42.763+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:27:42.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:27:42.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:27:42.807+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:27:42.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:27:42.828+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:27:42.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:27:42.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-16T06:28:13.115+0000] {processor.py:157} INFO - Started process (PID=29688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:28:13.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:28:13.118+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:28:13.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:28:13.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:28:13.147+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:28:13.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:28:13.170+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:28:13.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:28:13.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-16T06:28:43.461+0000] {processor.py:157} INFO - Started process (PID=29697) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:28:43.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:28:43.466+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:28:43.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:28:43.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:28:43.536+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:28:43.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:28:43.555+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:28:43.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:28:43.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T06:29:13.827+0000] {processor.py:157} INFO - Started process (PID=29708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:29:13.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:29:13.832+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:29:13.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:29:13.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:29:13.892+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:29:13.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:29:13.922+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:29:13.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:29:13.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-16T06:29:44.242+0000] {processor.py:157} INFO - Started process (PID=29718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:29:44.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:29:44.248+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:29:44.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:29:44.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:29:44.327+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:29:44.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:29:44.355+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:29:44.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:29:44.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-16T06:30:14.624+0000] {processor.py:157} INFO - Started process (PID=29728) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:30:14.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:30:14.637+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:30:14.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:30:14.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:30:14.718+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:30:14.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:30:14.740+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:30:14.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:30:14.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-16T06:30:45.136+0000] {processor.py:157} INFO - Started process (PID=29738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:30:45.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:30:45.142+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:30:45.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:30:45.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:30:45.214+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:30:45.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:30:45.238+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:30:45.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:30:45.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-16T06:31:15.512+0000] {processor.py:157} INFO - Started process (PID=29748) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:31:15.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:31:15.520+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:31:15.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:31:15.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:31:15.585+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:31:15.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:31:15.603+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:31:15.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:31:15.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-16T06:31:45.919+0000] {processor.py:157} INFO - Started process (PID=29756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:31:45.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:31:45.925+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:31:45.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:31:45.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:31:45.985+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:31:45.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:31:46.003+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:31:46.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:31:46.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-16T06:32:16.276+0000] {processor.py:157} INFO - Started process (PID=29768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:32:16.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:32:16.290+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:32:16.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:32:16.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:32:16.352+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:32:16.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:32:16.368+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:32:16.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:32:16.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-16T06:32:46.583+0000] {processor.py:157} INFO - Started process (PID=29776) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:32:46.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:32:46.589+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:32:46.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:32:46.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:32:46.639+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:32:46.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:32:46.656+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:32:46.656+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:32:46.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-16T06:33:16.920+0000] {processor.py:157} INFO - Started process (PID=29787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:33:16.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:33:16.926+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:33:16.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:33:16.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:33:16.991+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:33:16.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:33:17.011+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:33:17.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:33:17.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-16T06:33:47.375+0000] {processor.py:157} INFO - Started process (PID=29798) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:33:47.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:33:47.396+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:33:47.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:33:47.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:33:47.465+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:33:47.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:33:47.482+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:33:47.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:33:47.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-16T06:34:17.749+0000] {processor.py:157} INFO - Started process (PID=29808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:34:17.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:34:17.760+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:34:17.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:34:17.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:34:17.808+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:34:17.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:34:17.839+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:34:17.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:34:17.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T06:34:48.079+0000] {processor.py:157} INFO - Started process (PID=29818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:34:48.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:34:48.096+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:34:48.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:34:48.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:34:48.153+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:34:48.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:34:48.185+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:34:48.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:34:48.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-16T06:35:18.419+0000] {processor.py:157} INFO - Started process (PID=29828) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:35:18.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:35:18.428+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:35:18.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:35:18.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:35:18.501+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:35:18.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:35:18.519+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:35:18.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:35:18.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-16T06:35:49.036+0000] {processor.py:157} INFO - Started process (PID=29838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:35:49.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:35:49.049+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:35:49.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:35:49.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:35:49.144+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:35:49.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:35:49.192+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:35:49.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:35:49.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.195 seconds
[2024-09-16T06:36:19.454+0000] {processor.py:157} INFO - Started process (PID=29848) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:36:19.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:36:19.462+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:36:19.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:36:19.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:36:19.548+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:36:19.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:36:19.574+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:36:19.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:36:19.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-16T06:36:50.006+0000] {processor.py:157} INFO - Started process (PID=29858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:36:50.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:36:50.013+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:36:50.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:36:50.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:36:50.077+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:36:50.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:36:50.102+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:36:50.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:36:50.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-16T06:37:20.432+0000] {processor.py:157} INFO - Started process (PID=29868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:37:20.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:37:20.441+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:37:20.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:37:20.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:37:20.572+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:37:20.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:37:20.624+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:37:20.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:37:20.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.235 seconds
[2024-09-16T06:37:50.876+0000] {processor.py:157} INFO - Started process (PID=29878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:37:50.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:37:50.898+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:37:50.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:37:50.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:37:50.990+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:37:50.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:37:51.014+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:37:51.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:37:51.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.170 seconds
[2024-09-16T06:38:21.334+0000] {processor.py:157} INFO - Started process (PID=29888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:38:21.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:38:21.344+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:38:21.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:38:21.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:38:21.445+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:38:21.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:38:21.470+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:38:21.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:38:21.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-09-16T06:38:51.887+0000] {processor.py:157} INFO - Started process (PID=29898) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:38:51.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:38:51.896+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:38:51.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:38:51.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:38:51.947+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:38:51.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:38:51.976+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:38:51.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:38:51.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-16T06:39:22.360+0000] {processor.py:157} INFO - Started process (PID=29908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:39:22.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:39:22.365+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:39:22.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:39:22.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:39:22.427+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:39:22.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:39:22.452+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:39:22.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:39:22.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-16T06:39:52.908+0000] {processor.py:157} INFO - Started process (PID=29917) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:39:52.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:39:52.926+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:39:52.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:39:52.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:39:53.010+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:39:53.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:39:53.037+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:39:53.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:39:53.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-09-16T06:40:23.437+0000] {processor.py:157} INFO - Started process (PID=29927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:40:23.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:40:23.443+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:40:23.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:40:23.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:40:23.503+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:40:23.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:40:23.532+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:40:23.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:40:23.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-16T06:40:53.844+0000] {processor.py:157} INFO - Started process (PID=29938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:40:53.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:40:53.860+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:40:53.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:40:53.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:40:53.926+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:40:53.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:40:53.944+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:40:53.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:40:53.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-16T06:41:24.305+0000] {processor.py:157} INFO - Started process (PID=29948) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:41:24.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:41:24.324+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:41:24.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:41:24.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:41:24.425+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:41:24.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:41:24.447+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:41:24.447+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:41:24.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.175 seconds
[2024-09-16T06:41:54.663+0000] {processor.py:157} INFO - Started process (PID=29958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:41:54.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:41:54.669+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:41:54.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:41:54.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:41:54.720+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:41:54.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:41:54.751+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:41:54.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:41:54.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-16T06:42:25.021+0000] {processor.py:157} INFO - Started process (PID=29968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:42:25.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:42:25.028+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:42:25.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:42:25.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:42:25.126+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:42:25.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:42:25.169+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:42:25.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:42:25.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.177 seconds
[2024-09-16T06:42:55.711+0000] {processor.py:157} INFO - Started process (PID=29978) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:42:55.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:42:55.720+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:42:55.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:42:55.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:42:55.918+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:42:55.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:42:55.972+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:42:55.972+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:42:55.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.285 seconds
[2024-09-16T06:43:26.189+0000] {processor.py:157} INFO - Started process (PID=29988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:43:26.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:43:26.201+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:43:26.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:43:26.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:43:26.267+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:43:26.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:43:26.301+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:43:26.301+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:43:26.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-16T06:43:56.825+0000] {processor.py:157} INFO - Started process (PID=29998) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:43:56.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:43:56.848+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:43:56.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:43:56.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:43:56.945+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:43:56.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:43:56.968+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:43:56.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:43:56.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.184 seconds
[2024-09-16T06:44:27.418+0000] {processor.py:157} INFO - Started process (PID=30008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:44:27.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:44:27.428+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:44:27.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:44:27.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:44:27.499+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:44:27.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:44:27.531+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:44:27.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:44:27.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-16T06:44:57.774+0000] {processor.py:157} INFO - Started process (PID=30018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:44:57.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:44:57.797+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:44:57.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:44:57.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:44:57.877+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:44:57.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:44:57.925+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:44:57.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:44:57.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.179 seconds
[2024-09-16T06:45:28.270+0000] {processor.py:157} INFO - Started process (PID=30028) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:45:28.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:45:28.283+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:45:28.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:45:28.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:45:28.353+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:45:28.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:45:28.403+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:45:28.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:45:28.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-09-16T06:45:58.966+0000] {processor.py:157} INFO - Started process (PID=30038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:45:58.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:45:58.975+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:45:58.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:45:58.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:45:59.066+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:45:59.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:45:59.098+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:45:59.098+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:45:59.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.184 seconds
[2024-09-16T06:46:29.355+0000] {processor.py:157} INFO - Started process (PID=30048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:46:29.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:46:29.370+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:46:29.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:46:29.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:46:29.456+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:46:29.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:46:29.488+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:46:29.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:46:29.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-09-16T06:46:59.776+0000] {processor.py:157} INFO - Started process (PID=30058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:46:59.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:46:59.800+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:46:59.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:46:59.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:46:59.892+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:46:59.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:46:59.922+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:46:59.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:46:59.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.177 seconds
[2024-09-16T06:47:30.195+0000] {processor.py:157} INFO - Started process (PID=30068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:47:30.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:47:30.203+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:47:30.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:47:30.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:47:30.262+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:47:30.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:47:30.293+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:47:30.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:47:30.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-16T06:48:00.755+0000] {processor.py:157} INFO - Started process (PID=30077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:48:00.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:48:00.768+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:48:00.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:48:00.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:48:00.834+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:48:00.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:48:00.868+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:48:00.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:48:00.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-09-16T06:48:31.141+0000] {processor.py:157} INFO - Started process (PID=30088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:48:31.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:48:31.159+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:48:31.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:48:31.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:48:31.260+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:48:31.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:48:31.285+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:48:31.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:48:31.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.178 seconds
[2024-09-16T06:49:01.517+0000] {processor.py:157} INFO - Started process (PID=30098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:49:01.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:49:01.528+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:49:01.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:49:01.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:49:01.629+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:49:01.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:49:01.659+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:49:01.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:49:01.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-09-16T06:49:31.970+0000] {processor.py:157} INFO - Started process (PID=30108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:49:31.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:49:31.978+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:49:31.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:49:32.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:49:32.056+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:49:32.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:49:32.073+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:49:32.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:49:32.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-16T06:50:02.499+0000] {processor.py:157} INFO - Started process (PID=30118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:50:02.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:50:02.504+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:50:02.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:50:02.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:50:02.565+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:50:02.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:50:02.582+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:50:02.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:50:02.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-16T06:50:32.926+0000] {processor.py:157} INFO - Started process (PID=30128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:50:32.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:50:32.932+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:50:32.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:50:32.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:50:32.980+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:50:32.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:50:33.011+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:50:33.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:50:33.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-16T06:51:03.437+0000] {processor.py:157} INFO - Started process (PID=30138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:51:03.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:51:03.442+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:51:03.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:51:03.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:51:03.500+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:51:03.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:51:03.518+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:51:03.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:51:03.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-16T06:51:33.780+0000] {processor.py:157} INFO - Started process (PID=30148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:51:33.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:51:33.787+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:51:33.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:51:33.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:51:33.842+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:51:33.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:51:33.858+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:51:33.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:51:33.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-16T06:52:04.107+0000] {processor.py:157} INFO - Started process (PID=30158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:52:04.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:52:04.113+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:52:04.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:52:04.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:52:04.164+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:52:04.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:52:04.181+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:52:04.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:52:04.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-16T06:52:34.439+0000] {processor.py:157} INFO - Started process (PID=30168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:52:34.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:52:34.446+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:52:34.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:52:34.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:52:34.509+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:52:34.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:52:34.538+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:52:34.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:52:34.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-16T06:53:04.817+0000] {processor.py:157} INFO - Started process (PID=30178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:53:04.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:53:04.824+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:53:04.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:53:04.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:53:04.892+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:53:04.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:53:04.917+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:53:04.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:53:04.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-16T06:53:35.138+0000] {processor.py:157} INFO - Started process (PID=30188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:53:35.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:53:35.144+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:53:35.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:53:35.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:53:35.204+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:53:35.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:53:35.236+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:53:35.235+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:53:35.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-16T06:54:05.625+0000] {processor.py:157} INFO - Started process (PID=30198) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:54:05.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:54:05.642+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:54:05.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:54:05.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:54:05.695+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:54:05.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:54:05.720+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:54:05.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:54:05.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-16T06:54:35.990+0000] {processor.py:157} INFO - Started process (PID=30208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:54:35.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:54:35.997+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:54:35.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:54:36.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:54:36.067+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:54:36.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:54:36.099+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:54:36.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:54:36.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-16T06:55:06.316+0000] {processor.py:157} INFO - Started process (PID=30218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:55:06.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:55:06.322+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:55:06.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:55:06.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:55:06.370+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:55:06.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:55:06.388+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:55:06.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:55:06.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-16T06:55:36.778+0000] {processor.py:157} INFO - Started process (PID=30228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:55:36.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:55:36.786+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:55:36.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:55:36.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:55:36.878+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:55:36.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:55:36.896+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:55:36.896+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:55:36.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-16T06:56:07.139+0000] {processor.py:157} INFO - Started process (PID=30238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:56:07.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:56:07.145+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:56:07.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:56:07.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:56:07.205+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:56:07.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:56:07.231+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:56:07.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:56:07.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-16T06:56:37.484+0000] {processor.py:157} INFO - Started process (PID=30248) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:56:37.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:56:37.496+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:56:37.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:56:37.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:56:37.592+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:56:37.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:56:37.631+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:56:37.631+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:56:37.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-09-16T06:57:07.864+0000] {processor.py:157} INFO - Started process (PID=30258) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:57:07.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:57:07.873+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:57:07.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:57:07.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:57:07.940+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:57:07.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:57:07.955+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:57:07.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:57:07.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-16T06:57:38.356+0000] {processor.py:157} INFO - Started process (PID=30268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:57:38.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:57:38.362+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:57:38.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:57:38.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:57:38.418+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:57:38.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:57:38.433+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:57:38.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:57:38.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-16T06:58:08.831+0000] {processor.py:157} INFO - Started process (PID=30278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:58:08.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:58:08.839+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:58:08.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:58:08.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:58:08.905+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:58:08.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:58:08.931+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:58:08.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:58:08.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-16T06:58:39.130+0000] {processor.py:157} INFO - Started process (PID=30288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:58:39.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:58:39.138+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:58:39.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:58:39.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:58:39.180+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:58:39.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:58:39.209+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:58:39.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:58:39.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-16T06:59:09.619+0000] {processor.py:157} INFO - Started process (PID=30296) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:59:09.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:59:09.635+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:59:09.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:59:09.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:59:09.732+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:59:09.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:59:09.767+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:59:09.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:59:09.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-09-16T06:59:39.927+0000] {processor.py:157} INFO - Started process (PID=30308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:59:39.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T06:59:39.933+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:59:39.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:59:39.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T06:59:40.016+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:59:40.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T06:59:40.033+0000] {logging_mixin.py:151} INFO - [2024-09-16T06:59:40.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T06:59:40.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-16T07:00:10.454+0000] {processor.py:157} INFO - Started process (PID=30317) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:00:10.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:00:10.464+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:00:10.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:00:10.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:00:10.568+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:00:10.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:00:10.592+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:00:10.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:00:10.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-09-16T07:00:40.809+0000] {processor.py:157} INFO - Started process (PID=30328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:00:40.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:00:40.813+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:00:40.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:00:40.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:00:40.857+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:00:40.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:00:40.873+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:00:40.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:00:40.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-16T07:01:11.257+0000] {processor.py:157} INFO - Started process (PID=30336) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:01:11.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:01:11.281+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:01:11.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:01:11.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:01:11.349+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:01:11.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:01:11.366+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:01:11.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:01:11.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-16T07:01:41.753+0000] {processor.py:157} INFO - Started process (PID=30348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:01:41.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:01:41.760+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:01:41.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:01:41.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:01:41.838+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:01:41.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:01:41.874+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:01:41.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:01:41.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-16T07:02:12.107+0000] {processor.py:157} INFO - Started process (PID=30357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:02:12.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:02:12.114+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:02:12.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:02:12.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:02:12.182+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:02:12.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:02:12.199+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:02:12.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:02:12.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-16T07:02:42.384+0000] {processor.py:157} INFO - Started process (PID=30367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:02:42.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:02:42.393+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:02:42.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:02:42.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:02:42.445+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:02:42.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:02:42.471+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:02:42.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:02:42.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-16T07:03:12.842+0000] {processor.py:157} INFO - Started process (PID=30378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:03:12.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:03:12.848+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:03:12.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:03:12.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:03:12.916+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:03:12.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:03:12.932+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:03:12.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:03:12.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-16T07:03:43.152+0000] {processor.py:157} INFO - Started process (PID=30388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:03:43.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:03:43.155+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:03:43.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:03:43.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:03:43.183+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:03:43.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:03:43.198+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:03:43.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:03:43.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-16T07:04:13.502+0000] {processor.py:157} INFO - Started process (PID=30398) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:04:13.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:04:13.509+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:04:13.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:04:13.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:04:13.580+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:04:13.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:04:13.598+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:04:13.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:04:13.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-16T07:04:43.881+0000] {processor.py:157} INFO - Started process (PID=30407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:04:43.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:04:43.886+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:04:43.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:04:43.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:04:43.959+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:04:43.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:04:43.977+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:04:43.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:04:43.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-16T07:05:14.192+0000] {processor.py:157} INFO - Started process (PID=30418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:05:14.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:05:14.195+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:05:14.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:05:14.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:05:14.225+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:05:14.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:05:14.257+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:05:14.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:05:14.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-16T07:05:44.608+0000] {processor.py:157} INFO - Started process (PID=30428) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:05:44.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:05:44.616+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:05:44.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:05:44.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:05:44.682+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:05:44.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:05:44.705+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:05:44.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:05:44.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T07:06:14.983+0000] {processor.py:157} INFO - Started process (PID=30437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:06:14.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:06:14.990+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:06:14.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:06:15.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:06:15.068+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:06:15.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:06:15.091+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:06:15.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:06:15.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-16T07:06:45.342+0000] {processor.py:157} INFO - Started process (PID=30446) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:06:45.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:06:45.348+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:06:45.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:06:45.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:06:45.389+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:06:45.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:06:45.408+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:06:45.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:06:45.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-16T07:07:15.637+0000] {processor.py:157} INFO - Started process (PID=30458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:07:15.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:07:15.643+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:07:15.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:07:15.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:07:15.694+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:07:15.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:07:15.710+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:07:15.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:07:15.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-16T07:07:46.060+0000] {processor.py:157} INFO - Started process (PID=30468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:07:46.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:07:46.068+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:07:46.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:07:46.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:07:46.138+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:07:46.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:07:46.155+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:07:46.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:07:46.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-16T07:08:16.563+0000] {processor.py:157} INFO - Started process (PID=30477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:08:16.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:08:16.570+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:08:16.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:08:16.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:08:16.636+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:08:16.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:08:16.657+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:08:16.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:08:16.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-16T07:08:47.004+0000] {processor.py:157} INFO - Started process (PID=30487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:08:47.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:08:47.019+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:08:47.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:08:47.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:08:47.096+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:08:47.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:08:47.119+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:08:47.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:08:47.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-16T07:09:17.415+0000] {processor.py:157} INFO - Started process (PID=30498) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:09:17.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:09:17.424+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:09:17.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:09:17.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:09:17.493+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:09:17.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:09:17.508+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:09:17.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:09:17.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-16T07:09:47.789+0000] {processor.py:157} INFO - Started process (PID=30507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:09:47.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:09:47.806+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:09:47.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:09:47.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:09:47.865+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:09:47.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:09:47.882+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:09:47.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:09:47.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-16T07:10:18.119+0000] {processor.py:157} INFO - Started process (PID=30518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:10:18.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:10:18.122+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:10:18.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:10:18.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:10:18.153+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:10:18.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:10:18.169+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:10:18.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:10:18.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-16T07:10:48.556+0000] {processor.py:157} INFO - Started process (PID=30528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:10:48.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:10:48.563+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:10:48.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:10:48.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:10:48.626+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:10:48.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:10:48.643+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:10:48.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:10:48.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-16T07:11:19.043+0000] {processor.py:157} INFO - Started process (PID=30537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:11:19.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:11:19.054+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:11:19.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:11:19.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:11:19.126+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:11:19.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:11:19.143+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:11:19.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:11:19.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-16T07:11:49.525+0000] {processor.py:157} INFO - Started process (PID=30548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:11:49.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:11:49.537+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:11:49.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:11:49.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:11:49.600+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:11:49.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:11:49.632+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:11:49.631+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:11:49.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-16T07:12:19.915+0000] {processor.py:157} INFO - Started process (PID=30558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:12:19.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:12:19.921+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:12:19.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:12:19.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:12:19.989+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:12:19.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:12:20.009+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:12:20.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:12:20.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-16T07:12:50.317+0000] {processor.py:157} INFO - Started process (PID=30568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:12:50.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:12:50.327+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:12:50.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:12:50.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:12:50.393+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:12:50.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:12:50.417+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:12:50.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:12:50.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-16T07:13:20.652+0000] {processor.py:157} INFO - Started process (PID=30578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:13:20.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:13:20.664+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:13:20.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:13:20.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:13:20.728+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:13:20.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:13:20.755+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:13:20.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:13:20.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-16T07:13:51.030+0000] {processor.py:157} INFO - Started process (PID=30588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:13:51.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:13:51.037+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:13:51.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:13:51.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:13:51.109+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:13:51.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:13:51.125+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:13:51.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:13:51.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-16T07:14:21.400+0000] {processor.py:157} INFO - Started process (PID=30598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:14:21.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:14:21.432+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:14:21.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:14:21.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:14:21.501+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:14:21.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:14:21.523+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:14:21.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:14:21.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-16T07:14:51.821+0000] {processor.py:157} INFO - Started process (PID=30608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:14:51.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:14:51.828+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:14:51.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:14:51.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:14:51.893+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:14:51.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:14:51.911+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:14:51.911+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:14:51.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-16T07:15:22.241+0000] {processor.py:157} INFO - Started process (PID=30618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:15:22.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:15:22.252+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:15:22.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:15:22.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:15:22.315+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:15:22.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:15:22.332+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:15:22.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:15:22.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-16T07:15:52.596+0000] {processor.py:157} INFO - Started process (PID=30627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:15:52.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:15:52.603+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:15:52.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:15:52.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:15:52.666+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:15:52.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:15:52.695+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:15:52.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:15:52.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T07:16:23.012+0000] {processor.py:157} INFO - Started process (PID=30638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:16:23.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:16:23.019+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:16:23.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:16:23.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:16:23.086+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:16:23.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:16:23.109+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:16:23.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:16:23.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T07:16:53.434+0000] {processor.py:157} INFO - Started process (PID=30648) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:16:53.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:16:53.442+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:16:53.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:16:53.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:16:53.504+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:16:53.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:16:53.522+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:16:53.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:16:53.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-16T07:17:23.953+0000] {processor.py:157} INFO - Started process (PID=30658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:17:23.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:17:23.964+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:17:23.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:17:23.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:17:24.011+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:17:24.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:17:24.036+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:17:24.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:17:24.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T07:17:54.298+0000] {processor.py:157} INFO - Started process (PID=30668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:17:54.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:17:54.302+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:17:54.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:17:54.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:17:54.334+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:17:54.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:17:54.349+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:17:54.349+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:17:54.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-16T07:18:24.741+0000] {processor.py:157} INFO - Started process (PID=30678) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:18:24.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:18:24.751+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:18:24.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:18:24.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:18:24.819+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:18:24.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:18:24.836+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:18:24.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:18:24.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-16T07:18:55.182+0000] {processor.py:157} INFO - Started process (PID=30688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:18:55.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:18:55.188+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:18:55.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:18:55.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:18:55.260+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:18:55.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:18:55.278+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:18:55.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:18:55.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-16T07:19:25.563+0000] {processor.py:157} INFO - Started process (PID=30696) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:19:25.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:19:25.577+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:19:25.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:19:25.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:19:25.640+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:19:25.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:19:25.658+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:19:25.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:19:25.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-16T07:19:55.931+0000] {processor.py:157} INFO - Started process (PID=30708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:19:55.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:19:55.937+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:19:55.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:19:55.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:19:55.975+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:19:55.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:19:55.992+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:19:55.992+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:19:56.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-16T07:20:26.418+0000] {processor.py:157} INFO - Started process (PID=30718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:20:26.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:20:26.437+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:20:26.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:20:26.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:20:26.481+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:20:26.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:20:26.498+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:20:26.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:20:26.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-16T07:20:56.750+0000] {processor.py:157} INFO - Started process (PID=30728) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:20:56.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:20:56.754+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:20:56.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:20:56.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:20:56.783+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:20:56.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:20:56.800+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:20:56.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:20:56.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-16T07:21:27.205+0000] {processor.py:157} INFO - Started process (PID=30738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:21:27.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:21:27.227+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:21:27.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:21:27.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:21:27.285+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:21:27.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:21:27.315+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:21:27.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:21:27.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-16T07:21:57.582+0000] {processor.py:157} INFO - Started process (PID=30748) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:21:57.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:21:57.588+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:21:57.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:21:57.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:21:57.658+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:21:57.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:21:57.676+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:21:57.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:21:57.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-16T07:22:27.862+0000] {processor.py:157} INFO - Started process (PID=30758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:22:27.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:22:27.868+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:22:27.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:22:27.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:22:27.920+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:22:27.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:22:27.938+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:22:27.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:22:27.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-16T07:22:58.231+0000] {processor.py:157} INFO - Started process (PID=30768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:22:58.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:22:58.236+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:22:58.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:22:58.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:22:58.281+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:22:58.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:22:58.299+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:22:58.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:22:58.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-16T07:23:28.719+0000] {processor.py:157} INFO - Started process (PID=30778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:23:28.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:23:28.726+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:23:28.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:23:28.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:23:28.758+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:23:28.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:23:28.773+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:23:28.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:23:28.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-16T07:23:59.126+0000] {processor.py:157} INFO - Started process (PID=30788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:23:59.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:23:59.131+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:23:59.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:23:59.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:23:59.214+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:23:59.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:23:59.232+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:23:59.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:23:59.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-16T07:24:29.535+0000] {processor.py:157} INFO - Started process (PID=30798) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:24:29.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:24:29.539+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:24:29.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:24:29.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:24:29.591+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:24:29.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:24:29.607+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:24:29.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:24:29.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-16T07:24:59.971+0000] {processor.py:157} INFO - Started process (PID=30808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:24:59.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:24:59.976+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:24:59.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:24:59.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:25:00.013+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:25:00.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:25:00.046+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:25:00.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:25:00.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-16T07:25:30.331+0000] {processor.py:157} INFO - Started process (PID=30818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:25:30.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:25:30.352+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:25:30.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:25:30.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:25:30.410+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:25:30.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:25:30.446+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:25:30.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:25:30.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-16T07:26:00.709+0000] {processor.py:157} INFO - Started process (PID=30828) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:26:00.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:26:00.716+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:26:00.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:26:00.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:26:00.769+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:26:00.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:26:00.798+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:26:00.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:26:00.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-16T07:26:31.052+0000] {processor.py:157} INFO - Started process (PID=30838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:26:31.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:26:31.056+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:26:31.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:26:31.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:26:31.106+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:26:31.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:26:31.127+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:26:31.127+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:26:31.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-16T07:27:01.457+0000] {processor.py:157} INFO - Started process (PID=30848) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:27:01.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:27:01.463+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:27:01.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:27:01.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:27:01.533+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:27:01.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:27:01.550+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:27:01.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:27:01.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-16T07:27:31.966+0000] {processor.py:157} INFO - Started process (PID=30858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:27:31.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:27:31.973+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:27:31.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:27:32.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:27:32.048+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:27:32.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:27:32.063+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:27:32.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:27:32.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-16T07:28:02.324+0000] {processor.py:157} INFO - Started process (PID=30868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:28:02.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:28:02.326+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:28:02.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:28:02.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:28:02.356+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:28:02.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:28:02.375+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:28:02.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:28:02.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-16T07:28:32.732+0000] {processor.py:157} INFO - Started process (PID=30878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:28:32.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:28:32.744+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:28:32.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:28:32.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:28:32.797+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:28:32.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:28:32.832+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:28:32.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:28:32.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-16T07:29:03.108+0000] {processor.py:157} INFO - Started process (PID=30887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:29:03.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:29:03.115+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:29:03.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:29:03.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:29:03.182+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:29:03.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:29:03.199+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:29:03.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:29:03.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-16T07:29:33.434+0000] {processor.py:157} INFO - Started process (PID=30898) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:29:33.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:29:33.453+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:29:33.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:29:33.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:29:33.526+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:29:33.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:29:33.550+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:29:33.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:29:33.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-16T07:30:03.866+0000] {processor.py:157} INFO - Started process (PID=30908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:30:03.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:30:03.872+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:30:03.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:30:03.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:30:03.944+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:30:03.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:30:03.973+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:30:03.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:30:03.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-16T07:30:34.283+0000] {processor.py:157} INFO - Started process (PID=30918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:30:34.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:30:34.290+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:30:34.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:30:34.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:30:34.357+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:30:34.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:30:34.387+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:30:34.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:30:34.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-16T07:31:04.623+0000] {processor.py:157} INFO - Started process (PID=30928) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:31:04.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:31:04.627+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:31:04.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:31:04.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:31:04.678+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:31:04.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:31:04.708+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:31:04.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:31:04.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-16T07:31:34.991+0000] {processor.py:157} INFO - Started process (PID=30938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:31:34.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:31:34.998+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:31:34.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:31:35.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:31:35.056+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:31:35.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:31:35.072+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:31:35.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:31:35.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-16T07:32:05.456+0000] {processor.py:157} INFO - Started process (PID=30948) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:32:05.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:32:05.460+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:32:05.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:32:05.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:32:05.493+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:32:05.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:32:05.533+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:32:05.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:32:05.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-16T07:32:35.905+0000] {processor.py:157} INFO - Started process (PID=30957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:32:35.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:32:35.910+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:32:35.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:32:35.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:32:35.977+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:32:35.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:32:35.996+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:32:35.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:32:36.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-16T07:33:06.274+0000] {processor.py:157} INFO - Started process (PID=30968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:33:06.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:33:06.282+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:33:06.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:33:06.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:33:06.337+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:33:06.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:33:06.353+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:33:06.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:33:06.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-16T07:33:36.612+0000] {processor.py:157} INFO - Started process (PID=30978) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:33:36.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:33:36.616+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:33:36.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:33:36.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:33:36.660+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:33:36.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:33:36.689+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:33:36.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:33:36.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-16T07:34:07.072+0000] {processor.py:157} INFO - Started process (PID=30988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:34:07.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:34:07.075+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:34:07.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:34:07.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:34:07.106+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:34:07.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:34:07.126+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:34:07.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:34:07.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-16T07:34:37.547+0000] {processor.py:157} INFO - Started process (PID=30997) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:34:37.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:34:37.557+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:34:37.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:34:37.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:34:37.622+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:34:37.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:34:37.638+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:34:37.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:34:37.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-16T07:35:08.011+0000] {processor.py:157} INFO - Started process (PID=31008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:35:08.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:35:08.015+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:35:08.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:35:08.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:35:08.048+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:35:08.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:35:08.085+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:35:08.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:35:08.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-16T07:35:38.413+0000] {processor.py:157} INFO - Started process (PID=31017) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:35:38.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:35:38.434+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:35:38.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:35:38.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:35:38.502+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:35:38.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:35:38.522+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:35:38.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:35:38.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-16T07:36:08.765+0000] {processor.py:157} INFO - Started process (PID=31028) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:36:08.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:36:08.771+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:36:08.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:36:08.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:36:08.804+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:36:08.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:36:08.835+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:36:08.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:36:08.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-16T07:36:39.276+0000] {processor.py:157} INFO - Started process (PID=31038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:36:39.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:36:39.282+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:36:39.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:36:39.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:36:39.342+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:36:39.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:36:39.360+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:36:39.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:36:39.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-16T07:37:09.615+0000] {processor.py:157} INFO - Started process (PID=31048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:37:09.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:37:09.617+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:37:09.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:37:09.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:37:09.653+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:37:09.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:37:09.669+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:37:09.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:37:09.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-16T07:37:40.047+0000] {processor.py:157} INFO - Started process (PID=31057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:37:40.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:37:40.061+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:37:40.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:37:40.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:37:40.119+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:37:40.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:37:40.136+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:37:40.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:37:40.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T07:38:10.548+0000] {processor.py:157} INFO - Started process (PID=31068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:38:10.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:38:10.557+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:38:10.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:38:10.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:38:10.617+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:38:10.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:38:10.635+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:38:10.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:38:10.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-16T07:38:41.029+0000] {processor.py:157} INFO - Started process (PID=31077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:38:41.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:38:41.041+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:38:41.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:38:41.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:38:41.087+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:38:41.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:38:41.120+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:38:41.120+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:38:41.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-16T07:39:11.448+0000] {processor.py:157} INFO - Started process (PID=31088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:39:11.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:39:11.479+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:39:11.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:39:11.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:39:11.546+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:39:11.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:39:11.563+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:39:11.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:39:11.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-16T07:39:41.928+0000] {processor.py:157} INFO - Started process (PID=31098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:39:41.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:39:41.943+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:39:41.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:39:41.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:39:42.002+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:39:42.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:39:42.032+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:39:42.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:39:42.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-16T07:40:12.202+0000] {processor.py:157} INFO - Started process (PID=31108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:40:12.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:40:12.207+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:40:12.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:40:12.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:40:12.250+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:40:12.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:40:12.276+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:40:12.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:40:12.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-16T07:40:42.774+0000] {processor.py:157} INFO - Started process (PID=31118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:40:42.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:40:42.784+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:40:42.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:40:42.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:40:42.857+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:40:42.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:40:42.882+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:40:42.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:40:42.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-16T07:41:13.064+0000] {processor.py:157} INFO - Started process (PID=31126) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:41:13.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:41:13.076+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:41:13.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:41:13.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:41:13.137+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:41:13.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:41:13.154+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:41:13.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:41:13.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-16T07:41:43.447+0000] {processor.py:157} INFO - Started process (PID=31138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:41:43.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:41:43.455+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:41:43.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:41:43.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:41:43.512+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:41:43.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:41:43.546+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:41:43.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:41:43.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-16T07:42:13.811+0000] {processor.py:157} INFO - Started process (PID=31148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:42:13.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:42:13.817+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:42:13.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:42:13.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:42:13.871+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:42:13.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:42:13.888+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:42:13.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:42:13.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-16T07:42:44.240+0000] {processor.py:157} INFO - Started process (PID=31158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:42:44.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:42:44.247+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:42:44.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:42:44.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:42:44.295+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:42:44.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:42:44.322+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:42:44.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:42:44.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-16T07:43:14.640+0000] {processor.py:157} INFO - Started process (PID=31167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:43:14.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:43:14.649+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:43:14.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:43:14.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:43:14.728+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:43:14.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:43:14.745+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:43:14.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:43:14.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-16T07:43:45.011+0000] {processor.py:157} INFO - Started process (PID=31176) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:43:45.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:43:45.017+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:43:45.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:43:45.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:43:45.088+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:43:45.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:43:45.108+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:43:45.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:43:45.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-16T07:44:15.549+0000] {processor.py:157} INFO - Started process (PID=31188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:44:15.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:44:15.557+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:44:15.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:44:15.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:44:15.616+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:44:15.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:44:15.636+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:44:15.636+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:44:15.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-16T07:44:46.073+0000] {processor.py:157} INFO - Started process (PID=31198) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:44:46.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:44:46.086+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:44:46.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:44:46.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:44:46.164+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:44:46.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:44:46.191+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:44:46.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:44:46.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-16T07:45:16.347+0000] {processor.py:157} INFO - Started process (PID=31208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:45:16.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:45:16.350+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:45:16.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:45:16.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:45:16.386+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:45:16.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:45:16.399+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:45:16.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:45:16.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-16T07:45:46.678+0000] {processor.py:157} INFO - Started process (PID=31218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:45:46.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:45:46.683+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:45:46.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:45:46.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:45:46.741+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:45:46.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:45:46.773+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:45:46.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:45:46.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-16T07:46:17.198+0000] {processor.py:157} INFO - Started process (PID=31228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:46:17.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:46:17.206+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:46:17.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:46:17.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:46:17.250+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:46:17.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:46:17.269+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:46:17.269+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:46:17.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-16T07:46:47.559+0000] {processor.py:157} INFO - Started process (PID=31238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:46:47.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:46:47.575+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:46:47.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:46:47.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:46:47.620+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:46:47.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:46:47.636+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:46:47.636+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:46:47.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-16T07:47:17.908+0000] {processor.py:157} INFO - Started process (PID=31248) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:47:17.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:47:17.911+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:47:17.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:47:17.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:47:17.969+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:47:17.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:47:17.984+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:47:17.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:47:18.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-16T07:47:48.261+0000] {processor.py:157} INFO - Started process (PID=31257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:47:48.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:47:48.269+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:47:48.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:47:48.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:47:48.327+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:47:48.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:47:48.353+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:47:48.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:47:48.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T07:48:18.778+0000] {processor.py:157} INFO - Started process (PID=31267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:48:18.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:48:18.785+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:48:18.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:48:18.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:48:18.851+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:48:18.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:48:18.867+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:48:18.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:48:18.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-16T07:48:49.217+0000] {processor.py:157} INFO - Started process (PID=31276) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:48:49.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:48:49.226+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:48:49.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:48:49.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:48:49.298+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:48:49.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:48:49.325+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:48:49.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:48:49.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-16T07:49:19.532+0000] {processor.py:157} INFO - Started process (PID=31288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:49:19.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:49:19.540+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:49:19.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:49:19.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:49:19.584+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:49:19.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:49:19.601+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:49:19.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:49:19.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-16T07:49:50.045+0000] {processor.py:157} INFO - Started process (PID=31298) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:49:50.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:49:50.051+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:49:50.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:49:50.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:49:50.116+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:49:50.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:49:50.145+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:49:50.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:49:50.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-16T07:50:20.442+0000] {processor.py:157} INFO - Started process (PID=31308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:50:20.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:50:20.460+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:50:20.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:50:20.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:50:20.534+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:50:20.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:50:20.550+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:50:20.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:50:20.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-16T07:50:50.820+0000] {processor.py:157} INFO - Started process (PID=31318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:50:50.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:50:50.827+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:50:50.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:50:50.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:50:50.892+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:50:50.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:50:50.908+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:50:50.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:50:50.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-16T07:51:21.213+0000] {processor.py:157} INFO - Started process (PID=31328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:51:21.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:51:21.228+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:51:21.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:51:21.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:51:21.313+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:51:21.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:51:21.331+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:51:21.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:51:21.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-09-16T07:51:51.539+0000] {processor.py:157} INFO - Started process (PID=31338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:51:51.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:51:51.543+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:51:51.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:51:51.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:51:51.575+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:51:51.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:51:51.587+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:51:51.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:51:51.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-16T07:52:22.023+0000] {processor.py:157} INFO - Started process (PID=31348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:52:22.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:52:22.030+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:52:22.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:52:22.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:52:22.098+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:52:22.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:52:22.115+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:52:22.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:52:22.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-16T07:52:52.481+0000] {processor.py:157} INFO - Started process (PID=31358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:52:52.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:52:52.485+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:52:52.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:52:52.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:52:52.531+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:52:52.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:52:52.550+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:52:52.549+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:52:52.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-16T07:53:22.791+0000] {processor.py:157} INFO - Started process (PID=31368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:53:22.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:53:22.821+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:53:22.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:53:22.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:53:22.894+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:53:22.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:53:22.920+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:53:22.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:53:22.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-16T07:53:53.342+0000] {processor.py:157} INFO - Started process (PID=31377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:53:53.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:53:53.356+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:53:53.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:53:53.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:53:53.413+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:53:53.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:53:53.441+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:53:53.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:53:53.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-16T07:54:23.702+0000] {processor.py:157} INFO - Started process (PID=31388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:54:23.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:54:23.707+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:54:23.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:54:23.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:54:23.750+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:54:23.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:54:23.766+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:54:23.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:54:23.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-16T07:54:54.029+0000] {processor.py:157} INFO - Started process (PID=31398) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:54:54.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:54:54.033+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:54:54.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:54:54.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:54:54.063+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:54:54.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:54:54.078+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:54:54.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:54:54.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-16T07:55:24.498+0000] {processor.py:157} INFO - Started process (PID=31408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:55:24.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:55:24.504+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:55:24.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:55:24.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:55:24.588+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:55:24.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:55:24.604+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:55:24.604+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:55:24.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-16T07:55:54.829+0000] {processor.py:157} INFO - Started process (PID=31418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:55:54.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:55:54.832+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:55:54.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:55:54.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:55:54.890+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:55:54.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:55:54.910+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:55:54.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:55:54.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-16T07:56:25.249+0000] {processor.py:157} INFO - Started process (PID=31428) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:56:25.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:56:25.254+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:56:25.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:56:25.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:56:25.315+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:56:25.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:56:25.332+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:56:25.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:56:25.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-16T07:56:55.643+0000] {processor.py:157} INFO - Started process (PID=31438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:56:55.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:56:55.662+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:56:55.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:56:55.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:56:55.708+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:56:55.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:56:55.727+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:56:55.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:56:55.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-16T07:57:25.969+0000] {processor.py:157} INFO - Started process (PID=31448) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:57:25.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:57:25.973+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:57:25.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:57:25.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:57:26.018+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:57:26.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:57:26.034+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:57:26.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:57:26.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-16T07:57:56.405+0000] {processor.py:157} INFO - Started process (PID=31458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:57:56.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:57:56.408+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:57:56.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:57:56.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:57:56.436+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:57:56.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:57:56.452+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:57:56.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:57:56.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-16T07:58:26.825+0000] {processor.py:157} INFO - Started process (PID=31468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:58:26.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:58:26.835+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:58:26.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:58:26.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:58:26.890+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:58:26.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:58:26.918+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:58:26.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:58:26.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-16T07:58:57.120+0000] {processor.py:157} INFO - Started process (PID=31478) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:58:57.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:58:57.124+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:58:57.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:58:57.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:58:57.187+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:58:57.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:58:57.205+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:58:57.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:58:57.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-16T07:59:27.590+0000] {processor.py:157} INFO - Started process (PID=31488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:59:27.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:59:27.595+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:59:27.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:59:27.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:59:27.653+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:59:27.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:59:27.670+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:59:27.670+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:59:27.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-16T07:59:57.953+0000] {processor.py:157} INFO - Started process (PID=31498) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:59:57.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T07:59:57.973+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:59:57.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:59:57.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T07:59:58.022+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:59:58.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T07:59:58.040+0000] {logging_mixin.py:151} INFO - [2024-09-16T07:59:58.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T07:59:58.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-16T08:00:28.294+0000] {processor.py:157} INFO - Started process (PID=31508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:00:28.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:00:28.300+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:00:28.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:00:28.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:00:28.344+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:00:28.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:00:28.359+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:00:28.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:00:28.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-16T08:00:58.710+0000] {processor.py:157} INFO - Started process (PID=31518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:00:58.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:00:58.718+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:00:58.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:00:58.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:00:58.755+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:00:58.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:00:58.782+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:00:58.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:00:58.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-16T08:01:29.029+0000] {processor.py:157} INFO - Started process (PID=31528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:01:29.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:01:29.034+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:01:29.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:01:29.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:01:29.077+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:01:29.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:01:29.107+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:01:29.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:01:29.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-16T08:01:59.380+0000] {processor.py:157} INFO - Started process (PID=31537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:01:59.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:01:59.388+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:01:59.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:01:59.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:01:59.448+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:01:59.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:01:59.465+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:01:59.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:01:59.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-16T08:02:29.841+0000] {processor.py:157} INFO - Started process (PID=31548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:02:29.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:02:29.847+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:02:29.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:02:29.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:02:29.893+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:02:29.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:02:29.927+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:02:29.927+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:02:29.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T08:03:00.232+0000] {processor.py:157} INFO - Started process (PID=31558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:03:00.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:03:00.235+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:03:00.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:03:00.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:03:00.270+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:03:00.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:03:00.284+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:03:00.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:03:00.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-16T08:03:30.648+0000] {processor.py:157} INFO - Started process (PID=31568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:03:30.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:03:30.657+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:03:30.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:03:30.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:03:30.715+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:03:30.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:03:30.741+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:03:30.741+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:03:30.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-16T08:04:01.021+0000] {processor.py:157} INFO - Started process (PID=31578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:04:01.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:04:01.027+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:04:01.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:04:01.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:04:01.070+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:04:01.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:04:01.100+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:04:01.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:04:01.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-16T08:04:31.520+0000] {processor.py:157} INFO - Started process (PID=31588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:04:31.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:04:31.529+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:04:31.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:04:31.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:04:31.596+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:04:31.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:04:31.612+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:04:31.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:04:31.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-16T08:05:01.907+0000] {processor.py:157} INFO - Started process (PID=31598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:05:01.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:05:01.913+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:05:01.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:05:01.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:05:01.958+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:05:01.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:05:01.992+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:05:01.992+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:05:02.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-16T08:05:32.291+0000] {processor.py:157} INFO - Started process (PID=31607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:05:32.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:05:32.303+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:05:32.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:05:32.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:05:32.368+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:05:32.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:05:32.400+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:05:32.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:05:32.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-16T08:06:02.666+0000] {processor.py:157} INFO - Started process (PID=31618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:06:02.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:06:02.671+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:06:02.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:06:02.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:06:02.717+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:06:02.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:06:02.746+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:06:02.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:06:02.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T08:06:33.135+0000] {processor.py:157} INFO - Started process (PID=31628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:06:33.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:06:33.140+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:06:33.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:06:33.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:06:33.191+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:06:33.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:06:33.212+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:06:33.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:06:33.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-16T08:07:03.564+0000] {processor.py:157} INFO - Started process (PID=31638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:07:03.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:07:03.568+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:07:03.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:07:03.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:07:03.604+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:07:03.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:07:03.634+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:07:03.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:07:03.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-16T08:07:34.036+0000] {processor.py:157} INFO - Started process (PID=31648) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:07:34.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:07:34.048+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:07:34.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:07:34.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:07:34.101+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:07:34.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:07:34.130+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:07:34.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:07:34.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-16T08:08:04.460+0000] {processor.py:157} INFO - Started process (PID=31658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:08:04.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:08:04.463+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:08:04.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:08:04.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:08:04.491+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:08:04.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:08:04.527+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:08:04.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:08:04.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-16T08:08:34.913+0000] {processor.py:157} INFO - Started process (PID=31668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:08:34.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:08:34.921+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:08:34.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:08:34.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:08:34.986+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:08:34.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:08:35.003+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:08:35.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:08:35.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-16T08:09:05.338+0000] {processor.py:157} INFO - Started process (PID=31678) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:09:05.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:09:05.347+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:09:05.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:09:05.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:09:05.393+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:09:05.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:09:05.422+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:09:05.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:09:05.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-16T08:09:35.652+0000] {processor.py:157} INFO - Started process (PID=31688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:09:35.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:09:35.655+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:09:35.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:09:35.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:09:35.689+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:09:35.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:09:35.708+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:09:35.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:09:35.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-16T08:10:06.130+0000] {processor.py:157} INFO - Started process (PID=31697) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:10:06.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:10:06.136+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:10:06.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:10:06.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:10:06.191+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:10:06.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:10:06.214+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:10:06.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:10:06.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-16T08:10:36.442+0000] {processor.py:157} INFO - Started process (PID=31708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:10:36.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:10:36.448+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:10:36.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:10:36.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:10:36.515+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:10:36.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:10:36.532+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:10:36.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:10:36.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-16T08:11:06.908+0000] {processor.py:157} INFO - Started process (PID=31718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:11:06.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:11:06.912+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:11:06.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:11:06.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:11:06.953+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:11:06.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:11:06.971+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:11:06.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:11:06.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-16T08:11:37.278+0000] {processor.py:157} INFO - Started process (PID=31728) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:11:37.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:11:37.284+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:11:37.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:11:37.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:11:37.345+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:11:37.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:11:37.364+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:11:37.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:11:37.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-16T08:12:07.667+0000] {processor.py:157} INFO - Started process (PID=31738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:12:07.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:12:07.673+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:12:07.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:12:07.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:12:07.749+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:12:07.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:12:07.766+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:12:07.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:12:07.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-16T08:12:38.113+0000] {processor.py:157} INFO - Started process (PID=31748) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:12:38.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:12:38.124+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:12:38.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:12:38.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:12:38.202+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:12:38.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:12:38.224+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:12:38.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:12:38.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-16T08:13:08.497+0000] {processor.py:157} INFO - Started process (PID=31757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:13:08.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:13:08.506+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:13:08.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:13:08.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:13:08.578+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:13:08.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:13:08.597+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:13:08.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:13:08.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-16T08:13:38.968+0000] {processor.py:157} INFO - Started process (PID=31767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:13:38.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:13:38.974+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:13:38.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:13:39.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:13:39.046+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:13:39.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:13:39.064+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:13:39.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:13:39.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-16T08:14:09.323+0000] {processor.py:157} INFO - Started process (PID=31778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:14:09.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:14:09.330+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:14:09.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:14:09.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:14:09.395+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:14:09.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:14:09.417+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:14:09.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:14:09.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T08:14:39.616+0000] {processor.py:157} INFO - Started process (PID=31788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:14:39.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:14:39.622+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:14:39.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:14:39.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:14:39.685+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:14:39.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:14:39.706+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:14:39.706+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:14:39.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-16T08:15:10.062+0000] {processor.py:157} INFO - Started process (PID=31798) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:15:10.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:15:10.067+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:15:10.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:15:10.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:15:10.103+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:15:10.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:15:10.118+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:15:10.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:15:10.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-16T08:15:40.575+0000] {processor.py:157} INFO - Started process (PID=31808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:15:40.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:15:40.580+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:15:40.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:15:40.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:15:40.645+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:15:40.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:15:40.671+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:15:40.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:15:40.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-16T08:16:10.932+0000] {processor.py:157} INFO - Started process (PID=31818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:16:10.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:16:10.938+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:16:10.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:16:10.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:16:10.982+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:16:10.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:16:11.017+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:16:11.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:16:11.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-16T08:16:41.398+0000] {processor.py:157} INFO - Started process (PID=31828) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:16:41.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:16:41.401+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:16:41.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:16:41.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:16:41.434+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:16:41.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:16:41.449+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:16:41.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:16:41.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-16T08:17:11.793+0000] {processor.py:157} INFO - Started process (PID=31838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:17:11.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:17:11.801+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:17:11.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:17:11.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:17:11.861+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:17:11.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:17:11.877+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:17:11.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:17:11.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-16T08:17:42.312+0000] {processor.py:157} INFO - Started process (PID=31848) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:17:42.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:17:42.318+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:17:42.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:17:42.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:17:42.378+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:17:42.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:17:42.394+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:17:42.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:17:42.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-16T08:18:12.688+0000] {processor.py:157} INFO - Started process (PID=31858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:18:12.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:18:12.695+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:18:12.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:18:12.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:18:12.735+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:18:12.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:18:12.774+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:18:12.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:18:12.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-16T08:18:43.154+0000] {processor.py:157} INFO - Started process (PID=31868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:18:43.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:18:43.160+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:18:43.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:18:43.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:18:43.230+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:18:43.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:18:43.256+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:18:43.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:18:43.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-16T08:19:13.533+0000] {processor.py:157} INFO - Started process (PID=31878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:19:13.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:19:13.539+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:19:13.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:19:13.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:19:13.600+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:19:13.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:19:13.617+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:19:13.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:19:13.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T08:19:44.036+0000] {processor.py:157} INFO - Started process (PID=31888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:19:44.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:19:44.050+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:19:44.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:19:44.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:19:44.121+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:19:44.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:19:44.138+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:19:44.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:19:44.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-16T08:20:14.417+0000] {processor.py:157} INFO - Started process (PID=31898) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:20:14.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:20:14.424+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:20:14.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:20:14.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:20:14.502+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:20:14.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:20:14.519+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:20:14.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:20:14.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-16T08:20:44.864+0000] {processor.py:157} INFO - Started process (PID=31908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:20:44.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:20:44.870+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:20:44.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:20:44.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:20:44.914+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:20:44.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:20:44.953+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:20:44.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:20:44.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-16T08:21:15.190+0000] {processor.py:157} INFO - Started process (PID=31918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:21:15.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:21:15.196+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:21:15.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:21:15.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:21:15.242+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:21:15.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:21:15.259+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:21:15.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:21:15.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-16T08:21:45.664+0000] {processor.py:157} INFO - Started process (PID=31928) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:21:45.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:21:45.673+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:21:45.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:21:45.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:21:45.717+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:21:45.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:21:45.734+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:21:45.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:21:45.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-16T08:22:16.139+0000] {processor.py:157} INFO - Started process (PID=31938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:22:16.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:22:16.143+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:22:16.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:22:16.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:22:16.179+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:22:16.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:22:16.194+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:22:16.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:22:16.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-16T08:22:46.625+0000] {processor.py:157} INFO - Started process (PID=31948) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:22:46.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:22:46.632+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:22:46.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:22:46.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:22:46.700+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:22:46.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:22:46.716+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:22:46.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:22:46.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T08:23:17.022+0000] {processor.py:157} INFO - Started process (PID=31958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:23:17.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:23:17.036+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:23:17.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:23:17.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:23:17.133+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:23:17.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:23:17.161+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:23:17.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:23:17.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-09-16T08:39:52.708+0000] {processor.py:157} INFO - Started process (PID=31968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:39:52.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:39:52.713+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:39:52.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:39:52.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:39:52.766+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:39:52.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:39:52.791+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:39:52.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:39:52.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-16T08:40:23.060+0000] {processor.py:157} INFO - Started process (PID=31980) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:40:23.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:40:23.064+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:40:23.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:40:23.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:40:23.151+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:40:23.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:40:23.188+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:40:23.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:40:23.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-09-16T08:56:26.583+0000] {processor.py:157} INFO - Started process (PID=31991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:56:26.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:56:26.589+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:56:26.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:56:26.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:56:26.663+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:56:26.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:56:26.695+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:56:26.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:56:26.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-16T08:56:56.935+0000] {processor.py:157} INFO - Started process (PID=32001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:56:56.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:56:56.943+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:56:56.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:56:56.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:56:57.019+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:56:57.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:56:57.037+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:56:57.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:56:57.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-16T08:57:27.297+0000] {processor.py:157} INFO - Started process (PID=32011) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:57:27.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:57:27.305+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:57:27.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:57:27.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:57:27.353+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:57:27.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:57:27.370+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:57:27.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:57:27.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-16T08:57:57.672+0000] {processor.py:157} INFO - Started process (PID=32022) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:57:57.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:57:57.675+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:57:57.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:57:57.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:57:57.710+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:57:57.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:57:57.726+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:57:57.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:57:57.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-16T08:58:28.023+0000] {processor.py:157} INFO - Started process (PID=32032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:58:28.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:58:28.028+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:58:28.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:58:28.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:58:28.081+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:58:28.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:58:28.112+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:58:28.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:58:28.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-16T08:58:58.333+0000] {processor.py:157} INFO - Started process (PID=32042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:58:58.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:58:58.336+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:58:58.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:58:58.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:58:58.374+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:58:58.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:58:58.412+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:58:58.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:58:58.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-16T08:59:28.711+0000] {processor.py:157} INFO - Started process (PID=32050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:59:28.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:59:28.718+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:59:28.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:59:28.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:59:28.776+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:59:28.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:59:28.803+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:59:28.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:59:28.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-16T08:59:59.028+0000] {processor.py:157} INFO - Started process (PID=32062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:59:59.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T08:59:59.035+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:59:59.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:59:59.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T08:59:59.083+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:59:59.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T08:59:59.108+0000] {logging_mixin.py:151} INFO - [2024-09-16T08:59:59.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T08:59:59.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-16T09:00:29.382+0000] {processor.py:157} INFO - Started process (PID=32072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:00:29.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:00:29.390+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:00:29.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:00:29.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:00:29.433+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:00:29.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:00:29.450+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:00:29.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:00:29.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-16T09:00:59.685+0000] {processor.py:157} INFO - Started process (PID=32082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:00:59.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:00:59.689+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:00:59.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:00:59.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:00:59.726+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:00:59.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:00:59.750+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:00:59.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:00:59.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-16T09:01:30.074+0000] {processor.py:157} INFO - Started process (PID=32092) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:01:30.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:01:30.085+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:01:30.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:01:30.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:01:30.143+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:01:30.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:01:30.171+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:01:30.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:01:30.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-16T09:02:00.545+0000] {processor.py:157} INFO - Started process (PID=32102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:02:00.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:02:00.552+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:02:00.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:02:00.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:02:00.595+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:02:00.595+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:02:00.612+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:02:00.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:02:00.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-16T09:02:30.865+0000] {processor.py:157} INFO - Started process (PID=32112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:02:30.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:02:30.871+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:02:30.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:02:30.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:02:30.913+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:02:30.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:02:30.946+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:02:30.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:02:30.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-16T09:03:01.233+0000] {processor.py:157} INFO - Started process (PID=32122) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:03:01.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:03:01.239+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:03:01.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:03:01.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:03:01.306+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:03:01.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:03:01.321+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:03:01.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:03:01.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-16T09:03:31.550+0000] {processor.py:157} INFO - Started process (PID=32132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:03:31.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:03:31.558+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:03:31.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:03:31.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:03:31.601+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:03:31.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:03:31.634+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:03:31.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:03:31.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-16T09:04:01.864+0000] {processor.py:157} INFO - Started process (PID=32142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:04:01.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:04:01.868+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:04:01.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:04:01.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:04:01.905+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:04:01.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:04:01.924+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:04:01.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:04:01.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-16T09:04:32.323+0000] {processor.py:157} INFO - Started process (PID=32151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:04:32.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:04:32.340+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:04:32.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:04:32.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:04:32.407+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:04:32.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:04:32.426+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:04:32.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:04:32.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-16T09:05:02.770+0000] {processor.py:157} INFO - Started process (PID=32162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:05:02.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:05:02.785+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:05:02.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:05:02.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:05:02.836+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:05:02.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:05:02.850+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:05:02.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:05:02.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-16T09:05:33.265+0000] {processor.py:157} INFO - Started process (PID=32171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:05:33.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:05:33.271+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:05:33.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:05:33.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:05:33.341+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:05:33.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:05:33.358+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:05:33.358+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:05:33.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-16T09:06:03.619+0000] {processor.py:157} INFO - Started process (PID=32182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:06:03.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:06:03.624+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:06:03.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:06:03.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:06:03.678+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:06:03.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:06:03.701+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:06:03.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:06:03.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T09:06:34.092+0000] {processor.py:157} INFO - Started process (PID=32192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:06:34.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:06:34.101+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:06:34.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:06:34.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:06:34.170+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:06:34.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:06:34.194+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:06:34.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:06:34.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-16T09:07:04.408+0000] {processor.py:157} INFO - Started process (PID=32202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:07:04.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:07:04.414+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:07:04.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:07:04.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:07:04.461+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:07:04.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:07:04.488+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:07:04.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:07:04.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-16T09:07:34.811+0000] {processor.py:157} INFO - Started process (PID=32212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:07:34.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:07:34.816+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:07:34.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:07:34.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:07:34.861+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:07:34.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:07:34.877+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:07:34.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:07:34.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-16T09:08:05.182+0000] {processor.py:157} INFO - Started process (PID=32222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:08:05.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:08:05.184+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:08:05.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:08:05.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:08:05.219+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:08:05.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:08:05.245+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:08:05.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:08:05.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-16T09:08:35.597+0000] {processor.py:157} INFO - Started process (PID=32231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:08:35.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:08:35.615+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:08:35.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:08:35.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:08:35.686+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:08:35.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:08:35.704+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:08:35.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:08:35.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-16T09:09:05.919+0000] {processor.py:157} INFO - Started process (PID=32242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:09:05.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:09:05.922+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:09:05.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:09:05.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:09:05.961+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:09:05.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:09:05.983+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:09:05.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:09:06.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-16T09:09:36.355+0000] {processor.py:157} INFO - Started process (PID=32252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:09:36.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:09:36.368+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:09:36.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:09:36.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:09:36.433+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:09:36.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:09:36.461+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:09:36.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:09:36.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-16T09:10:06.694+0000] {processor.py:157} INFO - Started process (PID=32262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:10:06.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:10:06.697+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:10:06.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:10:06.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:10:06.734+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:10:06.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:10:06.751+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:10:06.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:10:06.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-16T09:10:37.063+0000] {processor.py:157} INFO - Started process (PID=32272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:10:37.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:10:37.067+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:10:37.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:10:37.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:10:37.102+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:10:37.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:10:37.118+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:10:37.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:10:37.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-16T09:11:07.366+0000] {processor.py:157} INFO - Started process (PID=32281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:11:07.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:11:07.373+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:11:07.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:11:07.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:11:07.433+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:11:07.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:11:07.448+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:11:07.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:11:07.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-16T09:11:37.759+0000] {processor.py:157} INFO - Started process (PID=32292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:11:37.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:11:37.772+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:11:37.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:11:37.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:11:37.840+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:11:37.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:11:37.858+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:11:37.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:11:37.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-16T09:12:08.082+0000] {processor.py:157} INFO - Started process (PID=32302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:12:08.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:12:08.086+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:12:08.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:12:08.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:12:08.122+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:12:08.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:12:08.160+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:12:08.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:12:08.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-16T09:12:38.424+0000] {processor.py:157} INFO - Started process (PID=32312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:12:38.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:12:38.432+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:12:38.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:12:38.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:12:38.491+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:12:38.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:12:38.510+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:12:38.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:12:38.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-16T09:13:08.827+0000] {processor.py:157} INFO - Started process (PID=32321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:13:08.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:13:08.843+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:13:08.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:13:08.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:13:08.915+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:13:08.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:13:08.932+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:13:08.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:13:08.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-16T09:13:39.190+0000] {processor.py:157} INFO - Started process (PID=32332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:13:39.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:13:39.209+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:13:39.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:13:39.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:13:39.270+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:13:39.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:13:39.297+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:13:39.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:13:39.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-16T09:14:09.516+0000] {processor.py:157} INFO - Started process (PID=32342) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:14:09.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:14:09.521+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:14:09.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:14:09.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:14:09.586+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:14:09.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:14:09.602+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:14:09.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:14:09.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-16T09:14:39.935+0000] {processor.py:157} INFO - Started process (PID=32352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:14:39.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:14:39.937+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:14:39.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:14:39.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:14:39.973+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:14:39.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:14:40.004+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:14:40.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:14:40.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-16T09:15:10.360+0000] {processor.py:157} INFO - Started process (PID=32362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:15:10.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:15:10.374+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:15:10.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:15:10.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:15:10.451+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:15:10.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:15:10.482+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:15:10.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:15:10.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-16T09:15:40.708+0000] {processor.py:157} INFO - Started process (PID=32372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:15:40.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:15:40.723+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:15:40.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:15:40.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:15:40.792+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:15:40.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:15:40.817+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:15:40.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:15:40.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-16T09:16:11.190+0000] {processor.py:157} INFO - Started process (PID=32382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:16:11.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:16:11.195+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:16:11.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:16:11.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:16:11.254+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:16:11.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:16:11.273+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:16:11.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:16:11.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-16T09:16:41.649+0000] {processor.py:157} INFO - Started process (PID=32392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:16:41.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:16:41.670+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:16:41.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:16:41.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:16:41.740+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:16:41.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:16:41.764+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:16:41.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:16:41.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-16T09:17:11.942+0000] {processor.py:157} INFO - Started process (PID=32402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:17:11.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:17:11.944+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:17:11.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:17:11.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:17:11.979+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:17:11.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:17:12.021+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:17:12.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:17:12.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T09:17:42.441+0000] {processor.py:157} INFO - Started process (PID=32411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:17:42.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:17:42.448+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:17:42.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:17:42.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:17:42.526+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:17:42.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:17:42.549+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:17:42.549+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:17:42.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-16T09:18:12.925+0000] {processor.py:157} INFO - Started process (PID=32422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:18:12.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:18:12.930+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:18:12.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:18:12.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:18:12.985+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:18:12.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:18:13.005+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:18:13.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:18:13.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-16T09:18:43.238+0000] {processor.py:157} INFO - Started process (PID=32432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:18:43.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:18:43.244+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:18:43.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:18:43.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:18:43.286+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:18:43.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:18:43.321+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:18:43.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:18:43.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-16T09:19:13.553+0000] {processor.py:157} INFO - Started process (PID=32442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:19:13.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:19:13.556+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:19:13.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:19:13.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:19:13.592+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:19:13.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:19:13.633+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:19:13.633+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:19:13.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-16T09:19:44.039+0000] {processor.py:157} INFO - Started process (PID=32452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:19:44.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:19:44.049+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:19:44.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:19:44.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:19:44.120+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:19:44.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:19:44.139+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:19:44.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:19:44.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-16T09:20:14.531+0000] {processor.py:157} INFO - Started process (PID=32461) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:20:14.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:20:14.537+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:20:14.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:20:14.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:20:14.608+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:20:14.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:20:14.638+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:20:14.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:20:14.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-16T09:20:44.826+0000] {processor.py:157} INFO - Started process (PID=32472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:20:44.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:20:44.831+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:20:44.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:20:44.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:20:44.877+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:20:44.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:20:44.905+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:20:44.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:20:44.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-16T09:21:15.200+0000] {processor.py:157} INFO - Started process (PID=32482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:21:15.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:21:15.204+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:21:15.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:21:15.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:21:15.249+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:21:15.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:21:15.264+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:21:15.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:21:15.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-16T09:21:45.573+0000] {processor.py:157} INFO - Started process (PID=32492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:21:45.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:21:45.582+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:21:45.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:21:45.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:21:45.657+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:21:45.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:21:45.681+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:21:45.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:21:45.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-16T09:22:15.832+0000] {processor.py:157} INFO - Started process (PID=32501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:22:15.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:22:15.837+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:22:15.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:22:15.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:22:15.898+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:22:15.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:22:15.915+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:22:15.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:22:15.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-16T09:39:11.226+0000] {processor.py:157} INFO - Started process (PID=32513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:39:11.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:39:11.255+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:39:11.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:39:11.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:39:11.381+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:39:11.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:39:11.424+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:39:11.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:39:11.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.238 seconds
[2024-09-16T09:39:41.538+0000] {processor.py:157} INFO - Started process (PID=32524) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:39:41.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:39:41.550+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:39:41.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:39:41.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:39:41.616+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:39:41.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:39:41.639+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:39:41.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:39:41.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-16T09:40:11.920+0000] {processor.py:157} INFO - Started process (PID=32534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:40:11.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:40:11.925+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:40:11.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:40:11.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:40:11.976+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:40:11.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:40:12.003+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:40:12.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:40:12.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-16T09:40:42.427+0000] {processor.py:157} INFO - Started process (PID=32544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:40:42.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:40:42.432+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:40:42.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:40:42.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:40:42.463+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:40:42.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:40:42.477+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:40:42.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:40:42.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-16T09:41:12.744+0000] {processor.py:157} INFO - Started process (PID=32554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:41:12.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:41:12.753+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:41:12.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:41:12.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:41:12.798+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:41:12.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:41:12.815+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:41:12.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:41:12.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-16T09:41:43.254+0000] {processor.py:157} INFO - Started process (PID=32564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:41:43.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:41:43.263+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:41:43.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:41:43.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:41:43.310+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:41:43.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:41:43.344+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:41:43.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:41:43.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-16T09:57:55.940+0000] {processor.py:157} INFO - Started process (PID=32574) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:57:55.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T09:57:55.950+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:57:55.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:57:55.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T09:57:56.008+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:57:56.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T09:57:56.030+0000] {logging_mixin.py:151} INFO - [2024-09-16T09:57:56.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T09:57:56.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-16T10:00:47.101+0000] {processor.py:157} INFO - Started process (PID=32584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:00:47.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:00:47.112+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:00:47.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:00:47.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:00:47.168+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:00:47.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:00:47.186+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:00:47.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:00:47.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-16T10:01:17.626+0000] {processor.py:157} INFO - Started process (PID=32594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:01:17.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:01:17.634+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:01:17.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:01:17.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:01:17.705+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:01:17.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:01:17.722+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:01:17.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:01:17.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-16T10:01:48.114+0000] {processor.py:157} INFO - Started process (PID=32605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:01:48.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:01:48.116+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:01:48.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:01:48.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:01:48.150+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:01:48.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:01:48.174+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:01:48.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:01:48.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-16T10:02:18.632+0000] {processor.py:157} INFO - Started process (PID=32614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:02:18.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:02:18.637+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:02:18.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:02:18.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:02:18.711+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:02:18.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:02:18.728+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:02:18.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:02:18.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-16T10:02:48.949+0000] {processor.py:157} INFO - Started process (PID=32625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:02:48.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:02:48.955+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:02:48.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:02:48.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:02:49.005+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:02:49.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:02:49.019+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:02:49.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:02:49.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-16T10:03:19.398+0000] {processor.py:157} INFO - Started process (PID=32635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:03:19.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:03:19.423+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:03:19.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:03:19.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:03:19.487+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:03:19.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:03:19.504+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:03:19.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:03:19.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-16T10:03:49.813+0000] {processor.py:157} INFO - Started process (PID=32645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:03:49.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:03:49.816+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:03:49.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:03:49.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:03:49.858+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:03:49.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:03:49.883+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:03:49.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:03:49.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-16T10:04:20.240+0000] {processor.py:157} INFO - Started process (PID=32655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:04:20.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:04:20.244+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:04:20.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:04:20.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:04:20.292+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:04:20.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:04:20.308+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:04:20.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:04:20.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-16T10:04:50.717+0000] {processor.py:157} INFO - Started process (PID=32665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:04:50.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:04:50.722+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:04:50.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:04:50.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:04:50.787+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:04:50.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:04:50.803+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:04:50.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:04:50.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T10:05:21.187+0000] {processor.py:157} INFO - Started process (PID=32675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:05:21.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:05:21.193+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:05:21.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:05:21.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:05:21.262+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:05:21.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:05:21.294+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:05:21.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:05:21.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-16T10:05:51.643+0000] {processor.py:157} INFO - Started process (PID=32685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:05:51.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:05:51.654+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:05:51.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:05:51.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:05:51.699+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:05:51.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:05:51.728+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:05:51.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:05:51.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-16T10:06:22.102+0000] {processor.py:157} INFO - Started process (PID=32695) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:06:22.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:06:22.108+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:06:22.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:06:22.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:06:22.167+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:06:22.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:06:22.183+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:06:22.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:06:22.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-16T10:06:52.434+0000] {processor.py:157} INFO - Started process (PID=32705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:06:52.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:06:52.443+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:06:52.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:06:52.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:06:52.483+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:06:52.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:06:52.498+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:06:52.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:06:52.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-16T10:07:22.787+0000] {processor.py:157} INFO - Started process (PID=32715) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:07:22.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:07:22.792+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:07:22.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:07:22.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:07:22.859+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:07:22.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:07:22.891+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:07:22.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:07:22.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-16T10:07:53.163+0000] {processor.py:157} INFO - Started process (PID=32725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:07:53.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:07:53.167+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:07:53.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:07:53.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:07:53.221+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:07:53.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:07:53.237+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:07:53.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:07:53.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-16T10:08:23.553+0000] {processor.py:157} INFO - Started process (PID=32734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:08:23.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:08:23.563+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:08:23.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:08:23.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:08:23.619+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:08:23.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:08:23.641+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:08:23.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:08:23.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-16T10:08:53.943+0000] {processor.py:157} INFO - Started process (PID=32745) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:08:53.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:08:53.948+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:08:53.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:08:53.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:08:54.021+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:08:54.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:08:54.038+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:08:54.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:08:54.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-16T10:09:24.393+0000] {processor.py:157} INFO - Started process (PID=32754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:09:24.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:09:24.398+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:09:24.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:09:24.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:09:24.465+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:09:24.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:09:24.485+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:09:24.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:09:24.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-16T10:09:54.677+0000] {processor.py:157} INFO - Started process (PID=32765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:09:54.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:09:54.685+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:09:54.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:09:54.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:09:54.743+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:09:54.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:09:54.756+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:09:54.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:09:54.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-16T10:10:25.077+0000] {processor.py:157} INFO - Started process (PID=32774) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:10:25.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:10:25.084+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:10:25.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:10:25.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:10:25.141+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:10:25.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:10:25.158+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:10:25.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:10:25.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-16T10:10:55.492+0000] {processor.py:157} INFO - Started process (PID=32785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:10:55.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:10:55.496+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:10:55.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:10:55.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:10:55.539+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:10:55.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:10:55.560+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:10:55.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:10:55.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-16T10:11:26.029+0000] {processor.py:157} INFO - Started process (PID=32794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:11:26.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:11:26.038+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:11:26.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:11:26.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:11:26.108+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:11:26.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:11:26.125+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:11:26.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:11:26.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-16T10:11:56.453+0000] {processor.py:157} INFO - Started process (PID=32805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:11:56.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:11:56.457+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:11:56.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:11:56.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:11:56.494+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:11:56.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:11:56.515+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:11:56.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:11:56.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-16T10:12:26.842+0000] {processor.py:157} INFO - Started process (PID=32814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:12:26.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:12:26.865+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:12:26.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:12:26.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:12:26.921+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:12:26.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:12:26.941+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:12:26.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:12:26.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-16T10:12:57.390+0000] {processor.py:157} INFO - Started process (PID=32825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:12:57.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:12:57.394+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:12:57.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:12:57.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:12:57.456+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:12:57.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:12:57.470+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:12:57.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:12:57.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-16T10:13:27.795+0000] {processor.py:157} INFO - Started process (PID=32834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:13:27.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:13:27.801+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:13:27.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:13:27.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:13:27.873+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:13:27.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:13:27.907+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:13:27.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:13:27.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-16T10:13:58.140+0000] {processor.py:157} INFO - Started process (PID=32845) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:13:58.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:13:58.143+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:13:58.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:13:58.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:13:58.192+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:13:58.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:13:58.226+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:13:58.225+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:13:58.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-16T10:14:28.678+0000] {processor.py:157} INFO - Started process (PID=32855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:14:28.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:14:28.684+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:14:28.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:14:28.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:14:28.755+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:14:28.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:14:28.774+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:14:28.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:14:28.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-16T10:14:58.957+0000] {processor.py:157} INFO - Started process (PID=32865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:14:58.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:14:58.961+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:14:58.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:14:58.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:14:59.013+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:14:59.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:14:59.029+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:14:59.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:14:59.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-16T10:15:29.435+0000] {processor.py:157} INFO - Started process (PID=32875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:15:29.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:15:29.441+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:15:29.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:15:29.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:15:29.504+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:15:29.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:15:29.526+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:15:29.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:15:29.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-16T10:15:59.908+0000] {processor.py:157} INFO - Started process (PID=32884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:15:59.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:15:59.914+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:15:59.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:15:59.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:15:59.981+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:15:59.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:15:59.997+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:15:59.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:16:00.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-16T10:16:30.233+0000] {processor.py:157} INFO - Started process (PID=32895) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:16:30.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:16:30.237+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:16:30.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:16:30.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:16:30.287+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:16:30.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:16:30.313+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:16:30.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:16:30.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-16T10:17:00.611+0000] {processor.py:157} INFO - Started process (PID=32905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:17:00.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:17:00.614+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:17:00.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:17:00.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:17:00.655+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:17:00.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:17:00.700+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:17:00.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:17:00.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T10:17:30.947+0000] {processor.py:157} INFO - Started process (PID=32915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:17:30.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:17:30.961+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:17:30.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:17:30.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:17:31.011+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:17:31.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:17:31.033+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:17:31.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:17:31.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-16T10:18:01.310+0000] {processor.py:157} INFO - Started process (PID=32925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:18:01.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:18:01.315+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:18:01.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:18:01.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:18:01.364+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:18:01.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:18:01.388+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:18:01.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:18:01.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-16T10:18:31.777+0000] {processor.py:157} INFO - Started process (PID=32935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:18:31.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:18:31.783+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:18:31.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:18:31.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:18:31.839+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:18:31.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:18:31.870+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:18:31.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:18:31.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-16T10:19:02.106+0000] {processor.py:157} INFO - Started process (PID=32945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:19:02.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:19:02.112+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:19:02.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:19:02.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:19:02.171+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:19:02.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:19:02.201+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:19:02.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:19:02.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-16T10:19:32.550+0000] {processor.py:157} INFO - Started process (PID=32955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:19:32.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:19:32.553+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:19:32.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:19:32.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:19:32.608+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:19:32.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:19:32.631+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:19:32.631+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:19:32.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-16T10:20:02.913+0000] {processor.py:157} INFO - Started process (PID=32965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:20:02.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:20:02.920+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:20:02.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:20:02.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:20:03.007+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:20:03.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:20:03.037+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:20:03.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:20:03.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-16T10:20:33.224+0000] {processor.py:157} INFO - Started process (PID=32975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:20:33.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:20:33.260+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:20:33.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:20:33.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:20:33.334+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:20:33.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:20:33.352+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:20:33.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:20:33.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-16T10:21:03.762+0000] {processor.py:157} INFO - Started process (PID=32985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:21:03.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:21:03.767+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:21:03.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:21:03.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:21:03.808+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:21:03.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:21:03.842+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:21:03.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:21:03.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-16T10:21:34.263+0000] {processor.py:157} INFO - Started process (PID=32995) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:21:34.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:21:34.269+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:21:34.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:21:34.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:21:34.336+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:21:34.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:21:34.357+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:21:34.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:21:34.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-16T10:22:04.812+0000] {processor.py:157} INFO - Started process (PID=33005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:22:04.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:22:04.819+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:22:04.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:22:04.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:22:04.882+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:22:04.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:22:04.902+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:22:04.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:22:04.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-16T10:22:35.252+0000] {processor.py:157} INFO - Started process (PID=33015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:22:35.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:22:35.256+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:22:35.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:22:35.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:22:35.318+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:22:35.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:22:35.334+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:22:35.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:22:35.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-16T10:23:05.785+0000] {processor.py:157} INFO - Started process (PID=33025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:23:05.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:23:05.795+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:23:05.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:23:05.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:23:05.866+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:23:05.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:23:05.890+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:23:05.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:23:05.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-16T10:23:36.077+0000] {processor.py:157} INFO - Started process (PID=33035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:23:36.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:23:36.080+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:23:36.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:23:36.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:23:36.152+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:23:36.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:23:36.167+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:23:36.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:23:36.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-16T10:24:06.563+0000] {processor.py:157} INFO - Started process (PID=33044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:24:06.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:24:06.571+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:24:06.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:24:06.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:24:06.627+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:24:06.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:24:06.644+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:24:06.644+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:24:06.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-16T10:24:36.967+0000] {processor.py:157} INFO - Started process (PID=33055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:24:36.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:24:36.970+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:24:36.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:24:36.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:24:37.028+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:24:37.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:24:37.044+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:24:37.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:24:37.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-16T10:25:07.455+0000] {processor.py:157} INFO - Started process (PID=33064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:25:07.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:25:07.462+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:25:07.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:25:07.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:25:07.538+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:25:07.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:25:07.557+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:25:07.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:25:07.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-16T10:25:37.789+0000] {processor.py:157} INFO - Started process (PID=33075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:25:37.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:25:37.793+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:25:37.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:25:37.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:25:37.835+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:25:37.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:25:37.867+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:25:37.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:25:37.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-16T10:26:08.310+0000] {processor.py:157} INFO - Started process (PID=33085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:26:08.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:26:08.326+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:26:08.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:26:08.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:26:08.401+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:26:08.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:26:08.418+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:26:08.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:26:08.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-16T10:26:38.671+0000] {processor.py:157} INFO - Started process (PID=33094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:26:38.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:26:38.681+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:26:38.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:26:38.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:26:38.732+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:26:38.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:26:38.748+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:26:38.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:26:38.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-16T10:27:09.161+0000] {processor.py:157} INFO - Started process (PID=33105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:27:09.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:27:09.164+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:27:09.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:27:09.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:27:09.205+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:27:09.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:27:09.245+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:27:09.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:27:09.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-16T10:27:39.633+0000] {processor.py:157} INFO - Started process (PID=33113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:27:39.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:27:39.638+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:27:39.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:27:39.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:27:39.701+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:27:39.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:27:39.721+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:27:39.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:27:39.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-16T10:28:10.025+0000] {processor.py:157} INFO - Started process (PID=33125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:28:10.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:28:10.033+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:28:10.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:28:10.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:28:10.095+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:28:10.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:28:10.114+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:28:10.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:28:10.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-16T10:28:40.409+0000] {processor.py:157} INFO - Started process (PID=33135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:28:40.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:28:40.413+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:28:40.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:28:40.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:28:40.464+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:28:40.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:28:40.483+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:28:40.483+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:28:40.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-16T10:29:10.770+0000] {processor.py:157} INFO - Started process (PID=33145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:29:10.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:29:10.774+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:29:10.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:29:10.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:29:10.821+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:29:10.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:29:10.836+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:29:10.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:29:10.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-16T10:29:41.103+0000] {processor.py:157} INFO - Started process (PID=33155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:29:41.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:29:41.109+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:29:41.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:29:41.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:29:41.162+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:29:41.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:29:41.179+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:29:41.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:29:41.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-16T10:30:11.621+0000] {processor.py:157} INFO - Started process (PID=33165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:30:11.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:30:11.627+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:30:11.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:30:11.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:30:11.707+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:30:11.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:30:11.724+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:30:11.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:30:11.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-16T10:30:42.040+0000] {processor.py:157} INFO - Started process (PID=33175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:30:42.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:30:42.059+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:30:42.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:30:42.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:30:42.110+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:30:42.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:30:42.132+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:30:42.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:30:42.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-16T10:31:12.526+0000] {processor.py:157} INFO - Started process (PID=33185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:31:12.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:31:12.532+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:31:12.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:31:12.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:31:12.590+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:31:12.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:31:12.618+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:31:12.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:31:12.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-16T10:31:43.017+0000] {processor.py:157} INFO - Started process (PID=33195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:31:43.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:31:43.021+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:31:43.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:31:43.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:31:43.061+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:31:43.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:31:43.094+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:31:43.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:31:43.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-16T10:32:13.470+0000] {processor.py:157} INFO - Started process (PID=33205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:32:13.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:32:13.482+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:32:13.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:32:13.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:32:13.528+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:32:13.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:32:13.547+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:32:13.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:32:13.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-16T10:32:43.749+0000] {processor.py:157} INFO - Started process (PID=33215) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:32:43.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:32:43.754+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:32:43.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:32:43.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:32:43.814+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:32:43.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:32:43.831+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:32:43.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:32:43.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-16T10:33:14.255+0000] {processor.py:157} INFO - Started process (PID=33224) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:33:14.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:33:14.263+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:33:14.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:33:14.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:33:14.336+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:33:14.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:33:14.360+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:33:14.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:33:14.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-16T10:33:44.673+0000] {processor.py:157} INFO - Started process (PID=33235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:33:44.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:33:44.676+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:33:44.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:33:44.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:33:44.714+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:33:44.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:33:44.729+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:33:44.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:33:44.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-16T10:34:15.038+0000] {processor.py:157} INFO - Started process (PID=33245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:34:15.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:34:15.044+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:34:15.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:34:15.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:34:15.098+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:34:15.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:34:15.128+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:34:15.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:34:15.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-16T10:34:45.524+0000] {processor.py:157} INFO - Started process (PID=33255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:34:45.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:34:45.527+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:34:45.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:34:45.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:34:45.581+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:34:45.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:34:45.595+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:34:45.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:34:45.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-16T10:35:15.939+0000] {processor.py:157} INFO - Started process (PID=33265) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:35:15.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:35:15.963+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:35:15.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:35:15.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:35:16.027+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:35:16.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:35:16.054+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:35:16.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:35:16.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-16T10:35:46.411+0000] {processor.py:157} INFO - Started process (PID=33275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:35:46.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:35:46.417+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:35:46.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:35:46.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:35:46.485+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:35:46.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:35:46.500+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:35:46.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:35:46.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-16T10:36:16.902+0000] {processor.py:157} INFO - Started process (PID=33284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:36:16.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:36:16.908+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:36:16.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:36:16.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:36:16.972+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:36:16.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:36:16.998+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:36:16.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:36:17.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T10:36:47.414+0000] {processor.py:157} INFO - Started process (PID=33295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:36:47.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:36:47.420+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:36:47.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:36:47.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:36:47.467+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:36:47.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:36:47.484+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:36:47.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:36:47.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-16T10:37:17.754+0000] {processor.py:157} INFO - Started process (PID=33305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:37:17.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:37:17.757+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:37:17.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:37:17.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:37:17.806+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:37:17.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:37:17.819+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:37:17.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:37:17.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-16T10:37:48.296+0000] {processor.py:157} INFO - Started process (PID=33315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:37:48.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:37:48.310+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:37:48.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:37:48.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:37:48.366+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:37:48.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:37:48.395+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:37:48.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:37:48.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-16T10:38:18.630+0000] {processor.py:157} INFO - Started process (PID=33325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:38:18.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:38:18.640+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:38:18.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:38:18.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:38:18.707+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:38:18.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:38:18.724+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:38:18.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:38:18.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-16T10:38:49.022+0000] {processor.py:157} INFO - Started process (PID=33335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:38:49.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:38:49.027+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:38:49.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:38:49.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:38:49.063+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:38:49.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:38:49.092+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:38:49.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:38:49.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-16T10:39:19.531+0000] {processor.py:157} INFO - Started process (PID=33345) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:39:19.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:39:19.545+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:39:19.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:39:19.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:39:19.605+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:39:19.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:39:19.621+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:39:19.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:39:19.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-16T10:39:49.891+0000] {processor.py:157} INFO - Started process (PID=33355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:39:49.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:39:49.895+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:39:49.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:39:49.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:39:49.952+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:39:49.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:39:49.976+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:39:49.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:39:49.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-16T10:40:20.364+0000] {processor.py:157} INFO - Started process (PID=33365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:40:20.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:40:20.369+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:40:20.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:40:20.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:40:20.437+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:40:20.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:40:20.459+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:40:20.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:40:20.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-16T10:40:50.916+0000] {processor.py:157} INFO - Started process (PID=33374) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:40:50.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:40:50.923+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:40:50.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:40:50.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:40:50.969+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:40:50.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:40:50.997+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:40:50.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:40:51.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-16T10:41:21.226+0000] {processor.py:157} INFO - Started process (PID=33385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:41:21.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:41:21.236+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:41:21.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:41:21.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:41:21.299+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:41:21.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:41:21.320+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:41:21.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:41:21.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-16T10:41:51.615+0000] {processor.py:157} INFO - Started process (PID=33395) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:41:51.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:41:51.630+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:41:51.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:41:51.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:41:51.687+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:41:51.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:41:51.708+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:41:51.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:41:51.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-16T10:42:22.050+0000] {processor.py:157} INFO - Started process (PID=33405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:42:22.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:42:22.061+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:42:22.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:42:22.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:42:22.106+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:42:22.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:42:22.137+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:42:22.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:42:22.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-16T10:42:52.435+0000] {processor.py:157} INFO - Started process (PID=33415) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:42:52.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:42:52.440+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:42:52.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:42:52.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:42:52.500+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:42:52.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:42:52.519+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:42:52.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:42:52.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-16T10:43:22.918+0000] {processor.py:157} INFO - Started process (PID=33425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:43:22.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:43:22.940+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:43:22.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:43:22.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:43:22.985+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:43:22.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:43:23.001+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:43:23.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:43:23.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-16T10:43:53.331+0000] {processor.py:157} INFO - Started process (PID=33435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:43:53.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:43:53.342+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:43:53.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:43:53.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:43:53.393+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:43:53.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:43:53.431+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:43:53.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:43:53.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-16T10:44:23.717+0000] {processor.py:157} INFO - Started process (PID=33445) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:44:23.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:44:23.723+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:44:23.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:44:23.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:44:23.792+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:44:23.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:44:23.830+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:44:23.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:44:23.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-16T10:44:54.179+0000] {processor.py:157} INFO - Started process (PID=33455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:44:54.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:44:54.182+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:44:54.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:44:54.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:44:54.238+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:44:54.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:44:54.257+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:44:54.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:44:54.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-16T10:45:24.623+0000] {processor.py:157} INFO - Started process (PID=33464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:45:24.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:45:24.629+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:45:24.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:45:24.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:45:24.706+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:45:24.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:45:24.736+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:45:24.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:45:24.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-16T10:45:55.064+0000] {processor.py:157} INFO - Started process (PID=33475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:45:55.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:45:55.068+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:45:55.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:45:55.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:45:55.140+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:45:55.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:45:55.189+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:45:55.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:45:55.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-16T10:46:25.593+0000] {processor.py:157} INFO - Started process (PID=33485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:46:25.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:46:25.600+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:46:25.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:46:25.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:46:25.684+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:46:25.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:46:25.703+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:46:25.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:46:25.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-16T10:46:56.018+0000] {processor.py:157} INFO - Started process (PID=33495) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:46:56.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:46:56.020+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:46:56.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:46:56.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:46:56.058+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:46:56.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:46:56.085+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:46:56.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:46:56.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-16T10:47:26.551+0000] {processor.py:157} INFO - Started process (PID=33505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:47:26.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:47:26.567+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:47:26.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:47:26.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:47:26.628+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:47:26.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:47:26.647+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:47:26.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:47:26.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-16T10:47:57.036+0000] {processor.py:157} INFO - Started process (PID=33515) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:47:57.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:47:57.040+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:47:57.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:47:57.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:47:57.097+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:47:57.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:47:57.115+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:47:57.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:47:57.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-16T10:48:27.539+0000] {processor.py:157} INFO - Started process (PID=33525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:48:27.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:48:27.555+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:48:27.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:48:27.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:48:27.625+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:48:27.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:48:27.645+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:48:27.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:48:27.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-16T10:48:57.937+0000] {processor.py:157} INFO - Started process (PID=33535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:48:57.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:48:57.943+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:48:57.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:48:57.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:48:58.018+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:48:58.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:48:58.039+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:48:58.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:48:58.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-16T10:49:28.385+0000] {processor.py:157} INFO - Started process (PID=33545) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:49:28.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:49:28.390+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:49:28.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:49:28.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:49:28.457+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:49:28.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:49:28.483+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:49:28.483+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:49:28.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T10:49:58.758+0000] {processor.py:157} INFO - Started process (PID=33554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:49:58.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:49:58.769+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:49:58.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:49:58.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:49:58.842+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:49:58.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:49:58.859+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:49:58.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:49:58.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-16T10:50:29.199+0000] {processor.py:157} INFO - Started process (PID=33565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:50:29.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:50:29.206+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:50:29.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:50:29.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:50:29.275+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:50:29.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:50:29.291+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:50:29.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:50:29.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-16T10:50:59.549+0000] {processor.py:157} INFO - Started process (PID=33575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:50:59.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:50:59.554+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:50:59.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:50:59.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:50:59.621+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:50:59.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:50:59.637+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:50:59.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:50:59.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-16T10:51:30.049+0000] {processor.py:157} INFO - Started process (PID=33585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:51:30.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:51:30.051+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:51:30.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:51:30.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:51:30.114+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:51:30.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:51:30.135+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:51:30.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:51:30.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-16T10:52:00.410+0000] {processor.py:157} INFO - Started process (PID=33595) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:52:00.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:52:00.415+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:52:00.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:52:00.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:52:00.457+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:52:00.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:52:00.485+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:52:00.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:52:00.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-16T10:52:30.767+0000] {processor.py:157} INFO - Started process (PID=33605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:52:30.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:52:30.769+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:52:30.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:52:30.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:52:30.839+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:52:30.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:52:30.857+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:52:30.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:52:30.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-16T10:53:01.208+0000] {processor.py:157} INFO - Started process (PID=33615) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:53:01.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:53:01.213+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:53:01.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:53:01.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:53:01.282+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:53:01.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:53:01.302+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:53:01.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:53:01.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-16T10:53:31.597+0000] {processor.py:157} INFO - Started process (PID=33624) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:53:31.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:53:31.603+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:53:31.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:53:31.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:53:31.673+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:53:31.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:53:31.697+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:53:31.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:53:31.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-16T10:54:01.855+0000] {processor.py:157} INFO - Started process (PID=33635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:54:01.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:54:01.859+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:54:01.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:54:01.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:54:01.918+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:54:01.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:54:01.937+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:54:01.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:54:01.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-16T10:54:32.370+0000] {processor.py:157} INFO - Started process (PID=33645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:54:32.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:54:32.396+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:54:32.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:54:32.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:54:32.465+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:54:32.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:54:32.482+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:54:32.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:54:32.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-16T10:55:02.699+0000] {processor.py:157} INFO - Started process (PID=33655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:55:02.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:55:02.703+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:55:02.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:55:02.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:55:02.755+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:55:02.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:55:02.769+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:55:02.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:55:02.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-16T10:55:33.138+0000] {processor.py:157} INFO - Started process (PID=33665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:55:33.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:55:33.143+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:55:33.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:55:33.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:55:33.206+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:55:33.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:55:33.224+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:55:33.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:55:33.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T10:56:03.592+0000] {processor.py:157} INFO - Started process (PID=33675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:56:03.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:56:03.599+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:56:03.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:56:03.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:56:03.645+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:56:03.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:56:03.680+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:56:03.680+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:56:03.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-16T10:56:33.927+0000] {processor.py:157} INFO - Started process (PID=33685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:56:33.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:56:33.932+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:56:33.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:56:33.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:56:33.989+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:56:33.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:56:34.014+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:56:34.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:56:34.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-16T10:57:04.302+0000] {processor.py:157} INFO - Started process (PID=33695) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:57:04.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:57:04.308+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:57:04.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:57:04.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:57:04.353+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:57:04.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:57:04.384+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:57:04.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:57:04.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-16T10:57:34.637+0000] {processor.py:157} INFO - Started process (PID=33705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:57:34.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:57:34.640+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:57:34.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:57:34.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:57:34.684+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:57:34.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:57:34.724+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:57:34.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:57:34.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-16T10:58:05.092+0000] {processor.py:157} INFO - Started process (PID=33714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:58:05.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:58:05.116+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:58:05.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:58:05.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:58:05.174+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:58:05.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:58:05.200+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:58:05.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:58:05.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-16T10:58:35.590+0000] {processor.py:157} INFO - Started process (PID=33725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:58:35.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:58:35.598+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:58:35.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:58:35.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:58:35.660+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:58:35.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:58:35.677+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:58:35.677+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:58:35.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-16T10:59:05.987+0000] {processor.py:157} INFO - Started process (PID=33735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:59:05.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:59:05.990+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:59:05.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:59:06.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:59:06.044+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:59:06.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:59:06.061+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:59:06.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:59:06.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-16T10:59:36.520+0000] {processor.py:157} INFO - Started process (PID=33744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:59:36.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T10:59:36.531+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:59:36.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:59:36.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T10:59:36.596+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:59:36.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T10:59:36.610+0000] {logging_mixin.py:151} INFO - [2024-09-16T10:59:36.610+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T10:59:36.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-16T11:00:06.857+0000] {processor.py:157} INFO - Started process (PID=33755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:00:06.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:00:06.863+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:00:06.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:00:06.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:00:06.899+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:00:06.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:00:06.921+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:00:06.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:00:06.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-16T11:00:37.292+0000] {processor.py:157} INFO - Started process (PID=33765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:00:37.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:00:37.302+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:00:37.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:00:37.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:00:37.358+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:00:37.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:00:37.388+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:00:37.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:00:37.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-16T11:01:07.615+0000] {processor.py:157} INFO - Started process (PID=33775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:01:07.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:01:07.622+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:01:07.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:01:07.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:01:07.695+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:01:07.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:01:07.712+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:01:07.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:01:07.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-16T11:01:38.113+0000] {processor.py:157} INFO - Started process (PID=33785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:01:38.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:01:38.118+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:01:38.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:01:38.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:01:38.153+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:01:38.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:01:38.189+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:01:38.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:01:38.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-16T11:02:08.443+0000] {processor.py:157} INFO - Started process (PID=33794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:02:08.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:02:08.450+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:02:08.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:02:08.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:02:08.512+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:02:08.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:02:08.542+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:02:08.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:02:08.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-16T11:02:38.958+0000] {processor.py:157} INFO - Started process (PID=33805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:02:38.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:02:38.964+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:02:38.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:02:38.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:02:39.005+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:02:39.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:02:39.037+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:02:39.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:02:39.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-16T11:03:09.400+0000] {processor.py:157} INFO - Started process (PID=33815) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:03:09.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:03:09.406+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:03:09.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:03:09.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:03:09.465+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:03:09.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:03:09.482+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:03:09.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:03:09.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-16T11:03:39.892+0000] {processor.py:157} INFO - Started process (PID=33825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:03:39.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:03:39.896+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:03:39.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:03:39.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:03:39.955+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:03:39.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:03:39.970+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:03:39.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:03:39.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-16T11:04:10.227+0000] {processor.py:157} INFO - Started process (PID=33835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:04:10.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:04:10.241+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:04:10.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:04:10.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:04:10.307+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:04:10.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:04:10.325+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:04:10.325+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:04:10.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-16T11:04:40.493+0000] {processor.py:157} INFO - Started process (PID=33845) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:04:40.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:04:40.497+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:04:40.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:04:40.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:04:40.551+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:04:40.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:04:40.580+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:04:40.579+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:04:40.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-16T11:05:11.037+0000] {processor.py:157} INFO - Started process (PID=33855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:05:11.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:05:11.043+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:05:11.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:05:11.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:05:11.118+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:05:11.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:05:11.135+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:05:11.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:05:11.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-16T11:05:41.402+0000] {processor.py:157} INFO - Started process (PID=33865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:05:41.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:05:41.410+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:05:41.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:05:41.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:05:41.460+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:05:41.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:05:41.476+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:05:41.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:05:41.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-16T11:06:11.886+0000] {processor.py:157} INFO - Started process (PID=33875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:06:11.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:06:11.893+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:06:11.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:06:11.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:06:11.960+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:06:11.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:06:11.997+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:06:11.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:06:12.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-16T11:06:42.288+0000] {processor.py:157} INFO - Started process (PID=33885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:06:42.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:06:42.292+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:06:42.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:06:42.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:06:42.337+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:06:42.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:06:42.362+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:06:42.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:06:42.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-16T11:07:12.638+0000] {processor.py:157} INFO - Started process (PID=33895) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:07:12.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:07:12.642+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:07:12.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:07:12.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:07:12.697+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:07:12.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:07:12.742+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:07:12.742+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:07:12.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-16T11:07:43.076+0000] {processor.py:157} INFO - Started process (PID=33905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:07:43.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:07:43.082+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:07:43.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:07:43.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:07:43.127+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:07:43.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:07:43.155+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:07:43.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:07:43.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-16T11:08:13.368+0000] {processor.py:157} INFO - Started process (PID=33915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:08:13.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:08:13.375+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:08:13.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:08:13.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:08:13.426+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:08:13.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:08:13.441+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:08:13.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:08:13.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-16T11:08:43.723+0000] {processor.py:157} INFO - Started process (PID=33925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:08:43.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:08:43.726+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:08:43.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:08:43.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:08:43.786+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:08:43.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:08:43.805+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:08:43.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:08:43.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-16T11:09:14.185+0000] {processor.py:157} INFO - Started process (PID=33934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:09:14.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:09:14.210+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:09:14.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:09:14.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:09:14.277+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:09:14.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:09:14.298+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:09:14.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:09:14.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-16T11:09:44.663+0000] {processor.py:157} INFO - Started process (PID=33945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:09:44.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:09:44.667+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:09:44.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:09:44.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:09:44.728+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:09:44.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:09:44.757+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:09:44.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:09:44.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-16T11:10:15.056+0000] {processor.py:157} INFO - Started process (PID=33955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:10:15.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:10:15.062+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:10:15.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:10:15.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:10:15.140+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:10:15.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:10:15.165+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:10:15.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:10:15.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-16T11:10:45.590+0000] {processor.py:157} INFO - Started process (PID=33965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:10:45.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:10:45.593+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:10:45.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:10:45.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:10:45.634+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:10:45.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:10:45.659+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:10:45.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:10:45.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-16T11:11:16.053+0000] {processor.py:157} INFO - Started process (PID=33975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:11:16.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:11:16.081+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:11:16.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:11:16.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:11:16.136+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:11:16.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:11:16.168+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:11:16.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:11:16.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-16T11:11:46.397+0000] {processor.py:157} INFO - Started process (PID=33985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:11:46.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:11:46.402+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:11:46.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:11:46.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:11:46.446+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:11:46.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:11:46.474+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:11:46.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:11:46.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-16T11:12:16.763+0000] {processor.py:157} INFO - Started process (PID=33995) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:12:16.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:12:16.771+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:12:16.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:12:16.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:12:16.842+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:12:16.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:12:16.864+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:12:16.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:12:16.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-16T11:12:47.173+0000] {processor.py:157} INFO - Started process (PID=34005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:12:47.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:12:47.197+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:12:47.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:12:47.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:12:47.245+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:12:47.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:12:47.275+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:12:47.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:12:47.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-16T11:13:17.542+0000] {processor.py:157} INFO - Started process (PID=34015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:13:17.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:13:17.547+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:13:17.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:13:17.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:13:17.596+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:13:17.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:13:17.618+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:13:17.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:13:17.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-16T11:13:47.969+0000] {processor.py:157} INFO - Started process (PID=34025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:13:47.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:13:47.974+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:13:47.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:13:47.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:13:48.046+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:13:48.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:13:48.070+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:13:48.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:13:48.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-16T11:14:18.443+0000] {processor.py:157} INFO - Started process (PID=34035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:14:18.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:14:18.449+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:14:18.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:14:18.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:14:18.509+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:14:18.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:14:18.526+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:14:18.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:14:18.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-16T11:14:48.802+0000] {processor.py:157} INFO - Started process (PID=34045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:14:48.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:14:48.807+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:14:48.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:14:48.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:14:48.872+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:14:48.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:14:48.900+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:14:48.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:14:48.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-16T11:15:19.240+0000] {processor.py:157} INFO - Started process (PID=34055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:15:19.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:15:19.247+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:15:19.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:15:19.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:15:19.298+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:15:19.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:15:19.337+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:15:19.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:15:19.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-16T11:15:49.597+0000] {processor.py:157} INFO - Started process (PID=34065) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:15:49.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:15:49.599+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:15:49.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:15:49.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:15:49.633+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:15:49.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:15:49.670+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:15:49.670+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:15:49.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-16T11:16:20.100+0000] {processor.py:157} INFO - Started process (PID=34075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:16:20.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:16:20.118+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:16:20.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:16:20.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:16:20.196+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:16:20.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:16:20.216+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:16:20.216+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:16:20.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-16T11:16:50.447+0000] {processor.py:157} INFO - Started process (PID=34085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:16:50.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:16:50.452+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:16:50.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:16:50.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:16:50.494+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:16:50.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:16:50.512+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:16:50.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:16:50.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-16T11:17:20.939+0000] {processor.py:157} INFO - Started process (PID=34095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:17:20.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:17:20.944+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:17:20.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:17:20.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:17:21.017+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:17:21.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:17:21.034+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:17:21.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:17:21.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-16T11:17:51.292+0000] {processor.py:157} INFO - Started process (PID=34105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:17:51.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:17:51.296+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:17:51.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:17:51.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:17:51.360+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:17:51.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:17:51.377+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:17:51.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:17:51.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-16T11:18:21.799+0000] {processor.py:157} INFO - Started process (PID=34115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:18:21.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:18:21.804+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:18:21.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:18:21.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:18:21.888+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:18:21.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:18:21.912+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:18:21.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:18:21.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-16T11:18:52.143+0000] {processor.py:157} INFO - Started process (PID=34125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:18:52.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:18:52.146+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:18:52.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:18:52.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:18:52.210+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:18:52.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:18:52.229+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:18:52.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:18:52.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-16T11:19:22.650+0000] {processor.py:157} INFO - Started process (PID=34135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:19:22.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:19:22.653+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:19:22.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:19:22.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:19:22.702+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:19:22.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:19:22.729+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:19:22.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:19:22.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-16T11:19:53.050+0000] {processor.py:157} INFO - Started process (PID=34144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:19:53.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:19:53.058+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:19:53.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:19:53.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:19:53.124+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:19:53.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:19:53.144+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:19:53.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:19:53.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T11:20:23.431+0000] {processor.py:157} INFO - Started process (PID=34155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:20:23.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:20:23.441+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:20:23.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:20:23.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:20:23.511+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:20:23.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:20:23.530+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:20:23.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:20:23.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-16T11:20:53.902+0000] {processor.py:157} INFO - Started process (PID=34165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:20:53.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:20:53.907+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:20:53.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:20:53.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:20:53.951+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:20:53.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:20:53.969+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:20:53.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:20:53.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-16T11:21:24.298+0000] {processor.py:157} INFO - Started process (PID=34175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:21:24.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:21:24.302+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:21:24.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:21:24.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:21:24.353+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:21:24.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:21:24.371+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:21:24.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:21:24.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-16T11:21:54.828+0000] {processor.py:157} INFO - Started process (PID=34185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:21:54.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:21:54.836+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:21:54.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:21:54.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:21:54.891+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:21:54.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:21:54.919+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:21:54.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:21:54.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-16T11:22:25.323+0000] {processor.py:157} INFO - Started process (PID=34195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:22:25.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:22:25.329+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:22:25.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:22:25.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:22:25.389+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:22:25.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:22:25.413+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:22:25.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:22:25.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T11:22:55.784+0000] {processor.py:157} INFO - Started process (PID=34205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:22:55.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:22:55.789+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:22:55.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:22:55.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:22:55.849+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:22:55.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:22:55.881+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:22:55.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:22:55.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-16T11:23:26.311+0000] {processor.py:157} INFO - Started process (PID=34214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:23:26.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:23:26.319+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:23:26.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:23:26.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:23:26.387+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:23:26.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:23:26.405+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:23:26.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:23:26.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-16T11:23:56.657+0000] {processor.py:157} INFO - Started process (PID=34225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:23:56.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:23:56.660+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:23:56.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:23:56.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:23:56.699+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:23:56.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:23:56.735+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:23:56.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:23:56.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-16T11:24:27.130+0000] {processor.py:157} INFO - Started process (PID=34234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:24:27.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:24:27.135+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:24:27.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:24:27.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:24:27.204+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:24:27.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:24:27.221+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:24:27.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:24:27.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-16T11:24:57.522+0000] {processor.py:157} INFO - Started process (PID=34245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:24:57.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:24:57.529+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:24:57.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:24:57.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:24:57.588+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:24:57.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:24:57.604+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:24:57.604+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:24:57.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-16T11:25:27.914+0000] {processor.py:157} INFO - Started process (PID=34255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:25:27.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:25:27.917+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:25:27.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:25:27.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:25:27.956+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:25:27.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:25:27.974+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:25:27.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:25:27.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-16T11:25:58.341+0000] {processor.py:157} INFO - Started process (PID=34264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:25:58.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:25:58.345+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:25:58.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:25:58.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:25:58.402+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:25:58.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:25:58.416+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:25:58.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:25:58.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-16T11:26:28.807+0000] {processor.py:157} INFO - Started process (PID=34275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:26:28.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:26:28.811+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:26:28.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:26:28.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:26:28.872+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:26:28.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:26:28.886+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:26:28.886+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:26:28.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-16T11:26:59.119+0000] {processor.py:157} INFO - Started process (PID=34284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:26:59.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:26:59.130+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:26:59.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:26:59.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:26:59.189+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:26:59.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:26:59.221+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:26:59.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:26:59.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-16T11:27:29.415+0000] {processor.py:157} INFO - Started process (PID=34295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:27:29.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:27:29.418+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:27:29.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:27:29.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:27:29.458+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:27:29.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:27:29.473+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:27:29.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:27:29.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-16T11:27:59.817+0000] {processor.py:157} INFO - Started process (PID=34305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:27:59.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:27:59.825+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:27:59.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:27:59.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:27:59.852+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:27:59.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:27:59.862+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:27:59.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:27:59.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-16T11:28:30.243+0000] {processor.py:157} INFO - Started process (PID=34315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:28:30.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:28:30.247+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:28:30.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:28:30.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:28:30.279+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:28:30.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:28:30.290+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:28:30.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:28:30.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-16T11:29:00.613+0000] {processor.py:157} INFO - Started process (PID=34325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:29:00.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:29:00.616+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:29:00.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:29:00.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:29:00.644+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:29:00.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:29:00.654+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:29:00.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:29:00.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-16T11:29:31.035+0000] {processor.py:157} INFO - Started process (PID=34335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:29:31.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:29:31.044+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:29:31.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:29:31.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:29:31.098+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:29:31.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:29:31.130+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:29:31.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:29:31.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-16T11:30:01.378+0000] {processor.py:157} INFO - Started process (PID=34345) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:30:01.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:30:01.380+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:30:01.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:30:01.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:30:01.409+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:30:01.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:30:01.441+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:30:01.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:30:01.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-16T11:30:31.820+0000] {processor.py:157} INFO - Started process (PID=34355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:30:31.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:30:31.825+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:30:31.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:30:31.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:30:31.864+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:30:31.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:30:31.878+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:30:31.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:30:31.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-16T11:31:02.240+0000] {processor.py:157} INFO - Started process (PID=34365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:31:02.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:31:02.244+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:31:02.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:31:02.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:31:02.273+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:31:02.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:31:02.285+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:31:02.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:31:02.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-16T11:31:32.636+0000] {processor.py:157} INFO - Started process (PID=34375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:31:32.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:31:32.641+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:31:32.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:31:32.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:31:32.677+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:31:32.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:31:32.691+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:31:32.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:31:32.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-16T11:32:03.020+0000] {processor.py:157} INFO - Started process (PID=34385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:32:03.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:32:03.024+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:32:03.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:32:03.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:32:03.056+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:32:03.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:32:03.070+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:32:03.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:32:03.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-16T11:32:33.440+0000] {processor.py:157} INFO - Started process (PID=34395) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:32:33.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:32:33.444+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:32:33.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:32:33.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:32:33.480+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:32:33.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:32:33.496+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:32:33.496+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:32:33.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-16T11:33:03.866+0000] {processor.py:157} INFO - Started process (PID=34405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:33:03.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:33:03.870+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:33:03.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:33:03.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:33:03.902+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:33:03.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:33:03.914+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:33:03.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:33:03.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-16T11:33:34.246+0000] {processor.py:157} INFO - Started process (PID=34415) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:33:34.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:33:34.250+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:33:34.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:33:34.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:33:34.305+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:33:34.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:33:34.324+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:33:34.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:33:34.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-16T11:34:04.603+0000] {processor.py:157} INFO - Started process (PID=34425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:34:04.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:34:04.607+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:34:04.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:34:04.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:34:04.647+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:34:04.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:34:04.666+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:34:04.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:34:04.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-16T11:34:35.034+0000] {processor.py:157} INFO - Started process (PID=34435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:34:35.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:34:35.040+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:34:35.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:34:35.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:34:35.081+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:34:35.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:34:35.097+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:34:35.097+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:34:35.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-16T11:35:05.373+0000] {processor.py:157} INFO - Started process (PID=34445) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:35:05.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:35:05.376+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:35:05.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:35:05.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:35:05.409+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:35:05.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:35:05.422+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:35:05.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:35:05.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-16T11:35:35.753+0000] {processor.py:157} INFO - Started process (PID=34455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:35:35.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:35:35.757+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:35:35.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:35:35.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:35:35.792+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:35:35.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:35:35.803+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:35:35.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:35:35.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-16T11:36:06.055+0000] {processor.py:157} INFO - Started process (PID=34465) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:36:06.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:36:06.059+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:36:06.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:36:06.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:36:06.093+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:36:06.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:36:06.106+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:36:06.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:36:06.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-16T11:36:36.500+0000] {processor.py:157} INFO - Started process (PID=34475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:36:36.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:36:36.503+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:36:36.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:36:36.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:36:36.533+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:36:36.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:36:36.548+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:36:36.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:36:36.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-16T11:37:06.920+0000] {processor.py:157} INFO - Started process (PID=34485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:37:06.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:37:06.925+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:37:06.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:37:06.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:37:06.963+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:37:06.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:37:06.978+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:37:06.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:37:06.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-16T11:37:37.348+0000] {processor.py:157} INFO - Started process (PID=34495) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:37:37.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:37:37.352+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:37:37.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:37:37.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:37:37.393+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:37:37.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:37:37.423+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:37:37.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:37:37.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-16T11:38:07.725+0000] {processor.py:157} INFO - Started process (PID=34505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:38:07.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:38:07.728+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:38:07.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:38:07.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:38:07.759+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:38:07.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:38:07.773+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:38:07.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:38:07.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-16T11:38:38.055+0000] {processor.py:157} INFO - Started process (PID=34515) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:38:38.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:38:38.060+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:38:38.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:38:38.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:38:38.097+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:38:38.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:38:38.111+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:38:38.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:38:38.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-16T11:39:08.388+0000] {processor.py:157} INFO - Started process (PID=34525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:39:08.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:39:08.393+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:39:08.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:39:08.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:39:08.430+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:39:08.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:39:08.441+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:39:08.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:39:08.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-16T11:39:38.803+0000] {processor.py:157} INFO - Started process (PID=34535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:39:38.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:39:38.808+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:39:38.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:39:38.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:39:38.842+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:39:38.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:39:38.857+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:39:38.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:39:38.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-16T11:40:09.104+0000] {processor.py:157} INFO - Started process (PID=34545) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:40:09.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:40:09.108+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:40:09.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:40:09.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:40:09.148+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:40:09.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:40:09.162+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:40:09.162+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:40:09.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-16T11:40:39.384+0000] {processor.py:157} INFO - Started process (PID=34555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:40:39.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:40:39.388+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:40:39.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:40:39.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:40:39.425+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:40:39.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:40:39.439+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:40:39.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:40:39.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-16T11:41:09.796+0000] {processor.py:157} INFO - Started process (PID=34565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:41:09.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:41:09.799+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:41:09.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:41:09.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:41:09.848+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:41:09.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:41:09.859+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:41:09.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:41:09.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-16T11:41:40.247+0000] {processor.py:157} INFO - Started process (PID=34575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:41:40.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:41:40.252+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:41:40.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:41:40.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:41:40.288+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:41:40.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:41:40.299+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:41:40.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:41:40.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-16T11:42:10.587+0000] {processor.py:157} INFO - Started process (PID=34585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:42:10.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:42:10.593+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:42:10.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:42:10.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:42:10.633+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:42:10.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:42:10.649+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:42:10.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:42:10.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-16T11:42:40.906+0000] {processor.py:157} INFO - Started process (PID=34595) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:42:40.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:42:40.909+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:42:40.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:42:40.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:42:40.944+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:42:40.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:42:40.963+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:42:40.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:42:40.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-16T11:43:11.361+0000] {processor.py:157} INFO - Started process (PID=34605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:43:11.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:43:11.365+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:43:11.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:43:11.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:43:11.402+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:43:11.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:43:11.416+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:43:11.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:43:11.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-16T11:43:41.772+0000] {processor.py:157} INFO - Started process (PID=34615) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:43:41.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:43:41.776+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:43:41.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:43:41.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:43:41.813+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:43:41.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:43:41.832+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:43:41.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:43:41.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-16T11:44:12.235+0000] {processor.py:157} INFO - Started process (PID=34625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:44:12.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:44:12.237+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:44:12.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:44:12.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:44:12.278+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:44:12.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:44:12.293+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:44:12.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:44:12.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-16T11:44:42.610+0000] {processor.py:157} INFO - Started process (PID=34635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:44:42.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:44:42.612+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:44:42.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:44:42.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:44:42.642+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:44:42.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:44:42.652+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:44:42.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:44:42.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-16T11:45:13.114+0000] {processor.py:157} INFO - Started process (PID=34645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:45:13.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:45:13.122+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:45:13.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:45:13.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:45:13.167+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:45:13.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:45:13.182+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:45:13.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:45:13.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-16T11:45:43.522+0000] {processor.py:157} INFO - Started process (PID=34655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:45:43.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:45:43.525+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:45:43.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:45:43.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:45:43.564+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:45:43.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:45:43.589+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:45:43.589+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:45:43.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-16T11:46:13.928+0000] {processor.py:157} INFO - Started process (PID=34665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:46:13.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:46:13.932+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:46:13.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:46:13.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:46:13.967+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:46:13.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:46:13.979+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:46:13.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:46:13.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-16T11:46:44.321+0000] {processor.py:157} INFO - Started process (PID=34675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:46:44.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:46:44.326+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:46:44.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:46:44.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:46:44.367+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:46:44.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:46:44.378+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:46:44.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:46:44.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-16T11:47:14.661+0000] {processor.py:157} INFO - Started process (PID=34685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:47:14.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:47:14.664+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:47:14.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:47:14.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:47:14.699+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:47:14.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:47:14.710+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:47:14.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:47:14.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-16T11:47:45.080+0000] {processor.py:157} INFO - Started process (PID=34695) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:47:45.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:47:45.084+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:47:45.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:47:45.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:47:45.139+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:47:45.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:47:45.154+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:47:45.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:47:45.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-16T11:48:15.486+0000] {processor.py:157} INFO - Started process (PID=34705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:48:15.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:48:15.493+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:48:15.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:48:15.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:48:15.581+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:48:15.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:48:15.601+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:48:15.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:48:15.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-16T11:48:46.012+0000] {processor.py:157} INFO - Started process (PID=34715) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:48:46.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:48:46.015+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:48:46.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:48:46.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:48:46.055+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:48:46.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:48:46.100+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:48:46.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:48:46.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T11:49:16.366+0000] {processor.py:157} INFO - Started process (PID=34725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:49:16.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:49:16.374+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:49:16.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:49:16.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:49:16.405+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:49:16.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:49:16.427+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:49:16.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:49:16.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-16T11:49:46.722+0000] {processor.py:157} INFO - Started process (PID=34735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:49:46.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:49:46.727+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:49:46.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:49:46.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:49:46.773+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:49:46.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:49:46.791+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:49:46.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:49:46.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-16T11:50:17.201+0000] {processor.py:157} INFO - Started process (PID=34745) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:50:17.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:50:17.205+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:50:17.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:50:17.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:50:17.264+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:50:17.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:50:17.280+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:50:17.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:50:17.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-16T11:50:47.650+0000] {processor.py:157} INFO - Started process (PID=34755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:50:47.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:50:47.654+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:50:47.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:50:47.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:50:47.709+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:50:47.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:50:47.724+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:50:47.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:50:47.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-16T11:51:17.999+0000] {processor.py:157} INFO - Started process (PID=34764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:51:18.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:51:18.004+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:51:18.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:51:18.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:51:18.048+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:51:18.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:51:18.077+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:51:18.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:51:18.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-16T11:51:48.370+0000] {processor.py:157} INFO - Started process (PID=34775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:51:48.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:51:48.373+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:51:48.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:51:48.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:51:48.414+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:51:48.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:51:48.433+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:51:48.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:51:48.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-16T11:52:18.833+0000] {processor.py:157} INFO - Started process (PID=34785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:52:18.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:52:18.841+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:52:18.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:52:18.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:52:18.905+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:52:18.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:52:18.924+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:52:18.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:52:18.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-16T11:52:49.313+0000] {processor.py:157} INFO - Started process (PID=34795) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:52:49.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:52:49.318+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:52:49.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:52:49.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:52:49.366+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:52:49.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:52:49.385+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:52:49.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:52:49.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-16T11:53:19.749+0000] {processor.py:157} INFO - Started process (PID=34805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:53:19.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:53:19.754+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:53:19.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:53:19.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:53:19.813+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:53:19.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:53:19.828+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:53:19.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:53:19.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-16T11:53:50.182+0000] {processor.py:157} INFO - Started process (PID=34815) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:53:50.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:53:50.185+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:53:50.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:53:50.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:53:50.224+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:53:50.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:53:50.240+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:53:50.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:53:50.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-16T11:54:20.597+0000] {processor.py:157} INFO - Started process (PID=34825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:54:20.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:54:20.601+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:54:20.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:54:20.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:54:20.631+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:54:20.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:54:20.642+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:54:20.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:54:20.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-16T11:54:50.954+0000] {processor.py:157} INFO - Started process (PID=34835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:54:50.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:54:50.958+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:54:50.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:54:50.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:54:50.988+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:54:50.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:54:51.000+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:54:51.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:54:51.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-16T11:55:21.399+0000] {processor.py:157} INFO - Started process (PID=34845) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:55:21.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:55:21.404+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:55:21.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:55:21.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:55:21.440+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:55:21.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:55:21.452+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:55:21.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:55:21.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-16T11:55:51.800+0000] {processor.py:157} INFO - Started process (PID=34855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:55:51.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:55:51.804+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:55:51.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:55:51.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:55:51.833+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:55:51.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:55:51.845+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:55:51.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:55:51.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-16T11:56:22.116+0000] {processor.py:157} INFO - Started process (PID=34865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:56:22.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:56:22.119+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:56:22.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:56:22.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:56:22.149+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:56:22.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:56:22.161+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:56:22.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:56:22.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-16T11:56:52.445+0000] {processor.py:157} INFO - Started process (PID=34875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:56:52.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:56:52.449+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:56:52.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:56:52.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:56:52.489+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:56:52.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:56:52.511+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:56:52.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:56:52.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-16T11:57:22.794+0000] {processor.py:157} INFO - Started process (PID=34885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:57:22.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:57:22.798+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:57:22.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:57:22.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:57:22.831+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:57:22.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:57:22.844+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:57:22.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:57:22.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-16T11:57:53.121+0000] {processor.py:157} INFO - Started process (PID=34895) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:57:53.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:57:53.126+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:57:53.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:57:53.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:57:53.162+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:57:53.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:57:53.175+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:57:53.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:57:53.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-16T11:58:23.516+0000] {processor.py:157} INFO - Started process (PID=34905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:58:23.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:58:23.520+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:58:23.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:58:23.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:58:23.557+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:58:23.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:58:23.573+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:58:23.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:58:23.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-16T11:58:53.903+0000] {processor.py:157} INFO - Started process (PID=34915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:58:53.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:58:53.906+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:58:53.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:58:53.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:58:53.940+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:58:53.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:58:53.952+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:58:53.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:58:53.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-16T11:59:24.286+0000] {processor.py:157} INFO - Started process (PID=34924) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:59:24.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:59:24.292+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:59:24.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:59:24.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:59:24.340+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:59:24.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:59:24.366+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:59:24.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:59:24.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-16T11:59:54.636+0000] {processor.py:157} INFO - Started process (PID=34935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:59:54.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T11:59:54.640+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:59:54.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:59:54.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T11:59:54.676+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:59:54.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T11:59:54.693+0000] {logging_mixin.py:151} INFO - [2024-09-16T11:59:54.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T11:59:54.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-16T12:00:25.005+0000] {processor.py:157} INFO - Started process (PID=34945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:00:25.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:00:25.013+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:00:25.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:00:25.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:00:25.077+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:00:25.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:00:25.092+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:00:25.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:00:25.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-16T12:00:55.540+0000] {processor.py:157} INFO - Started process (PID=34955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:00:55.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:00:55.548+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:00:55.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:00:55.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:00:55.612+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:00:55.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:00:55.633+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:00:55.633+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:00:55.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-16T12:01:26.016+0000] {processor.py:157} INFO - Started process (PID=34965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:01:26.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:01:26.024+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:01:26.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:01:26.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:01:26.088+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:01:26.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:01:26.105+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:01:26.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:01:26.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-16T12:01:56.316+0000] {processor.py:157} INFO - Started process (PID=34975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:01:56.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:01:56.318+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:01:56.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:01:56.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:01:56.348+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:01:56.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:01:56.363+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:01:56.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:01:56.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-16T12:02:26.722+0000] {processor.py:157} INFO - Started process (PID=34985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:02:26.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:02:26.726+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:02:26.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:02:26.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:02:26.759+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:02:26.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:02:26.768+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:02:26.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:02:26.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-16T12:02:57.122+0000] {processor.py:157} INFO - Started process (PID=34995) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:02:57.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:02:57.128+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:02:57.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:02:57.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:02:57.168+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:02:57.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:02:57.180+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:02:57.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:02:57.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-16T12:03:27.448+0000] {processor.py:157} INFO - Started process (PID=35005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:03:27.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:03:27.451+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:03:27.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:03:27.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:03:27.486+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:03:27.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:03:27.500+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:03:27.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:03:27.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-16T12:03:57.803+0000] {processor.py:157} INFO - Started process (PID=35015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:03:57.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:03:57.807+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:03:57.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:03:57.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:03:57.840+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:03:57.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:03:57.855+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:03:57.855+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:03:57.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-16T12:04:28.205+0000] {processor.py:157} INFO - Started process (PID=35025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:04:28.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:04:28.208+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:04:28.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:04:28.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:04:28.241+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:04:28.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:04:28.252+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:04:28.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:04:28.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-16T12:04:58.592+0000] {processor.py:157} INFO - Started process (PID=35035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:04:58.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:04:58.599+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:04:58.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:04:58.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:04:58.650+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:04:58.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:04:58.663+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:04:58.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:04:58.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-16T12:05:29.046+0000] {processor.py:157} INFO - Started process (PID=35045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:05:29.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:05:29.049+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:05:29.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:05:29.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:05:29.086+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:05:29.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:05:29.102+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:05:29.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:05:29.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-16T12:05:59.505+0000] {processor.py:157} INFO - Started process (PID=35055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:05:59.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:05:59.508+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:05:59.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:05:59.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:05:59.541+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:05:59.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:05:59.567+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:05:59.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:05:59.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-16T12:06:29.940+0000] {processor.py:157} INFO - Started process (PID=35065) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:06:29.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:06:29.944+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:06:29.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:06:29.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:06:29.973+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:06:29.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:06:29.983+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:06:29.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:06:29.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-16T12:07:00.382+0000] {processor.py:157} INFO - Started process (PID=35075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:07:00.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:07:00.388+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:07:00.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:07:00.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:07:00.429+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:07:00.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:07:00.443+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:07:00.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:07:00.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-16T12:07:30.701+0000] {processor.py:157} INFO - Started process (PID=35085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:07:30.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:07:30.704+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:07:30.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:07:30.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:07:30.738+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:07:30.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:07:30.752+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:07:30.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:07:30.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-16T12:08:01.098+0000] {processor.py:157} INFO - Started process (PID=35095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:08:01.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:08:01.100+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:08:01.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:08:01.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:08:01.134+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:08:01.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:08:01.145+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:08:01.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:08:01.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-16T12:08:31.451+0000] {processor.py:157} INFO - Started process (PID=35105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:08:31.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:08:31.456+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:08:31.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:08:31.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:08:31.493+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:08:31.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:08:31.506+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:08:31.506+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:08:31.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-16T12:09:01.819+0000] {processor.py:157} INFO - Started process (PID=35115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:09:01.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:09:01.825+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:09:01.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:09:01.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:09:01.863+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:09:01.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:09:01.878+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:09:01.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:09:01.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-16T12:09:32.146+0000] {processor.py:157} INFO - Started process (PID=35125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:09:32.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:09:32.151+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:09:32.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:09:32.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:09:32.181+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:09:32.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:09:32.195+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:09:32.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:09:32.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-16T12:10:02.595+0000] {processor.py:157} INFO - Started process (PID=35135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:10:02.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:10:02.599+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:10:02.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:10:02.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:10:02.646+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:10:02.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:10:02.668+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:10:02.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:10:02.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-16T12:10:32.983+0000] {processor.py:157} INFO - Started process (PID=35145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:10:32.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:10:32.988+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:10:32.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:10:33.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:10:33.030+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:10:33.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:10:33.045+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:10:33.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:10:33.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-16T12:11:03.395+0000] {processor.py:157} INFO - Started process (PID=35155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:11:03.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:11:03.399+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:11:03.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:11:03.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:11:03.434+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:11:03.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:11:03.447+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:11:03.447+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:11:03.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-16T12:11:33.796+0000] {processor.py:157} INFO - Started process (PID=35165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:11:33.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:11:33.800+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:11:33.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:11:33.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:11:33.834+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:11:33.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:11:33.847+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:11:33.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:11:33.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-16T12:12:04.223+0000] {processor.py:157} INFO - Started process (PID=35175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:12:04.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:12:04.235+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:12:04.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:12:04.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:12:04.283+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:12:04.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:12:04.298+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:12:04.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:12:04.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-16T12:12:34.530+0000] {processor.py:157} INFO - Started process (PID=35185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:12:34.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:12:34.534+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:12:34.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:12:34.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:12:34.570+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:12:34.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:12:34.585+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:12:34.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:12:34.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-16T12:13:04.917+0000] {processor.py:157} INFO - Started process (PID=35195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:13:04.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:13:04.921+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:13:04.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:13:04.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:13:04.956+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:13:04.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:13:04.966+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:13:04.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:13:04.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-16T12:13:35.331+0000] {processor.py:157} INFO - Started process (PID=35205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:13:35.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:13:35.337+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:13:35.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:13:35.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:13:35.379+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:13:35.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:13:35.398+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:13:35.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:13:35.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-16T12:14:05.781+0000] {processor.py:157} INFO - Started process (PID=35215) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:14:05.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:14:05.784+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:14:05.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:14:05.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:14:05.844+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:14:05.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:14:05.865+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:14:05.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:14:05.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-16T12:14:36.214+0000] {processor.py:157} INFO - Started process (PID=35225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:14:36.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:14:36.221+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:14:36.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:14:36.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:14:36.267+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:14:36.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:14:36.282+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:14:36.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:14:36.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-16T12:15:06.665+0000] {processor.py:157} INFO - Started process (PID=35235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:15:06.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:15:06.668+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:15:06.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:15:06.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:15:06.702+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:15:06.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:15:06.715+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:15:06.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:15:06.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-16T12:15:37.097+0000] {processor.py:157} INFO - Started process (PID=35245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:15:37.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:15:37.100+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:15:37.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:15:37.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:15:37.151+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:15:37.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:15:37.164+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:15:37.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:15:37.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-16T12:16:07.532+0000] {processor.py:157} INFO - Started process (PID=35255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:16:07.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:16:07.537+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:16:07.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:16:07.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:16:07.611+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:16:07.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:16:07.629+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:16:07.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:16:07.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-16T12:16:37.905+0000] {processor.py:157} INFO - Started process (PID=35265) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:16:37.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:16:37.909+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:16:37.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:16:37.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:16:37.953+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:16:37.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:16:37.966+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:16:37.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:16:37.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-16T12:17:08.326+0000] {processor.py:157} INFO - Started process (PID=35275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:17:08.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:17:08.329+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:17:08.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:17:08.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:17:08.368+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:17:08.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:17:08.381+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:17:08.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:17:08.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-16T12:17:38.776+0000] {processor.py:157} INFO - Started process (PID=35285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:17:38.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:17:38.781+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:17:38.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:17:38.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:17:38.814+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:17:38.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:17:38.827+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:17:38.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:17:38.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-16T12:18:09.182+0000] {processor.py:157} INFO - Started process (PID=35295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:18:09.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:18:09.189+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:18:09.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:18:09.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:18:09.227+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:18:09.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:18:09.240+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:18:09.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:18:09.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-16T12:18:39.590+0000] {processor.py:157} INFO - Started process (PID=35305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:18:39.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:18:39.594+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:18:39.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:18:39.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:18:39.641+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:18:39.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:18:39.684+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:18:39.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:18:39.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-16T12:19:09.938+0000] {processor.py:157} INFO - Started process (PID=35315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:19:09.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:19:09.945+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:19:09.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:19:09.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:19:09.990+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:19:09.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:19:10.006+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:19:10.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:19:10.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-16T12:19:40.280+0000] {processor.py:157} INFO - Started process (PID=35325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:19:40.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:19:40.284+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:19:40.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:19:40.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:19:40.325+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:19:40.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:19:40.340+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:19:40.340+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:19:40.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-16T12:20:10.728+0000] {processor.py:157} INFO - Started process (PID=35335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:20:10.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:20:10.732+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:20:10.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:20:10.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:20:10.789+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:20:10.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:20:10.819+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:20:10.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:20:10.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-16T12:20:41.089+0000] {processor.py:157} INFO - Started process (PID=35345) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:20:41.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:20:41.092+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:20:41.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:20:41.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:20:41.164+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:20:41.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:20:41.180+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:20:41.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:20:41.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-16T12:21:11.493+0000] {processor.py:157} INFO - Started process (PID=35355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:21:11.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:21:11.498+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:21:11.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:21:11.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:21:11.537+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:21:11.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:21:11.554+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:21:11.554+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:21:11.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-16T12:21:41.958+0000] {processor.py:157} INFO - Started process (PID=35365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:21:41.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:21:41.962+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:21:41.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:21:41.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:21:42.002+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:21:42.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:21:42.017+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:21:42.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:21:42.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-16T12:22:12.396+0000] {processor.py:157} INFO - Started process (PID=35375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:22:12.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:22:12.399+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:22:12.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:22:12.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:22:12.430+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:22:12.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:22:12.440+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:22:12.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:22:12.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-16T12:22:42.752+0000] {processor.py:157} INFO - Started process (PID=35385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:22:42.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:22:42.754+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:22:42.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:22:42.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:22:42.792+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:22:42.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:22:42.804+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:22:42.804+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:22:42.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-16T12:23:13.153+0000] {processor.py:157} INFO - Started process (PID=35395) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:23:13.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:23:13.158+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:23:13.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:23:13.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:23:13.199+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:23:13.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:23:13.226+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:23:13.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:23:13.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-16T12:23:43.552+0000] {processor.py:157} INFO - Started process (PID=35405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:23:43.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:23:43.555+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:23:43.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:23:43.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:23:43.593+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:23:43.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:23:43.606+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:23:43.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:23:43.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-16T12:24:13.974+0000] {processor.py:157} INFO - Started process (PID=35415) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:24:13.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:24:13.977+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:24:13.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:24:13.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:24:14.009+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:24:14.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:24:14.021+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:24:14.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:24:14.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-16T12:24:44.378+0000] {processor.py:157} INFO - Started process (PID=35425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:24:44.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:24:44.382+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:24:44.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:24:44.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:24:44.414+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:24:44.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:24:44.426+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:24:44.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:24:44.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-16T12:25:14.744+0000] {processor.py:157} INFO - Started process (PID=35435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:25:14.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:25:14.749+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:25:14.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:25:14.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:25:14.794+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:25:14.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:25:14.808+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:25:14.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:25:14.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-16T12:25:45.175+0000] {processor.py:157} INFO - Started process (PID=35445) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:25:45.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:25:45.178+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:25:45.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:25:45.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:25:45.214+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:25:45.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:25:45.227+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:25:45.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:25:45.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-16T12:26:15.563+0000] {processor.py:157} INFO - Started process (PID=35455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:26:15.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:26:15.567+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:26:15.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:26:15.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:26:15.599+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:26:15.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:26:15.613+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:26:15.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:26:15.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-16T12:26:45.922+0000] {processor.py:157} INFO - Started process (PID=35465) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:26:45.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:26:45.925+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:26:45.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:26:45.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:26:45.957+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:26:45.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:26:45.979+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:26:45.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:26:45.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-16T12:27:16.410+0000] {processor.py:157} INFO - Started process (PID=35475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:27:16.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:27:16.417+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:27:16.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:27:16.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:27:16.454+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:27:16.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:27:16.471+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:27:16.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:27:16.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-16T12:27:46.801+0000] {processor.py:157} INFO - Started process (PID=35485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:27:46.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:27:46.805+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:27:46.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:27:46.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:27:46.841+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:27:46.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:27:46.853+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:27:46.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:27:46.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-16T12:28:17.292+0000] {processor.py:157} INFO - Started process (PID=35495) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:28:17.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:28:17.295+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:28:17.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:28:17.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:28:17.333+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:28:17.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:28:17.347+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:28:17.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:28:17.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-16T12:28:47.753+0000] {processor.py:157} INFO - Started process (PID=35505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:28:47.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:28:47.758+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:28:47.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:28:47.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:28:47.793+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:28:47.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:28:47.806+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:28:47.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:28:47.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-16T12:29:18.165+0000] {processor.py:157} INFO - Started process (PID=35515) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:29:18.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:29:18.169+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:29:18.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:29:18.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:29:18.203+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:29:18.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:29:18.215+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:29:18.215+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:29:18.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-16T12:29:48.552+0000] {processor.py:157} INFO - Started process (PID=35525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:29:48.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:29:48.556+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:29:48.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:29:48.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:29:48.587+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:29:48.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:29:48.599+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:29:48.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:29:48.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-16T12:30:18.847+0000] {processor.py:157} INFO - Started process (PID=35535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:30:18.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:30:18.850+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:30:18.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:30:18.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:30:18.886+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:30:18.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:30:18.898+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:30:18.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:30:18.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-16T12:30:49.290+0000] {processor.py:157} INFO - Started process (PID=35545) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:30:49.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:30:49.296+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:30:49.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:30:49.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:30:49.335+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:30:49.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:30:49.350+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:30:49.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:30:49.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-16T12:31:19.717+0000] {processor.py:157} INFO - Started process (PID=35555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:31:19.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:31:19.719+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:31:19.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:31:19.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:31:19.767+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:31:19.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:31:19.780+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:31:19.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:31:19.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-16T12:31:50.128+0000] {processor.py:157} INFO - Started process (PID=35565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:31:50.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:31:50.131+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:31:50.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:31:50.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:31:50.166+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:31:50.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:31:50.191+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:31:50.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:31:50.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-16T12:32:20.463+0000] {processor.py:157} INFO - Started process (PID=35575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:32:20.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:32:20.466+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:32:20.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:32:20.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:32:20.499+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:32:20.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:32:20.511+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:32:20.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:32:20.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-16T12:32:50.960+0000] {processor.py:157} INFO - Started process (PID=35584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:32:50.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:32:50.980+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:32:50.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:32:51.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:32:51.095+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:32:51.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:32:51.121+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:32:51.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:32:51.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.214 seconds
[2024-09-16T12:33:21.246+0000] {processor.py:157} INFO - Started process (PID=35595) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:33:21.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:33:21.250+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:33:21.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:33:21.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:33:21.314+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:33:21.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:33:21.329+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:33:21.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:33:21.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T12:33:51.584+0000] {processor.py:157} INFO - Started process (PID=35605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:33:51.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:33:51.587+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:33:51.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:33:51.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:33:51.641+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:33:51.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:33:51.659+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:33:51.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:33:51.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-16T12:34:21.897+0000] {processor.py:157} INFO - Started process (PID=35615) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:34:21.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:34:21.903+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:34:21.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:34:21.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:34:21.948+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:34:21.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:34:21.970+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:34:21.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:34:21.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-16T12:34:52.327+0000] {processor.py:157} INFO - Started process (PID=35625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:34:52.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:34:52.340+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:34:52.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:34:52.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:34:52.377+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:34:52.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:34:52.393+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:34:52.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:34:52.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-16T12:35:22.724+0000] {processor.py:157} INFO - Started process (PID=35635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:35:22.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:35:22.730+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:35:22.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:35:22.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:35:22.789+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:35:22.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:35:22.824+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:35:22.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:35:22.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-16T12:35:53.026+0000] {processor.py:157} INFO - Started process (PID=35645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:35:53.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:35:53.030+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:35:53.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:35:53.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:35:53.086+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:35:53.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:35:53.104+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:35:53.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:35:53.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-16T12:36:23.512+0000] {processor.py:157} INFO - Started process (PID=35654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:36:23.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:36:23.519+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:36:23.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:36:23.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:36:23.577+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:36:23.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:36:23.594+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:36:23.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:36:23.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-16T12:36:53.851+0000] {processor.py:157} INFO - Started process (PID=35665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:36:53.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:36:53.856+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:36:53.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:36:53.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:36:53.896+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:36:53.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:36:53.925+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:36:53.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:36:53.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-16T12:37:24.187+0000] {processor.py:157} INFO - Started process (PID=35675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:37:24.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:37:24.202+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:37:24.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:37:24.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:37:24.250+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:37:24.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:37:24.265+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:37:24.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:37:24.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-16T12:37:54.533+0000] {processor.py:157} INFO - Started process (PID=35685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:37:54.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:37:54.538+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:37:54.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:37:54.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:37:54.579+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:37:54.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:37:54.593+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:37:54.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:37:54.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-16T12:38:25.003+0000] {processor.py:157} INFO - Started process (PID=35695) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:38:25.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:38:25.010+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:38:25.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:38:25.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:38:25.074+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:38:25.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:38:25.092+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:38:25.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:38:25.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T12:38:55.457+0000] {processor.py:157} INFO - Started process (PID=35705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:38:55.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:38:55.460+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:38:55.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:38:55.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:38:55.509+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:38:55.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:38:55.533+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:38:55.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:38:55.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-16T12:39:25.963+0000] {processor.py:157} INFO - Started process (PID=35715) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:39:25.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:39:25.974+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:39:25.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:39:26.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:39:26.063+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:39:26.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:39:26.080+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:39:26.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:39:26.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-09-16T12:39:56.278+0000] {processor.py:157} INFO - Started process (PID=35725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:39:56.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:39:56.281+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:39:56.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:39:56.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:39:56.320+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:39:56.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:39:56.356+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:39:56.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:39:56.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-16T12:40:26.702+0000] {processor.py:157} INFO - Started process (PID=35735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:40:26.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:40:26.708+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:40:26.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:40:26.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:40:26.781+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:40:26.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:40:26.815+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:40:26.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:40:26.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-16T12:40:57.049+0000] {processor.py:157} INFO - Started process (PID=35745) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:40:57.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:40:57.054+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:40:57.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:40:57.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:40:57.115+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:40:57.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:40:57.132+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:40:57.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:40:57.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-16T12:41:27.494+0000] {processor.py:157} INFO - Started process (PID=35755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:41:27.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:41:27.497+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:41:27.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:41:27.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:41:27.573+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:41:27.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:41:27.597+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:41:27.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:41:27.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-16T12:41:57.944+0000] {processor.py:157} INFO - Started process (PID=35765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:41:57.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:41:57.957+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:41:57.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:41:57.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:41:58.006+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:41:58.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:41:58.020+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:41:58.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:41:58.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-16T12:42:28.457+0000] {processor.py:157} INFO - Started process (PID=35775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:42:28.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:42:28.463+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:42:28.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:42:28.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:42:28.549+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:42:28.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:42:28.574+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:42:28.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:42:28.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-16T12:42:58.794+0000] {processor.py:157} INFO - Started process (PID=35785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:42:58.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:42:58.798+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:42:58.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:42:58.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:42:58.837+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:42:58.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:42:58.870+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:42:58.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:42:58.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-16T12:43:29.262+0000] {processor.py:157} INFO - Started process (PID=35795) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:43:29.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:43:29.267+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:43:29.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:43:29.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:43:29.309+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:43:29.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:43:29.327+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:43:29.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:43:29.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-16T12:43:59.740+0000] {processor.py:157} INFO - Started process (PID=35805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:43:59.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:43:59.744+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:43:59.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:43:59.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:43:59.784+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:43:59.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:43:59.800+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:43:59.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:43:59.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-16T12:44:30.224+0000] {processor.py:157} INFO - Started process (PID=35815) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:44:30.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:44:30.229+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:44:30.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:44:30.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:44:30.271+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:44:30.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:44:30.286+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:44:30.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:44:30.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-16T12:45:00.520+0000] {processor.py:157} INFO - Started process (PID=35825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:45:00.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:45:00.523+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:45:00.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:45:00.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:45:00.569+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:45:00.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:45:00.586+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:45:00.586+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:45:00.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-16T12:45:30.959+0000] {processor.py:157} INFO - Started process (PID=35835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:45:30.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:45:30.966+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:45:30.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:45:30.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:45:31.010+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:45:31.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:45:31.037+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:45:31.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:45:31.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-16T12:46:01.404+0000] {processor.py:157} INFO - Started process (PID=35845) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:46:01.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:46:01.412+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:46:01.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:46:01.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:46:01.469+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:46:01.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:46:01.499+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:46:01.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:46:01.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T12:46:31.899+0000] {processor.py:157} INFO - Started process (PID=35855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:46:31.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:46:31.906+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:46:31.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:46:31.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:46:31.978+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:46:31.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:46:31.996+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:46:31.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:46:32.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-16T12:47:02.303+0000] {processor.py:157} INFO - Started process (PID=35865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:47:02.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:47:02.307+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:47:02.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:47:02.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:47:02.350+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:47:02.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:47:02.376+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:47:02.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:47:02.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-16T12:47:32.661+0000] {processor.py:157} INFO - Started process (PID=35875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:47:32.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:47:32.668+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:47:32.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:47:32.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:47:32.707+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:47:32.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:47:32.722+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:47:32.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:47:32.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-16T12:48:03.075+0000] {processor.py:157} INFO - Started process (PID=35885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:48:03.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:48:03.080+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:48:03.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:48:03.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:48:03.147+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:48:03.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:48:03.165+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:48:03.165+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:48:03.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T12:48:33.559+0000] {processor.py:157} INFO - Started process (PID=35895) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:48:33.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:48:33.565+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:48:33.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:48:33.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:48:33.626+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:48:33.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:48:33.643+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:48:33.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:48:33.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-16T12:49:04.001+0000] {processor.py:157} INFO - Started process (PID=35905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:49:04.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:49:04.005+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:49:04.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:49:04.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:49:04.045+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:49:04.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:49:04.067+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:49:04.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:49:04.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-16T12:49:34.426+0000] {processor.py:157} INFO - Started process (PID=35915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:49:34.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:49:34.432+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:49:34.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:49:34.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:49:34.498+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:49:34.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:49:34.515+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:49:34.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:49:34.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-16T12:50:04.782+0000] {processor.py:157} INFO - Started process (PID=35925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:50:04.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:50:04.788+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:50:04.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:50:04.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:50:04.855+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:50:04.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:50:04.872+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:50:04.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:50:04.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-16T12:50:35.265+0000] {processor.py:157} INFO - Started process (PID=35935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:50:35.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:50:35.271+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:50:35.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:50:35.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:50:35.320+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:50:35.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:50:35.342+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:50:35.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:50:35.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-16T12:51:05.693+0000] {processor.py:157} INFO - Started process (PID=35945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:51:05.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:51:05.696+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:51:05.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:51:05.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:51:05.752+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:51:05.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:51:05.767+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:51:05.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:51:05.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-16T12:51:36.110+0000] {processor.py:157} INFO - Started process (PID=35955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:51:36.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:51:36.117+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:51:36.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:51:36.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:51:36.178+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:51:36.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:51:36.193+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:51:36.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:51:36.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-16T12:52:06.483+0000] {processor.py:157} INFO - Started process (PID=35965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:52:06.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:52:06.486+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:52:06.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:52:06.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:52:06.523+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:52:06.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:52:06.538+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:52:06.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:52:06.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-16T12:52:36.905+0000] {processor.py:157} INFO - Started process (PID=35975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:52:36.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:52:36.907+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:52:36.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:52:36.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:52:36.954+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:52:36.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:52:36.968+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:52:36.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:52:36.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-16T12:53:07.303+0000] {processor.py:157} INFO - Started process (PID=35985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:53:07.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:53:07.307+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:53:07.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:53:07.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:53:07.342+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:53:07.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:53:07.359+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:53:07.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:53:07.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-16T12:53:37.654+0000] {processor.py:157} INFO - Started process (PID=35995) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:53:37.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:53:37.659+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:53:37.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:53:37.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:53:37.698+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:53:37.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:53:37.710+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:53:37.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:53:37.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-16T12:54:08.026+0000] {processor.py:157} INFO - Started process (PID=36005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:54:08.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:54:08.030+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:54:08.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:54:08.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:54:08.092+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:54:08.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:54:08.109+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:54:08.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:54:08.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-16T12:54:38.459+0000] {processor.py:157} INFO - Started process (PID=36015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:54:38.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:54:38.465+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:54:38.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:54:38.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:54:38.515+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:54:38.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:54:38.536+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:54:38.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:54:38.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-16T12:55:08.874+0000] {processor.py:157} INFO - Started process (PID=36025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:55:08.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:55:08.878+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:55:08.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:55:08.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:55:08.909+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:55:08.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:55:08.920+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:55:08.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:55:08.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-16T12:55:39.351+0000] {processor.py:157} INFO - Started process (PID=36035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:55:39.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:55:39.365+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:55:39.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:55:39.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:55:39.424+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:55:39.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:55:39.442+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:55:39.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:55:39.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-16T12:56:09.752+0000] {processor.py:157} INFO - Started process (PID=36045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:56:09.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:56:09.757+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:56:09.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:56:09.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:56:09.807+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:56:09.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:56:09.823+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:56:09.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:56:09.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-16T12:56:40.036+0000] {processor.py:157} INFO - Started process (PID=36055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:56:40.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:56:40.041+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:56:40.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:56:40.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:56:40.097+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:56:40.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:56:40.114+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:56:40.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:56:40.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-16T12:57:10.521+0000] {processor.py:157} INFO - Started process (PID=36065) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:57:10.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:57:10.527+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:57:10.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:57:10.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:57:10.569+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:57:10.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:57:10.586+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:57:10.586+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:57:10.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-16T12:57:40.905+0000] {processor.py:157} INFO - Started process (PID=36075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:57:40.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:57:40.910+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:57:40.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:57:40.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:57:40.949+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:57:40.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:57:40.963+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:57:40.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:57:40.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-16T12:58:11.271+0000] {processor.py:157} INFO - Started process (PID=36085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:58:11.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:58:11.279+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:58:11.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:58:11.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:58:11.319+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:58:11.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:58:11.353+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:58:11.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:58:11.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-16T12:58:41.551+0000] {processor.py:157} INFO - Started process (PID=36095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:58:41.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:58:41.555+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:58:41.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:58:41.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:58:41.596+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:58:41.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:58:41.612+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:58:41.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:58:41.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-16T12:59:11.972+0000] {processor.py:157} INFO - Started process (PID=36105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:59:11.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:59:11.979+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:59:11.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:59:11.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:59:12.020+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:59:12.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:59:12.036+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:59:12.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:59:12.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-16T12:59:42.341+0000] {processor.py:157} INFO - Started process (PID=36115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:59:42.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T12:59:42.346+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:59:42.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:59:42.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T12:59:42.382+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:59:42.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T12:59:42.394+0000] {logging_mixin.py:151} INFO - [2024-09-16T12:59:42.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T12:59:42.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-16T13:00:12.969+0000] {processor.py:157} INFO - Started process (PID=36124) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:00:12.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:00:12.975+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:00:12.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:00:12.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:00:13.045+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:00:13.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:00:13.062+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:00:13.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:00:13.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-16T13:00:43.331+0000] {processor.py:157} INFO - Started process (PID=36135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:00:43.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:00:43.334+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:00:43.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:00:43.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:00:43.370+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:00:43.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:00:43.385+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:00:43.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:00:43.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-16T13:01:13.797+0000] {processor.py:157} INFO - Started process (PID=36145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:01:13.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:01:13.802+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:01:13.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:01:13.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:01:13.833+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:01:13.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:01:13.844+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:01:13.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:01:13.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-16T13:01:44.207+0000] {processor.py:157} INFO - Started process (PID=36155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:01:44.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:01:44.212+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:01:44.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:01:44.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:01:44.254+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:01:44.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:01:44.266+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:01:44.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:01:44.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-16T13:02:14.621+0000] {processor.py:157} INFO - Started process (PID=36165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:02:14.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:02:14.624+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:02:14.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:02:14.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:02:14.664+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:02:14.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:02:14.679+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:02:14.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:02:14.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-16T13:02:45.022+0000] {processor.py:157} INFO - Started process (PID=36175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:02:45.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:02:45.026+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:02:45.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:02:45.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:02:45.081+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:02:45.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:02:45.108+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:02:45.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:02:45.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-16T13:03:15.431+0000] {processor.py:157} INFO - Started process (PID=36185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:03:15.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:03:15.436+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:03:15.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:03:15.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:03:15.470+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:03:15.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:03:15.482+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:03:15.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:03:15.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-16T13:03:45.726+0000] {processor.py:157} INFO - Started process (PID=36195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:03:45.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:03:45.730+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:03:45.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:03:45.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:03:45.760+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:03:45.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:03:45.771+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:03:45.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:03:45.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-16T13:04:16.180+0000] {processor.py:157} INFO - Started process (PID=36205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:04:16.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:04:16.183+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:04:16.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:04:16.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:04:16.224+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:04:16.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:04:16.241+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:04:16.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:04:16.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-16T13:04:46.552+0000] {processor.py:157} INFO - Started process (PID=36215) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:04:46.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:04:46.557+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:04:46.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:04:46.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:04:46.593+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:04:46.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:04:46.610+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:04:46.610+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:04:46.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-16T13:05:17.049+0000] {processor.py:157} INFO - Started process (PID=36225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:05:17.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:05:17.070+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:05:17.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:05:17.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:05:17.132+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:05:17.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:05:17.147+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:05:17.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:05:17.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T13:05:47.438+0000] {processor.py:157} INFO - Started process (PID=36235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:05:47.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:05:47.441+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:05:47.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:05:47.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:05:47.471+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:05:47.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:05:47.482+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:05:47.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:05:47.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-16T13:06:17.910+0000] {processor.py:157} INFO - Started process (PID=36245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:06:17.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:06:17.915+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:06:17.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:06:17.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:06:17.949+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:06:17.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:06:17.963+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:06:17.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:06:17.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-16T13:06:48.202+0000] {processor.py:157} INFO - Started process (PID=36255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:06:48.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:06:48.205+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:06:48.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:06:48.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:06:48.246+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:06:48.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:06:48.261+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:06:48.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:06:48.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-16T13:07:18.615+0000] {processor.py:157} INFO - Started process (PID=36265) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:07:18.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:07:18.621+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:07:18.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:07:18.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:07:18.665+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:07:18.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:07:18.678+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:07:18.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:07:18.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-16T13:07:49.055+0000] {processor.py:157} INFO - Started process (PID=36275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:07:49.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:07:49.058+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:07:49.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:07:49.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:07:49.090+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:07:49.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:07:49.102+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:07:49.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:07:49.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-16T13:08:19.468+0000] {processor.py:157} INFO - Started process (PID=36285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:08:19.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:08:19.472+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:08:19.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:08:19.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:08:19.508+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:08:19.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:08:19.521+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:08:19.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:08:19.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-16T13:08:49.867+0000] {processor.py:157} INFO - Started process (PID=36295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:08:49.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:08:49.872+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:08:49.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:08:49.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:08:49.928+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:08:49.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:08:49.941+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:08:49.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:08:49.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-16T13:09:20.249+0000] {processor.py:157} INFO - Started process (PID=36305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:09:20.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:09:20.252+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:09:20.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:09:20.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:09:20.289+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:09:20.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:09:20.298+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:09:20.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:09:20.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-16T13:09:50.662+0000] {processor.py:157} INFO - Started process (PID=36315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:09:50.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:09:50.666+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:09:50.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:09:50.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:09:50.699+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:09:50.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:09:50.712+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:09:50.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:09:50.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-16T13:10:21.002+0000] {processor.py:157} INFO - Started process (PID=36325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:10:21.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:10:21.006+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:10:21.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:10:21.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:10:21.047+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:10:21.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:10:21.062+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:10:21.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:10:21.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-16T13:10:51.450+0000] {processor.py:157} INFO - Started process (PID=36335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:10:51.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:10:51.455+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:10:51.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:10:51.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:10:51.497+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:10:51.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:10:51.509+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:10:51.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:10:51.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-16T13:11:21.845+0000] {processor.py:157} INFO - Started process (PID=36345) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:11:21.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:11:21.849+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:11:21.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:11:21.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:11:21.886+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:11:21.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:11:21.900+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:11:21.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:11:21.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-16T13:11:52.322+0000] {processor.py:157} INFO - Started process (PID=36355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:11:52.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:11:52.326+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:11:52.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:11:52.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:11:52.370+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:11:52.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:11:52.383+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:11:52.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:11:52.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-16T13:12:22.722+0000] {processor.py:157} INFO - Started process (PID=36365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:12:22.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:12:22.727+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:12:22.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:12:22.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:12:22.758+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:12:22.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:12:22.771+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:12:22.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:12:22.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-16T13:12:53.095+0000] {processor.py:157} INFO - Started process (PID=36375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:12:53.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:12:53.098+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:12:53.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:12:53.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:12:53.130+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:12:53.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:12:53.141+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:12:53.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:12:53.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-16T13:13:23.547+0000] {processor.py:157} INFO - Started process (PID=36385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:13:23.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:13:23.555+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:13:23.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:13:23.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:13:23.599+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:13:23.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:13:23.615+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:13:23.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:13:23.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-16T13:13:53.908+0000] {processor.py:157} INFO - Started process (PID=36395) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:13:53.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:13:53.912+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:13:53.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:13:53.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:13:53.952+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:13:53.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:13:53.965+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:13:53.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:13:53.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-16T13:14:24.333+0000] {processor.py:157} INFO - Started process (PID=36405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:14:24.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:14:24.336+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:14:24.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:14:24.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:14:24.365+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:14:24.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:14:24.376+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:14:24.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:14:24.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-16T13:14:54.760+0000] {processor.py:157} INFO - Started process (PID=36415) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:14:54.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:14:54.767+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:14:54.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:14:54.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:14:54.805+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:14:54.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:14:54.819+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:14:54.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:14:54.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-16T13:15:25.158+0000] {processor.py:157} INFO - Started process (PID=36425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:15:25.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:15:25.169+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:15:25.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:15:25.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:15:25.205+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:15:25.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:15:25.218+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:15:25.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:15:25.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-16T13:15:55.559+0000] {processor.py:157} INFO - Started process (PID=36435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:15:55.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:15:55.563+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:15:55.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:15:55.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:15:55.599+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:15:55.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:15:55.610+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:15:55.610+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:15:55.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-16T13:16:26.030+0000] {processor.py:157} INFO - Started process (PID=36445) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:16:26.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:16:26.035+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:16:26.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:16:26.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:16:26.102+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:16:26.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:16:26.120+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:16:26.120+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:16:26.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-16T13:16:56.476+0000] {processor.py:157} INFO - Started process (PID=36455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:16:56.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:16:56.479+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:16:56.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:16:56.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:16:56.545+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:16:56.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:16:56.559+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:16:56.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:16:56.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-16T13:17:26.856+0000] {processor.py:157} INFO - Started process (PID=36465) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:17:26.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:17:26.861+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:17:26.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:17:26.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:17:26.908+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:17:26.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:17:26.925+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:17:26.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:17:26.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-16T13:17:57.228+0000] {processor.py:157} INFO - Started process (PID=36475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:17:57.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:17:57.231+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:17:57.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:17:57.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:17:57.268+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:17:57.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:17:57.284+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:17:57.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:17:57.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-16T13:18:27.725+0000] {processor.py:157} INFO - Started process (PID=36485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:18:27.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:18:27.751+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:18:27.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:18:27.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:18:27.821+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:18:27.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:18:27.840+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:18:27.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:18:27.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-16T13:18:58.196+0000] {processor.py:157} INFO - Started process (PID=36495) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:18:58.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:18:58.200+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:18:58.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:18:58.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:18:58.263+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:18:58.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:18:58.273+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:18:58.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:18:58.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-16T13:19:28.584+0000] {processor.py:157} INFO - Started process (PID=36505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:19:28.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:19:28.590+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:19:28.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:19:28.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:19:28.653+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:19:28.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:19:28.669+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:19:28.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:19:28.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T13:19:58.994+0000] {processor.py:157} INFO - Started process (PID=36514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:19:58.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:19:59.001+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:19:59.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:19:59.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:19:59.071+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:19:59.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:19:59.091+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:19:59.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:19:59.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-16T13:20:29.321+0000] {processor.py:157} INFO - Started process (PID=36525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:20:29.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:20:29.327+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:20:29.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:20:29.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:20:29.389+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:20:29.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:20:29.417+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:20:29.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:20:29.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-16T13:20:59.670+0000] {processor.py:157} INFO - Started process (PID=36535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:20:59.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:20:59.673+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:20:59.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:20:59.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:20:59.715+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:20:59.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:20:59.728+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:20:59.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:20:59.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-16T13:21:30.035+0000] {processor.py:157} INFO - Started process (PID=36545) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:21:30.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:21:30.041+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:21:30.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:21:30.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:21:30.124+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:21:30.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:21:30.136+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:21:30.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:21:30.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T13:22:00.458+0000] {processor.py:157} INFO - Started process (PID=36555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:22:00.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:22:00.463+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:22:00.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:22:00.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:22:00.501+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:22:00.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:22:00.515+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:22:00.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:22:00.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-16T13:22:30.861+0000] {processor.py:157} INFO - Started process (PID=36565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:22:30.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:22:30.868+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:22:30.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:22:30.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:22:30.933+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:22:30.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:22:30.948+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:22:30.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:22:30.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-16T13:23:01.301+0000] {processor.py:157} INFO - Started process (PID=36574) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:23:01.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:23:01.307+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:23:01.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:23:01.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:23:01.364+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:23:01.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:23:01.381+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:23:01.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:23:01.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-16T13:23:31.630+0000] {processor.py:157} INFO - Started process (PID=36585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:23:31.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:23:31.634+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:23:31.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:23:31.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:23:31.699+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:23:31.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:23:31.715+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:23:31.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:23:31.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-16T13:24:02.117+0000] {processor.py:157} INFO - Started process (PID=36595) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:24:02.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:24:02.125+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:24:02.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:24:02.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:24:02.193+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:24:02.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:24:02.204+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:24:02.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:24:02.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-16T13:24:32.523+0000] {processor.py:157} INFO - Started process (PID=36605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:24:32.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:24:32.525+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:24:32.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:24:32.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:24:32.573+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:24:32.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:24:32.586+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:24:32.586+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:24:32.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-16T13:25:02.978+0000] {processor.py:157} INFO - Started process (PID=36615) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:25:02.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:25:02.982+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:25:02.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:25:03.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:25:03.026+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:25:03.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:25:03.038+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:25:03.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:25:03.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-16T13:25:33.384+0000] {processor.py:157} INFO - Started process (PID=36625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:25:33.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:25:33.388+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:25:33.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:25:33.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:25:33.459+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:25:33.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:25:33.475+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:25:33.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:25:33.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-16T13:26:03.708+0000] {processor.py:157} INFO - Started process (PID=36635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:26:03.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:26:03.715+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:26:03.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:26:03.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:26:03.777+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:26:03.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:26:03.787+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:26:03.787+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:26:03.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-16T13:26:34.134+0000] {processor.py:157} INFO - Started process (PID=36645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:26:34.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:26:34.137+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:26:34.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:26:34.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:26:34.183+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:26:34.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:26:34.207+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:26:34.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:26:34.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-16T13:27:04.480+0000] {processor.py:157} INFO - Started process (PID=36654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:27:04.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:27:04.487+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:27:04.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:27:04.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:27:04.550+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:27:04.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:27:04.564+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:27:04.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:27:04.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-16T13:27:34.971+0000] {processor.py:157} INFO - Started process (PID=36665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:27:34.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:27:34.976+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:27:34.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:27:34.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:27:35.038+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:27:35.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:27:35.060+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:27:35.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:27:35.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-16T13:28:05.316+0000] {processor.py:157} INFO - Started process (PID=36675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:28:05.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:28:05.321+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:28:05.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:28:05.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:28:05.364+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:28:05.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:28:05.383+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:28:05.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:28:05.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-16T13:28:35.734+0000] {processor.py:157} INFO - Started process (PID=36685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:28:35.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:28:35.737+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:28:35.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:28:35.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:28:35.780+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:28:35.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:28:35.795+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:28:35.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:28:35.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-16T13:29:06.133+0000] {processor.py:157} INFO - Started process (PID=36694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:29:06.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:29:06.138+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:29:06.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:29:06.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:29:06.205+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:29:06.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:29:06.221+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:29:06.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:29:06.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-16T13:29:36.448+0000] {processor.py:157} INFO - Started process (PID=36705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:29:36.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:29:36.452+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:29:36.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:29:36.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:29:36.503+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:29:36.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:29:36.518+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:29:36.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:29:36.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-16T13:30:06.927+0000] {processor.py:157} INFO - Started process (PID=36714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:30:06.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:30:06.939+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:30:06.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:30:06.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:30:07.007+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:30:07.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:30:07.021+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:30:07.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:30:07.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-16T13:30:37.276+0000] {processor.py:157} INFO - Started process (PID=36725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:30:37.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:30:37.280+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:30:37.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:30:37.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:30:37.323+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:30:37.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:30:37.351+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:30:37.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:30:37.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-16T13:31:07.658+0000] {processor.py:157} INFO - Started process (PID=36735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:31:07.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:31:07.672+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:31:07.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:31:07.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:31:07.794+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:31:07.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:31:07.835+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:31:07.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:31:07.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.206 seconds
[2024-09-16T13:31:38.068+0000] {processor.py:157} INFO - Started process (PID=36744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:31:38.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:31:38.084+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:31:38.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:31:38.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:31:38.172+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:31:38.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:31:38.202+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:31:38.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:31:38.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-09-16T13:32:08.568+0000] {processor.py:157} INFO - Started process (PID=36754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:32:08.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:32:08.586+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:32:08.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:32:08.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:32:08.658+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:32:08.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:32:08.682+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:32:08.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:32:08.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-16T13:32:38.909+0000] {processor.py:157} INFO - Started process (PID=36765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:32:38.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:32:38.915+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:32:38.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:32:38.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:32:38.968+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:32:38.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:32:38.989+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:32:38.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:32:39.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-16T13:33:09.282+0000] {processor.py:157} INFO - Started process (PID=36775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:33:09.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:33:09.289+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:33:09.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:33:09.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:33:09.357+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:33:09.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:33:09.377+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:33:09.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:33:09.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-16T13:33:39.721+0000] {processor.py:157} INFO - Started process (PID=36785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:33:39.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:33:39.734+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:33:39.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:33:39.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:33:39.808+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:33:39.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:33:39.834+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:33:39.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:33:39.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-16T13:34:10.122+0000] {processor.py:157} INFO - Started process (PID=36795) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:34:10.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:34:10.132+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:34:10.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:34:10.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:34:10.185+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:34:10.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:34:10.200+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:34:10.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:34:10.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-16T13:34:40.517+0000] {processor.py:157} INFO - Started process (PID=36805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:34:40.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:34:40.521+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:34:40.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:34:40.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:34:40.564+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:34:40.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:34:40.577+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:34:40.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:34:40.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-16T13:35:10.944+0000] {processor.py:157} INFO - Started process (PID=36814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:35:10.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:35:10.951+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:35:10.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:35:10.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:35:11.019+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:35:11.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:35:11.038+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:35:11.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:35:11.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-16T13:35:41.325+0000] {processor.py:157} INFO - Started process (PID=36825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:35:41.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:35:41.331+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:35:41.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:35:41.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:35:41.394+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:35:41.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:35:41.407+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:35:41.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:35:41.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-16T13:36:11.742+0000] {processor.py:157} INFO - Started process (PID=36835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:36:11.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:36:11.747+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:36:11.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:36:11.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:36:11.797+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:36:11.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:36:11.817+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:36:11.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:36:11.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-16T13:36:42.043+0000] {processor.py:157} INFO - Started process (PID=36845) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:36:42.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:36:42.047+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:36:42.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:36:42.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:36:42.114+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:36:42.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:36:42.128+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:36:42.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:36:42.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-16T13:37:12.358+0000] {processor.py:157} INFO - Started process (PID=36855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:37:12.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:37:12.362+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:37:12.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:37:12.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:37:12.421+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:37:12.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:37:12.435+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:37:12.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:37:12.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-16T13:37:42.829+0000] {processor.py:157} INFO - Started process (PID=36865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:37:42.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:37:42.834+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:37:42.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:37:42.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:37:42.901+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:37:42.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:37:42.918+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:37:42.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:37:42.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-16T13:38:13.144+0000] {processor.py:157} INFO - Started process (PID=36875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:38:13.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:38:13.148+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:38:13.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:38:13.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:38:13.206+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:38:13.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:38:13.221+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:38:13.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:38:13.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-16T13:38:43.637+0000] {processor.py:157} INFO - Started process (PID=36885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:38:43.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:38:43.649+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:38:43.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:38:43.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:38:43.706+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:38:43.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:38:43.717+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:38:43.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:38:43.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-16T13:39:14.001+0000] {processor.py:157} INFO - Started process (PID=36895) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:39:14.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:39:14.005+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:39:14.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:39:14.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:39:14.072+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:39:14.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:39:14.088+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:39:14.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:39:14.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T13:39:44.502+0000] {processor.py:157} INFO - Started process (PID=36905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:39:44.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:39:44.507+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:39:44.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:39:44.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:39:44.595+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:39:44.595+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:39:44.606+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:39:44.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:39:44.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-16T13:40:15.017+0000] {processor.py:157} INFO - Started process (PID=36915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:40:15.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:40:15.023+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:40:15.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:40:15.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:40:15.091+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:40:15.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:40:15.112+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:40:15.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:40:15.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T13:40:45.488+0000] {processor.py:157} INFO - Started process (PID=36925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:40:45.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:40:45.491+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:40:45.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:40:45.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:40:45.539+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:40:45.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:40:45.553+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:40:45.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:40:45.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-16T13:41:15.997+0000] {processor.py:157} INFO - Started process (PID=36935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:41:15.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:41:16.010+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:41:16.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:41:16.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:41:16.074+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:41:16.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:41:16.091+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:41:16.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:41:16.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-16T13:41:46.362+0000] {processor.py:157} INFO - Started process (PID=36945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:41:46.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:41:46.366+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:41:46.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:41:46.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:41:46.433+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:41:46.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:41:46.444+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:41:46.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:41:46.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-16T13:42:16.803+0000] {processor.py:157} INFO - Started process (PID=36955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:42:16.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:42:16.815+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:42:16.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:42:16.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:42:16.885+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:42:16.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:42:16.905+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:42:16.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:42:16.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-16T13:42:47.140+0000] {processor.py:157} INFO - Started process (PID=36965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:42:47.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:42:47.148+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:42:47.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:42:47.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:42:47.223+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:42:47.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:42:47.234+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:42:47.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:42:47.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-16T13:43:17.573+0000] {processor.py:157} INFO - Started process (PID=36975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:43:17.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:43:17.581+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:43:17.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:43:17.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:43:17.659+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:43:17.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:43:17.674+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:43:17.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:43:17.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-16T13:43:47.917+0000] {processor.py:157} INFO - Started process (PID=36985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:43:47.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:43:47.926+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:43:47.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:43:47.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:43:47.982+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:43:47.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:43:47.993+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:43:47.993+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:43:48.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-16T13:44:18.336+0000] {processor.py:157} INFO - Started process (PID=36995) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:44:18.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:44:18.353+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:44:18.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:44:18.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:44:18.422+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:44:18.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:44:18.441+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:44:18.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:44:18.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-16T13:44:48.815+0000] {processor.py:157} INFO - Started process (PID=37005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:44:48.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:44:48.819+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:44:48.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:44:48.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:44:48.859+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:44:48.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:44:48.874+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:44:48.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:44:48.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-16T13:45:19.268+0000] {processor.py:157} INFO - Started process (PID=37014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:45:19.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:45:19.286+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:45:19.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:45:19.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:45:19.354+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:45:19.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:45:19.369+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:45:19.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:45:19.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-16T13:45:49.727+0000] {processor.py:157} INFO - Started process (PID=37025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:45:49.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:45:49.734+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:45:49.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:45:49.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:45:49.795+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:45:49.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:45:49.808+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:45:49.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:45:49.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-16T13:46:20.176+0000] {processor.py:157} INFO - Started process (PID=37035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:46:20.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:46:20.180+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:46:20.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:46:20.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:46:20.247+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:46:20.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:46:20.262+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:46:20.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:46:20.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-16T13:46:50.555+0000] {processor.py:157} INFO - Started process (PID=37045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:46:50.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:46:50.563+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:46:50.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:46:50.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:46:50.633+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:46:50.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:46:50.648+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:46:50.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:46:50.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T13:47:21.134+0000] {processor.py:157} INFO - Started process (PID=37055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:47:21.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:47:21.139+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:47:21.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:47:21.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:47:21.201+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:47:21.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:47:21.218+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:47:21.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:47:21.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-16T13:47:51.601+0000] {processor.py:157} INFO - Started process (PID=37065) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:47:51.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:47:51.605+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:47:51.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:47:51.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:47:51.653+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:47:51.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:47:51.672+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:47:51.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:47:51.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-16T13:48:22.023+0000] {processor.py:157} INFO - Started process (PID=37075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:48:22.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:48:22.029+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:48:22.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:48:22.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:48:22.104+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:48:22.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:48:22.133+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:48:22.133+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:48:22.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-16T13:48:52.434+0000] {processor.py:157} INFO - Started process (PID=37085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:48:52.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:48:52.439+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:48:52.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:48:52.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:48:52.508+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:48:52.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:48:52.526+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:48:52.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:48:52.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-16T13:49:22.818+0000] {processor.py:157} INFO - Started process (PID=37094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:49:22.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:49:22.828+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:49:22.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:49:22.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:49:22.886+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:49:22.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:49:22.895+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:49:22.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:49:22.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-16T13:49:53.339+0000] {processor.py:157} INFO - Started process (PID=37105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:49:53.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:49:53.345+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:49:53.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:49:53.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:49:53.418+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:49:53.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:49:53.444+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:49:53.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:49:53.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-16T13:50:23.891+0000] {processor.py:157} INFO - Started process (PID=37114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:50:23.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:50:23.897+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:50:23.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:50:23.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:50:23.963+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:50:23.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:50:23.980+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:50:23.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:50:23.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-16T13:50:54.378+0000] {processor.py:157} INFO - Started process (PID=37125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:50:54.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:50:54.381+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:50:54.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:50:54.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:50:54.424+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:50:54.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:50:54.435+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:50:54.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:50:54.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-16T13:51:24.685+0000] {processor.py:157} INFO - Started process (PID=37135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:51:24.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:51:24.690+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:51:24.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:51:24.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:51:24.759+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:51:24.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:51:24.774+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:51:24.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:51:24.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-16T13:51:55.022+0000] {processor.py:157} INFO - Started process (PID=37145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:51:55.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:51:55.030+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:51:55.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:51:55.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:51:55.069+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:51:55.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:51:55.079+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:51:55.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:51:55.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-16T13:52:25.352+0000] {processor.py:157} INFO - Started process (PID=37155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:52:25.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:52:25.358+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:52:25.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:52:25.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:52:25.400+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:52:25.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:52:25.414+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:52:25.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:52:25.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-16T13:52:55.757+0000] {processor.py:157} INFO - Started process (PID=37165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:52:55.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:52:55.761+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:52:55.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:52:55.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:52:55.802+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:52:55.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:52:55.817+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:52:55.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:52:55.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-16T13:53:26.192+0000] {processor.py:157} INFO - Started process (PID=37175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:53:26.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:53:26.209+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:53:26.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:53:26.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:53:26.255+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:53:26.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:53:26.270+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:53:26.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:53:26.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-16T13:53:56.579+0000] {processor.py:157} INFO - Started process (PID=37185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:53:56.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:53:56.585+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:53:56.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:53:56.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:53:56.625+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:53:56.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:53:56.638+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:53:56.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:53:56.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-16T13:54:27.065+0000] {processor.py:157} INFO - Started process (PID=37195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:54:27.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:54:27.075+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:54:27.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:54:27.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:54:27.117+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:54:27.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:54:27.131+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:54:27.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:54:27.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-16T13:54:57.433+0000] {processor.py:157} INFO - Started process (PID=37205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:54:57.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:54:57.442+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:54:57.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:54:57.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:54:57.475+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:54:57.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:54:57.485+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:54:57.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:54:57.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-16T13:55:27.800+0000] {processor.py:157} INFO - Started process (PID=37215) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:55:27.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:55:27.807+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:55:27.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:55:27.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:55:27.861+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:55:27.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:55:27.883+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:55:27.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:55:27.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-16T13:55:58.144+0000] {processor.py:157} INFO - Started process (PID=37225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:55:58.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:55:58.148+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:55:58.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:55:58.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:55:58.208+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:55:58.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:55:58.219+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:55:58.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:55:58.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-16T13:56:28.674+0000] {processor.py:157} INFO - Started process (PID=37235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:56:28.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:56:28.679+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:56:28.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:56:28.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:56:28.719+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:56:28.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:56:28.733+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:56:28.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:56:28.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-16T13:56:59.104+0000] {processor.py:157} INFO - Started process (PID=37245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:56:59.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:56:59.108+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:56:59.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:56:59.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:56:59.177+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:56:59.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:56:59.194+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:56:59.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:56:59.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-16T13:57:29.467+0000] {processor.py:157} INFO - Started process (PID=37255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:57:29.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:57:29.479+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:57:29.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:57:29.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:57:29.540+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:57:29.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:57:29.564+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:57:29.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:57:29.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-16T13:57:59.889+0000] {processor.py:157} INFO - Started process (PID=37265) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:57:59.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:57:59.893+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:57:59.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:57:59.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:57:59.959+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:57:59.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:57:59.968+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:57:59.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:57:59.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-16T13:58:30.378+0000] {processor.py:157} INFO - Started process (PID=37275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:58:30.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:58:30.384+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:58:30.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:58:30.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:58:30.454+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:58:30.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:58:30.471+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:58:30.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:58:30.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-16T13:59:00.721+0000] {processor.py:157} INFO - Started process (PID=37285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:59:00.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:59:00.727+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:59:00.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:59:00.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:59:00.790+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:59:00.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:59:00.807+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:59:00.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:59:00.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-16T13:59:31.136+0000] {processor.py:157} INFO - Started process (PID=37295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:59:31.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T13:59:31.140+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:59:31.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:59:31.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T13:59:31.203+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:59:31.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T13:59:31.219+0000] {logging_mixin.py:151} INFO - [2024-09-16T13:59:31.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T13:59:31.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-16T14:00:01.646+0000] {processor.py:157} INFO - Started process (PID=37305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:00:01.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:00:01.651+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:00:01.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:00:01.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:00:01.711+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:00:01.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:00:01.734+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:00:01.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:00:01.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-16T14:00:32.007+0000] {processor.py:157} INFO - Started process (PID=37315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:00:32.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:00:32.011+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:00:32.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:00:32.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:00:32.059+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:00:32.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:00:32.077+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:00:32.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:00:32.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-16T14:01:02.457+0000] {processor.py:157} INFO - Started process (PID=37325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:01:02.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:01:02.461+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:01:02.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:01:02.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:01:02.505+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:01:02.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:01:02.518+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:01:02.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:01:02.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-16T14:01:32.971+0000] {processor.py:157} INFO - Started process (PID=37335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:01:32.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:01:32.975+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:01:32.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:01:33.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:01:33.062+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:01:33.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:01:33.080+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:01:33.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:01:33.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-16T14:02:03.273+0000] {processor.py:157} INFO - Started process (PID=37345) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:02:03.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:02:03.275+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:02:03.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:02:03.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:02:03.314+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:02:03.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:02:03.324+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:02:03.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:02:03.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-16T14:02:33.721+0000] {processor.py:157} INFO - Started process (PID=37355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:02:33.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:02:33.728+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:02:33.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:02:33.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:02:33.796+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:02:33.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:02:33.813+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:02:33.813+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:02:33.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-16T14:03:04.010+0000] {processor.py:157} INFO - Started process (PID=37365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:03:04.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:03:04.023+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:03:04.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:03:04.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:03:04.061+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:03:04.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:03:04.070+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:03:04.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:03:04.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-16T14:03:34.452+0000] {processor.py:157} INFO - Started process (PID=37374) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:03:34.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:03:34.466+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:03:34.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:03:34.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:03:34.522+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:03:34.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:03:34.537+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:03:34.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:03:34.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-16T14:04:04.912+0000] {processor.py:157} INFO - Started process (PID=37385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:04:04.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:04:04.916+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:04:04.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:04:04.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:04:04.962+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:04:04.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:04:04.973+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:04:04.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:04:04.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-16T14:04:35.382+0000] {processor.py:157} INFO - Started process (PID=37395) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:04:35.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:04:35.387+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:04:35.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:04:35.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:04:35.458+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:04:35.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:04:35.483+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:04:35.483+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:04:35.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-16T14:05:05.705+0000] {processor.py:157} INFO - Started process (PID=37405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:05:05.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:05:05.713+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:05:05.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:05:05.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:05:05.771+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:05:05.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:05:05.796+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:05:05.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:05:05.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-16T14:05:36.194+0000] {processor.py:157} INFO - Started process (PID=37415) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:05:36.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:05:36.199+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:05:36.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:05:36.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:05:36.271+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:05:36.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:05:36.286+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:05:36.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:05:36.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-16T14:06:06.627+0000] {processor.py:157} INFO - Started process (PID=37425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:06:06.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:06:06.631+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:06:06.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:06:06.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:06:06.699+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:06:06.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:06:06.710+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:06:06.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:06:06.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-16T14:06:37.090+0000] {processor.py:157} INFO - Started process (PID=37434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:06:37.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:06:37.097+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:06:37.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:06:37.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:06:37.167+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:06:37.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:06:37.196+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:06:37.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:06:37.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-16T14:07:07.685+0000] {processor.py:157} INFO - Started process (PID=37445) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:07:07.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:07:07.690+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:07:07.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:07:07.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:07:07.752+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:07:07.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:07:07.767+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:07:07.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:07:07.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-16T14:07:38.205+0000] {processor.py:157} INFO - Started process (PID=37455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:07:38.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:07:38.208+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:07:38.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:07:38.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:07:38.265+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:07:38.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:07:38.278+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:07:38.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:07:38.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-16T14:08:08.613+0000] {processor.py:157} INFO - Started process (PID=37464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:08:08.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:08:08.630+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:08:08.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:08:08.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:08:08.693+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:08:08.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:08:08.712+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:08:08.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:08:08.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-16T14:08:39.046+0000] {processor.py:157} INFO - Started process (PID=37475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:08:39.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:08:39.051+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:08:39.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:08:39.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:08:39.092+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:08:39.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:08:39.105+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:08:39.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:08:39.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-16T14:09:09.525+0000] {processor.py:157} INFO - Started process (PID=37485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:09:09.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:09:09.532+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:09:09.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:09:09.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:09:09.613+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:09:09.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:09:09.628+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:09:09.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:09:09.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-16T14:09:40.013+0000] {processor.py:157} INFO - Started process (PID=37495) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:09:40.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:09:40.017+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:09:40.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:09:40.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:09:40.086+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:09:40.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:09:40.099+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:09:40.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:09:40.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-16T14:10:10.505+0000] {processor.py:157} INFO - Started process (PID=37505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:10:10.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:10:10.514+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:10:10.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:10:10.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:10:10.562+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:10:10.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:10:10.578+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:10:10.578+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:10:10.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-16T14:10:40.935+0000] {processor.py:157} INFO - Started process (PID=37515) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:10:40.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:10:40.940+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:10:40.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:10:40.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:10:41.002+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:10:41.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:10:41.015+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:10:41.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:10:41.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-16T14:11:11.372+0000] {processor.py:157} INFO - Started process (PID=37524) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:11:11.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:11:11.379+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:11:11.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:11:11.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:11:11.449+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:11:11.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:11:11.478+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:11:11.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:11:11.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-16T14:11:41.882+0000] {processor.py:157} INFO - Started process (PID=37535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:11:41.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:11:41.887+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:11:41.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:11:41.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:11:41.953+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:11:41.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:11:41.967+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:11:41.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:11:41.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-16T14:12:12.405+0000] {processor.py:157} INFO - Started process (PID=37545) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:12:12.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:12:12.425+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:12:12.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:12:12.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:12:12.475+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:12:12.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:12:12.500+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:12:12.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:12:12.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-16T14:12:42.756+0000] {processor.py:157} INFO - Started process (PID=37555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:12:42.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:12:42.763+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:12:42.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:12:42.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:12:42.832+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:12:42.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:12:42.846+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:12:42.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:12:42.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-16T14:13:13.183+0000] {processor.py:157} INFO - Started process (PID=37565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:13:13.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:13:13.186+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:13:13.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:13:13.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:13:13.246+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:13:13.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:13:13.258+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:13:13.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:13:13.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-16T14:13:43.569+0000] {processor.py:157} INFO - Started process (PID=37575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:13:43.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:13:43.574+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:13:43.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:13:43.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:13:43.641+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:13:43.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:13:43.657+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:13:43.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:13:43.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-16T14:14:13.902+0000] {processor.py:157} INFO - Started process (PID=37585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:14:13.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:14:13.907+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:14:13.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:14:13.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:14:13.961+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:14:13.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:14:13.988+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:14:13.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:14:13.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-16T14:14:44.185+0000] {processor.py:157} INFO - Started process (PID=37595) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:14:44.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:14:44.192+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:14:44.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:14:44.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:14:44.268+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:14:44.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:14:44.280+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:14:44.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:14:44.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-16T14:15:14.732+0000] {processor.py:157} INFO - Started process (PID=37605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:15:14.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:15:14.739+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:15:14.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:15:14.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:15:14.808+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:15:14.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:15:14.826+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:15:14.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:15:14.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-16T14:15:45.236+0000] {processor.py:157} INFO - Started process (PID=37615) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:15:45.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:15:45.244+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:15:45.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:15:45.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:15:45.318+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:15:45.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:15:45.336+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:15:45.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:15:45.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-16T14:31:33.305+0000] {processor.py:157} INFO - Started process (PID=37625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:31:33.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:31:33.312+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:31:33.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:31:33.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:31:33.386+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:31:33.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:31:33.418+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:31:33.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:31:33.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-16T14:32:03.809+0000] {processor.py:157} INFO - Started process (PID=37636) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:32:03.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:32:03.825+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:32:03.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:32:03.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:32:03.891+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:32:03.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:32:03.910+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:32:03.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:32:03.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-16T14:32:34.220+0000] {processor.py:157} INFO - Started process (PID=37646) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:32:34.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:32:34.234+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:32:34.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:32:34.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:32:34.366+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:32:34.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:32:34.396+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:32:34.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:32:34.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.206 seconds
[2024-09-16T14:33:04.532+0000] {processor.py:157} INFO - Started process (PID=37657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:33:04.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:33:04.546+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:33:04.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:33:04.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:33:04.600+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:33:04.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:33:04.618+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:33:04.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:33:04.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-16T14:33:35.023+0000] {processor.py:157} INFO - Started process (PID=37667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:33:35.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:33:35.032+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:33:35.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:33:35.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:33:35.106+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:33:35.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:33:35.128+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:33:35.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:33:35.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-16T14:34:05.370+0000] {processor.py:157} INFO - Started process (PID=37677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:34:05.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:34:05.383+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:34:05.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:34:05.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:34:05.466+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:34:05.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:34:05.487+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:34:05.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:34:05.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-16T14:34:35.721+0000] {processor.py:157} INFO - Started process (PID=37687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:34:35.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:34:35.727+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:34:35.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:34:35.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:34:35.789+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:34:35.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:34:35.808+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:34:35.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:34:35.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-16T14:35:06.172+0000] {processor.py:157} INFO - Started process (PID=37697) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:35:06.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:35:06.180+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:35:06.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:35:06.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:35:06.256+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:35:06.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:35:06.273+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:35:06.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:35:06.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-16T14:35:36.554+0000] {processor.py:157} INFO - Started process (PID=37707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:35:36.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:35:36.562+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:35:36.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:35:36.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:35:36.619+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:35:36.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:35:36.644+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:35:36.644+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:35:36.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-16T14:36:07.058+0000] {processor.py:157} INFO - Started process (PID=37717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:36:07.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:36:07.069+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:36:07.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:36:07.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:36:07.136+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:36:07.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:36:07.154+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:36:07.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:36:07.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-16T14:36:37.397+0000] {processor.py:157} INFO - Started process (PID=37727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:36:37.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:36:37.402+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:36:37.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:36:37.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:36:37.447+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:36:37.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:36:37.461+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:36:37.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:36:37.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-16T14:37:07.805+0000] {processor.py:157} INFO - Started process (PID=37737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:37:07.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:37:07.808+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:37:07.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:37:07.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:37:07.849+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:37:07.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:37:07.863+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:37:07.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:37:07.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-16T14:37:38.235+0000] {processor.py:157} INFO - Started process (PID=37746) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:37:38.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:37:38.246+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:37:38.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:37:38.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:37:38.311+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:37:38.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:37:38.326+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:37:38.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:37:38.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-16T14:38:08.603+0000] {processor.py:157} INFO - Started process (PID=37757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:38:08.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:38:08.607+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:38:08.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:38:08.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:38:08.672+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:38:08.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:38:08.687+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:38:08.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:38:08.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-16T14:38:38.946+0000] {processor.py:157} INFO - Started process (PID=37767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:38:38.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:38:38.965+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:38:38.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:38:38.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:38:39.042+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:38:39.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:38:39.057+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:38:39.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:38:39.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-16T14:39:09.291+0000] {processor.py:157} INFO - Started process (PID=37777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:39:09.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:39:09.295+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:39:09.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:39:09.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:39:09.331+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:39:09.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:39:09.343+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:39:09.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:39:09.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-16T14:39:39.774+0000] {processor.py:157} INFO - Started process (PID=37787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:39:39.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:39:39.780+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:39:39.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:39:39.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:39:39.871+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:39:39.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:39:39.894+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:39:39.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:39:39.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-16T14:40:10.249+0000] {processor.py:157} INFO - Started process (PID=37797) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:40:10.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:40:10.258+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:40:10.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:40:10.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:40:10.334+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:40:10.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:40:10.358+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:40:10.358+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:40:10.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-16T14:40:40.519+0000] {processor.py:157} INFO - Started process (PID=37807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:40:40.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:40:40.524+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:40:40.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:40:40.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:40:40.581+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:40:40.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:40:40.594+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:40:40.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:40:40.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-16T14:41:11.013+0000] {processor.py:157} INFO - Started process (PID=37817) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:41:11.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:41:11.029+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:41:11.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:41:11.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:41:11.105+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:41:11.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:41:11.123+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:41:11.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:41:11.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-16T14:41:41.352+0000] {processor.py:157} INFO - Started process (PID=37827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:41:41.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:41:41.359+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:41:41.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:41:41.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:41:41.427+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:41:41.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:41:41.441+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:41:41.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:41:41.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-16T14:42:11.759+0000] {processor.py:157} INFO - Started process (PID=37837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:42:11.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:42:11.773+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:42:11.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:42:11.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:42:11.835+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:42:11.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:42:11.854+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:42:11.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:42:11.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-16T14:42:42.222+0000] {processor.py:157} INFO - Started process (PID=37847) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:42:42.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:42:42.227+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:42:42.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:42:42.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:42:42.271+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:42:42.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:42:42.288+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:42:42.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:42:42.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-16T14:43:12.622+0000] {processor.py:157} INFO - Started process (PID=37857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:43:12.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:43:12.627+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:43:12.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:43:12.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:43:12.692+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:43:12.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:43:12.707+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:43:12.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:43:12.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-16T14:43:43.070+0000] {processor.py:157} INFO - Started process (PID=37867) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:43:43.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:43:43.075+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:43:43.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:43:43.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:43:43.121+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:43:43.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:43:43.134+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:43:43.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:43:43.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-16T14:44:13.567+0000] {processor.py:157} INFO - Started process (PID=37877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:44:13.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:44:13.573+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:44:13.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:44:13.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:44:13.636+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:44:13.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:44:13.652+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:44:13.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:44:13.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T14:44:43.914+0000] {processor.py:157} INFO - Started process (PID=37887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:44:43.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:44:43.920+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:44:43.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:44:43.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:44:43.990+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:44:43.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:44:44.003+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:44:44.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:44:44.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-16T14:45:14.401+0000] {processor.py:157} INFO - Started process (PID=37897) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:45:14.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:45:14.406+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:45:14.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:45:14.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:45:14.474+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:45:14.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:45:14.488+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:45:14.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:45:14.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-16T14:45:44.796+0000] {processor.py:157} INFO - Started process (PID=37907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:45:44.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:45:44.803+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:45:44.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:45:44.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:45:44.870+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:45:44.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:45:44.881+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:45:44.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:45:44.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-16T14:46:15.262+0000] {processor.py:157} INFO - Started process (PID=37917) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:46:15.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:46:15.272+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:46:15.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:46:15.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:46:15.333+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:46:15.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:46:15.349+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:46:15.349+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:46:15.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-16T14:46:45.602+0000] {processor.py:157} INFO - Started process (PID=37927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:46:45.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:46:45.608+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:46:45.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:46:45.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:46:45.679+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:46:45.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:46:45.697+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:46:45.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:46:45.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-16T14:47:16.052+0000] {processor.py:157} INFO - Started process (PID=37937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:47:16.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:47:16.055+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:47:16.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:47:16.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:47:16.101+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:47:16.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:47:16.110+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:47:16.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:47:16.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-16T14:47:46.425+0000] {processor.py:157} INFO - Started process (PID=37947) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:47:46.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:47:46.435+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:47:46.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:47:46.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:47:46.501+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:47:46.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:47:46.520+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:47:46.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:47:46.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-16T14:48:16.807+0000] {processor.py:157} INFO - Started process (PID=37957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:48:16.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:48:16.814+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:48:16.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:48:16.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:48:16.893+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:48:16.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:48:16.909+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:48:16.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:48:16.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-16T14:48:47.122+0000] {processor.py:157} INFO - Started process (PID=37967) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:48:47.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:48:47.125+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:48:47.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:48:47.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:48:47.165+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:48:47.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:48:47.176+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:48:47.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:48:47.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-16T14:49:17.606+0000] {processor.py:157} INFO - Started process (PID=37977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:49:17.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:49:17.611+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:49:17.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:49:17.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:49:17.654+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:49:17.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:49:17.668+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:49:17.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:49:17.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-16T14:49:47.955+0000] {processor.py:157} INFO - Started process (PID=37987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:49:47.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:49:47.957+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:49:47.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:49:47.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:49:48.013+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:49:48.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:49:48.027+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:49:48.027+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:49:48.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-16T14:50:18.416+0000] {processor.py:157} INFO - Started process (PID=37997) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:50:18.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:50:18.427+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:50:18.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:50:18.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:50:18.514+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:50:18.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:50:18.528+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:50:18.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:50:18.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-16T14:50:48.727+0000] {processor.py:157} INFO - Started process (PID=38007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:50:48.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:50:48.731+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:50:48.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:50:48.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:50:48.808+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:50:48.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:50:48.821+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:50:48.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:50:48.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-16T14:51:19.206+0000] {processor.py:157} INFO - Started process (PID=38017) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:51:19.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:51:19.216+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:51:19.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:51:19.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:51:19.283+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:51:19.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:51:19.304+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:51:19.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:51:19.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-16T14:51:49.512+0000] {processor.py:157} INFO - Started process (PID=38027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:51:49.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:51:49.517+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:51:49.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:51:49.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:51:49.562+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:51:49.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:51:49.572+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:51:49.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:51:49.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-16T14:52:19.838+0000] {processor.py:157} INFO - Started process (PID=38037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:52:19.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:52:19.847+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:52:19.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:52:19.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:52:19.929+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:52:19.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:52:19.949+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:52:19.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:52:19.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-16T14:52:50.133+0000] {processor.py:157} INFO - Started process (PID=38047) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:52:50.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:52:50.138+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:52:50.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:52:50.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:52:50.181+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:52:50.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:52:50.190+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:52:50.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:52:50.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-16T14:53:20.554+0000] {processor.py:157} INFO - Started process (PID=38057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:53:20.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:53:20.573+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:53:20.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:53:20.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:53:20.654+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:53:20.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:53:20.672+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:53:20.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:53:20.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-16T14:53:51.038+0000] {processor.py:157} INFO - Started process (PID=38067) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:53:51.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:53:51.044+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:53:51.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:53:51.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:53:51.109+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:53:51.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:53:51.119+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:53:51.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:53:51.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-16T14:54:21.437+0000] {processor.py:157} INFO - Started process (PID=38077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:54:21.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:54:21.442+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:54:21.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:54:21.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:54:21.516+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:54:21.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:54:21.532+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:54:21.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:54:21.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T14:54:51.763+0000] {processor.py:157} INFO - Started process (PID=38087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:54:51.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:54:51.770+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:54:51.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:54:51.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:54:51.826+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:54:51.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:54:51.842+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:54:51.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:54:51.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-16T14:55:22.162+0000] {processor.py:157} INFO - Started process (PID=38096) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:55:22.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:55:22.167+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:55:22.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:55:22.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:55:22.264+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:55:22.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:55:22.279+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:55:22.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:55:22.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-16T14:55:52.491+0000] {processor.py:157} INFO - Started process (PID=38107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:55:52.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:55:52.501+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:55:52.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:55:52.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:55:52.559+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:55:52.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:55:52.573+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:55:52.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:55:52.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-16T14:56:23.039+0000] {processor.py:157} INFO - Started process (PID=38117) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:56:23.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:56:23.047+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:56:23.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:56:23.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:56:23.125+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:56:23.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:56:23.158+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:56:23.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:56:23.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-16T14:56:53.365+0000] {processor.py:157} INFO - Started process (PID=38127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:56:53.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:56:53.369+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:56:53.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:56:53.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:56:53.412+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:56:53.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:56:53.427+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:56:53.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:56:53.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-16T14:57:23.799+0000] {processor.py:157} INFO - Started process (PID=38137) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:57:23.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:57:23.805+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:57:23.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:57:23.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:57:23.884+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:57:23.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:57:23.903+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:57:23.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:57:23.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-16T14:57:54.147+0000] {processor.py:157} INFO - Started process (PID=38147) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:57:54.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:57:54.152+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:57:54.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:57:54.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:57:54.216+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:57:54.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:57:54.227+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:57:54.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:57:54.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-16T14:58:24.630+0000] {processor.py:157} INFO - Started process (PID=38157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:58:24.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:58:24.637+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:58:24.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:58:24.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:58:24.699+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:58:24.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:58:24.717+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:58:24.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:58:24.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-16T14:58:54.978+0000] {processor.py:157} INFO - Started process (PID=38167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:58:54.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:58:54.982+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:58:54.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:58:54.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:58:55.026+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:58:55.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:58:55.052+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:58:55.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:58:55.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-16T14:59:25.354+0000] {processor.py:157} INFO - Started process (PID=38177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:59:25.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:59:25.358+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:59:25.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:59:25.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:59:25.401+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:59:25.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:59:25.419+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:59:25.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:59:25.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-16T14:59:55.781+0000] {processor.py:157} INFO - Started process (PID=38187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:59:55.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T14:59:55.785+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:59:55.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:59:55.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T14:59:55.832+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:59:55.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T14:59:55.844+0000] {logging_mixin.py:151} INFO - [2024-09-16T14:59:55.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T14:59:55.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-16T15:00:26.132+0000] {processor.py:157} INFO - Started process (PID=38196) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:00:26.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:00:26.137+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:00:26.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:00:26.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:00:26.216+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:00:26.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:00:26.228+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:00:26.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:00:26.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-16T15:00:56.471+0000] {processor.py:157} INFO - Started process (PID=38207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:00:56.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:00:56.475+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:00:56.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:00:56.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:00:56.536+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:00:56.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:00:56.548+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:00:56.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:00:56.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-16T15:01:26.933+0000] {processor.py:157} INFO - Started process (PID=38216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:01:26.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:01:26.939+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:01:26.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:01:26.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:01:27.007+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:01:27.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:01:27.019+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:01:27.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:01:27.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-16T15:01:57.325+0000] {processor.py:157} INFO - Started process (PID=38227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:01:57.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:01:57.334+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:01:57.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:01:57.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:01:57.409+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:01:57.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:01:57.430+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:01:57.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:01:57.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-16T15:02:27.721+0000] {processor.py:157} INFO - Started process (PID=38237) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:02:27.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:02:27.735+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:02:27.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:02:27.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:02:27.777+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:02:27.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:02:27.790+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:02:27.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:02:27.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-16T15:02:58.202+0000] {processor.py:157} INFO - Started process (PID=38247) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:02:58.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:02:58.205+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:02:58.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:02:58.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:02:58.279+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:02:58.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:02:58.297+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:02:58.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:02:58.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-16T15:03:28.582+0000] {processor.py:157} INFO - Started process (PID=38256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:03:28.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:03:28.589+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:03:28.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:03:28.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:03:28.653+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:03:28.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:03:28.662+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:03:28.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:03:28.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-16T15:03:58.997+0000] {processor.py:157} INFO - Started process (PID=38267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:03:58.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:03:59.006+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:03:59.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:03:59.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:03:59.086+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:03:59.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:03:59.113+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:03:59.113+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:03:59.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-16T15:04:29.392+0000] {processor.py:157} INFO - Started process (PID=38277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:04:29.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:04:29.400+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:04:29.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:04:29.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:04:29.465+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:04:29.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:04:29.489+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:04:29.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:04:29.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-16T15:04:59.793+0000] {processor.py:157} INFO - Started process (PID=38287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:04:59.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:04:59.800+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:04:59.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:04:59.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:04:59.891+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:04:59.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:04:59.913+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:04:59.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:04:59.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-16T15:05:30.358+0000] {processor.py:157} INFO - Started process (PID=38296) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:05:30.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:05:30.366+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:05:30.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:05:30.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:05:30.428+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:05:30.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:05:30.451+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:05:30.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:05:30.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-16T15:06:00.855+0000] {processor.py:157} INFO - Started process (PID=38307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:06:00.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:06:00.863+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:06:00.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:06:00.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:06:00.929+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:06:00.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:06:00.947+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:06:00.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:06:00.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-16T15:06:31.332+0000] {processor.py:157} INFO - Started process (PID=38317) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:06:31.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:06:31.338+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:06:31.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:06:31.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:06:31.385+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:06:31.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:06:31.401+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:06:31.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:06:31.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-16T15:07:01.713+0000] {processor.py:157} INFO - Started process (PID=38327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:07:01.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:07:01.715+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:07:01.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:07:01.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:07:01.763+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:07:01.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:07:01.773+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:07:01.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:07:01.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-16T15:07:32.147+0000] {processor.py:157} INFO - Started process (PID=38337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:07:32.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:07:32.152+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:07:32.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:07:32.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:07:32.215+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:07:32.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:07:32.228+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:07:32.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:07:32.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-16T15:08:02.516+0000] {processor.py:157} INFO - Started process (PID=38347) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:08:02.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:08:02.520+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:08:02.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:08:02.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:08:02.556+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:08:02.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:08:02.567+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:08:02.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:08:02.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-16T15:08:32.971+0000] {processor.py:157} INFO - Started process (PID=38356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:08:32.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:08:32.982+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:08:32.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:08:33.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:08:33.052+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:08:33.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:08:33.079+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:08:33.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:08:33.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-16T15:09:03.299+0000] {processor.py:157} INFO - Started process (PID=38367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:09:03.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:09:03.305+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:09:03.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:09:03.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:09:03.346+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:09:03.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:09:03.356+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:09:03.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:09:03.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-16T15:09:33.714+0000] {processor.py:157} INFO - Started process (PID=38376) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:09:33.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:09:33.725+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:09:33.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:09:33.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:09:33.790+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:09:33.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:09:33.818+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:09:33.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:09:33.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-16T15:10:04.039+0000] {processor.py:157} INFO - Started process (PID=38387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:10:04.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:10:04.046+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:10:04.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:10:04.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:10:04.096+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:10:04.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:10:04.109+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:10:04.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:10:04.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-16T15:10:34.488+0000] {processor.py:157} INFO - Started process (PID=38397) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:10:34.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:10:34.492+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:10:34.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:10:34.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:10:34.564+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:10:34.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:10:34.584+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:10:34.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:10:34.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-16T15:11:04.992+0000] {processor.py:157} INFO - Started process (PID=38406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:11:04.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:11:04.997+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:11:04.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:11:05.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:11:05.065+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:11:05.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:11:05.075+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:11:05.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:11:05.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-16T15:11:35.360+0000] {processor.py:157} INFO - Started process (PID=38417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:11:35.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:11:35.364+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:11:35.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:11:35.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:11:35.436+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:11:35.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:11:35.451+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:11:35.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:11:35.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-16T15:12:05.721+0000] {processor.py:157} INFO - Started process (PID=38427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:12:05.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:12:05.730+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:12:05.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:12:05.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:12:05.790+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:12:05.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:12:05.802+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:12:05.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:12:05.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-16T15:12:36.097+0000] {processor.py:157} INFO - Started process (PID=38437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:12:36.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:12:36.101+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:12:36.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:12:36.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:12:36.172+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:12:36.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:12:36.186+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:12:36.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:12:36.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T15:13:06.651+0000] {processor.py:157} INFO - Started process (PID=38445) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:13:06.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:13:06.657+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:13:06.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:13:06.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:13:06.708+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:13:06.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:13:06.719+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:13:06.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:13:06.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-16T15:13:37.072+0000] {processor.py:157} INFO - Started process (PID=38457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:13:37.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:13:37.075+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:13:37.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:13:37.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:13:37.146+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:13:37.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:13:37.167+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:13:37.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:13:37.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-16T15:14:07.460+0000] {processor.py:157} INFO - Started process (PID=38467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:14:07.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:14:07.466+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:14:07.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:14:07.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:14:07.524+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:14:07.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:14:07.539+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:14:07.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:14:07.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-16T15:14:37.814+0000] {processor.py:157} INFO - Started process (PID=38477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:14:37.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:14:37.826+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:14:37.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:14:37.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:14:37.874+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:14:37.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:14:37.897+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:14:37.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:14:37.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-16T15:15:08.203+0000] {processor.py:157} INFO - Started process (PID=38487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:15:08.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:15:08.210+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:15:08.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:15:08.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:15:08.280+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:15:08.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:15:08.293+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:15:08.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:15:08.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T15:15:38.636+0000] {processor.py:157} INFO - Started process (PID=38497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:15:38.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:15:38.642+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:15:38.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:15:38.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:15:38.683+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:15:38.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:15:38.696+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:15:38.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:15:38.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-16T15:16:09.129+0000] {processor.py:157} INFO - Started process (PID=38507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:16:09.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:16:09.137+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:16:09.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:16:09.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:16:09.205+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:16:09.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:16:09.222+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:16:09.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:16:09.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-16T15:16:39.476+0000] {processor.py:157} INFO - Started process (PID=38517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:16:39.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:16:39.492+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:16:39.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:16:39.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:16:39.573+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:16:39.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:16:39.608+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:16:39.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:16:39.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-16T15:17:09.859+0000] {processor.py:157} INFO - Started process (PID=38527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:17:09.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:17:09.865+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:17:09.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:17:09.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:17:09.941+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:17:09.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:17:09.970+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:17:09.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:17:09.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-16T15:17:40.311+0000] {processor.py:157} INFO - Started process (PID=38537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:17:40.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:17:40.314+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:17:40.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:17:40.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:17:40.365+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:17:40.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:17:40.375+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:17:40.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:17:40.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-16T15:18:10.764+0000] {processor.py:157} INFO - Started process (PID=38546) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:18:10.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:18:10.778+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:18:10.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:18:10.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:18:10.848+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:18:10.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:18:10.864+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:18:10.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:18:10.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-16T15:18:41.208+0000] {processor.py:157} INFO - Started process (PID=38557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:18:41.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:18:41.211+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:18:41.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:18:41.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:18:41.251+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:18:41.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:18:41.262+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:18:41.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:18:41.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-16T15:19:11.639+0000] {processor.py:157} INFO - Started process (PID=38566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:19:11.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:19:11.653+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:19:11.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:19:11.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:19:11.713+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:19:11.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:19:11.728+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:19:11.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:19:11.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-16T15:19:41.957+0000] {processor.py:157} INFO - Started process (PID=38577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:19:41.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:19:41.964+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:19:41.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:19:41.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:19:42.011+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:19:42.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:19:42.023+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:19:42.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:19:42.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-16T15:20:12.426+0000] {processor.py:157} INFO - Started process (PID=38587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:20:12.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:20:12.431+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:20:12.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:20:12.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:20:12.498+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:20:12.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:20:12.513+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:20:12.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:20:12.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-16T15:20:42.748+0000] {processor.py:157} INFO - Started process (PID=38597) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:20:42.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:20:42.753+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:20:42.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:20:42.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:20:42.812+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:20:42.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:20:42.824+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:20:42.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:20:42.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-16T15:21:13.130+0000] {processor.py:157} INFO - Started process (PID=38606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:21:13.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:21:13.136+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:21:13.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:21:13.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:21:13.227+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:21:13.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:21:13.249+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:21:13.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:21:13.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-16T15:21:43.494+0000] {processor.py:157} INFO - Started process (PID=38617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:21:43.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:21:43.498+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:21:43.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:21:43.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:21:43.567+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:21:43.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:21:43.580+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:21:43.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:21:43.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-16T15:22:13.871+0000] {processor.py:157} INFO - Started process (PID=38627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:22:13.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:22:13.876+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:22:13.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:22:13.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:22:13.964+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:22:13.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:22:13.980+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:22:13.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:22:13.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-16T15:22:44.432+0000] {processor.py:157} INFO - Started process (PID=38637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:22:44.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:22:44.453+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:22:44.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:22:44.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:22:44.501+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:22:44.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:22:44.516+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:22:44.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:22:44.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-16T15:23:14.850+0000] {processor.py:157} INFO - Started process (PID=38647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:23:14.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:23:14.855+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:23:14.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:23:14.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:23:14.911+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:23:14.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:23:14.926+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:23:14.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:23:14.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-16T15:23:45.362+0000] {processor.py:157} INFO - Started process (PID=38657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:23:45.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:23:45.366+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:23:45.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:23:45.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:23:45.425+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:23:45.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:23:45.439+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:23:45.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:23:45.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-16T15:24:15.813+0000] {processor.py:157} INFO - Started process (PID=38667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:24:15.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:24:15.821+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:24:15.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:24:15.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:24:15.878+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:24:15.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:24:15.894+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:24:15.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:24:15.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-16T15:24:46.164+0000] {processor.py:157} INFO - Started process (PID=38677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:24:46.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:24:46.168+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:24:46.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:24:46.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:24:46.204+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:24:46.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:24:46.215+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:24:46.215+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:24:46.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-16T15:25:16.647+0000] {processor.py:157} INFO - Started process (PID=38686) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:25:16.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:25:16.660+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:25:16.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:25:16.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:25:16.728+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:25:16.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:25:16.751+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:25:16.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:25:16.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-16T15:25:46.928+0000] {processor.py:157} INFO - Started process (PID=38697) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:25:46.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:25:46.933+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:25:46.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:25:46.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:25:46.987+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:25:46.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:25:46.997+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:25:46.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:25:47.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-16T15:26:17.228+0000] {processor.py:157} INFO - Started process (PID=38706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:26:17.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:26:17.240+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:26:17.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:26:17.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:26:17.306+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:26:17.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:26:17.331+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:26:17.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:26:17.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-16T15:26:47.650+0000] {processor.py:157} INFO - Started process (PID=38717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:26:47.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:26:47.653+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:26:47.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:26:47.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:26:47.697+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:26:47.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:26:47.709+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:26:47.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:26:47.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-16T15:27:18.116+0000] {processor.py:157} INFO - Started process (PID=38726) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:27:18.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:27:18.121+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:27:18.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:27:18.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:27:18.198+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:27:18.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:27:18.212+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:27:18.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:27:18.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-16T15:27:48.495+0000] {processor.py:157} INFO - Started process (PID=38737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:27:48.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:27:48.506+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:27:48.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:27:48.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:27:48.554+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:27:48.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:27:48.565+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:27:48.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:27:48.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-16T15:28:18.952+0000] {processor.py:157} INFO - Started process (PID=38747) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:28:18.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:28:18.957+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:28:18.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:28:18.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:28:19.025+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:28:19.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:28:19.044+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:28:19.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:28:19.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-16T15:28:49.293+0000] {processor.py:157} INFO - Started process (PID=38757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:28:49.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:28:49.301+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:28:49.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:28:49.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:28:49.367+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:28:49.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:28:49.383+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:28:49.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:28:49.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-16T15:29:19.792+0000] {processor.py:157} INFO - Started process (PID=38767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:29:19.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:29:19.805+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:29:19.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:29:19.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:29:19.860+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:29:19.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:29:19.875+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:29:19.875+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:29:19.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-16T15:29:50.149+0000] {processor.py:157} INFO - Started process (PID=38776) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:29:50.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:29:50.155+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:29:50.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:29:50.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:29:50.225+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:29:50.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:29:50.239+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:29:50.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:29:50.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-16T15:30:20.539+0000] {processor.py:157} INFO - Started process (PID=38787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:30:20.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:30:20.549+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:30:20.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:30:20.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:30:20.631+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:30:20.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:30:20.650+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:30:20.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:30:20.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-16T15:30:51.009+0000] {processor.py:157} INFO - Started process (PID=38796) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:30:51.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:30:51.016+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:30:51.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:30:51.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:30:51.113+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:30:51.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:30:51.131+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:30:51.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:30:51.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-16T15:31:21.326+0000] {processor.py:157} INFO - Started process (PID=38807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:31:21.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:31:21.332+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:31:21.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:31:21.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:31:21.379+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:31:21.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:31:21.394+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:31:21.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:31:21.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-16T15:31:51.770+0000] {processor.py:157} INFO - Started process (PID=38817) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:31:51.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:31:51.774+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:31:51.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:31:51.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:31:51.838+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:31:51.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:31:51.853+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:31:51.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:31:51.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-16T15:32:22.222+0000] {processor.py:157} INFO - Started process (PID=38826) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:32:22.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:32:22.238+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:32:22.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:32:22.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:32:22.315+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:32:22.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:32:22.329+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:32:22.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:32:22.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-16T15:32:52.741+0000] {processor.py:157} INFO - Started process (PID=38837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:32:52.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:32:52.753+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:32:52.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:32:52.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:32:52.840+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:32:52.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:32:52.869+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:32:52.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:32:52.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-09-16T15:33:23.116+0000] {processor.py:157} INFO - Started process (PID=38847) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:33:23.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:33:23.121+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:33:23.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:33:23.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:33:23.190+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:33:23.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:33:23.219+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:33:23.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:33:23.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-16T15:33:53.507+0000] {processor.py:157} INFO - Started process (PID=38857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:33:53.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:33:53.515+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:33:53.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:33:53.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:33:53.605+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:33:53.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:33:53.625+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:33:53.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:33:53.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-16T15:34:23.825+0000] {processor.py:157} INFO - Started process (PID=38867) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:34:23.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:34:23.829+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:34:23.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:34:23.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:34:23.866+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:34:23.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:34:23.875+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:34:23.875+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:34:23.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-16T15:34:54.173+0000] {processor.py:157} INFO - Started process (PID=38876) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:34:54.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:34:54.182+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:34:54.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:34:54.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:34:54.289+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:34:54.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:34:54.310+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:34:54.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:34:54.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-09-16T15:35:24.457+0000] {processor.py:157} INFO - Started process (PID=38887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:35:24.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:35:24.462+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:35:24.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:35:24.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:35:24.505+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:35:24.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:35:24.520+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:35:24.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:35:24.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-16T15:35:54.808+0000] {processor.py:157} INFO - Started process (PID=38897) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:35:54.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:35:54.815+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:35:54.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:35:54.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:35:54.881+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:35:54.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:35:54.906+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:35:54.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:35:54.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-16T15:36:25.181+0000] {processor.py:157} INFO - Started process (PID=38907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:36:25.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:36:25.186+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:36:25.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:36:25.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:36:25.232+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:36:25.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:36:25.244+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:36:25.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:36:25.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-16T15:36:55.616+0000] {processor.py:157} INFO - Started process (PID=38917) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:36:55.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:36:55.622+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:36:55.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:36:55.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:36:55.673+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:36:55.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:36:55.689+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:36:55.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:36:55.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-16T15:37:26.015+0000] {processor.py:157} INFO - Started process (PID=38927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:37:26.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:37:26.021+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:37:26.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:37:26.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:37:26.080+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:37:26.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:37:26.090+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:37:26.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:37:26.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-16T15:37:56.458+0000] {processor.py:157} INFO - Started process (PID=38937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:37:56.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:37:56.465+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:37:56.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:37:56.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:37:56.508+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:37:56.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:37:56.532+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:37:56.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:37:56.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-16T15:38:26.816+0000] {processor.py:157} INFO - Started process (PID=38947) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:38:26.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:38:26.821+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:38:26.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:38:26.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:38:26.865+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:38:26.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:38:26.876+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:38:26.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:38:26.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-16T15:38:57.201+0000] {processor.py:157} INFO - Started process (PID=38957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:38:57.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:38:57.205+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:38:57.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:38:57.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:38:57.245+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:38:57.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:38:57.259+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:38:57.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:38:57.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-16T15:39:27.485+0000] {processor.py:157} INFO - Started process (PID=38967) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:39:27.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:39:27.491+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:39:27.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:39:27.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:39:27.531+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:39:27.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:39:27.545+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:39:27.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:39:27.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-16T15:39:57.896+0000] {processor.py:157} INFO - Started process (PID=38977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:39:57.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:39:57.905+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:39:57.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:39:57.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:39:57.963+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:39:57.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:39:57.983+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:39:57.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:39:57.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-16T15:40:28.230+0000] {processor.py:157} INFO - Started process (PID=38987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:40:28.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:40:28.237+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:40:28.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:40:28.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:40:28.306+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:40:28.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:40:28.317+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:40:28.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:40:28.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-16T15:40:58.619+0000] {processor.py:157} INFO - Started process (PID=38997) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:40:58.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:40:58.623+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:40:58.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:40:58.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:40:58.659+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:40:58.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:40:58.673+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:40:58.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:40:58.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-16T15:41:29.113+0000] {processor.py:157} INFO - Started process (PID=39007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:41:29.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:41:29.116+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:41:29.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:41:29.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:41:29.158+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:41:29.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:41:29.170+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:41:29.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:41:29.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-16T15:41:59.537+0000] {processor.py:157} INFO - Started process (PID=39017) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:41:59.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:41:59.544+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:41:59.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:41:59.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:41:59.582+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:41:59.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:41:59.595+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:41:59.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:41:59.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-16T15:42:30.014+0000] {processor.py:157} INFO - Started process (PID=39027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:42:30.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:42:30.020+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:42:30.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:42:30.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:42:30.062+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:42:30.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:42:30.074+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:42:30.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:42:30.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-16T15:43:00.393+0000] {processor.py:157} INFO - Started process (PID=39037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:43:00.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:43:00.399+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:43:00.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:43:00.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:43:00.471+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:43:00.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:43:00.488+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:43:00.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:43:00.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-16T15:43:30.807+0000] {processor.py:157} INFO - Started process (PID=39047) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:43:30.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:43:30.813+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:43:30.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:43:30.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:43:30.878+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:43:30.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:43:30.888+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:43:30.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:43:30.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-16T15:44:01.297+0000] {processor.py:157} INFO - Started process (PID=39057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:44:01.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:44:01.302+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:44:01.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:44:01.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:44:01.341+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:44:01.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:44:01.359+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:44:01.358+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:44:01.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-16T15:44:31.704+0000] {processor.py:157} INFO - Started process (PID=39067) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:44:31.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:44:31.708+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:44:31.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:44:31.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:44:31.747+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:44:31.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:44:31.759+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:44:31.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:44:31.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-16T15:45:01.991+0000] {processor.py:157} INFO - Started process (PID=39077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:45:01.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:45:01.999+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:45:01.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:45:02.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:45:02.062+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:45:02.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:45:02.077+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:45:02.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:45:02.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T15:45:32.484+0000] {processor.py:157} INFO - Started process (PID=39087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:45:32.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:45:32.500+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:45:32.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:45:32.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:45:32.555+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:45:32.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:45:32.567+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:45:32.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:45:32.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-16T15:46:02.892+0000] {processor.py:157} INFO - Started process (PID=39095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:46:02.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:46:02.899+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:46:02.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:46:02.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:46:02.936+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:46:02.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:46:02.949+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:46:02.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:46:02.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-16T15:46:33.227+0000] {processor.py:157} INFO - Started process (PID=39106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:46:33.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:46:33.232+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:46:33.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:46:33.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:46:33.290+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:46:33.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:46:33.306+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:46:33.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:46:33.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-16T15:47:03.651+0000] {processor.py:157} INFO - Started process (PID=39116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:47:03.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:47:03.665+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:47:03.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:47:03.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:47:03.735+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:47:03.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:47:03.753+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:47:03.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:47:03.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-16T15:47:34.116+0000] {processor.py:157} INFO - Started process (PID=39127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:47:34.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:47:34.119+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:47:34.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:47:34.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:47:34.177+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:47:34.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:47:34.190+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:47:34.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:47:34.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-16T15:48:04.458+0000] {processor.py:157} INFO - Started process (PID=39137) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:48:04.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:48:04.463+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:48:04.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:48:04.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:48:04.527+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:48:04.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:48:04.540+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:48:04.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:48:04.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-16T15:48:34.916+0000] {processor.py:157} INFO - Started process (PID=39147) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:48:34.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:48:34.919+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:48:34.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:48:34.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:48:34.977+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:48:34.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:48:34.988+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:48:34.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:48:34.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-16T15:49:05.368+0000] {processor.py:157} INFO - Started process (PID=39157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:49:05.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:49:05.374+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:49:05.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:49:05.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:49:05.441+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:49:05.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:49:05.454+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:49:05.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:49:05.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T15:49:35.686+0000] {processor.py:157} INFO - Started process (PID=39167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:49:35.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:49:35.690+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:49:35.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:49:35.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:49:35.756+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:49:35.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:49:35.768+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:49:35.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:49:35.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-16T15:50:06.139+0000] {processor.py:157} INFO - Started process (PID=39177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:50:06.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:50:06.146+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:50:06.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:50:06.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:50:06.216+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:50:06.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:50:06.232+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:50:06.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:50:06.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-16T15:50:36.513+0000] {processor.py:157} INFO - Started process (PID=39187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:50:36.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:50:36.516+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:50:36.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:50:36.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:50:36.587+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:50:36.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:50:36.603+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:50:36.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:50:36.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-16T15:51:06.855+0000] {processor.py:157} INFO - Started process (PID=39197) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:51:06.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:51:06.859+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:51:06.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:51:06.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:51:06.898+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:51:06.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:51:06.911+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:51:06.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:51:06.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-16T15:51:37.264+0000] {processor.py:157} INFO - Started process (PID=39207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:51:37.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:51:37.266+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:51:37.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:51:37.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:51:37.338+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:51:37.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:51:37.360+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:51:37.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:51:37.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-16T15:52:07.767+0000] {processor.py:157} INFO - Started process (PID=39217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:52:07.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:52:07.775+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:52:07.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:52:07.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:52:07.842+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:52:07.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:52:07.857+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:52:07.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:52:07.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-16T15:52:38.107+0000] {processor.py:157} INFO - Started process (PID=39227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:52:38.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:52:38.112+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:52:38.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:52:38.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:52:38.175+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:52:38.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:52:38.190+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:52:38.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:52:38.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-16T15:53:08.589+0000] {processor.py:157} INFO - Started process (PID=39237) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:53:08.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:53:08.600+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:53:08.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:53:08.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:53:08.659+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:53:08.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:53:08.684+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:53:08.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:53:08.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-16T15:53:38.900+0000] {processor.py:157} INFO - Started process (PID=39247) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:53:38.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:53:38.906+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:53:38.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:53:38.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:53:38.944+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:53:38.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:53:38.954+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:53:38.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:53:38.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-16T15:54:09.247+0000] {processor.py:157} INFO - Started process (PID=39256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:54:09.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:54:09.254+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:54:09.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:54:09.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:54:09.325+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:54:09.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:54:09.342+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:54:09.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:54:09.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-16T15:54:39.547+0000] {processor.py:157} INFO - Started process (PID=39267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:54:39.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:54:39.553+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:54:39.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:54:39.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:54:39.604+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:54:39.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:54:39.613+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:54:39.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:54:39.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-16T15:55:10.017+0000] {processor.py:157} INFO - Started process (PID=39277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:55:10.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:55:10.023+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:55:10.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:55:10.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:55:10.111+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:55:10.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:55:10.129+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:55:10.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:55:10.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-16T15:55:40.336+0000] {processor.py:157} INFO - Started process (PID=39287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:55:40.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:55:40.341+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:55:40.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:55:40.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:55:40.410+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:55:40.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:55:40.423+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:55:40.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:55:40.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-16T15:56:10.898+0000] {processor.py:157} INFO - Started process (PID=39297) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:56:10.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:56:10.907+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:56:10.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:56:10.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:56:10.977+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:56:10.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:56:10.994+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:56:10.994+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:56:11.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-16T15:56:41.411+0000] {processor.py:157} INFO - Started process (PID=39307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:56:41.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:56:41.417+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:56:41.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:56:41.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:56:41.494+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:56:41.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:56:41.512+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:56:41.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:56:41.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-16T15:57:11.759+0000] {processor.py:157} INFO - Started process (PID=39317) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:57:11.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:57:11.769+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:57:11.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:57:11.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:57:11.830+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:57:11.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:57:11.842+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:57:11.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:57:11.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-16T15:57:42.120+0000] {processor.py:157} INFO - Started process (PID=39327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:57:42.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:57:42.125+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:57:42.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:57:42.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:57:42.200+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:57:42.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:57:42.218+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:57:42.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:57:42.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T15:58:12.428+0000] {processor.py:157} INFO - Started process (PID=39337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:58:12.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:58:12.433+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:58:12.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:58:12.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:58:12.503+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:58:12.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:58:12.518+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:58:12.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:58:12.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T15:58:42.993+0000] {processor.py:157} INFO - Started process (PID=39346) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:58:42.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:58:43.001+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:58:43.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:58:43.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:58:43.075+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:58:43.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:58:43.107+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:58:43.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:58:43.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-16T15:59:13.402+0000] {processor.py:157} INFO - Started process (PID=39357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:59:13.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:59:13.417+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:59:13.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:59:13.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:59:13.540+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:59:13.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:59:13.569+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:59:13.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:59:13.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.187 seconds
[2024-09-16T15:59:43.966+0000] {processor.py:157} INFO - Started process (PID=39367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:59:43.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T15:59:43.971+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:59:43.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:59:43.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T15:59:44.042+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:59:44.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T15:59:44.058+0000] {logging_mixin.py:151} INFO - [2024-09-16T15:59:44.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T15:59:44.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-16T16:00:14.460+0000] {processor.py:157} INFO - Started process (PID=39377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:00:14.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:00:14.477+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:00:14.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:00:14.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:00:14.539+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:00:14.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:00:14.556+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:00:14.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:00:14.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-16T16:00:44.791+0000] {processor.py:157} INFO - Started process (PID=39387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:00:44.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:00:44.795+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:00:44.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:00:44.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:00:44.856+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:00:44.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:00:44.866+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:00:44.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:00:44.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-16T16:01:15.342+0000] {processor.py:157} INFO - Started process (PID=39397) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:01:15.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:01:15.347+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:01:15.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:01:15.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:01:15.415+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:01:15.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:01:15.435+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:01:15.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:01:15.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-16T16:01:45.800+0000] {processor.py:157} INFO - Started process (PID=39407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:01:45.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:01:45.804+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:01:45.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:01:45.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:01:45.851+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:01:45.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:01:45.862+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:01:45.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:01:45.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-16T16:02:16.151+0000] {processor.py:157} INFO - Started process (PID=39417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:02:16.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:02:16.160+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:02:16.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:02:16.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:02:16.237+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:02:16.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:02:16.255+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:02:16.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:02:16.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-16T16:02:46.646+0000] {processor.py:157} INFO - Started process (PID=39427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:02:46.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:02:46.653+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:02:46.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:02:46.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:02:46.715+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:02:46.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:02:46.731+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:02:46.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:02:46.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-16T16:03:17.110+0000] {processor.py:157} INFO - Started process (PID=39437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:03:17.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:03:17.117+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:03:17.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:03:17.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:03:17.204+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:03:17.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:03:17.221+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:03:17.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:03:17.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-16T16:03:47.473+0000] {processor.py:157} INFO - Started process (PID=39447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:03:47.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:03:47.482+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:03:47.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:03:47.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:03:47.515+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:03:47.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:03:47.529+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:03:47.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:03:47.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-16T16:04:17.871+0000] {processor.py:157} INFO - Started process (PID=39457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:04:17.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:04:17.883+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:04:17.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:04:17.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:04:17.970+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:04:17.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:04:17.988+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:04:17.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:04:18.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-16T16:04:48.215+0000] {processor.py:157} INFO - Started process (PID=39467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:04:48.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:04:48.221+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:04:48.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:04:48.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:04:48.263+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:04:48.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:04:48.274+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:04:48.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:04:48.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-16T16:05:18.744+0000] {processor.py:157} INFO - Started process (PID=39477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:05:18.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:05:18.758+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:05:18.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:05:18.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:05:18.842+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:05:18.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:05:18.873+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:05:18.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:05:18.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-16T16:05:49.146+0000] {processor.py:157} INFO - Started process (PID=39487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:05:49.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:05:49.155+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:05:49.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:05:49.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:05:49.223+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:05:49.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:05:49.239+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:05:49.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:05:49.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-16T16:06:19.522+0000] {processor.py:157} INFO - Started process (PID=39497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:06:19.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:06:19.530+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:06:19.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:06:19.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:06:19.576+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:06:19.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:06:19.591+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:06:19.591+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:06:19.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-16T16:06:49.898+0000] {processor.py:157} INFO - Started process (PID=39507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:06:49.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:06:49.912+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:06:49.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:06:49.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:06:49.963+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:06:49.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:06:49.972+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:06:49.972+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:06:49.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-16T16:07:20.408+0000] {processor.py:157} INFO - Started process (PID=39516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:07:20.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:07:20.414+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:07:20.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:07:20.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:07:20.483+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:07:20.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:07:20.508+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:07:20.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:07:20.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-16T16:07:50.803+0000] {processor.py:157} INFO - Started process (PID=39527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:07:50.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:07:50.808+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:07:50.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:07:50.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:07:50.872+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:07:50.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:07:50.883+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:07:50.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:07:50.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-16T16:08:21.283+0000] {processor.py:157} INFO - Started process (PID=39537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:08:21.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:08:21.288+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:08:21.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:08:21.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:08:21.354+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:08:21.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:08:21.369+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:08:21.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:08:21.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-16T16:08:51.618+0000] {processor.py:157} INFO - Started process (PID=39547) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:08:51.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:08:51.623+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:08:51.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:08:51.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:08:51.664+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:08:51.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:08:51.675+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:08:51.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:08:51.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-16T16:09:22.016+0000] {processor.py:157} INFO - Started process (PID=39556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:09:22.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:09:22.023+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:09:22.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:09:22.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:09:22.101+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:09:22.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:09:22.115+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:09:22.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:09:22.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-16T16:09:52.368+0000] {processor.py:157} INFO - Started process (PID=39567) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:09:52.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:09:52.373+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:09:52.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:09:52.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:09:52.420+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:09:52.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:09:52.431+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:09:52.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:09:52.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-16T16:10:22.745+0000] {processor.py:157} INFO - Started process (PID=39577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:10:22.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:10:22.754+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:10:22.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:10:22.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:10:22.826+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:10:22.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:10:22.839+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:10:22.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:10:22.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-16T16:10:53.150+0000] {processor.py:157} INFO - Started process (PID=39587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:10:53.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:10:53.156+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:10:53.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:10:53.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:10:53.228+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:10:53.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:10:53.246+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:10:53.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:10:53.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-16T16:11:23.547+0000] {processor.py:157} INFO - Started process (PID=39597) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:11:23.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:11:23.549+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:11:23.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:11:23.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:11:23.589+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:11:23.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:11:23.599+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:11:23.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:11:23.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-16T16:11:53.999+0000] {processor.py:157} INFO - Started process (PID=39607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:11:54.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:11:54.007+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:11:54.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:11:54.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:11:54.050+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:11:54.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:11:54.066+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:11:54.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:11:54.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-16T16:12:24.389+0000] {processor.py:157} INFO - Started process (PID=39617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:12:24.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:12:24.393+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:12:24.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:12:24.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:12:24.427+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:12:24.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:12:24.435+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:12:24.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:12:24.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-16T16:12:54.781+0000] {processor.py:157} INFO - Started process (PID=39627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:12:54.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:12:54.786+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:12:54.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:12:54.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:12:54.817+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:12:54.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:12:54.828+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:12:54.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:12:54.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-16T16:13:25.179+0000] {processor.py:157} INFO - Started process (PID=39637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:13:25.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:13:25.184+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:13:25.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:13:25.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:13:25.226+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:13:25.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:13:25.241+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:13:25.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:13:25.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-16T16:13:55.572+0000] {processor.py:157} INFO - Started process (PID=39647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:13:55.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:13:55.578+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:13:55.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:13:55.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:13:55.610+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:13:55.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:13:55.620+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:13:55.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:13:55.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-16T16:14:25.945+0000] {processor.py:157} INFO - Started process (PID=39657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:14:25.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:14:25.949+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:14:25.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:14:25.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:14:25.982+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:14:25.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:14:25.994+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:14:25.993+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:14:26.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-16T16:14:56.377+0000] {processor.py:157} INFO - Started process (PID=39667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:14:56.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:14:56.383+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:14:56.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:14:56.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:14:56.418+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:14:56.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:14:56.428+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:14:56.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:14:56.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-16T16:15:26.794+0000] {processor.py:157} INFO - Started process (PID=39677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:15:26.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:15:26.802+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:15:26.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:15:26.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:15:26.845+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:15:26.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:15:26.859+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:15:26.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:15:26.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-16T16:15:57.155+0000] {processor.py:157} INFO - Started process (PID=39687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:15:57.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:15:57.159+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:15:57.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:15:57.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:15:57.196+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:15:57.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:15:57.210+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:15:57.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:15:57.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-16T16:16:27.475+0000] {processor.py:157} INFO - Started process (PID=39697) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:16:27.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:16:27.480+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:16:27.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:16:27.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:16:27.510+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:16:27.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:16:27.520+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:16:27.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:16:27.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-16T16:16:57.927+0000] {processor.py:157} INFO - Started process (PID=39707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:16:57.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:16:57.932+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:16:57.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:16:57.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:16:57.973+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:16:57.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:16:57.988+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:16:57.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:16:57.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-16T16:17:28.260+0000] {processor.py:157} INFO - Started process (PID=39717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:17:28.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:17:28.265+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:17:28.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:17:28.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:17:28.296+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:17:28.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:17:28.309+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:17:28.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:17:28.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-16T16:17:58.603+0000] {processor.py:157} INFO - Started process (PID=39727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:17:58.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:17:58.607+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:17:58.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:17:58.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:17:58.642+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:17:58.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:17:58.654+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:17:58.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:17:58.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-16T16:18:29.050+0000] {processor.py:157} INFO - Started process (PID=39737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:18:29.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:18:29.054+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:18:29.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:18:29.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:18:29.089+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:18:29.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:18:29.105+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:18:29.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:18:29.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-16T16:18:59.382+0000] {processor.py:157} INFO - Started process (PID=39747) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:18:59.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:18:59.387+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:18:59.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:18:59.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:18:59.436+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:18:59.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:18:59.451+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:18:59.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:18:59.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-16T16:19:29.721+0000] {processor.py:157} INFO - Started process (PID=39757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:19:29.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:19:29.726+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:19:29.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:19:29.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:19:29.760+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:19:29.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:19:29.773+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:19:29.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:19:29.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-16T16:20:00.067+0000] {processor.py:157} INFO - Started process (PID=39767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:20:00.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:20:00.070+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:20:00.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:20:00.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:20:00.107+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:20:00.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:20:00.120+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:20:00.120+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:20:00.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-16T16:20:30.515+0000] {processor.py:157} INFO - Started process (PID=39777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:20:30.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:20:30.520+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:20:30.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:20:30.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:20:30.559+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:20:30.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:20:30.571+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:20:30.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:20:30.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-16T16:21:01.018+0000] {processor.py:157} INFO - Started process (PID=39787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:21:01.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:21:01.023+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:21:01.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:21:01.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:21:01.057+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:21:01.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:21:01.068+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:21:01.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:21:01.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-16T16:21:31.415+0000] {processor.py:157} INFO - Started process (PID=39797) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:21:31.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:21:31.420+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:21:31.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:21:31.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:21:31.476+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:21:31.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:21:31.489+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:21:31.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:21:31.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-16T16:22:01.915+0000] {processor.py:157} INFO - Started process (PID=39807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:22:01.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:22:01.921+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:22:01.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:22:01.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:22:01.982+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:22:01.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:22:02.010+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:22:02.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:22:02.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-16T16:22:32.352+0000] {processor.py:157} INFO - Started process (PID=39817) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:22:32.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:22:32.359+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:22:32.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:22:32.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:22:32.402+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:22:32.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:22:32.415+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:22:32.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:22:32.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-16T16:23:02.671+0000] {processor.py:157} INFO - Started process (PID=39826) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:23:02.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:23:02.703+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:23:02.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:23:02.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:23:02.753+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:23:02.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:23:02.782+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:23:02.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:23:02.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-16T16:23:33.232+0000] {processor.py:157} INFO - Started process (PID=39837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:23:33.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:23:33.243+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:23:33.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:23:33.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:23:33.307+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:23:33.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:23:33.328+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:23:33.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:23:33.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-16T16:41:14.294+0000] {processor.py:157} INFO - Started process (PID=39849) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:41:14.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:41:14.299+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:41:14.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:41:14.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:41:14.344+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:41:14.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:41:14.353+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:41:14.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:41:14.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-16T16:41:44.676+0000] {processor.py:157} INFO - Started process (PID=39859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:41:44.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:41:44.684+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:41:44.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:41:44.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:41:44.761+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:41:44.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:41:44.779+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:41:44.779+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:41:44.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-16T16:42:15.014+0000] {processor.py:157} INFO - Started process (PID=39869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:42:15.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:42:15.026+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:42:15.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:42:15.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:42:15.049+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:42:15.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:42:15.057+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:42:15.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:42:15.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-16T16:58:27.165+0000] {processor.py:157} INFO - Started process (PID=39879) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:58:27.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:58:27.171+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:58:27.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:58:27.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:58:27.258+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:58:27.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:58:27.297+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:58:27.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:58:27.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-09-16T16:58:57.587+0000] {processor.py:157} INFO - Started process (PID=39887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:58:57.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:58:57.605+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:58:57.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:58:57.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:58:57.696+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:58:57.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:58:57.717+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:58:57.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:58:57.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-09-16T16:59:28.117+0000] {processor.py:157} INFO - Started process (PID=39899) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:59:28.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:59:28.120+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:59:28.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:59:28.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:59:28.159+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:59:28.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:59:28.172+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:59:28.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:59:28.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-16T16:59:58.575+0000] {processor.py:157} INFO - Started process (PID=39909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:59:58.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T16:59:58.583+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:59:58.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:59:58.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T16:59:58.645+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:59:58.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T16:59:58.667+0000] {logging_mixin.py:151} INFO - [2024-09-16T16:59:58.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T16:59:58.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-16T17:00:28.898+0000] {processor.py:157} INFO - Started process (PID=39919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:00:28.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:00:28.903+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:00:28.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:00:28.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:00:28.950+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:00:28.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:00:28.966+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:00:28.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:00:28.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-16T17:00:59.306+0000] {processor.py:157} INFO - Started process (PID=39929) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:00:59.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:00:59.309+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:00:59.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:00:59.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:00:59.342+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:00:59.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:00:59.351+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:00:59.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:00:59.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-16T17:01:29.767+0000] {processor.py:157} INFO - Started process (PID=39939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:01:29.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:01:29.771+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:01:29.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:01:29.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:01:29.816+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:01:29.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:01:29.830+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:01:29.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:01:29.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-16T17:02:00.068+0000] {processor.py:157} INFO - Started process (PID=39949) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:02:00.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:02:00.074+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:02:00.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:02:00.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:02:00.117+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:02:00.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:02:00.129+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:02:00.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:02:00.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-16T17:02:30.436+0000] {processor.py:157} INFO - Started process (PID=39959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:02:30.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:02:30.443+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:02:30.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:02:30.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:02:30.508+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:02:30.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:02:30.527+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:02:30.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:02:30.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T17:03:00.943+0000] {processor.py:157} INFO - Started process (PID=39969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:03:00.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:03:00.946+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:03:00.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:03:00.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:03:00.977+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:03:00.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:03:00.987+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:03:00.987+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:03:00.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-16T17:03:31.450+0000] {processor.py:157} INFO - Started process (PID=39979) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:03:31.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:03:31.465+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:03:31.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:03:31.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:03:31.525+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:03:31.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:03:31.539+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:03:31.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:03:31.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-16T17:04:01.858+0000] {processor.py:157} INFO - Started process (PID=39989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:04:01.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:04:01.861+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:04:01.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:04:01.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:04:01.904+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:04:01.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:04:01.923+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:04:01.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:04:01.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-16T17:04:32.362+0000] {processor.py:157} INFO - Started process (PID=39999) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:04:32.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:04:32.377+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:04:32.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:04:32.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:04:32.435+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:04:32.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:04:32.456+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:04:32.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:04:32.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-16T17:05:02.813+0000] {processor.py:157} INFO - Started process (PID=40009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:05:02.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:05:02.818+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:05:02.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:05:02.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:05:02.890+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:05:02.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:05:02.901+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:05:02.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:05:02.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T17:05:33.266+0000] {processor.py:157} INFO - Started process (PID=40019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:05:33.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:05:33.280+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:05:33.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:05:33.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:05:33.337+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:05:33.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:05:33.363+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:05:33.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:05:33.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-16T17:06:03.655+0000] {processor.py:157} INFO - Started process (PID=40029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:06:03.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:06:03.662+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:06:03.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:06:03.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:06:03.700+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:06:03.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:06:03.713+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:06:03.713+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:06:03.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-16T17:06:34.084+0000] {processor.py:157} INFO - Started process (PID=40039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:06:34.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:06:34.088+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:06:34.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:06:34.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:06:34.128+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:06:34.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:06:34.141+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:06:34.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:06:34.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-16T17:07:04.474+0000] {processor.py:157} INFO - Started process (PID=40048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:07:04.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:07:04.477+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:07:04.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:07:04.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:07:04.511+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:07:04.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:07:04.523+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:07:04.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:07:04.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-16T17:07:34.925+0000] {processor.py:157} INFO - Started process (PID=40059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:07:34.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:07:34.933+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:07:34.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:07:34.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:07:35.007+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:07:35.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:07:35.041+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:07:35.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:07:35.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-16T17:08:05.292+0000] {processor.py:157} INFO - Started process (PID=40069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:08:05.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:08:05.295+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:08:05.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:08:05.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:08:05.339+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:08:05.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:08:05.350+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:08:05.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:08:05.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-16T17:08:35.783+0000] {processor.py:157} INFO - Started process (PID=40079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:08:35.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:08:35.789+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:08:35.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:08:35.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:08:35.852+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:08:35.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:08:35.869+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:08:35.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:08:35.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-16T17:09:06.171+0000] {processor.py:157} INFO - Started process (PID=40089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:09:06.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:09:06.179+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:09:06.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:09:06.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:09:06.250+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:09:06.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:09:06.266+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:09:06.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:09:06.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-16T17:09:36.581+0000] {processor.py:157} INFO - Started process (PID=40099) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:09:36.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:09:36.587+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:09:36.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:09:36.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:09:36.659+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:09:36.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:09:36.676+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:09:36.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:09:36.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-16T17:10:06.929+0000] {processor.py:157} INFO - Started process (PID=40109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:10:06.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:10:06.934+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:10:06.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:10:06.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:10:06.969+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:10:06.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:10:06.978+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:10:06.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:10:06.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-16T17:10:37.402+0000] {processor.py:157} INFO - Started process (PID=40119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:10:37.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:10:37.423+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:10:37.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:10:37.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:10:37.494+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:10:37.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:10:37.511+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:10:37.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:10:37.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-16T17:11:07.761+0000] {processor.py:157} INFO - Started process (PID=40129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:11:07.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:11:07.765+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:11:07.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:11:07.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:11:07.803+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:11:07.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:11:07.815+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:11:07.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:11:07.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-16T17:11:38.248+0000] {processor.py:157} INFO - Started process (PID=40139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:11:38.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:11:38.263+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:11:38.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:11:38.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:11:38.339+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:11:38.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:11:38.357+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:11:38.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:11:38.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-16T17:12:08.561+0000] {processor.py:157} INFO - Started process (PID=40149) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:12:08.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:12:08.566+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:12:08.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:12:08.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:12:08.600+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:12:08.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:12:08.615+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:12:08.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:12:08.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-16T17:12:38.961+0000] {processor.py:157} INFO - Started process (PID=40159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:12:38.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:12:38.968+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:12:38.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:12:38.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:12:39.027+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:12:39.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:12:39.043+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:12:39.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:12:39.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-16T17:13:09.324+0000] {processor.py:157} INFO - Started process (PID=40169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:13:09.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:13:09.329+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:13:09.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:13:09.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:13:09.392+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:13:09.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:13:09.409+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:13:09.409+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:13:09.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T17:13:39.890+0000] {processor.py:157} INFO - Started process (PID=40178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:13:39.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:13:39.914+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:13:39.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:13:39.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:13:39.985+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:13:39.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:13:40.005+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:13:40.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:13:40.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-16T17:14:10.276+0000] {processor.py:157} INFO - Started process (PID=40189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:14:10.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:14:10.280+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:14:10.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:14:10.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:14:10.308+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:14:10.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:14:10.319+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:14:10.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:14:10.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-16T17:14:40.641+0000] {processor.py:157} INFO - Started process (PID=40197) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:14:40.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:14:40.646+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:14:40.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:14:40.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:14:40.714+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:14:40.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:14:40.743+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:14:40.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:14:40.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-16T17:15:10.971+0000] {processor.py:157} INFO - Started process (PID=40208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:15:10.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:15:10.997+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:15:10.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:15:11.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:15:11.067+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:15:11.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:15:11.083+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:15:11.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:15:11.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-16T17:15:41.431+0000] {processor.py:157} INFO - Started process (PID=40219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:15:41.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:15:41.437+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:15:41.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:15:41.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:15:41.479+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:15:41.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:15:41.495+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:15:41.495+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:15:41.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-16T17:16:11.898+0000] {processor.py:157} INFO - Started process (PID=40229) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:16:11.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:16:11.901+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:16:11.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:16:11.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:16:11.928+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:16:11.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:16:11.946+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:16:11.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:16:11.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-16T17:16:42.318+0000] {processor.py:157} INFO - Started process (PID=40239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:16:42.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:16:42.328+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:16:42.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:16:42.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:16:42.395+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:16:42.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:16:42.412+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:16:42.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:16:42.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-16T17:17:12.654+0000] {processor.py:157} INFO - Started process (PID=40249) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:17:12.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:17:12.657+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:17:12.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:17:12.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:17:12.687+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:17:12.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:17:12.702+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:17:12.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:17:12.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-16T17:17:43.146+0000] {processor.py:157} INFO - Started process (PID=40259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:17:43.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:17:43.152+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:17:43.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:17:43.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:17:43.232+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:17:43.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:17:43.252+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:17:43.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:17:43.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-16T17:18:13.598+0000] {processor.py:157} INFO - Started process (PID=40269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:18:13.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:18:13.601+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:18:13.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:18:13.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:18:13.622+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:18:13.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:18:13.631+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:18:13.631+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:18:13.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-09-16T17:18:44.081+0000] {processor.py:157} INFO - Started process (PID=40279) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:18:44.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:18:44.096+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:18:44.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:18:44.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:18:44.166+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:18:44.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:18:44.182+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:18:44.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:18:44.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-16T17:19:14.406+0000] {processor.py:157} INFO - Started process (PID=40289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:19:14.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:19:14.409+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:19:14.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:19:14.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:19:14.438+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:19:14.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:19:14.449+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:19:14.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:19:14.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-16T17:19:44.825+0000] {processor.py:157} INFO - Started process (PID=40299) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:19:44.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:19:44.845+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:19:44.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:19:44.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:19:44.917+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:19:44.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:19:44.949+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:19:44.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:19:44.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-16T17:20:15.270+0000] {processor.py:157} INFO - Started process (PID=40309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:20:15.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:20:15.292+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:20:15.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:20:15.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:20:15.356+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:20:15.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:20:15.382+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:20:15.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:20:15.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-16T17:20:45.760+0000] {processor.py:157} INFO - Started process (PID=40319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:20:45.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:20:45.763+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:20:45.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:20:45.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:20:45.788+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:20:45.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:20:45.797+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:20:45.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:20:45.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-16T17:21:16.123+0000] {processor.py:157} INFO - Started process (PID=40329) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:21:16.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:21:16.130+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:21:16.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:21:16.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:21:16.200+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:21:16.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:21:16.218+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:21:16.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:21:16.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-16T17:21:46.499+0000] {processor.py:157} INFO - Started process (PID=40338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:21:46.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:21:46.503+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:21:46.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:21:46.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:21:46.531+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:21:46.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:21:46.543+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:21:46.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:21:46.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-16T17:22:16.936+0000] {processor.py:157} INFO - Started process (PID=40349) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:22:16.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:22:16.942+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:22:16.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:22:16.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:22:17.030+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:22:17.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:22:17.062+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:22:17.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:22:17.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-16T17:22:47.299+0000] {processor.py:157} INFO - Started process (PID=40359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:22:47.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:22:47.302+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:22:47.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:22:47.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:22:47.334+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:22:47.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:22:47.346+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:22:47.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:22:47.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-16T17:23:17.717+0000] {processor.py:157} INFO - Started process (PID=40369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:23:17.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:23:17.721+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:23:17.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:23:17.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:23:17.792+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:23:17.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:23:17.807+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:23:17.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:23:17.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-16T17:23:48.198+0000] {processor.py:157} INFO - Started process (PID=40379) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:23:48.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:23:48.209+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:23:48.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:23:48.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:23:48.244+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:23:48.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:23:48.257+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:23:48.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:23:48.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-16T17:24:18.672+0000] {processor.py:157} INFO - Started process (PID=40389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:24:18.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:24:18.686+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:24:18.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:24:18.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:24:18.770+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:24:18.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:24:18.788+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:24:18.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:24:18.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-09-16T17:24:49.055+0000] {processor.py:157} INFO - Started process (PID=40399) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:24:49.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:24:49.061+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:24:49.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:24:49.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:24:49.106+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:24:49.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:24:49.121+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:24:49.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:24:49.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-16T17:25:19.446+0000] {processor.py:157} INFO - Started process (PID=40409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:25:19.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:25:19.466+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:25:19.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:25:19.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:25:19.542+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:25:19.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:25:19.559+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:25:19.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:25:19.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-16T17:25:49.955+0000] {processor.py:157} INFO - Started process (PID=40419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:25:49.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:25:49.957+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:25:49.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:25:49.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:25:49.985+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:25:49.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:25:49.995+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:25:49.995+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:25:50.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-16T17:26:20.282+0000] {processor.py:157} INFO - Started process (PID=40429) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:26:20.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:26:20.305+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:26:20.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:26:20.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:26:20.356+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:26:20.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:26:20.371+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:26:20.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:26:20.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-16T17:26:50.695+0000] {processor.py:157} INFO - Started process (PID=40437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:26:50.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:26:50.698+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:26:50.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:26:50.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:26:50.724+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:26:50.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:26:50.734+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:26:50.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:26:50.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-16T17:27:21.127+0000] {processor.py:157} INFO - Started process (PID=40449) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:27:21.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:27:21.133+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:27:21.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:27:21.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:27:21.210+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:27:21.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:27:21.229+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:27:21.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:27:21.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-16T17:27:51.628+0000] {processor.py:157} INFO - Started process (PID=40459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:27:51.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:27:51.630+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:27:51.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:27:51.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:27:51.660+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:27:51.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:27:51.673+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:27:51.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:27:51.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-16T17:28:22.045+0000] {processor.py:157} INFO - Started process (PID=40469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:28:22.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:28:22.057+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:28:22.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:28:22.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:28:22.139+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:28:22.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:28:22.162+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:28:22.162+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:28:22.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-16T17:28:52.428+0000] {processor.py:157} INFO - Started process (PID=40478) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:28:52.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:28:52.433+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:28:52.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:28:52.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:28:52.475+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:28:52.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:28:52.488+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:28:52.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:28:52.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-16T17:29:22.803+0000] {processor.py:157} INFO - Started process (PID=40488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:29:22.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:29:22.807+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:29:22.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:29:22.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:29:22.856+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:29:22.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:29:22.877+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:29:22.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:29:22.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-16T17:29:53.202+0000] {processor.py:157} INFO - Started process (PID=40499) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:29:53.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:29:53.223+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:29:53.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:29:53.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:29:53.261+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:29:53.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:29:53.272+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:29:53.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:29:53.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-16T17:30:23.723+0000] {processor.py:157} INFO - Started process (PID=40508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:30:23.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:30:23.753+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:30:23.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:30:23.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:30:23.808+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:30:23.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:30:23.830+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:30:23.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:30:23.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-16T17:30:54.102+0000] {processor.py:157} INFO - Started process (PID=40519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:30:54.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:30:54.109+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:30:54.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:30:54.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:30:54.135+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:30:54.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:30:54.146+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:30:54.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:30:54.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-16T17:31:24.449+0000] {processor.py:157} INFO - Started process (PID=40529) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:31:24.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:31:24.476+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:31:24.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:31:24.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:31:24.549+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:31:24.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:31:24.567+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:31:24.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:31:24.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-16T17:31:54.779+0000] {processor.py:157} INFO - Started process (PID=40539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:31:54.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:31:54.783+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:31:54.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:31:54.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:31:54.825+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:31:54.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:31:54.840+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:31:54.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:31:54.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-16T17:32:25.200+0000] {processor.py:157} INFO - Started process (PID=40549) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:32:25.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:32:25.204+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:32:25.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:32:25.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:32:25.276+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:32:25.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:32:25.293+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:32:25.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:32:25.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-16T17:32:55.627+0000] {processor.py:157} INFO - Started process (PID=40559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:32:55.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:32:55.638+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:32:55.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:32:55.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:32:55.717+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:32:55.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:32:55.741+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:32:55.741+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:32:55.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-16T17:33:26.006+0000] {processor.py:157} INFO - Started process (PID=40569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:33:26.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:33:26.013+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:33:26.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:33:26.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:33:26.043+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:33:26.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:33:26.055+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:33:26.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:33:26.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-16T17:33:56.417+0000] {processor.py:157} INFO - Started process (PID=40578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:33:56.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:33:56.429+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:33:56.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:33:56.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:33:56.494+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:33:56.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:33:56.525+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:33:56.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:33:56.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-16T17:34:26.962+0000] {processor.py:157} INFO - Started process (PID=40589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:34:26.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:34:26.965+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:34:26.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:34:26.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:34:26.996+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:34:26.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:34:27.011+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:34:27.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:34:27.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-16T17:34:57.354+0000] {processor.py:157} INFO - Started process (PID=40597) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:34:57.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:34:57.360+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:34:57.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:34:57.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:34:57.419+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:34:57.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:34:57.435+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:34:57.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:34:57.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-16T17:35:27.681+0000] {processor.py:157} INFO - Started process (PID=40609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:35:27.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:35:27.689+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:35:27.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:35:27.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:35:27.728+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:35:27.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:35:27.740+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:35:27.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:35:27.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-16T17:35:58.134+0000] {processor.py:157} INFO - Started process (PID=40619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:35:58.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:35:58.139+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:35:58.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:35:58.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:35:58.206+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:35:58.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:35:58.221+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:35:58.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:35:58.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T17:36:28.594+0000] {processor.py:157} INFO - Started process (PID=40629) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:36:28.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:36:28.599+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:36:28.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:36:28.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:36:28.663+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:36:28.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:36:28.679+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:36:28.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:36:28.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-16T17:36:59.002+0000] {processor.py:157} INFO - Started process (PID=40639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:36:59.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:36:59.004+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:36:59.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:36:59.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:36:59.033+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:36:59.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:36:59.046+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:36:59.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:36:59.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-16T17:37:29.466+0000] {processor.py:157} INFO - Started process (PID=40649) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:37:29.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:37:29.479+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:37:29.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:37:29.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:37:29.567+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:37:29.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:37:29.589+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:37:29.589+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:37:29.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-16T17:37:59.803+0000] {processor.py:157} INFO - Started process (PID=40659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:37:59.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:37:59.807+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:37:59.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:37:59.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:37:59.854+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:37:59.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:37:59.870+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:37:59.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:37:59.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-16T17:38:30.240+0000] {processor.py:157} INFO - Started process (PID=40669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:38:30.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:38:30.255+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:38:30.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:38:30.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:38:30.325+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:38:30.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:38:30.347+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:38:30.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:38:30.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-16T17:39:00.811+0000] {processor.py:157} INFO - Started process (PID=40679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:39:00.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:39:00.827+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:39:00.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:39:00.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:39:00.889+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:39:00.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:39:00.906+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:39:00.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:39:00.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T17:39:31.377+0000] {processor.py:157} INFO - Started process (PID=40689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:39:31.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:39:31.391+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:39:31.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:39:31.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:39:31.463+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:39:31.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:39:31.480+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:39:31.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:39:31.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-16T17:40:01.863+0000] {processor.py:157} INFO - Started process (PID=40699) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:40:01.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:40:01.865+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:40:01.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:40:01.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:40:01.893+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:40:01.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:40:01.903+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:40:01.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:40:01.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-16T17:40:32.286+0000] {processor.py:157} INFO - Started process (PID=40709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:40:32.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:40:32.299+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:40:32.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:40:32.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:40:32.374+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:40:32.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:40:32.393+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:40:32.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:40:32.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-16T17:41:02.593+0000] {processor.py:157} INFO - Started process (PID=40719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:41:02.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:41:02.601+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:41:02.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:41:02.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:41:02.627+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:41:02.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:41:02.636+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:41:02.636+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:41:02.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-16T17:41:32.971+0000] {processor.py:157} INFO - Started process (PID=40729) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:41:32.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:41:32.976+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:41:32.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:41:33.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:41:33.050+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:41:33.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:41:33.065+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:41:33.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:41:33.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-16T17:42:03.459+0000] {processor.py:157} INFO - Started process (PID=40739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:42:03.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:42:03.466+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:42:03.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:42:03.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:42:03.504+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:42:03.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:42:03.527+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:42:03.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:42:03.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-16T17:42:33.934+0000] {processor.py:157} INFO - Started process (PID=40749) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:42:33.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:42:33.939+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:42:33.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:42:33.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:42:33.984+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:42:33.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:42:33.999+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:42:33.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:42:34.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-16T17:43:04.459+0000] {processor.py:157} INFO - Started process (PID=40758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:43:04.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:43:04.467+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:43:04.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:43:04.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:43:04.531+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:43:04.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:43:04.549+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:43:04.549+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:43:04.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-16T17:43:34.857+0000] {processor.py:157} INFO - Started process (PID=40769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:43:34.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:43:34.860+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:43:34.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:43:34.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:43:34.899+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:43:34.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:43:34.915+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:43:34.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:43:34.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-16T17:44:05.300+0000] {processor.py:157} INFO - Started process (PID=40779) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:44:05.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:44:05.319+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:44:05.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:44:05.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:44:05.383+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:44:05.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:44:05.401+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:44:05.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:44:05.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-16T17:44:35.622+0000] {processor.py:157} INFO - Started process (PID=40789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:44:35.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:44:35.629+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:44:35.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:44:35.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:44:35.677+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:44:35.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:44:35.692+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:44:35.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:44:35.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-16T17:45:06.044+0000] {processor.py:157} INFO - Started process (PID=40799) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:45:06.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:45:06.046+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:45:06.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:45:06.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:45:06.082+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:45:06.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:45:06.092+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:45:06.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:45:06.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-16T17:45:36.488+0000] {processor.py:157} INFO - Started process (PID=40809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:45:36.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:45:36.513+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:45:36.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:45:36.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:45:36.593+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:45:36.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:45:36.611+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:45:36.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:45:36.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-16T17:46:06.849+0000] {processor.py:157} INFO - Started process (PID=40819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:46:06.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:46:06.853+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:46:06.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:46:06.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:46:06.883+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:46:06.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:46:06.893+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:46:06.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:46:06.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-16T17:46:37.263+0000] {processor.py:157} INFO - Started process (PID=40829) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:46:37.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:46:37.293+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:46:37.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:46:37.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:46:37.369+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:46:37.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:46:37.392+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:46:37.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:46:37.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-16T17:47:07.588+0000] {processor.py:157} INFO - Started process (PID=40839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:47:07.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T17:47:07.590+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:47:07.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:47:07.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T17:47:07.620+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:47:07.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T17:47:07.635+0000] {logging_mixin.py:151} INFO - [2024-09-16T17:47:07.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T17:47:07.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-16T18:03:04.887+0000] {processor.py:157} INFO - Started process (PID=40850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:03:04.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:03:04.898+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:03:04.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:03:04.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:03:04.975+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:03:04.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:03:04.999+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:03:04.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:03:05.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-16T18:03:35.483+0000] {processor.py:157} INFO - Started process (PID=40859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:03:35.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:03:35.491+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:03:35.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:03:35.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:03:35.561+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:03:35.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:03:35.578+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:03:35.578+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:03:35.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-16T18:04:05.854+0000] {processor.py:157} INFO - Started process (PID=40871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:04:05.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:04:05.877+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:04:05.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:04:05.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:04:05.918+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:04:05.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:04:05.936+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:04:05.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:04:05.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-16T18:04:36.366+0000] {processor.py:157} INFO - Started process (PID=40881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:04:36.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:04:36.372+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:04:36.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:04:36.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:04:36.412+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:04:36.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:04:36.422+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:04:36.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:04:36.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-16T18:05:06.884+0000] {processor.py:157} INFO - Started process (PID=40890) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:05:06.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:05:06.898+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:05:06.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:05:06.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:05:06.961+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:05:06.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:05:06.979+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:05:06.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:05:06.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-16T18:05:37.240+0000] {processor.py:157} INFO - Started process (PID=40901) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:05:37.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:05:37.244+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:05:37.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:05:37.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:05:37.276+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:05:37.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:05:37.289+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:05:37.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:05:37.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-16T18:06:07.615+0000] {processor.py:157} INFO - Started process (PID=40911) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:06:07.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:06:07.621+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:06:07.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:06:07.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:06:07.664+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:06:07.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:06:07.681+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:06:07.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:06:07.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-16T18:06:37.971+0000] {processor.py:157} INFO - Started process (PID=40921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:06:37.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:06:37.975+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:06:37.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:06:37.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:06:38.016+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:06:38.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:06:38.026+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:06:38.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:06:38.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-16T18:07:08.420+0000] {processor.py:157} INFO - Started process (PID=40931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:07:08.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:07:08.425+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:07:08.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:07:08.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:07:08.466+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:07:08.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:07:08.481+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:07:08.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:07:08.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-16T18:07:38.835+0000] {processor.py:157} INFO - Started process (PID=40941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:07:38.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:07:38.839+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:07:38.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:07:38.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:07:38.875+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:07:38.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:07:38.887+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:07:38.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:07:38.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-16T18:13:39.141+0000] {processor.py:157} INFO - Started process (PID=40951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:13:39.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:13:39.148+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:13:39.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:13:39.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:13:39.229+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:13:39.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:13:39.257+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:13:39.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:13:39.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-09-16T18:14:09.515+0000] {processor.py:157} INFO - Started process (PID=40963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:14:09.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:14:09.534+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:14:09.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:14:09.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:14:09.604+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:14:09.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:14:09.635+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:14:09.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:14:09.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-16T18:14:40.000+0000] {processor.py:157} INFO - Started process (PID=40973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:14:40.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:14:40.007+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:14:40.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:14:40.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:14:40.067+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:14:40.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:14:40.090+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:14:40.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:14:40.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-16T18:15:10.257+0000] {processor.py:157} INFO - Started process (PID=40983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:15:10.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:15:10.261+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:15:10.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:15:10.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:15:10.291+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:15:10.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:15:10.304+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:15:10.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:15:10.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-16T18:15:40.727+0000] {processor.py:157} INFO - Started process (PID=40992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:15:40.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:15:40.733+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:15:40.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:15:40.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:15:40.776+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:15:40.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:15:40.792+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:15:40.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:15:40.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-16T18:32:06.790+0000] {processor.py:157} INFO - Started process (PID=41005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:32:06.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:32:06.795+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:32:06.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:32:06.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:32:06.929+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:32:06.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:32:06.970+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:32:06.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:32:06.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.208 seconds
[2024-09-16T18:32:37.143+0000] {processor.py:157} INFO - Started process (PID=41014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:32:37.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:32:37.152+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:32:37.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:32:37.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:32:37.233+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:32:37.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:32:37.255+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:32:37.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:32:37.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-16T18:33:07.637+0000] {processor.py:157} INFO - Started process (PID=41025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:33:07.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:33:07.641+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:33:07.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:33:07.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:33:07.671+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:33:07.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:33:07.681+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:33:07.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:33:07.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-16T18:33:38.075+0000] {processor.py:157} INFO - Started process (PID=41035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:33:38.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:33:38.082+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:33:38.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:33:38.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:33:38.152+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:33:38.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:33:38.169+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:33:38.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:33:38.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-16T18:34:08.394+0000] {processor.py:157} INFO - Started process (PID=41045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:34:08.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:34:08.398+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:34:08.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:34:08.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:34:08.446+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:34:08.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:34:08.459+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:34:08.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:34:08.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-16T18:34:38.826+0000] {processor.py:157} INFO - Started process (PID=41055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:34:38.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:34:38.833+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:34:38.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:34:38.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:34:38.892+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:34:38.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:34:38.909+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:34:38.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:34:38.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-16T18:35:09.236+0000] {processor.py:157} INFO - Started process (PID=41065) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:35:09.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:35:09.238+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:35:09.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:35:09.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:35:09.265+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:35:09.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:35:09.279+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:35:09.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:35:09.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-16T18:35:39.656+0000] {processor.py:157} INFO - Started process (PID=41075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:35:39.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:35:39.663+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:35:39.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:35:39.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:35:39.717+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:35:39.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:35:39.732+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:35:39.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:35:39.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-16T18:36:09.987+0000] {processor.py:157} INFO - Started process (PID=41085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:36:09.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:36:09.990+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:36:09.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:36:10.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:36:10.019+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:36:10.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:36:10.030+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:36:10.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:36:10.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-16T18:36:40.355+0000] {processor.py:157} INFO - Started process (PID=41095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:36:40.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:36:40.361+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:36:40.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:36:40.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:36:40.403+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:36:40.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:36:40.418+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:36:40.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:36:40.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-16T18:37:10.715+0000] {processor.py:157} INFO - Started process (PID=41105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:37:10.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:37:10.719+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:37:10.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:37:10.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:37:10.752+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:37:10.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:37:10.764+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:37:10.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:37:10.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-16T18:37:41.172+0000] {processor.py:157} INFO - Started process (PID=41115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:37:41.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:37:41.177+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:37:41.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:37:41.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:37:41.222+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:37:41.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:37:41.238+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:37:41.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:37:41.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-16T18:38:11.569+0000] {processor.py:157} INFO - Started process (PID=41125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:38:11.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:38:11.576+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:38:11.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:38:11.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:38:11.619+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:38:11.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:38:11.633+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:38:11.633+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:38:11.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-16T18:38:41.967+0000] {processor.py:157} INFO - Started process (PID=41135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:38:41.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:38:41.973+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:38:41.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:38:41.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:38:42.005+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:38:42.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:38:42.018+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:38:42.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:38:42.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-16T18:39:12.359+0000] {processor.py:157} INFO - Started process (PID=41145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:39:12.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:39:12.361+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:39:12.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:39:12.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:39:12.391+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:39:12.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:39:12.400+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:39:12.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:39:12.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-16T18:39:42.761+0000] {processor.py:157} INFO - Started process (PID=41155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:39:42.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:39:42.768+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:39:42.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:39:42.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:39:42.810+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:39:42.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:39:42.825+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:39:42.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:39:42.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-16T18:40:13.105+0000] {processor.py:157} INFO - Started process (PID=41165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:40:13.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:40:13.107+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:40:13.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:40:13.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:40:13.136+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:40:13.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:40:13.150+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:40:13.150+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:40:13.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-16T18:40:43.511+0000] {processor.py:157} INFO - Started process (PID=41175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:40:43.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:40:43.515+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:40:43.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:40:43.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:40:43.559+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:40:43.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:40:43.575+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:40:43.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:40:43.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-16T18:41:13.924+0000] {processor.py:157} INFO - Started process (PID=41185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:41:13.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:41:13.926+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:41:13.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:41:13.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:41:13.956+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:41:13.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:41:13.969+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:41:13.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:41:13.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-16T18:41:44.313+0000] {processor.py:157} INFO - Started process (PID=41195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:41:44.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:41:44.316+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:41:44.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:41:44.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:41:44.342+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:41:44.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:41:44.354+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:41:44.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:41:44.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-16T18:42:14.726+0000] {processor.py:157} INFO - Started process (PID=41204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:42:14.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:42:14.732+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:42:14.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:42:14.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:42:14.794+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:42:14.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:42:14.810+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:42:14.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:42:14.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-16T18:42:45.162+0000] {processor.py:157} INFO - Started process (PID=41215) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:42:45.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:42:45.168+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:42:45.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:42:45.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:42:45.197+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:42:45.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:42:45.208+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:42:45.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:42:45.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-16T18:43:15.554+0000] {processor.py:157} INFO - Started process (PID=41225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:43:15.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:43:15.561+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:43:15.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:43:15.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:43:15.602+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:43:15.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:43:15.616+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:43:15.616+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:43:15.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-16T18:43:46.009+0000] {processor.py:157} INFO - Started process (PID=41235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:43:46.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:43:46.012+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:43:46.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:43:46.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:43:46.043+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:43:46.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:43:46.053+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:43:46.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:43:46.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-16T18:44:16.472+0000] {processor.py:157} INFO - Started process (PID=41245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:44:16.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:44:16.498+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:44:16.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:44:16.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:44:16.576+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:44:16.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:44:16.595+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:44:16.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:44:16.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-16T18:44:46.777+0000] {processor.py:157} INFO - Started process (PID=41255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:44:46.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:44:46.782+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:44:46.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:44:46.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:44:46.814+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:44:46.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:44:46.827+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:44:46.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:44:46.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-16T18:45:17.204+0000] {processor.py:157} INFO - Started process (PID=41265) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:45:17.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:45:17.219+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:45:17.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:45:17.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:45:17.280+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:45:17.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:45:17.306+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:45:17.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:45:17.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-16T18:45:47.583+0000] {processor.py:157} INFO - Started process (PID=41275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:45:47.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:45:47.590+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:45:47.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:45:47.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:45:47.631+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:45:47.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:45:47.647+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:45:47.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:45:47.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-16T18:46:17.888+0000] {processor.py:157} INFO - Started process (PID=41285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:46:17.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:46:17.895+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:46:17.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:46:17.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:46:17.946+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:46:17.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:46:17.962+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:46:17.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:46:17.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-16T18:46:48.292+0000] {processor.py:157} INFO - Started process (PID=41295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:46:48.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:46:48.299+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:46:48.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:46:48.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:46:48.334+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:46:48.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:46:48.348+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:46:48.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:46:48.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-16T18:47:18.600+0000] {processor.py:157} INFO - Started process (PID=41305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:47:18.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:47:18.607+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:47:18.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:47:18.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:47:18.676+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:47:18.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:47:18.710+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:47:18.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:47:18.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-16T18:47:48.944+0000] {processor.py:157} INFO - Started process (PID=41314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:47:48.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T18:47:48.950+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:47:48.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:47:48.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T18:47:48.996+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:47:48.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T18:47:49.011+0000] {logging_mixin.py:151} INFO - [2024-09-16T18:47:49.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T18:47:49.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-16T19:03:41.338+0000] {processor.py:157} INFO - Started process (PID=41326) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:03:41.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:03:41.346+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:03:41.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:03:41.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:03:41.410+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:03:41.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:03:41.431+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:03:41.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:03:41.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-16T19:04:11.834+0000] {processor.py:157} INFO - Started process (PID=41337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:04:11.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:04:11.841+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:04:11.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:04:11.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:04:11.915+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:04:11.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:04:11.941+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:04:11.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:04:11.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-16T19:04:42.339+0000] {processor.py:157} INFO - Started process (PID=41347) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:04:42.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:04:42.344+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:04:42.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:04:42.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:04:42.386+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:04:42.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:04:42.403+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:04:42.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:04:42.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-16T19:05:12.728+0000] {processor.py:157} INFO - Started process (PID=41357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:05:12.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:05:12.731+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:05:12.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:05:12.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:05:12.763+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:05:12.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:05:12.772+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:05:12.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:05:12.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-16T19:05:43.074+0000] {processor.py:157} INFO - Started process (PID=41367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:05:43.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:05:43.081+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:05:43.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:05:43.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:05:43.123+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:05:43.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:05:43.138+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:05:43.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:05:43.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-16T19:06:13.548+0000] {processor.py:157} INFO - Started process (PID=41377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:06:13.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:06:13.551+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:06:13.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:06:13.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:06:13.578+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:06:13.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:06:13.589+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:06:13.589+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:06:13.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-16T19:06:43.910+0000] {processor.py:157} INFO - Started process (PID=41387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:06:43.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:06:43.913+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:06:43.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:06:43.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:06:43.942+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:06:43.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:06:43.953+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:06:43.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:06:43.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-16T19:07:14.302+0000] {processor.py:157} INFO - Started process (PID=41397) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:07:14.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:07:14.312+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:07:14.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:07:14.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:07:14.363+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:07:14.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:07:14.380+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:07:14.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:07:14.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-16T19:07:44.762+0000] {processor.py:157} INFO - Started process (PID=41407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:07:44.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:07:44.767+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:07:44.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:07:44.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:07:44.797+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:07:44.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:07:44.808+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:07:44.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:07:44.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-16T19:08:15.116+0000] {processor.py:157} INFO - Started process (PID=41417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:08:15.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:08:15.121+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:08:15.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:08:15.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:08:15.165+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:08:15.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:08:15.181+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:08:15.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:08:15.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-16T19:08:45.568+0000] {processor.py:157} INFO - Started process (PID=41427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:08:45.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:08:45.575+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:08:45.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:08:45.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:08:45.615+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:08:45.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:08:45.631+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:08:45.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:08:45.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-16T19:09:16.102+0000] {processor.py:157} INFO - Started process (PID=41437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:09:16.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:09:16.108+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:09:16.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:09:16.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:09:16.162+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:09:16.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:09:16.179+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:09:16.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:09:16.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-16T19:09:46.420+0000] {processor.py:157} INFO - Started process (PID=41447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:09:46.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:09:46.423+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:09:46.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:09:46.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:09:46.468+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:09:46.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:09:46.479+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:09:46.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:09:46.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-16T19:10:16.861+0000] {processor.py:157} INFO - Started process (PID=41457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:10:16.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:10:16.866+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:10:16.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:10:16.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:10:16.907+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:10:16.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:10:16.921+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:10:16.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:10:16.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-16T19:10:47.256+0000] {processor.py:157} INFO - Started process (PID=41467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:10:47.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:10:47.260+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:10:47.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:10:47.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:10:47.291+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:10:47.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:10:47.302+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:10:47.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:10:47.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-16T19:11:17.709+0000] {processor.py:157} INFO - Started process (PID=41477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:11:17.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:11:17.712+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:11:17.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:11:17.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:11:17.739+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:11:17.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:11:17.750+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:11:17.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:11:17.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-16T19:11:48.136+0000] {processor.py:157} INFO - Started process (PID=41487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:11:48.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:11:48.150+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:11:48.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:11:48.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:11:48.213+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:11:48.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:11:48.233+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:11:48.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:11:48.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-16T19:12:18.379+0000] {processor.py:157} INFO - Started process (PID=41497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:12:18.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:12:18.383+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:12:18.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:12:18.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:12:18.411+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:12:18.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:12:18.424+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:12:18.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:12:18.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-16T19:12:48.680+0000] {processor.py:157} INFO - Started process (PID=41507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:12:48.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:12:48.684+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:12:48.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:12:48.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:12:48.722+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:12:48.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:12:48.736+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:12:48.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:12:48.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-16T19:13:19.152+0000] {processor.py:157} INFO - Started process (PID=41517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:13:19.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:13:19.162+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:13:19.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:13:19.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:13:19.228+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:13:19.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:13:19.242+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:13:19.242+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:13:19.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-16T19:13:49.533+0000] {processor.py:157} INFO - Started process (PID=41527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:13:49.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:13:49.538+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:13:49.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:13:49.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:13:49.571+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:13:49.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:13:49.584+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:13:49.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:13:49.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-16T19:14:19.896+0000] {processor.py:157} INFO - Started process (PID=41537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:14:19.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:14:19.903+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:14:19.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:14:19.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:14:19.961+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:14:19.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:14:19.973+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:14:19.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:14:19.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-16T19:14:50.263+0000] {processor.py:157} INFO - Started process (PID=41546) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:14:50.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:14:50.269+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:14:50.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:14:50.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:14:50.304+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:14:50.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:14:50.321+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:14:50.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:14:50.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-16T19:15:20.697+0000] {processor.py:157} INFO - Started process (PID=41557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:15:20.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:15:20.704+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:15:20.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:15:20.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:15:20.746+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:15:20.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:15:20.758+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:15:20.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:15:20.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-16T19:15:51.132+0000] {processor.py:157} INFO - Started process (PID=41566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:15:51.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:15:51.136+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:15:51.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:15:51.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:15:51.170+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:15:51.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:15:51.184+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:15:51.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:15:51.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-16T19:16:21.508+0000] {processor.py:157} INFO - Started process (PID=41577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:16:21.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:16:21.512+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:16:21.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:16:21.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:16:21.553+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:16:21.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:16:21.566+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:16:21.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:16:21.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-16T19:16:51.935+0000] {processor.py:157} INFO - Started process (PID=41587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:16:51.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:16:51.941+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:16:51.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:16:51.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:16:51.985+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:16:51.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:16:51.998+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:16:51.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:16:52.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-16T19:17:22.448+0000] {processor.py:157} INFO - Started process (PID=41597) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:17:22.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:17:22.453+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:17:22.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:17:22.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:17:22.494+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:17:22.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:17:22.506+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:17:22.506+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:17:22.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-16T19:17:52.815+0000] {processor.py:157} INFO - Started process (PID=41607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:17:52.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:17:52.820+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:17:52.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:17:52.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:17:52.864+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:17:52.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:17:52.880+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:17:52.880+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:17:52.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-16T19:18:23.231+0000] {processor.py:157} INFO - Started process (PID=41617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:18:23.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:18:23.238+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:18:23.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:18:23.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:18:23.285+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:18:23.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:18:23.300+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:18:23.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:18:23.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-16T19:18:53.641+0000] {processor.py:157} INFO - Started process (PID=41627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:18:53.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:18:53.644+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:18:53.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:18:53.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:18:53.675+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:18:53.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:18:53.685+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:18:53.685+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:18:53.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-16T19:19:24.060+0000] {processor.py:157} INFO - Started process (PID=41637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:19:24.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:19:24.064+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:19:24.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:19:24.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:19:24.097+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:19:24.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:19:24.110+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:19:24.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:19:24.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-16T19:19:54.477+0000] {processor.py:157} INFO - Started process (PID=41647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:19:54.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:19:54.481+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:19:54.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:19:54.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:19:54.522+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:19:54.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:19:54.535+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:19:54.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:19:54.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-16T19:20:24.900+0000] {processor.py:157} INFO - Started process (PID=41657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:20:24.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:20:24.905+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:20:24.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:20:24.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:20:24.947+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:20:24.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:20:24.961+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:20:24.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:20:24.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-16T19:20:55.360+0000] {processor.py:157} INFO - Started process (PID=41667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:20:55.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:20:55.362+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:20:55.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:20:55.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:20:55.394+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:20:55.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:20:55.405+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:20:55.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:20:55.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-16T19:21:25.780+0000] {processor.py:157} INFO - Started process (PID=41677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:21:25.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:21:25.786+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:21:25.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:21:25.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:21:25.850+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:21:25.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:21:25.867+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:21:25.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:21:25.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-16T19:21:56.071+0000] {processor.py:157} INFO - Started process (PID=41687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:21:56.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:21:56.074+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:21:56.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:21:56.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:21:56.103+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:21:56.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:21:56.115+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:21:56.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:21:56.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-16T19:22:26.577+0000] {processor.py:157} INFO - Started process (PID=41697) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:22:26.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:22:26.583+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:22:26.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:22:26.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:22:26.639+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:22:26.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:22:26.655+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:22:26.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:22:26.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-16T19:22:56.904+0000] {processor.py:157} INFO - Started process (PID=41707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:22:56.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:22:56.906+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:22:56.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:22:56.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:22:56.938+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:22:56.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:22:56.949+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:22:56.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:22:56.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-16T19:23:27.319+0000] {processor.py:157} INFO - Started process (PID=41717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:23:27.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:23:27.325+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:23:27.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:23:27.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:23:27.365+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:23:27.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:23:27.378+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:23:27.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:23:27.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-16T19:23:57.727+0000] {processor.py:157} INFO - Started process (PID=41726) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:23:57.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:23:57.735+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:23:57.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:23:57.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:23:57.787+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:23:57.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:23:57.809+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:23:57.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:23:57.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-16T19:24:28.232+0000] {processor.py:157} INFO - Started process (PID=41737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:24:28.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:24:28.235+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:24:28.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:24:28.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:24:28.261+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:24:28.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:24:28.271+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:24:28.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:24:28.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-16T19:24:58.705+0000] {processor.py:157} INFO - Started process (PID=41745) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:24:58.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:24:58.712+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:24:58.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:24:58.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:24:58.766+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:24:58.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:24:58.787+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:24:58.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:24:58.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-16T19:25:29.155+0000] {processor.py:157} INFO - Started process (PID=41757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:25:29.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:25:29.159+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:25:29.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:25:29.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:25:29.189+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:25:29.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:25:29.200+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:25:29.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:25:29.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-16T19:25:59.592+0000] {processor.py:157} INFO - Started process (PID=41767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:25:59.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:25:59.599+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:25:59.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:25:59.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:25:59.644+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:25:59.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:25:59.659+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:25:59.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:25:59.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-16T19:26:29.948+0000] {processor.py:157} INFO - Started process (PID=41777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:26:29.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:26:29.958+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:26:29.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:26:29.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:26:29.989+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:26:29.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:26:29.999+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:26:29.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:26:30.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-16T19:27:00.268+0000] {processor.py:157} INFO - Started process (PID=41787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:27:00.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:27:00.277+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:27:00.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:27:00.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:27:00.339+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:27:00.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:27:00.359+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:27:00.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:27:00.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-16T19:27:30.609+0000] {processor.py:157} INFO - Started process (PID=41797) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:27:30.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:27:30.615+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:27:30.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:27:30.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:27:30.649+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:27:30.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:27:30.659+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:27:30.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:27:30.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-16T19:28:01.055+0000] {processor.py:157} INFO - Started process (PID=41807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:28:01.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:28:01.061+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:28:01.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:28:01.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:28:01.132+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:28:01.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:28:01.151+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:28:01.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:28:01.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-16T19:28:31.431+0000] {processor.py:157} INFO - Started process (PID=41817) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:28:31.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:28:31.435+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:28:31.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:28:31.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:28:31.461+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:28:31.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:28:31.471+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:28:31.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:28:31.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-16T19:29:01.803+0000] {processor.py:157} INFO - Started process (PID=41827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:29:01.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:29:01.808+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:29:01.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:29:01.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:29:01.856+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:29:01.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:29:01.875+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:29:01.875+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:29:01.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-16T19:29:32.243+0000] {processor.py:157} INFO - Started process (PID=41837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:29:32.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:29:32.255+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:29:32.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:29:32.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:29:32.307+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:29:32.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:29:32.324+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:29:32.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:29:32.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-16T19:30:02.739+0000] {processor.py:157} INFO - Started process (PID=41847) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:30:02.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:30:02.743+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:30:02.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:30:02.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:30:02.786+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:30:02.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:30:02.798+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:30:02.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:30:02.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-16T19:30:33.202+0000] {processor.py:157} INFO - Started process (PID=41857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:30:33.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:30:33.208+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:30:33.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:30:33.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:30:33.276+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:30:33.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:30:33.295+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:30:33.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:30:33.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-16T19:31:03.552+0000] {processor.py:157} INFO - Started process (PID=41867) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:31:03.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:31:03.556+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:31:03.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:31:03.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:31:03.586+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:31:03.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:31:03.599+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:31:03.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:31:03.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-16T19:31:34.040+0000] {processor.py:157} INFO - Started process (PID=41876) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:31:34.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:31:34.053+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:31:34.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:31:34.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:31:34.141+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:31:34.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:31:34.175+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:31:34.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:31:34.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-09-16T19:32:04.422+0000] {processor.py:157} INFO - Started process (PID=41887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:32:04.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:32:04.426+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:32:04.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:32:04.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:32:04.472+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:32:04.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:32:04.488+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:32:04.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:32:04.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-16T19:32:34.836+0000] {processor.py:157} INFO - Started process (PID=41897) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:32:34.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:32:34.840+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:32:34.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:32:34.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:32:34.870+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:32:34.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:32:34.882+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:32:34.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:32:34.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-16T19:33:05.307+0000] {processor.py:157} INFO - Started process (PID=41907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:33:05.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:33:05.332+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:33:05.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:33:05.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:33:05.438+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:33:05.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:33:05.472+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:33:05.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:33:05.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.186 seconds
[2024-09-16T19:33:35.627+0000] {processor.py:157} INFO - Started process (PID=41917) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:33:35.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:33:35.633+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:33:35.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:33:35.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:33:35.675+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:33:35.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:33:35.692+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:33:35.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:33:35.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-16T19:34:06.035+0000] {processor.py:157} INFO - Started process (PID=41927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:34:06.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:34:06.039+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:34:06.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:34:06.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:34:06.067+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:34:06.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:34:06.079+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:34:06.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:34:06.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-16T19:34:36.473+0000] {processor.py:157} INFO - Started process (PID=41937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:34:36.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:34:36.482+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:34:36.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:34:36.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:34:36.532+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:34:36.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:34:36.551+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:34:36.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:34:36.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-16T19:35:06.831+0000] {processor.py:157} INFO - Started process (PID=41947) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:35:06.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:35:06.837+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:35:06.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:35:06.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:35:06.863+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:35:06.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:35:06.873+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:35:06.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:35:06.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-16T19:35:37.302+0000] {processor.py:157} INFO - Started process (PID=41957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:35:37.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:35:37.308+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:35:37.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:35:37.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:35:37.350+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:35:37.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:35:37.367+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:35:37.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:35:37.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-16T19:36:07.705+0000] {processor.py:157} INFO - Started process (PID=41967) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:36:07.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:36:07.714+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:36:07.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:36:07.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:36:07.738+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:36:07.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:36:07.749+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:36:07.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:36:07.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-16T19:36:38.143+0000] {processor.py:157} INFO - Started process (PID=41977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:36:38.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:36:38.148+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:36:38.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:36:38.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:36:38.190+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:36:38.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:36:38.203+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:36:38.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:36:38.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-16T19:37:08.500+0000] {processor.py:157} INFO - Started process (PID=41987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:37:08.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:37:08.503+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:37:08.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:37:08.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:37:08.544+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:37:08.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:37:08.557+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:37:08.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:37:08.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-16T19:37:38.927+0000] {processor.py:157} INFO - Started process (PID=41997) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:37:38.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:37:38.933+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:37:38.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:37:38.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:37:39.005+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:37:39.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:37:39.021+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:37:39.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:37:39.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-16T19:38:09.213+0000] {processor.py:157} INFO - Started process (PID=42007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:38:09.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:38:09.215+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:38:09.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:38:09.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:38:09.246+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:38:09.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:38:09.260+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:38:09.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:38:09.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-16T19:38:39.655+0000] {processor.py:157} INFO - Started process (PID=42017) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:38:39.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:38:39.673+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:38:39.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:38:39.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:38:39.745+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:38:39.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:38:39.762+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:38:39.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:38:39.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-16T19:39:10.196+0000] {processor.py:157} INFO - Started process (PID=42025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:39:10.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:39:10.201+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:39:10.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:39:10.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:39:10.228+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:39:10.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:39:10.238+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:39:10.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:39:10.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-16T19:39:40.649+0000] {processor.py:157} INFO - Started process (PID=42037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:39:40.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:39:40.656+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:39:40.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:39:40.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:39:40.732+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:39:40.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:39:40.751+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:39:40.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:39:40.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-16T19:40:10.980+0000] {processor.py:157} INFO - Started process (PID=42046) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:40:10.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:40:10.982+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:40:10.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:40:10.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:40:11.013+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:40:11.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:40:11.024+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:40:11.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:40:11.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-16T19:40:41.364+0000] {processor.py:157} INFO - Started process (PID=42057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:40:41.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:40:41.390+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:40:41.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:40:41.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:40:41.462+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:40:41.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:40:41.478+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:40:41.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:40:41.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-16T19:41:11.845+0000] {processor.py:157} INFO - Started process (PID=42066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:41:11.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:41:11.852+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:41:11.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:41:11.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:41:11.882+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:41:11.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:41:11.893+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:41:11.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:41:11.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-16T19:41:42.320+0000] {processor.py:157} INFO - Started process (PID=42077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:41:42.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:41:42.331+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:41:42.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:41:42.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:41:42.398+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:41:42.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:41:42.429+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:41:42.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:41:42.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-16T19:42:12.702+0000] {processor.py:157} INFO - Started process (PID=42087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:42:12.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:42:12.706+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:42:12.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:42:12.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:42:12.737+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:42:12.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:42:12.749+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:42:12.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:42:12.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-16T19:42:42.997+0000] {processor.py:157} INFO - Started process (PID=42097) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:42:42.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:42:43.034+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:42:43.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:42:43.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:42:43.097+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:42:43.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:42:43.123+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:42:43.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:42:43.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-16T19:43:13.487+0000] {processor.py:157} INFO - Started process (PID=42107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:43:13.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:43:13.491+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:43:13.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:43:13.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:43:13.525+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:43:13.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:43:13.536+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:43:13.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:43:13.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-16T19:43:43.994+0000] {processor.py:157} INFO - Started process (PID=42117) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:43:43.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:43:44.015+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:43:44.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:43:44.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:43:44.068+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:43:44.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:43:44.095+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:43:44.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:43:44.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-16T19:44:14.420+0000] {processor.py:157} INFO - Started process (PID=42126) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:44:14.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:44:14.427+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:44:14.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:44:14.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:44:14.510+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:44:14.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:44:14.532+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:44:14.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:44:14.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-16T19:44:44.889+0000] {processor.py:157} INFO - Started process (PID=42137) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:44:44.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:44:44.893+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:44:44.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:44:44.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:44:44.919+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:44:44.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:44:44.928+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:44:44.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:44:44.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-16T19:45:15.383+0000] {processor.py:157} INFO - Started process (PID=42147) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:45:15.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:45:15.408+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:45:15.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:45:15.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:45:15.485+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:45:15.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:45:15.505+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:45:15.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:45:15.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-16T19:45:45.857+0000] {processor.py:157} INFO - Started process (PID=42157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:45:45.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:45:45.859+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:45:45.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:45:45.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:45:45.890+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:45:45.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:45:45.902+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:45:45.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:45:45.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-16T19:46:16.204+0000] {processor.py:157} INFO - Started process (PID=42167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:46:16.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:46:16.211+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:46:16.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:46:16.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:46:16.294+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:46:16.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:46:16.316+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:46:16.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:46:16.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-16T19:46:46.724+0000] {processor.py:157} INFO - Started process (PID=42177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:46:46.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:46:46.732+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:46:46.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:46:46.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:46:46.761+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:46:46.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:46:46.772+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:46:46.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:46:46.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-16T19:47:17.126+0000] {processor.py:157} INFO - Started process (PID=42187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:47:17.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:47:17.132+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:47:17.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:47:17.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:47:17.217+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:47:17.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:47:17.234+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:47:17.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:47:17.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-16T19:47:47.427+0000] {processor.py:157} INFO - Started process (PID=42197) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:47:47.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:47:47.435+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:47:47.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:47:47.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:47:47.477+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:47:47.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:47:47.492+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:47:47.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:47:47.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-16T19:48:18.003+0000] {processor.py:157} INFO - Started process (PID=42207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:48:18.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:48:18.015+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:48:18.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:48:18.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:48:18.097+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:48:18.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:48:18.114+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:48:18.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:48:18.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-16T19:48:48.351+0000] {processor.py:157} INFO - Started process (PID=42217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:48:48.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:48:48.355+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:48:48.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:48:48.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:48:48.381+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:48:48.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:48:48.391+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:48:48.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:48:48.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-16T19:49:18.815+0000] {processor.py:157} INFO - Started process (PID=42227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:49:18.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:49:18.820+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:49:18.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:49:18.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:49:18.891+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:49:18.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:49:18.913+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:49:18.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:49:18.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T19:49:49.334+0000] {processor.py:157} INFO - Started process (PID=42237) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:49:49.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:49:49.336+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:49:49.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:49:49.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:49:49.365+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:49:49.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:49:49.377+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:49:49.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:49:49.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-16T19:50:19.693+0000] {processor.py:157} INFO - Started process (PID=42245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:50:19.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:50:19.699+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:50:19.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:50:19.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:50:19.777+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:50:19.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:50:19.799+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:50:19.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:50:19.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-16T19:50:50.037+0000] {processor.py:157} INFO - Started process (PID=42257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:50:50.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:50:50.043+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:50:50.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:50:50.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:50:50.067+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:50:50.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:50:50.077+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:50:50.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:50:50.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-16T19:51:20.366+0000] {processor.py:157} INFO - Started process (PID=42267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:51:20.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:51:20.389+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:51:20.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:51:20.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:51:20.461+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:51:20.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:51:20.476+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:51:20.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:51:20.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-16T19:51:50.895+0000] {processor.py:157} INFO - Started process (PID=42277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:51:50.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:51:50.899+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:51:50.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:51:50.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:51:50.929+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:51:50.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:51:50.939+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:51:50.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:51:50.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-16T19:52:21.371+0000] {processor.py:157} INFO - Started process (PID=42286) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:52:21.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:52:21.386+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:52:21.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:52:21.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:52:21.460+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:52:21.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:52:21.480+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:52:21.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:52:21.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-16T19:52:51.746+0000] {processor.py:157} INFO - Started process (PID=42297) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:52:51.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:52:51.753+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:52:51.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:52:51.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:52:51.792+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:52:51.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:52:51.805+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:52:51.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:52:51.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-16T19:53:22.243+0000] {processor.py:157} INFO - Started process (PID=42307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:53:22.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:53:22.250+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:53:22.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:53:22.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:53:22.292+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:53:22.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:53:22.305+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:53:22.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:53:22.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-16T19:53:52.636+0000] {processor.py:157} INFO - Started process (PID=42317) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:53:52.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:53:52.641+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:53:52.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:53:52.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:53:52.679+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:53:52.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:53:52.691+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:53:52.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:53:52.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-16T19:54:23.105+0000] {processor.py:157} INFO - Started process (PID=42327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:54:23.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:54:23.116+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:54:23.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:54:23.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:54:23.155+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:54:23.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:54:23.168+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:54:23.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:54:23.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-16T19:54:53.587+0000] {processor.py:157} INFO - Started process (PID=42336) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:54:53.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:54:53.593+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:54:53.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:54:53.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:54:53.644+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:54:53.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:54:53.669+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:54:53.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:54:53.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-16T19:55:23.964+0000] {processor.py:157} INFO - Started process (PID=42347) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:55:23.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:55:23.968+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:55:23.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:55:23.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:55:24.006+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:55:24.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:55:24.034+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:55:24.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:55:24.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-16T19:55:54.311+0000] {processor.py:157} INFO - Started process (PID=42357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:55:54.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:55:54.316+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:55:54.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:55:54.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:55:54.400+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:55:54.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:55:54.414+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:55:54.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:55:54.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-16T19:56:24.666+0000] {processor.py:157} INFO - Started process (PID=42367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:56:24.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:56:24.670+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:56:24.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:56:24.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:56:24.703+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:56:24.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:56:24.717+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:56:24.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:56:24.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-16T19:56:55.113+0000] {processor.py:157} INFO - Started process (PID=42377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:56:55.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:56:55.127+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:56:55.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:56:55.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:56:55.185+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:56:55.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:56:55.198+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:56:55.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:56:55.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-16T19:57:25.584+0000] {processor.py:157} INFO - Started process (PID=42387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:57:25.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:57:25.589+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:57:25.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:57:25.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:57:25.640+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:57:25.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:57:25.655+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:57:25.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:57:25.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-16T19:57:56.075+0000] {processor.py:157} INFO - Started process (PID=42397) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:57:56.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:57:56.088+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:57:56.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:57:56.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:57:56.150+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:57:56.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:57:56.166+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:57:56.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:57:56.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-16T19:58:26.624+0000] {processor.py:157} INFO - Started process (PID=42407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:58:26.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:58:26.638+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:58:26.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:58:26.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:58:26.709+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:58:26.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:58:26.724+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:58:26.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:58:26.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-16T19:58:57.041+0000] {processor.py:157} INFO - Started process (PID=42417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:58:57.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:58:57.044+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:58:57.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:58:57.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:58:57.075+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:58:57.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:58:57.087+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:58:57.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:58:57.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-16T19:59:27.477+0000] {processor.py:157} INFO - Started process (PID=42426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:59:27.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:59:27.492+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:59:27.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:59:27.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:59:27.558+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:59:27.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:59:27.574+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:59:27.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:59:27.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-16T19:59:57.858+0000] {processor.py:157} INFO - Started process (PID=42437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:59:57.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T19:59:57.869+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:59:57.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:59:57.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T19:59:57.920+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:59:57.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T19:59:57.936+0000] {logging_mixin.py:151} INFO - [2024-09-16T19:59:57.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T19:59:57.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-16T20:00:28.335+0000] {processor.py:157} INFO - Started process (PID=42447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:00:28.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:00:28.340+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:00:28.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:00:28.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:00:28.376+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:00:28.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:00:28.387+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:00:28.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:00:28.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-16T20:00:58.766+0000] {processor.py:157} INFO - Started process (PID=42457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:00:58.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:00:58.774+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:00:58.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:00:58.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:00:58.827+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:00:58.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:00:58.844+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:00:58.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:00:58.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-16T20:01:29.105+0000] {processor.py:157} INFO - Started process (PID=42467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:01:29.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:01:29.109+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:01:29.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:01:29.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:01:29.152+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:01:29.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:01:29.167+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:01:29.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:01:29.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-16T20:01:59.552+0000] {processor.py:157} INFO - Started process (PID=42476) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:01:59.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:01:59.563+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:01:59.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:01:59.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:01:59.615+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:01:59.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:01:59.639+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:01:59.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:01:59.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-16T20:02:29.986+0000] {processor.py:157} INFO - Started process (PID=42487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:02:29.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:02:29.993+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:02:29.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:02:30.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:02:30.035+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:02:30.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:02:30.051+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:02:30.051+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:02:30.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-16T20:03:00.315+0000] {processor.py:157} INFO - Started process (PID=42497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:03:00.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:03:00.320+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:03:00.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:03:00.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:03:00.348+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:03:00.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:03:00.363+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:03:00.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:03:00.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-16T20:03:30.742+0000] {processor.py:157} INFO - Started process (PID=42507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:03:30.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:03:30.747+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:03:30.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:03:30.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:03:30.788+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:03:30.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:03:30.802+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:03:30.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:03:30.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-16T20:04:01.172+0000] {processor.py:157} INFO - Started process (PID=42517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:04:01.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:04:01.176+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:04:01.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:04:01.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:04:01.211+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:04:01.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:04:01.225+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:04:01.225+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:04:01.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-16T20:04:31.651+0000] {processor.py:157} INFO - Started process (PID=42527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:04:31.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:04:31.679+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:04:31.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:04:31.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:04:31.795+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:04:31.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:04:31.818+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:04:31.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:04:31.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.187 seconds
[2024-09-16T20:21:01.143+0000] {processor.py:157} INFO - Started process (PID=42539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:21:01.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:21:01.151+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:21:01.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:21:01.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:21:01.235+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:21:01.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:21:01.280+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:21:01.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:21:01.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.177 seconds
[2024-09-16T20:21:31.518+0000] {processor.py:157} INFO - Started process (PID=42548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:21:31.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:21:31.526+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:21:31.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:21:31.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:21:31.602+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:21:31.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:21:31.620+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:21:31.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:21:31.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-16T20:22:01.873+0000] {processor.py:157} INFO - Started process (PID=42559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:22:01.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:22:01.877+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:22:01.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:22:01.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:22:01.913+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:22:01.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:22:01.924+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:22:01.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:22:01.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-16T20:22:32.279+0000] {processor.py:157} INFO - Started process (PID=42569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:22:32.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:22:32.289+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:22:32.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:22:32.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:22:32.336+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:22:32.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:22:32.357+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:22:32.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:22:32.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-16T20:23:02.646+0000] {processor.py:157} INFO - Started process (PID=42577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:23:02.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:23:02.651+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:23:02.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:23:02.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:23:02.707+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:23:02.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:23:02.724+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:23:02.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:23:02.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-16T20:23:33.025+0000] {processor.py:157} INFO - Started process (PID=42589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:23:33.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:23:33.028+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:23:33.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:23:33.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:23:33.056+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:23:33.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:23:33.068+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:23:33.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:23:33.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-16T20:24:03.425+0000] {processor.py:157} INFO - Started process (PID=42599) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:24:03.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:24:03.432+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:24:03.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:24:03.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:24:03.495+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:24:03.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:24:03.519+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:24:03.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:24:03.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-16T20:24:33.790+0000] {processor.py:157} INFO - Started process (PID=42608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:24:33.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:24:33.796+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:24:33.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:24:33.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:24:33.875+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:24:33.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:24:33.896+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:24:33.896+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:24:33.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-16T20:25:04.186+0000] {processor.py:157} INFO - Started process (PID=42619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:25:04.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:25:04.192+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:25:04.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:25:04.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:25:04.230+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:25:04.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:25:04.243+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:25:04.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:25:04.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-16T20:25:34.549+0000] {processor.py:157} INFO - Started process (PID=42629) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:25:34.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:25:34.552+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:25:34.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:25:34.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:25:34.603+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:25:34.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:25:34.618+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:25:34.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:25:34.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-16T20:26:05.056+0000] {processor.py:157} INFO - Started process (PID=42639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:26:05.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:26:05.062+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:26:05.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:26:05.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:26:05.123+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:26:05.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:26:05.138+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:26:05.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:26:05.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T20:26:35.387+0000] {processor.py:157} INFO - Started process (PID=42649) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:26:35.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:26:35.390+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:26:35.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:26:35.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:26:35.416+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:26:35.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:26:35.426+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:26:35.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:26:35.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-16T20:27:05.753+0000] {processor.py:157} INFO - Started process (PID=42659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:27:05.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:27:05.772+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:27:05.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:27:05.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:27:05.855+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:27:05.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:27:05.871+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:27:05.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:27:05.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-16T20:27:36.110+0000] {processor.py:157} INFO - Started process (PID=42669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:27:36.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:27:36.116+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:27:36.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:27:36.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:27:36.154+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:27:36.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:27:36.166+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:27:36.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:27:36.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-16T20:28:06.500+0000] {processor.py:157} INFO - Started process (PID=42679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:28:06.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:28:06.507+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:28:06.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:28:06.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:28:06.550+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:28:06.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:28:06.566+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:28:06.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:28:06.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-16T20:28:36.842+0000] {processor.py:157} INFO - Started process (PID=42688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:28:36.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:28:36.849+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:28:36.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:28:36.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:28:36.905+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:28:36.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:28:36.923+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:28:36.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:28:36.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-16T20:29:07.175+0000] {processor.py:157} INFO - Started process (PID=42699) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:29:07.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:29:07.180+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:29:07.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:29:07.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:29:07.218+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:29:07.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:29:07.229+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:29:07.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:29:07.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-16T20:29:37.605+0000] {processor.py:157} INFO - Started process (PID=42709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:29:37.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:29:37.611+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:29:37.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:29:37.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:29:37.669+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:29:37.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:29:37.698+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:29:37.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:29:37.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-16T20:30:07.970+0000] {processor.py:157} INFO - Started process (PID=42719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:30:07.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:30:07.973+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:30:07.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:30:07.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:30:08.001+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:30:08.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:30:08.012+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:30:08.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:30:08.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-16T20:30:38.401+0000] {processor.py:157} INFO - Started process (PID=42729) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:30:38.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:30:38.409+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:30:38.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:30:38.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:30:38.482+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:30:38.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:30:38.499+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:30:38.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:30:38.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-16T20:31:08.745+0000] {processor.py:157} INFO - Started process (PID=42739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:31:08.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:31:08.752+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:31:08.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:31:08.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:31:08.781+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:31:08.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:31:08.791+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:31:08.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:31:08.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-16T20:31:39.156+0000] {processor.py:157} INFO - Started process (PID=42748) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:31:39.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:31:39.169+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:31:39.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:31:39.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:31:39.227+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:31:39.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:31:39.246+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:31:39.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:31:39.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-16T20:32:09.611+0000] {processor.py:157} INFO - Started process (PID=42759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:32:09.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:32:09.614+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:32:09.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:32:09.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:32:09.646+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:32:09.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:32:09.660+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:32:09.660+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:32:09.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-16T20:32:39.957+0000] {processor.py:157} INFO - Started process (PID=42769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:32:39.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:32:39.978+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:32:39.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:32:40.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:32:40.056+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:32:40.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:32:40.074+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:32:40.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:32:40.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-16T20:33:10.360+0000] {processor.py:157} INFO - Started process (PID=42778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:33:10.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:33:10.370+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:33:10.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:33:10.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:33:10.449+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:33:10.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:33:10.478+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:33:10.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:33:10.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-16T20:33:40.726+0000] {processor.py:157} INFO - Started process (PID=42789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:33:40.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:33:40.733+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:33:40.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:33:40.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:33:40.825+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:33:40.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:33:40.842+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:33:40.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:33:40.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-16T20:34:11.041+0000] {processor.py:157} INFO - Started process (PID=42799) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:34:11.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:34:11.044+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:34:11.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:34:11.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:34:11.072+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:34:11.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:34:11.083+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:34:11.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:34:11.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-16T20:34:41.509+0000] {processor.py:157} INFO - Started process (PID=42808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:34:41.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:34:41.520+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:34:41.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:34:41.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:34:41.592+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:34:41.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:34:41.609+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:34:41.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:34:41.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-16T20:35:11.843+0000] {processor.py:157} INFO - Started process (PID=42819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:35:11.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:35:11.847+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:35:11.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:35:11.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:35:11.883+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:35:11.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:35:11.899+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:35:11.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:35:11.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-16T20:35:42.251+0000] {processor.py:157} INFO - Started process (PID=42829) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:35:42.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:35:42.255+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:35:42.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:35:42.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:35:42.314+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:35:42.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:35:42.330+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:35:42.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:35:42.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-16T20:36:12.590+0000] {processor.py:157} INFO - Started process (PID=42839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:36:12.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:36:12.596+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:36:12.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:36:12.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:36:12.632+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:36:12.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:36:12.645+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:36:12.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:36:12.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-16T20:36:43.003+0000] {processor.py:157} INFO - Started process (PID=42849) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:36:43.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:36:43.008+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:36:43.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:36:43.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:36:43.050+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:36:43.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:36:43.064+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:36:43.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:36:43.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-16T20:37:13.372+0000] {processor.py:157} INFO - Started process (PID=42859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:37:13.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:37:13.377+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:37:13.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:37:13.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:37:13.412+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:37:13.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:37:13.423+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:37:13.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:37:13.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-16T20:37:43.693+0000] {processor.py:157} INFO - Started process (PID=42869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:37:43.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:37:43.698+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:37:43.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:37:43.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:37:43.762+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:37:43.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:37:43.777+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:37:43.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:37:43.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-16T20:38:14.037+0000] {processor.py:157} INFO - Started process (PID=42878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:38:14.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:38:14.046+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:38:14.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:38:14.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:38:14.094+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:38:14.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:38:14.105+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:38:14.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:38:14.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-16T20:38:44.495+0000] {processor.py:157} INFO - Started process (PID=42889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:38:44.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:38:44.500+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:38:44.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:38:44.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:38:44.554+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:38:44.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:38:44.569+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:38:44.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:38:44.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-16T20:39:14.952+0000] {processor.py:157} INFO - Started process (PID=42899) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:39:14.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:39:14.955+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:39:14.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:39:14.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:39:14.989+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:39:14.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:39:14.999+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:39:14.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:39:15.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-16T20:39:45.343+0000] {processor.py:157} INFO - Started process (PID=42909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:39:45.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:39:45.349+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:39:45.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:39:45.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:39:45.410+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:39:45.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:39:45.427+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:39:45.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:39:45.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-16T20:40:15.793+0000] {processor.py:157} INFO - Started process (PID=42918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:40:15.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:40:15.798+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:40:15.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:40:15.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:40:15.855+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:40:15.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:40:15.878+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:40:15.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:40:15.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-16T20:40:46.140+0000] {processor.py:157} INFO - Started process (PID=42929) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:40:46.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:40:46.145+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:40:46.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:40:46.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:40:46.201+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:40:46.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:40:46.217+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:40:46.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:40:46.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-16T20:41:16.627+0000] {processor.py:157} INFO - Started process (PID=42939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:41:16.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:41:16.637+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:41:16.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:41:16.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:41:16.686+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:41:16.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:41:16.698+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:41:16.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:41:16.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-16T20:41:46.942+0000] {processor.py:157} INFO - Started process (PID=42949) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:41:46.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:41:46.945+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:41:46.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:41:46.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:41:46.994+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:41:46.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:41:47.009+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:41:47.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:41:47.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-16T20:42:17.240+0000] {processor.py:157} INFO - Started process (PID=42958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:42:17.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:42:17.243+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:42:17.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:42:17.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:42:17.294+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:42:17.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:42:17.308+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:42:17.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:42:17.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-16T20:42:47.684+0000] {processor.py:157} INFO - Started process (PID=42969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:42:47.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:42:47.687+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:42:47.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:42:47.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:42:47.722+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:42:47.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:42:47.735+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:42:47.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:42:47.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-16T20:43:18.081+0000] {processor.py:157} INFO - Started process (PID=42979) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:43:18.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:43:18.085+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:43:18.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:43:18.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:43:18.124+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:43:18.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:43:18.137+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:43:18.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:43:18.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-16T20:43:48.412+0000] {processor.py:157} INFO - Started process (PID=42989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:43:48.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:43:48.415+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:43:48.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:43:48.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:43:48.463+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:43:48.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:43:48.478+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:43:48.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:43:48.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-16T20:44:18.754+0000] {processor.py:157} INFO - Started process (PID=42998) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:44:18.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:44:18.777+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:44:18.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:44:18.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:44:18.836+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:44:18.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:44:18.851+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:44:18.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:44:18.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-16T20:44:49.280+0000] {processor.py:157} INFO - Started process (PID=43009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:44:49.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:44:49.284+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:44:49.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:44:49.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:44:49.321+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:44:49.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:44:49.338+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:44:49.338+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:44:49.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-16T20:45:19.621+0000] {processor.py:157} INFO - Started process (PID=43019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:45:19.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:45:19.626+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:45:19.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:45:19.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:45:19.675+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:45:19.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:45:19.686+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:45:19.686+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:45:19.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-16T20:45:50.006+0000] {processor.py:157} INFO - Started process (PID=43029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:45:50.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:45:50.010+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:45:50.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:45:50.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:45:50.050+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:45:50.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:45:50.065+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:45:50.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:45:50.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-16T20:46:20.406+0000] {processor.py:157} INFO - Started process (PID=43039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:46:20.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:46:20.413+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:46:20.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:46:20.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:46:20.479+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:46:20.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:46:20.501+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:46:20.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:46:20.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-16T20:46:50.754+0000] {processor.py:157} INFO - Started process (PID=43049) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:46:50.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:46:50.759+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:46:50.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:46:50.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:46:50.791+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:46:50.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:46:50.801+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:46:50.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:46:50.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-16T20:47:21.232+0000] {processor.py:157} INFO - Started process (PID=43059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:47:21.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:47:21.242+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:47:21.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:47:21.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:47:21.309+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:47:21.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:47:21.324+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:47:21.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:47:21.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-16T20:47:51.574+0000] {processor.py:157} INFO - Started process (PID=43069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:47:51.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:47:51.580+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:47:51.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:47:51.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:47:51.637+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:47:51.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:47:51.655+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:47:51.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:47:51.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-16T20:48:22.037+0000] {processor.py:157} INFO - Started process (PID=43078) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:48:22.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:48:22.042+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:48:22.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:48:22.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:48:22.102+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:48:22.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:48:22.118+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:48:22.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:48:22.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-16T20:48:52.417+0000] {processor.py:157} INFO - Started process (PID=43089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:48:52.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:48:52.422+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:48:52.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:48:52.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:48:52.448+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:48:52.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:48:52.459+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:48:52.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:48:52.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-16T20:49:22.733+0000] {processor.py:157} INFO - Started process (PID=43099) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:49:22.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:49:22.740+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:49:22.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:49:22.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:49:22.806+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:49:22.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:49:22.825+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:49:22.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:49:22.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-16T20:49:53.144+0000] {processor.py:157} INFO - Started process (PID=43108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:49:53.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:49:53.150+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:49:53.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:49:53.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:49:53.204+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:49:53.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:49:53.221+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:49:53.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:49:53.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-16T20:50:23.517+0000] {processor.py:157} INFO - Started process (PID=43119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:50:23.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:50:23.521+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:50:23.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:50:23.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:50:23.567+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:50:23.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:50:23.606+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:50:23.605+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:50:23.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-16T20:50:53.783+0000] {processor.py:157} INFO - Started process (PID=43129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:50:53.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:50:53.787+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:50:53.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:50:53.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:50:53.829+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:50:53.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:50:53.842+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:50:53.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:50:53.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-16T20:51:24.147+0000] {processor.py:157} INFO - Started process (PID=43139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:51:24.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:51:24.155+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:51:24.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:51:24.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:51:24.193+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:51:24.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:51:24.208+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:51:24.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:51:24.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-16T20:51:54.566+0000] {processor.py:157} INFO - Started process (PID=43149) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:51:54.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:51:54.576+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:51:54.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:51:54.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:51:54.617+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:51:54.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:51:54.629+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:51:54.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:51:54.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-16T20:52:24.897+0000] {processor.py:157} INFO - Started process (PID=43159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:52:24.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:52:24.908+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:52:24.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:52:24.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:52:24.945+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:52:24.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:52:24.960+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:52:24.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:52:24.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-16T20:52:55.320+0000] {processor.py:157} INFO - Started process (PID=43169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:52:55.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:52:55.325+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:52:55.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:52:55.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:52:55.362+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:52:55.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:52:55.375+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:52:55.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:52:55.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-16T20:53:25.704+0000] {processor.py:157} INFO - Started process (PID=43178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:53:25.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:53:25.709+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:53:25.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:53:25.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:53:25.741+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:53:25.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:53:25.752+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:53:25.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:53:25.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-16T20:53:55.994+0000] {processor.py:157} INFO - Started process (PID=43189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:53:55.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:53:56.000+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:53:56.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:53:56.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:53:56.039+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:53:56.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:53:56.053+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:53:56.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:53:56.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-16T20:54:26.301+0000] {processor.py:157} INFO - Started process (PID=43199) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:54:26.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:54:26.304+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:54:26.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:54:26.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:54:26.342+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:54:26.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:54:26.355+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:54:26.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:54:26.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-16T20:54:56.675+0000] {processor.py:157} INFO - Started process (PID=43209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:54:56.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:54:56.679+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:54:56.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:54:56.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:54:56.712+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:54:56.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:54:56.726+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:54:56.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:54:56.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-16T20:55:27.040+0000] {processor.py:157} INFO - Started process (PID=43219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:55:27.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:55:27.046+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:55:27.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:55:27.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:55:27.109+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:55:27.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:55:27.125+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:55:27.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:55:27.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-16T20:55:57.387+0000] {processor.py:157} INFO - Started process (PID=43229) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:55:57.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:55:57.391+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:55:57.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:55:57.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:55:57.422+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:55:57.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:55:57.436+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:55:57.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:55:57.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-16T20:56:27.848+0000] {processor.py:157} INFO - Started process (PID=43239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:56:27.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:56:27.853+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:56:27.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:56:27.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:56:27.926+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:56:27.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:56:27.964+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:56:27.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:56:27.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-16T20:56:58.323+0000] {processor.py:157} INFO - Started process (PID=43248) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:56:58.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:56:58.326+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:56:58.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:56:58.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:56:58.358+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:56:58.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:56:58.369+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:56:58.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:56:58.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-16T20:57:28.735+0000] {processor.py:157} INFO - Started process (PID=43259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:57:28.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:57:28.740+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:57:28.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:57:28.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:57:28.783+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:57:28.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:57:28.797+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:57:28.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:57:28.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-16T20:57:59.068+0000] {processor.py:157} INFO - Started process (PID=43269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:57:59.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:57:59.072+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:57:59.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:57:59.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:57:59.103+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:57:59.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:57:59.113+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:57:59.113+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:57:59.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-16T20:58:29.470+0000] {processor.py:157} INFO - Started process (PID=43279) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:58:29.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:58:29.475+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:58:29.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:58:29.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:58:29.516+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:58:29.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:58:29.529+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:58:29.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:58:29.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-16T20:58:59.824+0000] {processor.py:157} INFO - Started process (PID=43289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:58:59.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:58:59.827+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:58:59.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:58:59.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:58:59.861+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:58:59.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:58:59.873+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:58:59.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:58:59.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-16T20:59:30.204+0000] {processor.py:157} INFO - Started process (PID=43299) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:59:30.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T20:59:30.220+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:59:30.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:59:30.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T20:59:30.286+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:59:30.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T20:59:30.300+0000] {logging_mixin.py:151} INFO - [2024-09-16T20:59:30.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T20:59:30.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-16T21:00:00.590+0000] {processor.py:157} INFO - Started process (PID=43309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:00:00.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:00:00.593+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:00:00.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:00:00.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:00:00.635+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:00:00.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:00:00.646+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:00:00.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:00:00.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-16T21:00:31.049+0000] {processor.py:157} INFO - Started process (PID=43319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:00:31.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:00:31.059+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:00:31.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:00:31.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:00:31.128+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:00:31.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:00:31.145+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:00:31.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:00:31.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-16T21:01:01.504+0000] {processor.py:157} INFO - Started process (PID=43328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:01:01.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:01:01.514+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:01:01.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:01:01.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:01:01.547+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:01:01.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:01:01.558+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:01:01.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:01:01.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-16T21:01:31.889+0000] {processor.py:157} INFO - Started process (PID=43339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:01:31.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:01:31.912+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:01:31.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:01:31.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:01:31.965+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:01:31.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:01:31.993+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:01:31.993+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:01:32.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-16T21:02:02.182+0000] {processor.py:157} INFO - Started process (PID=43348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:02:02.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:02:02.186+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:02:02.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:02:02.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:02:02.219+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:02:02.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:02:02.232+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:02:02.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:02:02.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-16T21:02:32.576+0000] {processor.py:157} INFO - Started process (PID=43359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:02:32.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:02:32.583+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:02:32.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:02:32.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:02:32.644+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:02:32.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:02:32.659+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:02:32.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:02:32.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-16T21:03:02.948+0000] {processor.py:157} INFO - Started process (PID=43368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:03:02.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:03:02.951+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:03:02.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:03:02.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:03:02.981+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:03:02.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:03:02.992+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:03:02.992+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:03:03.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-16T21:03:33.255+0000] {processor.py:157} INFO - Started process (PID=43378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:03:33.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:03:33.261+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:03:33.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:03:33.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:03:33.325+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:03:33.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:03:33.338+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:03:33.338+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:03:33.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-16T21:04:03.719+0000] {processor.py:157} INFO - Started process (PID=43388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:04:03.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:04:03.722+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:04:03.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:04:03.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:04:03.748+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:04:03.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:04:03.758+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:04:03.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:04:03.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-16T21:04:34.181+0000] {processor.py:157} INFO - Started process (PID=43399) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:04:34.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:04:34.186+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:04:34.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:04:34.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:04:34.248+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:04:34.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:04:34.273+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:04:34.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:04:34.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-16T21:05:04.479+0000] {processor.py:157} INFO - Started process (PID=43409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:05:04.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:05:04.482+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:05:04.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:05:04.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:05:04.516+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:05:04.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:05:04.536+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:05:04.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:05:04.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-16T21:05:34.948+0000] {processor.py:157} INFO - Started process (PID=43418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:05:34.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:05:34.961+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:05:34.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:05:34.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:05:35.025+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:05:35.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:05:35.041+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:05:35.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:05:35.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-16T21:06:05.327+0000] {processor.py:157} INFO - Started process (PID=43429) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:06:05.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:06:05.333+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:06:05.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:06:05.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:06:05.375+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:06:05.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:06:05.388+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:06:05.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:06:05.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-16T21:06:35.671+0000] {processor.py:157} INFO - Started process (PID=43438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:06:35.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:06:35.678+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:06:35.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:06:35.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:06:35.743+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:06:35.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:06:35.756+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:06:35.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:06:35.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-16T21:07:06.010+0000] {processor.py:157} INFO - Started process (PID=43449) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:07:06.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:07:06.013+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:07:06.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:07:06.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:07:06.045+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:07:06.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:07:06.055+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:07:06.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:07:06.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-16T21:07:36.439+0000] {processor.py:157} INFO - Started process (PID=43459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:07:36.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:07:36.445+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:07:36.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:07:36.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:07:36.503+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:07:36.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:07:36.519+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:07:36.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:07:36.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-16T21:08:06.881+0000] {processor.py:157} INFO - Started process (PID=43469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:08:06.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:08:06.885+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:08:06.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:08:06.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:08:06.922+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:08:06.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:08:06.941+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:08:06.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:08:06.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-16T21:08:37.351+0000] {processor.py:157} INFO - Started process (PID=43479) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:08:37.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:08:37.360+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:08:37.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:08:37.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:08:37.428+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:08:37.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:08:37.446+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:08:37.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:08:37.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-16T21:09:07.637+0000] {processor.py:157} INFO - Started process (PID=43489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:09:07.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:09:07.647+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:09:07.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:09:07.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:09:07.681+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:09:07.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:09:07.691+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:09:07.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:09:07.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-16T21:09:38.092+0000] {processor.py:157} INFO - Started process (PID=43499) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:09:38.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:09:38.101+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:09:38.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:09:38.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:09:38.175+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:09:38.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:09:38.193+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:09:38.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:09:38.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T21:10:08.551+0000] {processor.py:157} INFO - Started process (PID=43509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:10:08.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:10:08.559+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:10:08.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:10:08.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:10:08.587+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:10:08.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:10:08.597+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:10:08.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:10:08.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-16T21:10:38.872+0000] {processor.py:157} INFO - Started process (PID=43519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:10:38.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:10:38.881+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:10:38.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:10:38.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:10:38.949+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:10:38.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:10:38.962+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:10:38.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:10:38.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-16T21:11:09.201+0000] {processor.py:157} INFO - Started process (PID=43529) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:11:09.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:11:09.210+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:11:09.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:11:09.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:11:09.259+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:11:09.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:11:09.275+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:11:09.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:11:09.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-16T21:11:39.657+0000] {processor.py:157} INFO - Started process (PID=43539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:11:39.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:11:39.661+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:11:39.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:11:39.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:11:39.691+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:11:39.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:11:39.702+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:11:39.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:11:39.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-16T21:12:10.095+0000] {processor.py:157} INFO - Started process (PID=43549) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:12:10.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:12:10.104+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:12:10.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:12:10.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:12:10.168+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:12:10.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:12:10.182+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:12:10.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:12:10.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T21:12:40.587+0000] {processor.py:157} INFO - Started process (PID=43559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:12:40.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:12:40.591+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:12:40.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:12:40.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:12:40.627+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:12:40.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:12:40.638+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:12:40.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:12:40.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-16T21:13:10.958+0000] {processor.py:157} INFO - Started process (PID=43569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:13:10.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:13:10.968+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:13:10.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:13:11.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:13:11.027+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:13:11.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:13:11.049+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:13:11.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:13:11.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-16T21:13:41.343+0000] {processor.py:157} INFO - Started process (PID=43579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:13:41.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:13:41.349+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:13:41.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:13:41.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:13:41.410+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:13:41.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:13:41.426+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:13:41.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:13:41.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-16T21:14:11.744+0000] {processor.py:157} INFO - Started process (PID=43589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:14:11.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:14:11.746+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:14:11.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:14:11.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:14:11.778+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:14:11.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:14:11.790+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:14:11.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:14:11.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-16T21:14:42.176+0000] {processor.py:157} INFO - Started process (PID=43598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:14:42.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:14:42.182+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:14:42.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:14:42.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:14:42.257+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:14:42.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:14:42.274+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:14:42.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:14:42.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-16T21:15:12.525+0000] {processor.py:157} INFO - Started process (PID=43609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:15:12.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:15:12.528+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:15:12.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:15:12.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:15:12.559+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:15:12.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:15:12.571+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:15:12.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:15:12.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-16T21:15:42.945+0000] {processor.py:157} INFO - Started process (PID=43619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:15:42.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:15:42.952+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:15:42.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:15:42.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:15:43.017+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:15:43.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:15:43.032+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:15:43.032+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:15:43.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T21:16:13.496+0000] {processor.py:157} INFO - Started process (PID=43629) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:16:13.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:16:13.503+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:16:13.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:16:13.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:16:13.573+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:16:13.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:16:13.598+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:16:13.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:16:13.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-16T21:16:43.911+0000] {processor.py:157} INFO - Started process (PID=43639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:16:43.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:16:43.918+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:16:43.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:16:43.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:16:43.994+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:16:43.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:16:44.021+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:16:44.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:16:44.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-16T21:17:14.427+0000] {processor.py:157} INFO - Started process (PID=43649) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:17:14.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:17:14.432+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:17:14.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:17:14.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:17:14.479+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:17:14.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:17:14.493+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:17:14.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:17:14.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-16T21:17:44.791+0000] {processor.py:157} INFO - Started process (PID=43659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:17:44.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:17:44.800+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:17:44.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:17:44.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:17:44.867+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:17:44.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:17:44.899+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:17:44.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:17:44.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-16T21:18:15.265+0000] {processor.py:157} INFO - Started process (PID=43669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:18:15.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:18:15.272+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:18:15.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:18:15.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:18:15.342+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:18:15.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:18:15.358+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:18:15.358+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:18:15.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-16T21:18:45.635+0000] {processor.py:157} INFO - Started process (PID=43679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:18:45.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:18:45.645+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:18:45.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:18:45.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:18:45.694+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:18:45.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:18:45.709+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:18:45.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:18:45.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-16T21:19:16.082+0000] {processor.py:157} INFO - Started process (PID=43689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:19:16.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:19:16.085+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:19:16.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:19:16.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:19:16.141+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:19:16.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:19:16.155+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:19:16.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:19:16.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-16T21:19:46.562+0000] {processor.py:157} INFO - Started process (PID=43697) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:19:46.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:19:46.574+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:19:46.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:19:46.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:19:46.633+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:19:46.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:19:46.648+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:19:46.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:19:46.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-16T21:20:16.977+0000] {processor.py:157} INFO - Started process (PID=43709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:20:16.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:20:16.984+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:20:16.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:20:17.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:20:17.029+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:20:17.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:20:17.045+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:20:17.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:20:17.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-16T21:20:47.279+0000] {processor.py:157} INFO - Started process (PID=43719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:20:47.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:20:47.282+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:20:47.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:20:47.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:20:47.309+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:20:47.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:20:47.320+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:20:47.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:20:47.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-16T21:36:44.219+0000] {processor.py:157} INFO - Started process (PID=43729) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:36:44.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:36:44.245+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:36:44.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:36:44.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:36:44.336+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:36:44.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:36:44.378+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:36:44.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:36:44.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.183 seconds
[2024-09-16T21:37:14.775+0000] {processor.py:157} INFO - Started process (PID=43741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:37:14.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:37:14.786+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:37:14.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:37:14.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:37:14.858+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:37:14.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:37:14.872+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:37:14.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:37:14.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-16T21:48:34.901+0000] {processor.py:157} INFO - Started process (PID=43751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:48:34.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T21:48:34.907+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:48:34.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:48:34.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T21:48:34.974+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:48:34.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T21:48:34.988+0000] {logging_mixin.py:151} INFO - [2024-09-16T21:48:34.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T21:48:34.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-16T22:04:12.436+0000] {processor.py:157} INFO - Started process (PID=43760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:04:12.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:04:12.448+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:04:12.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:04:12.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:04:12.563+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:04:12.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:04:12.593+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:04:12.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:04:12.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.196 seconds
[2024-09-16T22:04:43.092+0000] {processor.py:157} INFO - Started process (PID=43770) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:04:43.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:04:43.098+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:04:43.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:04:43.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:04:43.180+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:04:43.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:04:43.196+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:04:43.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:04:43.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-16T22:17:21.847+0000] {processor.py:157} INFO - Started process (PID=43783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:17:21.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:17:21.862+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:17:21.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:17:21.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:17:21.962+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:17:21.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:17:21.994+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:17:21.994+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:17:22.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.191 seconds
[2024-09-16T22:17:52.179+0000] {processor.py:157} INFO - Started process (PID=43793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:17:52.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:17:52.189+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:17:52.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:17:52.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:17:52.255+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:17:52.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:17:52.279+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:17:52.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:17:52.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-16T22:18:22.799+0000] {processor.py:157} INFO - Started process (PID=43803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:18:22.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:18:22.809+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:18:22.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:18:22.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:18:22.868+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:18:22.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:18:22.884+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:18:22.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:18:22.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-16T22:18:53.111+0000] {processor.py:157} INFO - Started process (PID=43813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:18:53.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:18:53.117+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:18:53.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:18:53.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:18:53.161+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:18:53.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:18:53.175+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:18:53.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:18:53.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-16T22:19:23.563+0000] {processor.py:157} INFO - Started process (PID=43823) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:19:23.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:19:23.577+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:19:23.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:19:23.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:19:23.649+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:19:23.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:19:23.667+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:19:23.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:19:23.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-16T22:19:53.891+0000] {processor.py:157} INFO - Started process (PID=43833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:19:53.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:19:53.899+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:19:53.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:19:53.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:19:53.970+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:19:53.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:19:53.997+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:19:53.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:19:54.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-16T22:20:24.309+0000] {processor.py:157} INFO - Started process (PID=43843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:20:24.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:20:24.316+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:20:24.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:20:24.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:20:24.379+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:20:24.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:20:24.394+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:20:24.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:20:24.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-16T22:20:54.883+0000] {processor.py:157} INFO - Started process (PID=43853) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:20:54.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:20:54.895+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:20:54.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:20:54.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:20:55.027+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:20:55.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:20:55.077+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:20:55.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:20:55.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.220 seconds
[2024-09-16T22:21:25.567+0000] {processor.py:157} INFO - Started process (PID=43863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:21:25.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:21:25.593+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:21:25.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:21:25.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:21:25.671+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:21:25.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:21:25.693+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:21:25.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:21:25.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-16T22:21:55.927+0000] {processor.py:157} INFO - Started process (PID=43873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:21:55.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:21:55.935+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:21:55.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:21:55.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:21:56.016+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:21:56.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:21:56.040+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:21:56.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:21:56.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-16T22:22:26.379+0000] {processor.py:157} INFO - Started process (PID=43883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:22:26.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:22:26.386+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:22:26.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:22:26.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:22:26.444+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:22:26.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:22:26.458+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:22:26.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:22:26.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-16T22:22:56.752+0000] {processor.py:157} INFO - Started process (PID=43893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:22:56.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:22:56.760+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:22:56.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:22:56.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:22:56.814+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:22:56.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:22:56.830+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:22:56.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:22:56.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-16T22:23:27.225+0000] {processor.py:157} INFO - Started process (PID=43903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:23:27.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:23:27.236+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:23:27.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:23:27.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:23:27.323+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:23:27.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:23:27.342+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:23:27.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:23:27.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-16T22:23:57.576+0000] {processor.py:157} INFO - Started process (PID=43913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:23:57.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:23:57.584+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:23:57.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:23:57.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:23:57.652+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:23:57.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:23:57.684+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:23:57.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:23:57.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-16T22:24:27.949+0000] {processor.py:157} INFO - Started process (PID=43923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:24:27.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:24:27.961+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:24:27.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:24:27.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:24:28.018+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:24:28.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:24:28.037+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:24:28.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:24:28.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T22:24:58.469+0000] {processor.py:157} INFO - Started process (PID=43933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:24:58.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:24:58.480+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:24:58.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:24:58.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:24:58.576+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:24:58.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:24:58.593+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:24:58.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:24:58.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-16T22:25:28.762+0000] {processor.py:157} INFO - Started process (PID=43943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:25:28.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:25:28.765+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:25:28.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:25:28.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:25:28.794+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:25:28.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:25:28.807+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:25:28.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:25:28.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-16T22:25:59.151+0000] {processor.py:157} INFO - Started process (PID=43953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:25:59.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:25:59.164+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:25:59.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:25:59.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:25:59.236+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:25:59.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:25:59.255+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:25:59.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:25:59.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-16T22:26:29.650+0000] {processor.py:157} INFO - Started process (PID=43963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:26:29.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:26:29.656+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:26:29.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:26:29.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:26:29.709+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:26:29.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:26:29.725+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:26:29.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:26:29.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-16T22:27:00.012+0000] {processor.py:157} INFO - Started process (PID=43973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:27:00.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:27:00.016+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:27:00.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:27:00.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:27:00.059+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:27:00.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:27:00.076+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:27:00.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:27:00.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-16T22:27:30.307+0000] {processor.py:157} INFO - Started process (PID=43983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:27:30.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:27:30.312+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:27:30.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:27:30.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:27:30.347+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:27:30.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:27:30.359+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:27:30.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:27:30.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-16T22:28:00.685+0000] {processor.py:157} INFO - Started process (PID=43993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:28:00.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:28:00.689+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:28:00.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:28:00.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:28:00.738+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:28:00.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:28:00.756+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:28:00.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:28:00.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-16T22:28:31.098+0000] {processor.py:157} INFO - Started process (PID=44003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:28:31.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:28:31.102+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:28:31.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:28:31.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:28:31.142+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:28:31.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:28:31.155+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:28:31.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:28:31.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-16T22:29:01.554+0000] {processor.py:157} INFO - Started process (PID=44013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:29:01.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:29:01.561+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:29:01.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:29:01.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:29:01.636+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:29:01.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:29:01.653+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:29:01.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:29:01.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-16T22:29:31.931+0000] {processor.py:157} INFO - Started process (PID=44023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:29:31.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:29:31.939+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:29:31.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:29:31.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:29:31.998+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:29:31.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:29:32.014+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:29:32.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:29:32.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-16T22:30:02.292+0000] {processor.py:157} INFO - Started process (PID=44033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:30:02.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:30:02.301+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:30:02.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:30:02.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:30:02.370+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:30:02.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:30:02.401+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:30:02.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:30:02.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-16T22:30:32.668+0000] {processor.py:157} INFO - Started process (PID=44043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:30:32.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:30:32.679+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:30:32.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:30:32.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:30:32.743+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:30:32.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:30:32.760+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:30:32.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:30:32.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-16T22:31:03.040+0000] {processor.py:157} INFO - Started process (PID=44053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:31:03.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:31:03.045+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:31:03.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:31:03.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:31:03.091+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:31:03.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:31:03.108+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:31:03.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:31:03.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-16T22:31:33.364+0000] {processor.py:157} INFO - Started process (PID=44063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:31:33.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:31:33.372+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:31:33.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:31:33.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:31:33.430+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:31:33.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:31:33.444+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:31:33.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:31:33.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-16T22:32:03.736+0000] {processor.py:157} INFO - Started process (PID=44073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:32:03.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:32:03.743+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:32:03.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:32:03.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:32:03.802+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:32:03.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:32:03.820+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:32:03.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:32:03.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-16T22:32:34.142+0000] {processor.py:157} INFO - Started process (PID=44082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:32:34.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:32:34.169+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:32:34.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:32:34.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:32:34.229+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:32:34.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:32:34.250+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:32:34.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:32:34.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-16T22:33:04.608+0000] {processor.py:157} INFO - Started process (PID=44093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:33:04.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:33:04.611+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:33:04.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:33:04.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:33:04.640+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:33:04.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:33:04.650+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:33:04.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:33:04.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-16T22:33:35.153+0000] {processor.py:157} INFO - Started process (PID=44103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:33:35.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:33:35.160+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:33:35.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:33:35.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:33:35.273+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:33:35.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:33:35.297+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:33:35.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:33:35.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-09-16T22:34:05.541+0000] {processor.py:157} INFO - Started process (PID=44113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:34:05.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:34:05.548+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:34:05.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:34:05.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:34:05.629+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:34:05.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:34:05.647+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:34:05.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:34:05.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-16T22:34:36.172+0000] {processor.py:157} INFO - Started process (PID=44123) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:34:36.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:34:36.179+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:34:36.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:34:36.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:34:36.246+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:34:36.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:34:36.263+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:34:36.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:34:36.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-16T22:35:06.515+0000] {processor.py:157} INFO - Started process (PID=44133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:35:06.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:35:06.524+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:35:06.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:35:06.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:35:06.605+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:35:06.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:35:06.623+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:35:06.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:35:06.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-16T22:35:37.002+0000] {processor.py:157} INFO - Started process (PID=44143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:35:37.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:35:37.013+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:35:37.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:35:37.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:35:37.110+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:35:37.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:35:37.129+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:35:37.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:35:37.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-16T22:36:07.435+0000] {processor.py:157} INFO - Started process (PID=44153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:36:07.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:36:07.439+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:36:07.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:36:07.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:36:07.494+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:36:07.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:36:07.510+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:36:07.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:36:07.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-16T22:36:37.824+0000] {processor.py:157} INFO - Started process (PID=44163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:36:37.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:36:37.834+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:36:37.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:36:37.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:36:37.885+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:36:37.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:36:37.901+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:36:37.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:36:37.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-16T22:37:08.323+0000] {processor.py:157} INFO - Started process (PID=44173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:37:08.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:37:08.329+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:37:08.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:37:08.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:37:08.400+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:37:08.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:37:08.435+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:37:08.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:37:08.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-16T22:37:38.681+0000] {processor.py:157} INFO - Started process (PID=44183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:37:38.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:37:38.687+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:37:38.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:37:38.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:37:38.752+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:37:38.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:37:38.770+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:37:38.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:37:38.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-16T22:38:09.048+0000] {processor.py:157} INFO - Started process (PID=44193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:38:09.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:38:09.057+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:38:09.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:38:09.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:38:09.139+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:38:09.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:38:09.160+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:38:09.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:38:09.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-16T22:38:39.501+0000] {processor.py:157} INFO - Started process (PID=44203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:38:39.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:38:39.508+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:38:39.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:38:39.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:38:39.576+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:38:39.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:38:39.598+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:38:39.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:38:39.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-16T22:39:10.064+0000] {processor.py:157} INFO - Started process (PID=44213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:39:10.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:39:10.070+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:39:10.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:39:10.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:39:10.115+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:39:10.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:39:10.131+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:39:10.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:39:10.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-16T22:39:40.456+0000] {processor.py:157} INFO - Started process (PID=44223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:39:40.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:39:40.460+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:39:40.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:39:40.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:39:40.487+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:39:40.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:39:40.500+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:39:40.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:39:40.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-16T22:40:10.933+0000] {processor.py:157} INFO - Started process (PID=44233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:40:10.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:40:10.953+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:40:10.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:40:10.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:40:11.027+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:40:11.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:40:11.044+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:40:11.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:40:11.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-16T22:40:41.340+0000] {processor.py:157} INFO - Started process (PID=44242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:40:41.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:40:41.355+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:40:41.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:40:41.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:40:41.433+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:40:41.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:40:41.455+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:40:41.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:40:41.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-16T22:41:11.794+0000] {processor.py:157} INFO - Started process (PID=44253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:41:11.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:41:11.799+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:41:11.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:41:11.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:41:11.851+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:41:11.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:41:11.867+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:41:11.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:41:11.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-16T22:41:42.179+0000] {processor.py:157} INFO - Started process (PID=44263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:41:42.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:41:42.184+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:41:42.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:41:42.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:41:42.218+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:41:42.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:41:42.240+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:41:42.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:41:42.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-16T22:42:12.622+0000] {processor.py:157} INFO - Started process (PID=44273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:42:12.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:42:12.627+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:42:12.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:42:12.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:42:12.687+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:42:12.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:42:12.712+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:42:12.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:42:12.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-16T22:42:42.939+0000] {processor.py:157} INFO - Started process (PID=44283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:42:42.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:42:42.946+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:42:42.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:42:42.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:42:42.992+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:42:42.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:42:43.006+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:42:43.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:42:43.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-16T22:43:13.354+0000] {processor.py:157} INFO - Started process (PID=44293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:43:13.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:43:13.359+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:43:13.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:43:13.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:43:13.388+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:43:13.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:43:13.400+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:43:13.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:43:13.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-16T22:43:43.824+0000] {processor.py:157} INFO - Started process (PID=44303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:43:43.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:43:43.838+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:43:43.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:43:43.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:43:43.905+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:43:43.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:43:43.928+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:43:43.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:43:43.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-16T22:44:14.380+0000] {processor.py:157} INFO - Started process (PID=44313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:44:14.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:44:14.395+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:44:14.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:44:14.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:44:14.465+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:44:14.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:44:14.483+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:44:14.483+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:44:14.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-16T22:44:44.745+0000] {processor.py:157} INFO - Started process (PID=44323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:44:44.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:44:44.749+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:44:44.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:44:44.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:44:44.778+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:44:44.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:44:44.791+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:44:44.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:44:44.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-16T22:45:15.230+0000] {processor.py:157} INFO - Started process (PID=44333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:45:15.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:45:15.235+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:45:15.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:45:15.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:45:15.309+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:45:15.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:45:15.327+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:45:15.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:45:15.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-16T22:45:45.638+0000] {processor.py:157} INFO - Started process (PID=44343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:45:45.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:45:45.643+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:45:45.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:45:45.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:45:45.688+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:45:45.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:45:45.703+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:45:45.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:45:45.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-16T22:46:16.065+0000] {processor.py:157} INFO - Started process (PID=44353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:46:16.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:46:16.068+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:46:16.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:46:16.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:46:16.130+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:46:16.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:46:16.141+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:46:16.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:46:16.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-16T22:46:46.481+0000] {processor.py:157} INFO - Started process (PID=44363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:46:46.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:46:46.487+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:46:46.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:46:46.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:46:46.553+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:46:46.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:46:46.580+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:46:46.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:46:46.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T22:47:16.880+0000] {processor.py:157} INFO - Started process (PID=44373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:47:16.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:47:16.884+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:47:16.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:47:16.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:47:16.920+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:47:16.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:47:16.932+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:47:16.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:47:16.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-16T22:47:47.251+0000] {processor.py:157} INFO - Started process (PID=44383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:47:47.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:47:47.259+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:47:47.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:47:47.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:47:47.305+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:47:47.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:47:47.320+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:47:47.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:47:47.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-16T22:48:17.751+0000] {processor.py:157} INFO - Started process (PID=44393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:48:17.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:48:17.758+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:48:17.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:48:17.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:48:17.852+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:48:17.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:48:17.880+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:48:17.880+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:48:17.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-16T22:48:48.180+0000] {processor.py:157} INFO - Started process (PID=44402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:48:48.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:48:48.188+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:48:48.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:48:48.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:48:48.256+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:48:48.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:48:48.288+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:48:48.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:48:48.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-16T22:49:18.585+0000] {processor.py:157} INFO - Started process (PID=44411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:49:18.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:49:18.592+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:49:18.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:49:18.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:49:18.671+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:49:18.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:49:18.688+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:49:18.688+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:49:18.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-16T22:49:48.995+0000] {processor.py:157} INFO - Started process (PID=44423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:49:48.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:49:49.003+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:49:49.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:49:49.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:49:49.089+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:49:49.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:49:49.123+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:49:49.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:49:49.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-16T22:50:19.431+0000] {processor.py:157} INFO - Started process (PID=44433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:50:19.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:50:19.436+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:50:19.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:50:19.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:50:19.513+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:50:19.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:50:19.535+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:50:19.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:50:19.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-16T22:50:49.893+0000] {processor.py:157} INFO - Started process (PID=44443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:50:49.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:50:49.900+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:50:49.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:50:49.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:50:49.974+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:50:49.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:50:50.006+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:50:50.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:50:50.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-16T22:51:20.317+0000] {processor.py:157} INFO - Started process (PID=44453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:51:20.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:51:20.325+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:51:20.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:51:20.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:51:20.400+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:51:20.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:51:20.416+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:51:20.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:51:20.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-16T22:51:50.792+0000] {processor.py:157} INFO - Started process (PID=44463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:51:50.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:51:50.801+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:51:50.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:51:50.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:51:50.881+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:51:50.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:51:50.898+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:51:50.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:51:50.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-16T22:52:21.249+0000] {processor.py:157} INFO - Started process (PID=44473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:52:21.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:52:21.260+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:52:21.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:52:21.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:52:21.331+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:52:21.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:52:21.360+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:52:21.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:52:21.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-16T22:52:51.590+0000] {processor.py:157} INFO - Started process (PID=44483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:52:51.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:52:51.593+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:52:51.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:52:51.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:52:51.630+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:52:51.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:52:51.639+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:52:51.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:52:51.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-16T22:53:22.069+0000] {processor.py:157} INFO - Started process (PID=44493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:53:22.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:53:22.078+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:53:22.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:53:22.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:53:22.143+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:53:22.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:53:22.161+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:53:22.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:53:22.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-16T22:53:52.469+0000] {processor.py:157} INFO - Started process (PID=44503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:53:52.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:53:52.474+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:53:52.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:53:52.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:53:52.521+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:53:52.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:53:52.535+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:53:52.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:53:52.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-16T22:54:22.906+0000] {processor.py:157} INFO - Started process (PID=44513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:54:22.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:54:22.912+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:54:22.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:54:22.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:54:22.975+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:54:22.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:54:22.989+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:54:22.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:54:22.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-16T22:54:53.296+0000] {processor.py:157} INFO - Started process (PID=44523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:54:53.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:54:53.302+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:54:53.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:54:53.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:54:53.341+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:54:53.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:54:53.353+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:54:53.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:54:53.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-16T22:55:23.809+0000] {processor.py:157} INFO - Started process (PID=44533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:55:23.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:55:23.815+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:55:23.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:55:23.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:55:23.879+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:55:23.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:55:23.919+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:55:23.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:55:23.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-16T22:55:54.222+0000] {processor.py:157} INFO - Started process (PID=44542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:55:54.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:55:54.230+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:55:54.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:55:54.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:55:54.296+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:55:54.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:55:54.312+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:55:54.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:55:54.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-16T22:56:24.678+0000] {processor.py:157} INFO - Started process (PID=44553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:56:24.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:56:24.681+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:56:24.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:56:24.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:56:24.709+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:56:24.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:56:24.720+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:56:24.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:56:24.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-16T22:56:55.253+0000] {processor.py:157} INFO - Started process (PID=44563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:56:55.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:56:55.277+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:56:55.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:56:55.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:56:55.396+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:56:55.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:56:55.434+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:56:55.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:56:55.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.216 seconds
[2024-09-16T22:57:26.016+0000] {processor.py:157} INFO - Started process (PID=44571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:57:26.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:57:26.053+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:57:26.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:57:26.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:57:26.186+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:57:26.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:57:26.214+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:57:26.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:57:26.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.245 seconds
[2024-09-16T22:57:56.675+0000] {processor.py:157} INFO - Started process (PID=44583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:57:56.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:57:56.686+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:57:56.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:57:56.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:57:56.784+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:57:56.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:57:56.812+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:57:56.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:57:56.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-09-16T22:58:27.236+0000] {processor.py:157} INFO - Started process (PID=44593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:58:27.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:58:27.245+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:58:27.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:58:27.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:58:27.339+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:58:27.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:58:27.362+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:58:27.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:58:27.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-09-16T22:58:57.752+0000] {processor.py:157} INFO - Started process (PID=44603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:58:57.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:58:57.793+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:58:57.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:58:57.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:58:58.035+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:58:58.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:58:58.063+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:58:58.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:58:58.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.352 seconds
[2024-09-16T22:59:28.283+0000] {processor.py:157} INFO - Started process (PID=44613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:59:28.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:59:28.311+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:59:28.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:59:28.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:59:28.391+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:59:28.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:59:28.421+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:59:28.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:59:28.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.185 seconds
[2024-09-16T22:59:58.814+0000] {processor.py:157} INFO - Started process (PID=44623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:59:58.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T22:59:58.829+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:59:58.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:59:58.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T22:59:58.969+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:59:58.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T22:59:58.998+0000] {logging_mixin.py:151} INFO - [2024-09-16T22:59:58.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T22:59:59.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.212 seconds
[2024-09-16T23:00:29.175+0000] {processor.py:157} INFO - Started process (PID=44633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:00:29.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:00:29.190+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:00:29.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:00:29.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:00:29.288+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:00:29.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:00:29.306+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:00:29.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:00:29.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-16T23:00:59.805+0000] {processor.py:157} INFO - Started process (PID=44643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:00:59.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:00:59.823+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:00:59.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:00:59.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:00:59.899+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:00:59.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:00:59.919+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:00:59.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:00:59.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-09-16T23:01:30.323+0000] {processor.py:157} INFO - Started process (PID=44653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:01:30.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:01:30.333+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:01:30.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:01:30.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:01:30.443+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:01:30.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:01:30.467+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:01:30.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:01:30.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-09-16T23:02:00.868+0000] {processor.py:157} INFO - Started process (PID=44663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:02:00.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:02:00.875+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:02:00.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:02:00.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:02:00.965+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:02:00.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:02:00.983+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:02:00.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:02:00.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-16T23:02:31.242+0000] {processor.py:157} INFO - Started process (PID=44673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:02:31.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:02:31.250+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:02:31.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:02:31.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:02:31.309+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:02:31.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:02:31.337+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:02:31.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:02:31.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-16T23:03:01.862+0000] {processor.py:157} INFO - Started process (PID=44683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:03:01.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:03:01.876+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:03:01.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:03:01.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:03:02.023+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:03:02.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:03:02.065+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:03:02.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:03:02.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.228 seconds
[2024-09-16T23:03:32.214+0000] {processor.py:157} INFO - Started process (PID=44693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:03:32.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:03:32.225+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:03:32.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:03:32.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:03:32.304+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:03:32.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:03:32.324+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:03:32.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:03:32.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-16T23:04:02.577+0000] {processor.py:157} INFO - Started process (PID=44703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:04:02.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:04:02.586+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:04:02.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:04:02.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:04:02.649+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:04:02.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:04:02.675+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:04:02.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:04:02.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-16T23:04:32.890+0000] {processor.py:157} INFO - Started process (PID=44713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:04:32.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:04:32.899+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:04:32.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:04:32.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:04:32.956+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:04:32.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:04:32.983+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:04:32.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:04:32.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-16T23:05:03.452+0000] {processor.py:157} INFO - Started process (PID=44723) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:05:03.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:05:03.460+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:05:03.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:05:03.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:05:03.555+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:05:03.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:05:03.575+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:05:03.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:05:03.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-16T23:05:33.893+0000] {processor.py:157} INFO - Started process (PID=44733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:05:33.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:05:33.903+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:05:33.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:05:33.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:05:33.971+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:05:33.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:05:34.000+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:05:34.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:05:34.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-16T23:06:04.300+0000] {processor.py:157} INFO - Started process (PID=44743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:06:04.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:06:04.307+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:06:04.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:06:04.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:06:04.371+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:06:04.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:06:04.388+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:06:04.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:06:04.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-16T23:06:34.719+0000] {processor.py:157} INFO - Started process (PID=44753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:06:34.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:06:34.729+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:06:34.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:06:34.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:06:34.809+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:06:34.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:06:34.830+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:06:34.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:06:34.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-16T23:07:05.206+0000] {processor.py:157} INFO - Started process (PID=44763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:07:05.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:07:05.217+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:07:05.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:07:05.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:07:05.288+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:07:05.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:07:05.307+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:07:05.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:07:05.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-16T23:07:35.616+0000] {processor.py:157} INFO - Started process (PID=44773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:07:35.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:07:35.624+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:07:35.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:07:35.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:07:35.682+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:07:35.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:07:35.699+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:07:35.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:07:35.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-16T23:08:06.031+0000] {processor.py:157} INFO - Started process (PID=44783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:08:06.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:08:06.054+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:08:06.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:08:06.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:08:06.114+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:08:06.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:08:06.135+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:08:06.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:08:06.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-16T23:08:36.377+0000] {processor.py:157} INFO - Started process (PID=44793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:08:36.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:08:36.383+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:08:36.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:08:36.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:08:36.448+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:08:36.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:08:36.472+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:08:36.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:08:36.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-16T23:09:06.810+0000] {processor.py:157} INFO - Started process (PID=44803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:09:06.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:09:06.817+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:09:06.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:09:06.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:09:06.891+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:09:06.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:09:06.923+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:09:06.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:09:06.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-09-16T23:09:37.331+0000] {processor.py:157} INFO - Started process (PID=44813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:09:37.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:09:37.343+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:09:37.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:09:37.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:09:37.451+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:09:37.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:09:37.492+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:09:37.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:09:37.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.207 seconds
[2024-09-16T23:10:07.722+0000] {processor.py:157} INFO - Started process (PID=44823) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:10:07.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:10:07.732+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:10:07.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:10:07.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:10:07.803+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:10:07.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:10:07.821+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:10:07.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:10:07.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-16T23:10:38.114+0000] {processor.py:157} INFO - Started process (PID=44833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:10:38.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:10:38.119+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:10:38.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:10:38.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:10:38.174+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:10:38.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:10:38.190+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:10:38.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:10:38.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-16T23:11:08.581+0000] {processor.py:157} INFO - Started process (PID=44842) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:11:08.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:11:08.600+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:11:08.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:11:08.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:11:08.693+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:11:08.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:11:08.731+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:11:08.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:11:08.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.191 seconds
[2024-09-16T23:11:38.954+0000] {processor.py:157} INFO - Started process (PID=44853) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:11:38.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:11:38.964+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:11:38.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:11:39.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:11:39.068+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:11:39.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:11:39.086+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:11:39.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:11:39.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-09-16T23:12:09.480+0000] {processor.py:157} INFO - Started process (PID=44863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:12:09.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:12:09.493+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:12:09.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:12:09.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:12:09.564+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:12:09.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:12:09.590+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:12:09.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:12:09.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-16T23:12:40.091+0000] {processor.py:157} INFO - Started process (PID=44873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:12:40.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:12:40.096+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:12:40.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:12:40.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:12:40.184+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:12:40.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:12:40.208+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:12:40.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:12:40.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-16T23:13:10.531+0000] {processor.py:157} INFO - Started process (PID=44883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:13:10.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:13:10.537+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:13:10.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:13:10.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:13:10.605+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:13:10.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:13:10.622+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:13:10.622+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:13:10.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-16T23:13:40.949+0000] {processor.py:157} INFO - Started process (PID=44893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:13:40.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:13:40.961+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:13:40.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:13:40.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:13:41.037+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:13:41.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:13:41.062+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:13:41.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:13:41.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-16T23:14:11.345+0000] {processor.py:157} INFO - Started process (PID=44903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:14:11.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:14:11.366+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:14:11.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:14:11.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:14:11.458+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:14:11.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:14:11.484+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:14:11.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:14:11.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-09-16T23:14:41.802+0000] {processor.py:157} INFO - Started process (PID=44913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:14:41.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:14:41.812+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:14:41.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:14:41.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:14:41.933+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:14:41.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:14:41.956+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:14:41.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:14:41.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-09-16T23:15:12.370+0000] {processor.py:157} INFO - Started process (PID=44923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:15:12.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:15:12.384+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:15:12.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:15:12.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:15:12.505+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:15:12.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:15:12.525+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:15:12.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:15:12.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-09-16T23:15:42.861+0000] {processor.py:157} INFO - Started process (PID=44933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:15:42.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:15:42.868+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:15:42.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:15:42.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:15:42.929+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:15:42.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:15:42.954+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:15:42.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:15:42.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-16T23:16:13.304+0000] {processor.py:157} INFO - Started process (PID=44943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:16:13.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:16:13.316+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:16:13.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:16:13.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:16:13.407+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:16:13.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:16:13.442+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:16:13.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:16:13.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-09-16T23:16:43.695+0000] {processor.py:157} INFO - Started process (PID=44952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:16:43.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:16:43.720+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:16:43.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:16:43.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:16:43.830+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:16:43.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:16:43.876+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:16:43.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:16:43.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.218 seconds
[2024-09-16T23:17:14.239+0000] {processor.py:157} INFO - Started process (PID=44963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:17:14.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:17:14.251+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:17:14.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:17:14.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:17:14.367+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:17:14.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:17:14.394+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:17:14.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:17:14.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.187 seconds
[2024-09-16T23:17:44.914+0000] {processor.py:157} INFO - Started process (PID=44973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:17:44.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:17:44.935+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:17:44.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:17:44.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:17:45.028+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:17:45.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:17:45.046+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:17:45.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:17:45.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-09-16T23:18:15.546+0000] {processor.py:157} INFO - Started process (PID=44983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:18:15.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:18:15.552+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:18:15.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:18:15.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:18:15.632+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:18:15.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:18:15.653+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:18:15.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:18:15.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-16T23:18:45.972+0000] {processor.py:157} INFO - Started process (PID=44993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:18:45.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:18:46.008+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:18:46.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:18:46.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:18:46.107+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:18:46.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:18:46.160+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:18:46.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:18:46.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.229 seconds
[2024-09-16T23:19:16.383+0000] {processor.py:157} INFO - Started process (PID=45003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:19:16.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:19:16.393+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:19:16.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:19:16.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:19:16.486+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:19:16.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:19:16.504+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:19:16.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:19:16.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-16T23:19:46.824+0000] {processor.py:157} INFO - Started process (PID=45013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:19:46.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:19:46.837+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:19:46.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:19:46.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:19:46.912+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:19:46.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:19:46.930+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:19:46.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:19:46.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-16T23:20:17.200+0000] {processor.py:157} INFO - Started process (PID=45023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:20:17.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:20:17.219+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:20:17.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:20:17.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:20:17.310+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:20:17.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:20:17.330+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:20:17.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:20:17.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-16T23:20:47.628+0000] {processor.py:157} INFO - Started process (PID=45033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:20:47.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:20:47.637+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:20:47.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:20:47.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:20:47.735+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:20:47.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:20:47.754+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:20:47.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:20:47.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-16T23:21:17.981+0000] {processor.py:157} INFO - Started process (PID=45043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:21:17.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:21:17.988+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:21:17.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:21:18.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:21:18.065+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:21:18.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:21:18.087+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:21:18.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:21:18.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-16T23:21:48.513+0000] {processor.py:157} INFO - Started process (PID=45052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:21:48.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:21:48.521+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:21:48.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:21:48.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:21:48.658+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:21:48.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:21:48.680+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:21:48.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:21:48.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.191 seconds
[2024-09-16T23:22:18.872+0000] {processor.py:157} INFO - Started process (PID=45063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:22:18.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:22:18.890+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:22:18.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:22:18.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:22:18.975+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:22:18.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:22:18.995+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:22:18.995+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:22:19.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-16T23:22:49.367+0000] {processor.py:157} INFO - Started process (PID=45072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:22:49.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:22:49.378+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:22:49.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:22:49.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:22:49.447+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:22:49.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:22:49.480+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:22:49.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:22:49.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-16T23:23:19.733+0000] {processor.py:157} INFO - Started process (PID=45083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:23:19.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:23:19.745+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:23:19.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:23:19.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:23:19.821+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:23:19.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:23:19.845+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:23:19.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:23:19.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-16T23:23:50.221+0000] {processor.py:157} INFO - Started process (PID=45093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:23:50.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:23:50.227+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:23:50.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:23:50.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:23:50.312+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:23:50.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:23:50.348+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:23:50.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:23:50.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-16T23:24:20.640+0000] {processor.py:157} INFO - Started process (PID=45103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:24:20.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:24:20.651+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:24:20.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:24:20.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:24:20.734+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:24:20.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:24:20.753+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:24:20.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:24:20.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-16T23:24:50.985+0000] {processor.py:157} INFO - Started process (PID=45113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:24:50.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:24:50.995+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:24:50.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:24:51.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:24:51.102+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:24:51.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:24:51.133+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:24:51.133+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:24:51.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-09-16T23:25:21.383+0000] {processor.py:157} INFO - Started process (PID=45123) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:25:21.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:25:21.391+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:25:21.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:25:21.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:25:21.491+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:25:21.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:25:21.514+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:25:21.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:25:21.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-09-16T23:25:51.985+0000] {processor.py:157} INFO - Started process (PID=45133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:25:51.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:25:51.992+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:25:51.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:25:52.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:25:52.062+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:25:52.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:25:52.081+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:25:52.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:25:52.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-16T23:26:22.424+0000] {processor.py:157} INFO - Started process (PID=45143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:26:22.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:26:22.448+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:26:22.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:26:22.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:26:22.542+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:26:22.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:26:22.578+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:26:22.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:26:22.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.178 seconds
[2024-09-16T23:26:52.794+0000] {processor.py:157} INFO - Started process (PID=45153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:26:52.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:26:52.810+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:26:52.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:26:52.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:26:52.914+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:26:52.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:26:52.939+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:26:52.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:26:52.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-09-16T23:27:23.261+0000] {processor.py:157} INFO - Started process (PID=45163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:27:23.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:27:23.270+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:27:23.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:27:23.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:27:23.361+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:27:23.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:27:23.388+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:27:23.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:27:23.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-16T23:27:53.895+0000] {processor.py:157} INFO - Started process (PID=45173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:27:53.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:27:53.912+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:27:53.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:27:53.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:27:53.996+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:27:53.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:27:54.017+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:27:54.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:27:54.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-09-16T23:28:24.980+0000] {processor.py:157} INFO - Started process (PID=45183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:28:24.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:28:25.006+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:28:25.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:28:25.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:28:25.825+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:28:25.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:28:25.895+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:28:25.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:28:25.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.951 seconds
[2024-09-16T23:28:56.345+0000] {processor.py:157} INFO - Started process (PID=45193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:28:56.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:28:56.354+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:28:56.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:28:56.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:28:56.411+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:28:56.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:28:56.436+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:28:56.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:28:56.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-16T23:29:26.705+0000] {processor.py:157} INFO - Started process (PID=45203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:29:26.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:29:26.730+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:29:26.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:29:26.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:29:26.816+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:29:26.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:29:26.871+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:29:26.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:29:26.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.194 seconds
[2024-09-16T23:29:57.231+0000] {processor.py:157} INFO - Started process (PID=45213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:29:57.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:29:57.247+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:29:57.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:29:57.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:29:57.307+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:29:57.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:29:57.323+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:29:57.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:29:57.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-16T23:30:27.719+0000] {processor.py:157} INFO - Started process (PID=45223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:30:27.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:30:27.749+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:30:27.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:30:27.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:30:27.849+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:30:27.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:30:27.868+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:30:27.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:30:27.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-09-16T23:30:58.156+0000] {processor.py:157} INFO - Started process (PID=45233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:30:58.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:30:58.171+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:30:58.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:30:58.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:30:58.298+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:30:58.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:30:58.324+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:30:58.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:30:58.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.198 seconds
[2024-09-16T23:31:28.556+0000] {processor.py:157} INFO - Started process (PID=45243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:31:28.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:31:28.587+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:31:28.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:31:28.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:31:28.673+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:31:28.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:31:28.701+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:31:28.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:31:28.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-09-16T23:31:59.102+0000] {processor.py:157} INFO - Started process (PID=45253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:31:59.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:31:59.118+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:31:59.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:31:59.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:31:59.204+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:31:59.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:31:59.223+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:31:59.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:31:59.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-16T23:32:29.750+0000] {processor.py:157} INFO - Started process (PID=45263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:32:29.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:32:29.760+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:32:29.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:32:29.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:32:29.877+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:32:29.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:32:29.897+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:32:29.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:32:29.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-09-16T23:33:00.214+0000] {processor.py:157} INFO - Started process (PID=45272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:33:00.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:33:00.222+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:33:00.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:33:00.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:33:00.311+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:33:00.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:33:00.332+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:33:00.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:33:00.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-09-16T23:33:30.701+0000] {processor.py:157} INFO - Started process (PID=45283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:33:30.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:33:30.711+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:33:30.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:33:30.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:33:30.795+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:33:30.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:33:30.814+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:33:30.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:33:30.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-16T23:34:01.037+0000] {processor.py:157} INFO - Started process (PID=45293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:34:01.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:34:01.043+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:34:01.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:34:01.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:34:01.118+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:34:01.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:34:01.134+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:34:01.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:34:01.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-16T23:34:31.509+0000] {processor.py:157} INFO - Started process (PID=45303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:34:31.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:34:31.517+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:34:31.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:34:31.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:34:31.594+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:34:31.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:34:31.619+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:34:31.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:34:31.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-16T23:35:01.956+0000] {processor.py:157} INFO - Started process (PID=45313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:35:01.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:35:01.964+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:35:01.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:35:02.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:35:02.106+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:35:02.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:35:02.124+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:35:02.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:35:02.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.185 seconds
[2024-09-16T23:35:32.557+0000] {processor.py:157} INFO - Started process (PID=45323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:35:32.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:35:32.572+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:35:32.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:35:32.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:35:32.652+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:35:32.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:35:32.668+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:35:32.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:35:32.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-16T23:36:03.092+0000] {processor.py:157} INFO - Started process (PID=45333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:36:03.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:36:03.099+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:36:03.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:36:03.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:36:03.209+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:36:03.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:36:03.232+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:36:03.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:36:03.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-09-16T23:36:33.560+0000] {processor.py:157} INFO - Started process (PID=45343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:36:33.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:36:33.572+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:36:33.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:36:33.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:36:33.671+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:36:33.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:36:33.697+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:36:33.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:36:33.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-09-16T23:37:04.022+0000] {processor.py:157} INFO - Started process (PID=45353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:37:04.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:37:04.029+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:37:04.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:37:04.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:37:04.111+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:37:04.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:37:04.125+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:37:04.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:37:04.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-16T23:37:34.590+0000] {processor.py:157} INFO - Started process (PID=45363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:37:34.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:37:34.598+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:37:34.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:37:34.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:37:34.700+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:37:34.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:37:34.724+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:37:34.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:37:34.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-09-16T23:38:05.006+0000] {processor.py:157} INFO - Started process (PID=45373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:38:05.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:38:05.031+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:38:05.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:38:05.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:38:05.220+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:38:05.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:38:05.257+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:38:05.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:38:05.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.293 seconds
[2024-09-16T23:38:35.550+0000] {processor.py:157} INFO - Started process (PID=45383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:38:35.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:38:35.562+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:38:35.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:38:35.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:38:35.675+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:38:35.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:38:35.698+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:38:35.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:38:35.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.180 seconds
[2024-09-16T23:39:06.257+0000] {processor.py:157} INFO - Started process (PID=45393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:39:06.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:39:06.265+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:39:06.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:39:06.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:39:06.346+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:39:06.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:39:06.373+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:39:06.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:39:06.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-16T23:39:36.738+0000] {processor.py:157} INFO - Started process (PID=45403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:39:36.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:39:36.748+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:39:36.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:39:36.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:39:36.832+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:39:36.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:39:36.853+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:39:36.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:39:36.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-16T23:40:07.247+0000] {processor.py:157} INFO - Started process (PID=45413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:40:07.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:40:07.280+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:40:07.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:40:07.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:40:07.385+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:40:07.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:40:07.435+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:40:07.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:40:07.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.221 seconds
[2024-09-16T23:40:37.686+0000] {processor.py:157} INFO - Started process (PID=45423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:40:37.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:40:37.702+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:40:37.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:40:37.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:40:37.785+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:40:37.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:40:37.806+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:40:37.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:40:37.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-16T23:41:08.158+0000] {processor.py:157} INFO - Started process (PID=45433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:41:08.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:41:08.169+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:41:08.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:41:08.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:41:08.332+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:41:08.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:41:08.351+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:41:08.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:41:08.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.236 seconds
[2024-09-16T23:41:38.920+0000] {processor.py:157} INFO - Started process (PID=45443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:41:38.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:41:38.928+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:41:38.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:41:38.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:41:38.995+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:41:38.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:41:39.021+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:41:39.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:41:39.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-16T23:42:09.319+0000] {processor.py:157} INFO - Started process (PID=45453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:42:09.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:42:09.326+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:42:09.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:42:09.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:42:09.391+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:42:09.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:42:09.417+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:42:09.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:42:09.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T23:42:39.700+0000] {processor.py:157} INFO - Started process (PID=45462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:42:39.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:42:39.710+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:42:39.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:42:39.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:42:39.797+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:42:39.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:42:39.815+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:42:39.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:42:39.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-16T23:43:10.136+0000] {processor.py:157} INFO - Started process (PID=45473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:43:10.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:43:10.146+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:43:10.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:43:10.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:43:10.230+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:43:10.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:43:10.249+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:43:10.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:43:10.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-16T23:43:40.580+0000] {processor.py:157} INFO - Started process (PID=45483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:43:40.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:43:40.603+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:43:40.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:43:40.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:43:40.730+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:43:40.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:43:40.755+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:43:40.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:43:40.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.231 seconds
[2024-09-16T23:44:11.023+0000] {processor.py:157} INFO - Started process (PID=45492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:44:11.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:44:11.029+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:44:11.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:44:11.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:44:11.085+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:44:11.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:44:11.103+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:44:11.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:44:11.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-16T23:44:41.462+0000] {processor.py:157} INFO - Started process (PID=45503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:44:41.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:44:41.474+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:44:41.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:44:41.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:44:41.577+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:44:41.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:44:41.611+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:44:41.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:44:41.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-09-16T23:45:11.983+0000] {processor.py:157} INFO - Started process (PID=45513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:45:11.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:45:11.991+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:45:11.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:45:12.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:45:12.080+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:45:12.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:45:12.099+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:45:12.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:45:12.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-16T23:45:42.304+0000] {processor.py:157} INFO - Started process (PID=45523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:45:42.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:45:42.324+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:45:42.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:45:42.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:45:42.377+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:45:42.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:45:42.396+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:45:42.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:45:42.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-16T23:46:12.773+0000] {processor.py:157} INFO - Started process (PID=45533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:46:12.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:46:12.788+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:46:12.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:46:12.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:46:12.868+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:46:12.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:46:12.896+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:46:12.896+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:46:12.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-16T23:46:43.198+0000] {processor.py:157} INFO - Started process (PID=45543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:46:43.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:46:43.223+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:46:43.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:46:43.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:46:43.346+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:46:43.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:46:43.372+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:46:43.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:46:43.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.193 seconds
[2024-09-16T23:47:13.603+0000] {processor.py:157} INFO - Started process (PID=45553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:47:13.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:47:13.607+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:47:13.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:47:13.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:47:13.664+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:47:13.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:47:13.689+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:47:13.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:47:13.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-16T23:47:44.095+0000] {processor.py:157} INFO - Started process (PID=45562) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:47:44.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:47:44.111+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:47:44.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:47:44.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:47:44.176+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:47:44.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:47:44.192+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:47:44.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:47:44.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-16T23:48:14.551+0000] {processor.py:157} INFO - Started process (PID=45573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:48:14.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:48:14.567+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:48:14.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:48:14.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:48:14.672+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:48:14.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:48:14.695+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:48:14.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:48:14.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-09-16T23:48:44.933+0000] {processor.py:157} INFO - Started process (PID=45583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:48:44.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:48:44.947+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:48:44.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:48:44.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:48:45.047+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:48:45.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:48:45.066+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:48:45.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:48:45.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.177 seconds
[2024-09-16T23:49:15.358+0000] {processor.py:157} INFO - Started process (PID=45593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:49:15.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:49:15.365+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:49:15.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:49:15.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:49:15.464+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:49:15.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:49:15.483+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:49:15.483+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:49:15.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-09-16T23:49:45.775+0000] {processor.py:157} INFO - Started process (PID=45603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:49:45.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:49:45.789+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:49:45.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:49:45.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:49:45.858+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:49:45.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:49:45.882+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:49:45.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:49:45.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-16T23:50:16.125+0000] {processor.py:157} INFO - Started process (PID=45613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:50:16.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:50:16.142+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:50:16.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:50:16.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:50:16.236+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:50:16.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:50:16.254+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:50:16.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:50:16.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-16T23:50:46.554+0000] {processor.py:157} INFO - Started process (PID=45623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:50:46.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:50:46.565+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:50:46.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:50:46.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:50:46.640+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:50:46.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:50:46.657+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:50:46.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:50:46.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-16T23:51:16.935+0000] {processor.py:157} INFO - Started process (PID=45633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:51:16.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:51:16.942+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:51:16.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:51:16.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:51:17.015+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:51:17.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:51:17.033+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:51:17.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:51:17.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-16T23:51:47.361+0000] {processor.py:157} INFO - Started process (PID=45643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:51:47.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:51:47.377+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:51:47.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:51:47.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:51:47.449+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:51:47.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:51:47.468+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:51:47.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:51:47.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-16T23:52:17.771+0000] {processor.py:157} INFO - Started process (PID=45653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:52:17.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:52:17.784+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:52:17.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:52:17.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:52:17.843+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:52:17.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:52:17.860+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:52:17.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:52:17.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-16T23:52:48.149+0000] {processor.py:157} INFO - Started process (PID=45663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:52:48.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:52:48.159+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:52:48.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:52:48.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:52:48.219+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:52:48.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:52:48.237+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:52:48.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:52:48.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-16T23:53:18.497+0000] {processor.py:157} INFO - Started process (PID=45673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:53:18.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:53:18.503+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:53:18.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:53:18.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:53:18.589+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:53:18.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:53:18.613+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:53:18.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:53:18.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-16T23:53:48.916+0000] {processor.py:157} INFO - Started process (PID=45683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:53:48.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:53:48.942+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:53:48.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:53:48.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:53:49.016+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:53:49.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:53:49.036+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:53:49.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:53:49.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-16T23:54:19.422+0000] {processor.py:157} INFO - Started process (PID=45693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:54:19.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:54:19.442+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:54:19.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:54:19.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:54:19.505+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:54:19.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:54:19.524+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:54:19.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:54:19.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-16T23:54:49.807+0000] {processor.py:157} INFO - Started process (PID=45703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:54:49.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:54:49.825+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:54:49.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:54:49.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:54:49.900+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:54:49.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:54:49.919+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:54:49.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:54:49.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-16T23:55:20.123+0000] {processor.py:157} INFO - Started process (PID=45713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:55:20.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:55:20.143+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:55:20.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:55:20.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:55:20.211+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:55:20.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:55:20.237+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:55:20.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:55:20.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-16T23:55:50.759+0000] {processor.py:157} INFO - Started process (PID=45722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:55:50.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:55:50.775+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:55:50.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:55:50.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:55:50.840+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:55:50.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:55:50.867+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:55:50.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:55:50.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-16T23:56:21.087+0000] {processor.py:157} INFO - Started process (PID=45733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:56:21.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:56:21.093+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:56:21.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:56:21.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:56:21.143+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:56:21.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:56:21.159+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:56:21.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:56:21.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-16T23:56:51.545+0000] {processor.py:157} INFO - Started process (PID=45743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:56:51.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:56:51.548+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:56:51.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:56:51.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:56:51.574+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:56:51.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:56:51.584+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:56:51.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:56:51.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-16T23:57:21.941+0000] {processor.py:157} INFO - Started process (PID=45751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:57:21.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:57:21.949+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:57:21.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:57:21.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:57:22.009+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:57:22.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:57:22.025+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:57:22.025+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:57:22.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-16T23:57:52.245+0000] {processor.py:157} INFO - Started process (PID=45763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:57:52.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:57:52.247+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:57:52.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:57:52.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:57:52.274+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:57:52.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:57:52.284+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:57:52.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:57:52.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-16T23:58:22.671+0000] {processor.py:157} INFO - Started process (PID=45773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:58:22.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:58:22.679+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:58:22.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:58:22.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:58:22.742+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:58:22.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:58:22.762+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:58:22.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:58:22.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-16T23:58:53.206+0000] {processor.py:157} INFO - Started process (PID=45783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:58:53.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:58:53.219+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:58:53.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:58:53.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:58:53.289+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:58:53.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:58:53.306+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:58:53.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:58:53.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-16T23:59:23.532+0000] {processor.py:157} INFO - Started process (PID=45793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:59:23.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:59:23.542+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:59:23.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:59:23.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:59:23.613+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:59:23.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:59:23.637+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:59:23.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:59:23.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-16T23:59:53.891+0000] {processor.py:157} INFO - Started process (PID=45803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:59:53.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-16T23:59:53.896+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:59:53.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:59:53.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-16T23:59:53.931+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:59:53.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-16T23:59:53.946+0000] {logging_mixin.py:151} INFO - [2024-09-16T23:59:53.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-16T23:59:53.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
